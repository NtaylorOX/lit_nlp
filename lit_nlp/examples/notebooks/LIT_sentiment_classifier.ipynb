{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2c6PyqQaNiA"
      },
      "source": [
        "# Using the Language Interpretability Tool in Notebooks\n",
        "\n",
        "This notebook shows use of the [Language Interpretability Tool](https://pair-code.github.io/lit) on a binary classifier for labelling statement sentiment (0 for negative, 1 for positive).\n",
        "\n",
        "The LitWidget object constructor takes a dict mapping model names to model objects, and a dict mapping dataset names to dataset objects. Those will be the datasets and models displayed in LIT. It also optionally takes in a `height` parameter for how tall to render the LIT UI in pixels (it defaults to 1000 pixels). Running the constructor will cause the LIT server to be started in the background, loading the models and datasets and enabling the UI to be served.\n",
        "\n",
        "Render the LIT UI in an output cell by calling the `render` method on the LitWidget object. The LIT UI can be rendered multiple times in separate cells if desired. The widget also contains a `stop` method to shut down the LIT server.\n",
        "\n",
        "Copyright 2020 Google LLC.\n",
        "SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukXamAB_FBM8"
      },
      "outputs": [],
      "source": [
        "# Install LIT and transformers packages. The transformers package is needed by the model and dataset we are using.\n",
        "# Replace tensorflow-datasets with the nightly package to get up-to-date dataset paths.\n",
        "# !pip uninstall -y tensorflow-datasets\n",
        "# !pip install lit_nlp tfds-nightly transformers==4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30l9ZyTjxJjf"
      },
      "outputs": [],
      "source": [
        "# # Fetch the trained model weights\n",
        "# !wget https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\n",
        "# !tar -xvf sst2_tiny.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AWhbAZg57RpB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-12 14:18:03.320585: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n",
            "2022-08-12 14:18:03.766462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-08-12 14:18:04.739768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10415 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1\n",
            "2022-08-12 14:18:04.741169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10415 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "Can't load config for './'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './' is the correct path to a directory containing a config.json file",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/transformers/configuration_utils.py:601\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m    602\u001b[0m         config_file,\n\u001b[1;32m    603\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    604\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    605\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    606\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    607\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    608\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    609\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    612\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/transformers/utils/hub.py:299\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melif\u001b[39;00m urlparse(url_or_filename)\u001b[39m.\u001b[39mscheme \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    298\u001b[0m     \u001b[39m# File, but it doesn't exist.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m{\u001b[39;00murl_or_filename\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[39m# Something unknown\u001b[39;00m\n",
            "\u001b[0;31mOSError\u001b[0m: file ./config.json not found",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m/home/niallt/lit_nlp/lit_nlp/examples/notebooks/LIT_sentiment_classifier.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.152.16/home/niallt/lit_nlp/lit_nlp/examples/notebooks/LIT_sentiment_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m6,7\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.152.16/home/niallt/lit_nlp/lit_nlp/examples/notebooks/LIT_sentiment_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m datasets \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39msst_dev\u001b[39m\u001b[39m'\u001b[39m: glue\u001b[39m.\u001b[39mSST2Data(\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m)}\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B129.67.152.16/home/niallt/lit_nlp/lit_nlp/examples/notebooks/LIT_sentiment_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m models \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39msst_tiny\u001b[39m\u001b[39m'\u001b[39m: glue_models\u001b[39m.\u001b[39;49mSST2Model(\u001b[39m'\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m'\u001b[39;49m)}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B129.67.152.16/home/niallt/lit_nlp/lit_nlp/examples/notebooks/LIT_sentiment_classifier.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m widget \u001b[39m=\u001b[39m notebook\u001b[39m.\u001b[39mLitWidget(models, datasets, height\u001b[39m=\u001b[39m\u001b[39m800\u001b[39m)\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/lit_nlp/examples/models/glue_models.py:500\u001b[0m, in \u001b[0;36mSST2Model.__init__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m--> 500\u001b[0m   \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    501\u001b[0m       \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    502\u001b[0m       text_a_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msentence\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    503\u001b[0m       text_b_name\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    504\u001b[0m       labels\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    505\u001b[0m       null_label_idx\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m    506\u001b[0m       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/lit_nlp/examples/models/glue_models.py:61\u001b[0m, in \u001b[0;36mGlueModel.__init__\u001b[0;34m(self, model_name_or_path, **config_kw)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     58\u001b[0m              model_name_or_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_kw):\n\u001b[1;32m     60\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m GlueModelConfig(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_kw)\n\u001b[0;32m---> 61\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_model(model_name_or_path)\n\u001b[1;32m     62\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/lit_nlp/examples/models/glue_models.py:66\u001b[0m, in \u001b[0;36mGlueModel._load_model\u001b[0;34m(self, model_name_or_path)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_model\u001b[39m(\u001b[39mself\u001b[39m, model_name_or_path):\n\u001b[1;32m     65\u001b[0m   \u001b[39m\"\"\"Load model. Can be overridden for testing.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39;49mAutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     67\u001b[0m       model_name_or_path)\n\u001b[1;32m     68\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(\n\u001b[1;32m     69\u001b[0m       \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer)))\n\u001b[1;32m     70\u001b[0m   model_config \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mAutoConfig\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     71\u001b[0m       model_name_or_path,\n\u001b[1;32m     72\u001b[0m       num_labels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_regression \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlabels),\n\u001b[1;32m     73\u001b[0m       return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,  \u001b[39m# default for training; overridden for predict\u001b[39;00m\n\u001b[1;32m     74\u001b[0m   )\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:535\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mif\u001b[39;00m config_tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    534\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 535\u001b[0m         config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    536\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    537\u001b[0m         )\n\u001b[1;32m    538\u001b[0m     config_tokenizer_class \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mtokenizer_class\n\u001b[1;32m    539\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoTokenizer\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:705\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    704\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 705\u001b[0m config_dict, _ \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    707\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/transformers/configuration_utils.py:553\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    552\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    555\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
            "File \u001b[0;32m~/venvs/39nlp/lib/python3.9/site-packages/transformers/configuration_utils.py:641\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    635\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this model, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    636\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m the cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m containing a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    638\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m library in offline mode at \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m     )\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[0;32m--> 641\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load config for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    645\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    648\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     \u001b[39m# Load config dict\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     config_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load config for './'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './' is the correct path to a directory containing a config.json file"
          ]
        }
      ],
      "source": [
        "# Create the LIT widget with the model and dataset to analyze.\n",
        "from lit_nlp import notebook\n",
        "from lit_nlp.examples.datasets import glue\n",
        "from lit_nlp.examples.models import glue_models\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='6,7'\n",
        "\n",
        "datasets = {'sst_dev': glue.SST2Data('validation')}\n",
        "models = {'sst_tiny': glue_models.SST2Model('./')}\n",
        "\n",
        "widget = notebook.LitWidget(models, datasets, height=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "lit_nlp.examples.models.glue_models.SST2Model"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "glue_models.SST2Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GSfs1waBdLd"
      },
      "outputs": [],
      "source": [
        "# Render the widget\n",
        "widget.render()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LIT in Notebooks",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('39nlp': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d44b152dbbde612076d8602bde2edf912cdc31b3ee3f21712bf40e7ec5a8c74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
