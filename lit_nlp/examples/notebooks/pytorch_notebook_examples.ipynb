{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lint as: python3\n",
    "r\"\"\"Code example for a custom model, using PyTorch.\n",
    "\n",
    "This demo shows how to use a custom model with LIT, in just a few lines of code.\n",
    "We'll use a transformers model, with a minimal amount of code to implement the\n",
    "LIT API. Compared to models/glue_models.py, this has fewer features, but the\n",
    "code is more readable.\n",
    "\n",
    "This demo is equivalent in functionality to simple_tf2_demo.py, but uses PyTorch\n",
    "instead of TensorFlow 2. The models behave identically as far as LIT is\n",
    "concerned, and the implementation is quite similar - to see changes, run:\n",
    "  git diff --no-index simple_tf2_demo.py simple_pytorch_demo.py\n",
    "\n",
    "The transformers library can load weights from either,\n",
    "so you can use any saved model compatible with the underlying model class\n",
    "(AutoModelForSequenceClassification). To train something for this demo, you can:\n",
    "- Use quickstart_sst_demo.py, and set --model_path to somewhere durable\n",
    "- Or: Use tools/glue_trainer.py\n",
    "- Or: Use any fine-tuning code that works with transformers, such as\n",
    "https://github.com/huggingface/transformers#quick-tour-of-the-fine-tuningusage-scripts\n",
    "\n",
    "To run locally:\n",
    "  python -m lit_nlp.examples.simple_pytorch_demo \\\n",
    "      --port=5432 --model_path=/path/to/saved/model\n",
    "\n",
    "Then navigate to localhost:5432 to access the demo UI.\n",
    "\n",
    "NOTE: this demo still uses TensorFlow Datasets (which depends on TensorFlow) to\n",
    "load the data. However, the output of glue.SST2Data is just NumPy arrays and\n",
    "plain Python data, and you can easily replace this with a different library or\n",
    "directly loading from CSV.\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "from lit_nlp import dev_server\n",
    "from lit_nlp import server_flags\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.api import types as lit_types\n",
    "# Use the regular GLUE data loaders, because these are very simple already.\n",
    "from lit_nlp.examples.datasets import glue\n",
    "from lit_nlp.lib import utils\n",
    "from lit_nlp import notebook\n",
    "\n",
    "from lit_nlp.examples.models import glue_models\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: additional flags defined in server_flags.py\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "FLAGS.set_default(\"development_demo\", True)\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"model_path\",\n",
    "    \"https://storage.googleapis.com/what-if-tool-resources/lit-models/sst2_tiny.tar.gz\",\n",
    "    \"Path to trained model, in standard transformers format, e.g. as \"\n",
    "    \"saved by model.save_pretrained() and tokenizer.save_pretrained()\")\n",
    "\n",
    "\n",
    "def _from_pretrained(cls, *args, **kw):\n",
    "  \"\"\"Load a transformers model in PyTorch, with fallback to TF2/Keras weights.\"\"\"\n",
    "  try:\n",
    "    return cls.from_pretrained(*args, **kw)\n",
    "  except OSError as e:\n",
    "    logging.warning(\"Caught OSError loading model: %s\", e)\n",
    "    logging.warning(\n",
    "        \"Re-trying to convert from TensorFlow checkpoint (from_tf=True)\")\n",
    "    return cls.from_pretrained(*args, from_tf=True, **kw)\n",
    "\n",
    "\n",
    "class SimpleSentimentModel(lit_model.Model):\n",
    "  \"\"\"Simple sentiment analysis model.\"\"\"\n",
    "\n",
    "  LABELS = [\"0\", \"1\"]  # negative, positive\n",
    "\n",
    "  def __init__(self, model_name_or_path, cache_dir = None):\n",
    "    self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path, cache_dir = cache_dir)\n",
    "    model_config = transformers.AutoConfig.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=2,\n",
    "        output_hidden_states=True,\n",
    "        output_attentions=True,\n",
    "        cache_dir = cache_dir\n",
    "    )\n",
    "    # This is a just a regular PyTorch model.\n",
    "    self.model = _from_pretrained(\n",
    "        transformers.AutoModelForSequenceClassification,\n",
    "        model_name_or_path,\n",
    "        config=model_config,\n",
    "        cache_dir = cache_dir)\n",
    "    self.model.eval()\n",
    "\n",
    "  ##\n",
    "  # LIT API implementation\n",
    "  def max_minibatch_size(self):\n",
    "    # This tells lit_model.Model.predict() how to batch inputs to\n",
    "    # predict_minibatch().\n",
    "    # Alternately, you can just override predict() and handle batching yourself.\n",
    "    return 2\n",
    "\n",
    "  def predict_minibatch(self, inputs):\n",
    "    # Preprocess to ids and masks, and make the input batch.\n",
    "    encoded_input = self.tokenizer.batch_encode_plus(\n",
    "        [ex[\"sentence\"] for ex in inputs],\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding=\"longest\",\n",
    "        truncation=\"longest_first\")\n",
    "\n",
    "    print(f\"encoded input is: {encoded_input}\")\n",
    "\n",
    "    # Check and send to cuda (GPU) if available\n",
    "    if torch.cuda.is_available():\n",
    "      self.model.cuda()\n",
    "      for tensor in encoded_input:\n",
    "        encoded_input[tensor] = encoded_input[tensor].cuda()\n",
    "    # Run a forward pass.\n",
    "    print(f\"encoded input after passing to cuda: {encoded_input}\")\n",
    "    with torch.no_grad():  # remove this if you need gradients.\n",
    "      out: transformers.modeling_outputs.SequenceClassifierOutput = \\\n",
    "          self.model(**encoded_input)\n",
    "\n",
    "    # Post-process outputs.\n",
    "    batched_outputs = {\n",
    "        \"probas\": torch.nn.functional.softmax(out.logits, dim=-1),\n",
    "        \"input_ids\": encoded_input[\"input_ids\"],\n",
    "        \"ntok\": torch.sum(encoded_input[\"attention_mask\"], dim=1),\n",
    "        \"cls_emb\": out.hidden_states[-1][:, 0],  # last layer, first token\n",
    "    }\n",
    "\n",
    "    print(f\"Batched outputs are: {batched_outputs}\")\n",
    "    # Return as NumPy for further processing.\n",
    "    detached_outputs = {k: v.cpu().numpy() for k, v in batched_outputs.items()}\n",
    "    # Unbatch outputs so we get one record per input example.\n",
    "    for output in utils.unbatch_preds(detached_outputs):\n",
    "      print(f\"output in unbatch: {output}\")\n",
    "      ntok = output.pop(\"ntok\")\n",
    "      output[\"tokens\"] = self.tokenizer.convert_ids_to_tokens(\n",
    "          output.pop(\"input_ids\")[1:ntok - 1])\n",
    "      yield output\n",
    "\n",
    "  def input_spec(self) -> lit_types.Spec:\n",
    "    return {\n",
    "        \"sentence\": lit_types.TextSegment(),\n",
    "        \"label\": lit_types.CategoryLabel(vocab=self.LABELS, required=False)\n",
    "    }\n",
    "\n",
    "  def output_spec(self) -> lit_types.Spec:\n",
    "    return {\n",
    "        \"tokens\": lit_types.Tokens(),\n",
    "        \"probas\": lit_types.MulticlassPreds(parent=\"label\", vocab=self.LABELS,\n",
    "                                            null_idx=0),\n",
    "        \"cls_emb\": lit_types.Embeddings()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SST2Data(lit_dataset.Dataset):\n",
    "#   \"\"\"Stanford Sentiment Treebank, binary version (SST-2).\n",
    "#   See https://www.tensorflow.org/datasets/catalog/glue#gluesst2.\n",
    "#   \"\"\"\n",
    "\n",
    "#   LABELS = ['0', '1']\n",
    "\n",
    "#   def __init__(self, split: str):\n",
    "#     self._examples = []\n",
    "#     for ex in load_tfds('glue/sst2', split=split):\n",
    "#       self._examples.append({\n",
    "#           'sentence': ex['sentence'].decode('utf-8'),\n",
    "#           'label': self.LABELS[ex['label']],\n",
    "#       })\n",
    "\n",
    "#   def spec(self):\n",
    "#     return {\n",
    "#         'sentence': lit_types.TextSegment(),\n",
    "#         'label': lit_types.CategoryLabel(vocab=self.LABELS)\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tensorflow dataset\n",
    "data = glue.load_tfds('glue/sst2', split = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67349"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsgi_app():\n",
    "  \"\"\"Returns a LitApp instance for consumption by gunicorn.\"\"\"\n",
    "  FLAGS.set_default(\"server_type\", \"external\")\n",
    "  FLAGS.set_default(\"demo_mode\", True)\n",
    "  # Parse flags without calling app.run(main), to avoid conflict with\n",
    "  # gunicorn command line flags.\n",
    "  unused = flags.FLAGS(sys.argv, known_only=True)\n",
    "  return main(unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SimpleSentimentModel at 0x7fad754b6f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleSentimentModel(\"bert-base-uncased\",cache_dir = \"/mnt/sdg/niallt/hf_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"sst_dev\": glue.SST2Data(\"validation\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(_):\n",
    "#   # Normally path is a directory; if it's an archive file, download and\n",
    "#   # extract to the transformers cache.\n",
    "#   model_path = FLAGS.model_path\n",
    "#   if model_path.endswith(\".tar.gz\"):\n",
    "#     model_path = transformers.file_utils.cached_path(\n",
    "#         model_path, extract_compressed_file=True)\n",
    "\n",
    "#   # Load the model we defined above.\n",
    "#   models = {\"sst\": SimpleSentimentModel(model_path)}\n",
    "#   # Load SST-2 validation set from TFDS.\n",
    "#   datasets = {\"sst_dev\": glue.SST2Data(\"validation\")}\n",
    "\n",
    "#   # Start the LIT server. See server_flags.py for server options.\n",
    "#   lit_demo = dev_server.Server(models, datasets, **server_flags.get_flags())\n",
    "#   return lit_demo.serve()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#   app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 15:13:44.636543: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n",
      "2022-08-12 15:13:45.018598: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-08-12 15:13:45.018643: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: doraemon1\n",
      "2022-08-12 15:13:45.018652: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: doraemon1\n",
      "2022-08-12 15:13:45.018744: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.65.1\n",
      "2022-08-12 15:13:45.018772: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.1\n",
      "2022-08-12 15:13:45.018779: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.65.1\n",
      "2022-08-12 15:13:45.019137: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 11951,  1998,  2411, 12473,  4990,\n",
      "          1012,   102],\n",
      "        [  101,  4895, 10258,  2378,  8450,  2135, 21657,  1998,  7143,   102,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 11951,  1998,  2411, 12473,  4990,\n",
      "          1012,   102],\n",
      "        [  101,  4895, 10258,  2378,  8450,  2135, 21657,  1998,  7143,   102,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2650, 0.7350],\n",
      "        [0.2847, 0.7153]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 11951,  1998,  2411, 12473,  4990,\n",
      "          1012,   102],\n",
      "        [  101,  4895, 10258,  2378,  8450,  2135, 21657,  1998,  7143,   102,\n",
      "             0,     0]]), 'ntok': tensor([12, 10]), 'cls_emb': tensor([[ 0.2259,  0.1228,  0.0286,  ..., -0.2109,  0.2551,  0.4585],\n",
      "        [-0.6754,  0.1192, -0.3979,  ..., -0.5444,  0.4008,  0.2704]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4473,  2149,  2000,  3246,  2008, 13401,  2003, 22303,  2000,\n",
      "         28866,  1037,  2350,  2476,  2004,  1037,  3293,  2664,  1999, 15338,\n",
      "          3512, 12127,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3772,  1010, 12703,  1010,  2189,  1010, 16434,  1998,\n",
      "          2614,  2024,  2035,  2004, 24826, 15683,  2445,  1996,  2537,  1005,\n",
      "          1055, 17151,  3334,  2063,  2334,  2229,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4473,  2149,  2000,  3246,  2008, 13401,  2003, 22303,  2000,\n",
      "         28866,  1037,  2350,  2476,  2004,  1037,  3293,  2664,  1999, 15338,\n",
      "          3512, 12127,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3772,  1010, 12703,  1010,  2189,  1010, 16434,  1998,\n",
      "          2614,  2024,  2035,  2004, 24826, 15683,  2445,  1996,  2537,  1005,\n",
      "          1055, 17151,  3334,  2063,  2334,  2229,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2335, 0.7665],\n",
      "        [0.2633, 0.7367]]), 'input_ids': tensor([[  101,  4473,  2149,  2000,  3246,  2008, 13401,  2003, 22303,  2000,\n",
      "         28866,  1037,  2350,  2476,  2004,  1037,  3293,  2664,  1999, 15338,\n",
      "          3512, 12127,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3772,  1010, 12703,  1010,  2189,  1010, 16434,  1998,\n",
      "          2614,  2024,  2035,  2004, 24826, 15683,  2445,  1996,  2537,  1005,\n",
      "          1055, 17151,  3334,  2063,  2334,  2229,  1012,   102]]), 'ntok': tensor([24, 28]), 'cls_emb': tensor([[-0.1371, -0.0670, -0.3842,  ..., -0.5215,  0.4210,  0.2068],\n",
      "        [-0.1896,  0.1576, -0.2843,  ..., -0.3177,  0.3937,  0.7080]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  4030,  1011,  1011,  2200,  1010,  2200,\n",
      "          4030,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2348, 17958,  2007,  8562,  1998,  1037,  2261,  5470, 26336,\n",
      "         12817,  1010,  1996,  2143,  2003,  1037, 27150,  2135,  3809,  2298,\n",
      "          2012,  2402,  2308,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  4030,  1011,  1011,  2200,  1010,  2200,\n",
      "          4030,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2348, 17958,  2007,  8562,  1998,  1037,  2261,  5470, 26336,\n",
      "         12817,  1010,  1996,  2143,  2003,  1037, 27150,  2135,  3809,  2298,\n",
      "          2012,  2402,  2308,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2755, 0.7245],\n",
      "        [0.2602, 0.7398]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  4030,  1011,  1011,  2200,  1010,  2200,\n",
      "          4030,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2348, 17958,  2007,  8562,  1998,  1037,  2261,  5470, 26336,\n",
      "         12817,  1010,  1996,  2143,  2003,  1037, 27150,  2135,  3809,  2298,\n",
      "          2012,  2402,  2308,  1012,   102]]), 'ntok': tensor([13, 25]), 'cls_emb': tensor([[ 0.0768,  0.3808,  0.3312,  ..., -0.0315,  0.1480,  0.7715],\n",
      "        [-0.1975, -0.0315, -0.5029,  ..., -0.2582,  0.4753,  0.5592]])}\n",
      "encoded input is: {'input_ids': tensor([[ 101, 1037, 2823, 6945, 6313, 2143, 1012,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0],\n",
      "        [ 101, 2030, 2725, 2197, 2095, 1005, 1055, 7773, 2007, 2115, 4654, 1011,\n",
      "         2564, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[ 101, 1037, 2823, 6945, 6313, 2143, 1012,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0],\n",
      "        [ 101, 2030, 2725, 2197, 2095, 1005, 1055, 7773, 2007, 2115, 4654, 1011,\n",
      "         2564, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2932, 0.7068],\n",
      "        [0.2859, 0.7141]]), 'input_ids': tensor([[ 101, 1037, 2823, 6945, 6313, 2143, 1012,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0],\n",
      "        [ 101, 2030, 2725, 2197, 2095, 1005, 1055, 7773, 2007, 2115, 4654, 1011,\n",
      "         2564, 1012,  102]]), 'ntok': tensor([ 8, 15]), 'cls_emb': tensor([[-0.3149, -0.0334, -0.3919,  ..., -0.0953,  0.3031,  0.2837],\n",
      "        [-0.1435, -0.0507, -0.7798,  ..., -0.5366,  0.1065,  0.3354]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2017,  2079,  1050,  1005,  1056,  2031,  2000,  2113,  2055,\n",
      "          2189,  2000,  9120,  1996,  2143,  1005,  1055,  3733, 26966, 12586,\n",
      "          1997,  4038,  1998,  7472,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  3599,  6486,  2781,  1010,  2087,  1997,  2029,  2979,\n",
      "          2004,  3254,  2004,  2065,  1045,  1005,  1040,  2042,  3564,  6248,\n",
      "          2006,  2019,  1045, 23296,  9541,  1010,  5675,  4868,  7569,  2013,\n",
      "         21864, 15952,  2000, 12181,  2100,  2000, 14395,  4977,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2017,  2079,  1050,  1005,  1056,  2031,  2000,  2113,  2055,\n",
      "          2189,  2000,  9120,  1996,  2143,  1005,  1055,  3733, 26966, 12586,\n",
      "          1997,  4038,  1998,  7472,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  3599,  6486,  2781,  1010,  2087,  1997,  2029,  2979,\n",
      "          2004,  3254,  2004,  2065,  1045,  1005,  1040,  2042,  3564,  6248,\n",
      "          2006,  2019,  1045, 23296,  9541,  1010,  5675,  4868,  7569,  2013,\n",
      "         21864, 15952,  2000, 12181,  2100,  2000, 14395,  4977,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2566, 0.7434],\n",
      "        [0.2520, 0.7480]]), 'input_ids': tensor([[  101,  2017,  2079,  1050,  1005,  1056,  2031,  2000,  2113,  2055,\n",
      "          2189,  2000,  9120,  1996,  2143,  1005,  1055,  3733, 26966, 12586,\n",
      "          1997,  4038,  1998,  7472,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  3599,  6486,  2781,  1010,  2087,  1997,  2029,  2979,\n",
      "          2004,  3254,  2004,  2065,  1045,  1005,  1040,  2042,  3564,  6248,\n",
      "          2006,  2019,  1045, 23296,  9541,  1010,  5675,  4868,  7569,  2013,\n",
      "         21864, 15952,  2000, 12181,  2100,  2000, 14395,  4977,  1012,   102]]), 'ntok': tensor([26, 40]), 'cls_emb': tensor([[-0.0741, -0.1677, -0.5522,  ..., -0.3047,  0.4765,  0.2538],\n",
      "        [-0.0592,  0.1517, -0.1517,  ..., -0.2681,  0.6931,  0.4693]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2033,  6491, 11124,  6774,  4616,  1997,  1996,  5260,\n",
      "          2562,  1996,  2143, 16764,  1998,  2562,  1996,  4378, 15544, 19510,\n",
      "          2098,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  3138,  1037,  4326,  2785,  1997,  2474, 21254,  4757,\n",
      "          2000,  5949,  1996, 11725,  1997,  2728, 21316,  1010,  4776,  2033,\n",
      "          5400,  1010,  8207, 12767,  1010,  1998, 14435,  2310,  2140,  5558,\n",
      "          7295,  3385,  2035,  1999,  1996,  2168,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2033,  6491, 11124,  6774,  4616,  1997,  1996,  5260,\n",
      "          2562,  1996,  2143, 16764,  1998,  2562,  1996,  4378, 15544, 19510,\n",
      "          2098,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  3138,  1037,  4326,  2785,  1997,  2474, 21254,  4757,\n",
      "          2000,  5949,  1996, 11725,  1997,  2728, 21316,  1010,  4776,  2033,\n",
      "          5400,  1010,  8207, 12767,  1010,  1998, 14435,  2310,  2140,  5558,\n",
      "          7295,  3385,  2035,  1999,  1996,  2168,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2481, 0.7519],\n",
      "        [0.2415, 0.7585]]), 'input_ids': tensor([[  101,  1996,  2033,  6491, 11124,  6774,  4616,  1997,  1996,  5260,\n",
      "          2562,  1996,  2143, 16764,  1998,  2562,  1996,  4378, 15544, 19510,\n",
      "          2098,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  3138,  1037,  4326,  2785,  1997,  2474, 21254,  4757,\n",
      "          2000,  5949,  1996, 11725,  1997,  2728, 21316,  1010,  4776,  2033,\n",
      "          5400,  1010,  8207, 12767,  1010,  1998, 14435,  2310,  2140,  5558,\n",
      "          7295,  3385,  2035,  1999,  1996,  2168,  3185,  1012,   102]]), 'ntok': tensor([23, 39]), 'cls_emb': tensor([[ 0.0628,  0.2063, -0.0904,  ..., -0.4882,  0.3470,  0.0184],\n",
      "        [ 0.1585,  0.2270, -0.5070,  ..., -0.3403,  0.4220,  0.6739]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1996,  2143, 17567,  2013,  1037,  3768,\n",
      "          1997,  8562,  1006,  2242,  2734,  2000,  5703,  2041,  1996,  4808,\n",
      "          1007,  1012,  1012,  1012,   102,     0],\n",
      "        [  101,  2057,  7117,  2005,  1006, 10254,  1998,  2703,  1007,  1010,\n",
      "          2130,  2066,  2068,  1010,  2295,  3383,  2009,  1005,  1055,  2019,\n",
      "          7603,  3553,  2000, 12063,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1996,  2143, 17567,  2013,  1037,  3768,\n",
      "          1997,  8562,  1006,  2242,  2734,  2000,  5703,  2041,  1996,  4808,\n",
      "          1007,  1012,  1012,  1012,   102,     0],\n",
      "        [  101,  2057,  7117,  2005,  1006, 10254,  1998,  2703,  1007,  1010,\n",
      "          2130,  2066,  2068,  1010,  2295,  3383,  2009,  1005,  1055,  2019,\n",
      "          7603,  3553,  2000, 12063,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2691, 0.7309],\n",
      "        [0.2535, 0.7465]]), 'input_ids': tensor([[  101,  1012,  1012,  1012,  1996,  2143, 17567,  2013,  1037,  3768,\n",
      "          1997,  8562,  1006,  2242,  2734,  2000,  5703,  2041,  1996,  4808,\n",
      "          1007,  1012,  1012,  1012,   102,     0],\n",
      "        [  101,  2057,  7117,  2005,  1006, 10254,  1998,  2703,  1007,  1010,\n",
      "          2130,  2066,  2068,  1010,  2295,  3383,  2009,  1005,  1055,  2019,\n",
      "          7603,  3553,  2000, 12063,  1012,   102]]), 'ntok': tensor([25, 26]), 'cls_emb': tensor([[ 0.0302,  0.1895, -0.1432,  ..., -0.0917,  0.9055,  0.3367],\n",
      "        [-0.3258, -0.0024, -0.3096,  ..., -0.2056,  0.3574,  0.3585]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2130,  5469,  4599,  2097,  2087,  3497,  2025,  2424,  2054,\n",
      "          2027,  1005,  2128,  6224,  2007,  4390,  2296,  2154,  1025,  1996,\n",
      "          3185, 14087,  2119, 16959,  2015,  1998,  8562,  1012,   102],\n",
      "        [  101,  1037,  9882,  1010,  2152,  1011, 24462,  3315,  2013,  2634,\n",
      "          2008, 19401,  2135, 12586,  2015,  2189,  1010,  3153,  1010,  2299,\n",
      "          1010,  1998,  2152,  3689,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2130,  5469,  4599,  2097,  2087,  3497,  2025,  2424,  2054,\n",
      "          2027,  1005,  2128,  6224,  2007,  4390,  2296,  2154,  1025,  1996,\n",
      "          3185, 14087,  2119, 16959,  2015,  1998,  8562,  1012,   102],\n",
      "        [  101,  1037,  9882,  1010,  2152,  1011, 24462,  3315,  2013,  2634,\n",
      "          2008, 19401,  2135, 12586,  2015,  2189,  1010,  3153,  1010,  2299,\n",
      "          1010,  1998,  2152,  3689,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2494, 0.7506],\n",
      "        [0.2733, 0.7267]]), 'input_ids': tensor([[  101,  2130,  5469,  4599,  2097,  2087,  3497,  2025,  2424,  2054,\n",
      "          2027,  1005,  2128,  6224,  2007,  4390,  2296,  2154,  1025,  1996,\n",
      "          3185, 14087,  2119, 16959,  2015,  1998,  8562,  1012,   102],\n",
      "        [  101,  1037,  9882,  1010,  2152,  1011, 24462,  3315,  2013,  2634,\n",
      "          2008, 19401,  2135, 12586,  2015,  2189,  1010,  3153,  1010,  2299,\n",
      "          1010,  1998,  2152,  3689,  1012,   102,     0,     0,     0]]), 'ntok': tensor([29, 26]), 'cls_emb': tensor([[ 0.2977, -0.0287, -0.0488,  ..., -0.2073,  0.4147,  0.4671],\n",
      "        [-0.4574, -0.4059, -0.0590,  ..., -0.4200,  0.5954,  0.4088]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  6699,  2024,  6315,  1998,  2097,  4894,  1037,  9113,\n",
      "          2007,  3087,  2040,  1005,  1055,  2412,  2018,  2155, 12603,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 14166, 11937, 24826,  2038,  1037, 14161,  8684,  2005,  8130,\n",
      "          4395,  2008, 23848,  3490, 12031,  2014, 25506, 11084,  1010,  1998,\n",
      "          1999,  2023, 23675,  3686,  2413,  4038,  1010,  2016,  1005,  1055,\n",
      "          2004,  2851,  1011,  8294,  4654, 21436,  4630,  2004,  2016,  2001,\n",
      "          1999, 25285,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  6699,  2024,  6315,  1998,  2097,  4894,  1037,  9113,\n",
      "          2007,  3087,  2040,  1005,  1055,  2412,  2018,  2155, 12603,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 14166, 11937, 24826,  2038,  1037, 14161,  8684,  2005,  8130,\n",
      "          4395,  2008, 23848,  3490, 12031,  2014, 25506, 11084,  1010,  1998,\n",
      "          1999,  2023, 23675,  3686,  2413,  4038,  1010,  2016,  1005,  1055,\n",
      "          2004,  2851,  1011,  8294,  4654, 21436,  4630,  2004,  2016,  2001,\n",
      "          1999, 25285,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2789, 0.7211],\n",
      "        [0.2525, 0.7475]]), 'input_ids': tensor([[  101,  1996,  6699,  2024,  6315,  1998,  2097,  4894,  1037,  9113,\n",
      "          2007,  3087,  2040,  1005,  1055,  2412,  2018,  2155, 12603,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 14166, 11937, 24826,  2038,  1037, 14161,  8684,  2005,  8130,\n",
      "          4395,  2008, 23848,  3490, 12031,  2014, 25506, 11084,  1010,  1998,\n",
      "          1999,  2023, 23675,  3686,  2413,  4038,  1010,  2016,  1005,  1055,\n",
      "          2004,  2851,  1011,  8294,  4654, 21436,  4630,  2004,  2016,  2001,\n",
      "          1999, 25285,  1012,   102]]), 'ntok': tensor([21, 44]), 'cls_emb': tensor([[-0.0838,  0.2410, -0.2638,  ..., -0.3923,  0.1397,  0.4526],\n",
      "        [-0.2330, -0.4084, -0.5767,  ..., -0.0442,  0.6820,  0.8147]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1996,  3185,  2003,  2074,  1037,  5810,\n",
      "          2214,  6071,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  1999,  2049,  2190,  5312,  1010, 12950,  1037,  2919,  2152,\n",
      "          2082,  2537,  1997, 21956,  1010,  2302,  5770,  1997,  2299,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1996,  3185,  2003,  2074,  1037,  5810,\n",
      "          2214,  6071,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  1999,  2049,  2190,  5312,  1010, 12950,  1037,  2919,  2152,\n",
      "          2082,  2537,  1997, 21956,  1010,  2302,  5770,  1997,  2299,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2496, 0.7504],\n",
      "        [0.2593, 0.7407]]), 'input_ids': tensor([[  101,  1012,  1012,  1012,  1996,  3185,  2003,  2074,  1037,  5810,\n",
      "          2214,  6071,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  1999,  2049,  2190,  5312,  1010, 12950,  1037,  2919,  2152,\n",
      "          2082,  2537,  1997, 21956,  1010,  2302,  5770,  1997,  2299,  1012,\n",
      "           102]]), 'ntok': tensor([14, 21]), 'cls_emb': tensor([[ 0.0944,  0.3886,  0.1286,  ..., -0.3475,  0.7496,  0.5421],\n",
      "        [-0.4134, -0.0283, -0.1817,  ..., -0.5037,  0.4524,  0.4709]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 25730,  3138,  2019,  4748, 14503,  3085,  2298,  2012,  1996,\n",
      "          1044, 22571, 10085,  6935,  2100,  1997,  2576,  6149,  2791,  1010,\n",
      "          2021,  2009,  2515,  2061,  2007,  2107,  2019, 17837,  4309,  2008,\n",
      "          2017,  2196,  2113,  2043,  8562,  4515,  1998, 10576,  4269,  1012,\n",
      "           102],\n",
      "        [  101,  1996,  8909,  6590, 14127, 16180,  2005,  2420,  1011,  2023,\n",
      "          2074,  2371,  2066,  2009,  2106,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 25730,  3138,  2019,  4748, 14503,  3085,  2298,  2012,  1996,\n",
      "          1044, 22571, 10085,  6935,  2100,  1997,  2576,  6149,  2791,  1010,\n",
      "          2021,  2009,  2515,  2061,  2007,  2107,  2019, 17837,  4309,  2008,\n",
      "          2017,  2196,  2113,  2043,  8562,  4515,  1998, 10576,  4269,  1012,\n",
      "           102],\n",
      "        [  101,  1996,  8909,  6590, 14127, 16180,  2005,  2420,  1011,  2023,\n",
      "          2074,  2371,  2066,  2009,  2106,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2405, 0.7595],\n",
      "        [0.2779, 0.7221]]), 'input_ids': tensor([[  101, 25730,  3138,  2019,  4748, 14503,  3085,  2298,  2012,  1996,\n",
      "          1044, 22571, 10085,  6935,  2100,  1997,  2576,  6149,  2791,  1010,\n",
      "          2021,  2009,  2515,  2061,  2007,  2107,  2019, 17837,  4309,  2008,\n",
      "          2017,  2196,  2113,  2043,  8562,  4515,  1998, 10576,  4269,  1012,\n",
      "           102],\n",
      "        [  101,  1996,  8909,  6590, 14127, 16180,  2005,  2420,  1011,  2023,\n",
      "          2074,  2371,  2066,  2009,  2106,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([41, 17]), 'cls_emb': tensor([[-0.0493,  0.0902, -0.6006,  ..., -0.1896,  0.3481,  0.3185],\n",
      "        [ 0.3714, -0.1839,  0.3986,  ..., -0.3015,  0.1540,  0.4617]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  9988,  6187, 21007, 12891,  2106,  2009,  2488,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3972, 22471,  3085,  1998, 23824, 10874,  3561,  2007,\n",
      "         20096,  1010,  3191,  2026,  2970,  2003,  2019,  2434,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  9988,  6187, 21007, 12891,  2106,  2009,  2488,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3972, 22471,  3085,  1998, 23824, 10874,  3561,  2007,\n",
      "         20096,  1010,  3191,  2026,  2970,  2003,  2019,  2434,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2683, 0.7317],\n",
      "        [0.2730, 0.7270]]), 'input_ids': tensor([[  101,  9988,  6187, 21007, 12891,  2106,  2009,  2488,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3972, 22471,  3085,  1998, 23824, 10874,  3561,  2007,\n",
      "         20096,  1010,  3191,  2026,  2970,  2003,  2019,  2434,  1012,   102]]), 'ntok': tensor([10, 20]), 'cls_emb': tensor([[-0.1037,  0.0181, -0.1075,  ..., -0.3492,  0.5118,  0.4825],\n",
      "        [-0.1019, -0.3681,  0.0404,  ..., -0.3522,  0.1465,  0.3007]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 15839,  2038,  1037,  3185,  2061,  4876, 10349,  1996,  4382,\n",
      "          1997,  1037,  2158,  1998,  2010,  2147,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  4172,  2015,  1010,  9428,  9662,  2054,  1005,  1055,  2183,\n",
      "          2000,  2191,  2111,  4756,  1010,  3216,  1996, 11721, 28120,  2013,\n",
      "         26729, 12354,  2000, 10958,  4609, 11714,  3348, 18201,  2015,  2000,\n",
      "          5675,  6298,  4038,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 15839,  2038,  1037,  3185,  2061,  4876, 10349,  1996,  4382,\n",
      "          1997,  1037,  2158,  1998,  2010,  2147,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  4172,  2015,  1010,  9428,  9662,  2054,  1005,  1055,  2183,\n",
      "          2000,  2191,  2111,  4756,  1010,  3216,  1996, 11721, 28120,  2013,\n",
      "         26729, 12354,  2000, 10958,  4609, 11714,  3348, 18201,  2015,  2000,\n",
      "          5675,  6298,  4038,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2478, 0.7522],\n",
      "        [0.2539, 0.7461]]), 'input_ids': tensor([[  101, 15839,  2038,  1037,  3185,  2061,  4876, 10349,  1996,  4382,\n",
      "          1997,  1037,  2158,  1998,  2010,  2147,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  4172,  2015,  1010,  9428,  9662,  2054,  1005,  1055,  2183,\n",
      "          2000,  2191,  2111,  4756,  1010,  3216,  1996, 11721, 28120,  2013,\n",
      "         26729, 12354,  2000, 10958,  4609, 11714,  3348, 18201,  2015,  2000,\n",
      "          5675,  6298,  4038,  1012,   102]]), 'ntok': tensor([18, 35]), 'cls_emb': tensor([[-0.3633,  0.1731, -0.6494,  ..., -0.0926,  0.3994,  0.4965],\n",
      "        [-0.1937,  0.1825, -0.3962,  ..., -0.0678,  0.9086,  0.5618]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2895, 15924,  2090,  2627,  1998,  2556,  1010,  2021,\n",
      "          1996,  3430,  4957,  2003,  2205,  2702,  8918,  2000,  8133,  1996,\n",
      "          6832,  7264,  2008, 16405, 14536, 11589,  2000,  8487,  1037,  8732,\n",
      "          1011,  2095, 11443,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2019,  2125, 19442,  7438,  2008, 26202,\n",
      "          2015,  4569,  2012,  1996,  3537,  6912,  2096,  2036, 12843,  2049,\n",
      "          7784,  2005,  2216,  2040,  2202,  2112,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2895, 15924,  2090,  2627,  1998,  2556,  1010,  2021,\n",
      "          1996,  3430,  4957,  2003,  2205,  2702,  8918,  2000,  8133,  1996,\n",
      "          6832,  7264,  2008, 16405, 14536, 11589,  2000,  8487,  1037,  8732,\n",
      "          1011,  2095, 11443,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2019,  2125, 19442,  7438,  2008, 26202,\n",
      "          2015,  4569,  2012,  1996,  3537,  6912,  2096,  2036, 12843,  2049,\n",
      "          7784,  2005,  2216,  2040,  2202,  2112,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2517, 0.7483],\n",
      "        [0.2396, 0.7604]]), 'input_ids': tensor([[  101,  1996,  2895, 15924,  2090,  2627,  1998,  2556,  1010,  2021,\n",
      "          1996,  3430,  4957,  2003,  2205,  2702,  8918,  2000,  8133,  1996,\n",
      "          6832,  7264,  2008, 16405, 14536, 11589,  2000,  8487,  1037,  8732,\n",
      "          1011,  2095, 11443,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2019,  2125, 19442,  7438,  2008, 26202,\n",
      "          2015,  4569,  2012,  1996,  3537,  6912,  2096,  2036, 12843,  2049,\n",
      "          7784,  2005,  2216,  2040,  2202,  2112,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 28]), 'cls_emb': tensor([[-0.3015,  0.0207, -0.3818,  ..., -0.4011,  0.4419,  0.6438],\n",
      "        [ 0.0363,  0.0307, -0.0501,  ..., -0.2810,  0.2714,  0.4173]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17387,  1011, 16343,  3185,  1010,\n",
      "          1037,  3013,  1011,  1998,  1011, 19351,  3105,  1012,   102],\n",
      "        [  101,  1045,  2018,  2000,  2298,  2185,  1011,  2023,  2001,  2643,\n",
      "          9643,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17387,  1011, 16343,  3185,  1010,\n",
      "          1037,  3013,  1011,  1998,  1011, 19351,  3105,  1012,   102],\n",
      "        [  101,  1045,  2018,  2000,  2298,  2185,  1011,  2023,  2001,  2643,\n",
      "          9643,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2597, 0.7403],\n",
      "        [0.2629, 0.7371]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17387,  1011, 16343,  3185,  1010,\n",
      "          1037,  3013,  1011,  1998,  1011, 19351,  3105,  1012,   102],\n",
      "        [  101,  1045,  2018,  2000,  2298,  2185,  1011,  2023,  2001,  2643,\n",
      "          9643,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([19, 13]), 'cls_emb': tensor([[ 0.0365,  0.0470, -0.0678,  ..., -0.0781,  0.4899,  0.6402],\n",
      "        [ 0.1940,  0.2268, -0.3825,  ..., -0.1016,  0.4465,  0.4901]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4283,  2000,  3660,  1005,  1055, 23916,  5074,  1998,  1041,\n",
      "         28992,  4059,  1005,  1055,  4086,  7833,  1010,  5074, 11898,  2099,\n",
      "          2003,  2028,  1997,  1996,  2087, 17075,  8358,  2006,  1999,  1996,\n",
      "          2194,  1997,  2273,  1012,   102,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  2881,  2000,  3073,  1037,  4666,  1997,\n",
      "          8451,  1998,  4000,  1010,  1036,  1036, 16760,  1005,  1005,  2612,\n",
      "         27895,  2015,  1037,  9210,  1997,  4895, 18447,  4765, 19301, 22912,\n",
      "          2545,  1998,  3365,  8038,  7962,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4283,  2000,  3660,  1005,  1055, 23916,  5074,  1998,  1041,\n",
      "         28992,  4059,  1005,  1055,  4086,  7833,  1010,  5074, 11898,  2099,\n",
      "          2003,  2028,  1997,  1996,  2087, 17075,  8358,  2006,  1999,  1996,\n",
      "          2194,  1997,  2273,  1012,   102,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  2881,  2000,  3073,  1037,  4666,  1997,\n",
      "          8451,  1998,  4000,  1010,  1036,  1036, 16760,  1005,  1005,  2612,\n",
      "         27895,  2015,  1037,  9210,  1997,  4895, 18447,  4765, 19301, 22912,\n",
      "          2545,  1998,  3365,  8038,  7962,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2559, 0.7441],\n",
      "        [0.2809, 0.7191]]), 'input_ids': tensor([[  101,  4283,  2000,  3660,  1005,  1055, 23916,  5074,  1998,  1041,\n",
      "         28992,  4059,  1005,  1055,  4086,  7833,  1010,  5074, 11898,  2099,\n",
      "          2003,  2028,  1997,  1996,  2087, 17075,  8358,  2006,  1999,  1996,\n",
      "          2194,  1997,  2273,  1012,   102,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  2881,  2000,  3073,  1037,  4666,  1997,\n",
      "          8451,  1998,  4000,  1010,  1036,  1036, 16760,  1005,  1005,  2612,\n",
      "         27895,  2015,  1037,  9210,  1997,  4895, 18447,  4765, 19301, 22912,\n",
      "          2545,  1998,  3365,  8038,  7962,  2015,  1012,   102]]), 'ntok': tensor([35, 38]), 'cls_emb': tensor([[-0.3969, -0.1620, -0.3083,  ..., -0.1316,  0.6024,  0.8137],\n",
      "        [ 0.1609,  0.0436,  0.1023,  ..., -0.0273,  0.7150,  0.5138]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  9882,  1010, 25591,  1010, 23182,  3185,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1996,  3185, 21645,  1999, 16021, 28345,  2075,  1037,\n",
      "         15705,  3168,  1997,  1036,  2045,  2021,  2005,  1996,  4519,  1997,\n",
      "          2643,  1010,  1005,  2009,  2003,  2521,  2205,  2969,  1011,  9715,\n",
      "          2000,  4009,  2017,  6171,  2046,  2049,  2088,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  9882,  1010, 25591,  1010, 23182,  3185,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1996,  3185, 21645,  1999, 16021, 28345,  2075,  1037,\n",
      "         15705,  3168,  1997,  1036,  2045,  2021,  2005,  1996,  4519,  1997,\n",
      "          2643,  1010,  1005,  2009,  2003,  2521,  2205,  2969,  1011,  9715,\n",
      "          2000,  4009,  2017,  6171,  2046,  2049,  2088,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2647, 0.7353],\n",
      "        [0.2410, 0.7590]]), 'input_ids': tensor([[  101,  1037,  9882,  1010, 25591,  1010, 23182,  3185,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2065,  1996,  3185, 21645,  1999, 16021, 28345,  2075,  1037,\n",
      "         15705,  3168,  1997,  1036,  2045,  2021,  2005,  1996,  4519,  1997,\n",
      "          2643,  1010,  1005,  2009,  2003,  2521,  2205,  2969,  1011,  9715,\n",
      "          2000,  4009,  2017,  6171,  2046,  2049,  2088,  1012,   102]]), 'ntok': tensor([10, 39]), 'cls_emb': tensor([[-0.5468, -0.4923, -0.4737,  ..., -0.8651,  0.3489,  0.3307],\n",
      "        [ 0.0545, -0.1728, -0.4548,  ..., -0.1656,  0.1991,  0.6174]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2515,  1050,  1005,  1056,  2903,  1999,  2993,  1010,\n",
      "          2009,  2038,  2053,  3168,  1997,  8562,  1012,  1012,  1012,  2009,\n",
      "          1005,  1055,  2074,  5810, 11471,  1012,   102],\n",
      "        [  101,  1037,  5537,  1997,  9951,  5607,  1011,  1005,  7861,  1011,\n",
      "          2039,  5019,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2515,  1050,  1005,  1056,  2903,  1999,  2993,  1010,\n",
      "          2009,  2038,  2053,  3168,  1997,  8562,  1012,  1012,  1012,  2009,\n",
      "          1005,  1055,  2074,  5810, 11471,  1012,   102],\n",
      "        [  101,  1037,  5537,  1997,  9951,  5607,  1011,  1005,  7861,  1011,\n",
      "          2039,  5019,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2475, 0.7525],\n",
      "        [0.2605, 0.7395]]), 'input_ids': tensor([[  101,  2009,  2515,  1050,  1005,  1056,  2903,  1999,  2993,  1010,\n",
      "          2009,  2038,  2053,  3168,  1997,  8562,  1012,  1012,  1012,  2009,\n",
      "          1005,  1055,  2074,  5810, 11471,  1012,   102],\n",
      "        [  101,  1037,  5537,  1997,  9951,  5607,  1011,  1005,  7861,  1011,\n",
      "          2039,  5019,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([27, 14]), 'cls_emb': tensor([[ 0.2870,  0.3161, -0.0229,  ..., -0.0123,  0.6115,  0.6097],\n",
      "        [-0.2019, -0.1536, -0.8623,  ..., -0.7473,  0.4938,  0.1932]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3635,  1997,  1996,  3538,  1010,  1996, 16655, 18807,\n",
      "          2658,  2964,  1997,  1996, 24222,  2537,  1010,  1998,  1996, 18987,\n",
      "         11157,  1999,  1996, 11320, 14615,  8476,  6011, 12832,  2438,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  1059,  1007,  7632,  2571,  2146,  2006, 26445,  3085,\n",
      "         17059,  1998, 11007,  4483,  2964,  1010,  4869,  2204,  8095,  1005,\n",
      "          1055,  3748,  9610,  8737,  2319, 23940,  2015,  2003,  2460,  2006,\n",
      "          1996, 16959,  2015,  1996, 15849,  4697,  5396,  7670,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3635,  1997,  1996,  3538,  1010,  1996, 16655, 18807,\n",
      "          2658,  2964,  1997,  1996, 24222,  2537,  1010,  1998,  1996, 18987,\n",
      "         11157,  1999,  1996, 11320, 14615,  8476,  6011, 12832,  2438,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  1059,  1007,  7632,  2571,  2146,  2006, 26445,  3085,\n",
      "         17059,  1998, 11007,  4483,  2964,  1010,  4869,  2204,  8095,  1005,\n",
      "          1055,  3748,  9610,  8737,  2319, 23940,  2015,  2003,  2460,  2006,\n",
      "          1996, 16959,  2015,  1996, 15849,  4697,  5396,  7670,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2436, 0.7564],\n",
      "        [0.2565, 0.7435]]), 'input_ids': tensor([[  101,  1996,  3635,  1997,  1996,  3538,  1010,  1996, 16655, 18807,\n",
      "          2658,  2964,  1997,  1996, 24222,  2537,  1010,  1998,  1996, 18987,\n",
      "         11157,  1999,  1996, 11320, 14615,  8476,  6011, 12832,  2438,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  1059,  1007,  7632,  2571,  2146,  2006, 26445,  3085,\n",
      "         17059,  1998, 11007,  4483,  2964,  1010,  4869,  2204,  8095,  1005,\n",
      "          1055,  3748,  9610,  8737,  2319, 23940,  2015,  2003,  2460,  2006,\n",
      "          1996, 16959,  2015,  1996, 15849,  4697,  5396,  7670,  1012,   102]]), 'ntok': tensor([31, 40]), 'cls_emb': tensor([[ 0.0991,  0.3202,  0.0905,  ..., -0.0842,  0.2156,  0.4975],\n",
      "        [-0.4309,  0.0045, -0.0790,  ..., -0.5212,  0.6786,  0.4626]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2004, 16524,  2004,  1037,  3959,  1998,  2004,  6851,  2004,\n",
      "          1037,  9982,  1010,  2004, 17453, 14375,  3560,  2004,  2009,  2003,\n",
      "          2012,  2335, 28575,  2135, 10827,  1012,   102],\n",
      "        [  101, 13002,  1996,  2996,  1010, 27263, 25778,  2072,  2003, 22775,\n",
      "         12473,  1998,  2061,  2003,  2023,  4748, 26692, 14626, 10124,  2923,\n",
      "          3185,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2004, 16524,  2004,  1037,  3959,  1998,  2004,  6851,  2004,\n",
      "          1037,  9982,  1010,  2004, 17453, 14375,  3560,  2004,  2009,  2003,\n",
      "          2012,  2335, 28575,  2135, 10827,  1012,   102],\n",
      "        [  101, 13002,  1996,  2996,  1010, 27263, 25778,  2072,  2003, 22775,\n",
      "         12473,  1998,  2061,  2003,  2023,  4748, 26692, 14626, 10124,  2923,\n",
      "          3185,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2426, 0.7574],\n",
      "        [0.2631, 0.7369]]), 'input_ids': tensor([[  101,  2004, 16524,  2004,  1037,  3959,  1998,  2004,  6851,  2004,\n",
      "          1037,  9982,  1010,  2004, 17453, 14375,  3560,  2004,  2009,  2003,\n",
      "          2012,  2335, 28575,  2135, 10827,  1012,   102],\n",
      "        [  101, 13002,  1996,  2996,  1010, 27263, 25778,  2072,  2003, 22775,\n",
      "         12473,  1998,  2061,  2003,  2023,  4748, 26692, 14626, 10124,  2923,\n",
      "          3185,  1012,   102,     0,     0,     0,     0]]), 'ntok': tensor([27, 23]), 'cls_emb': tensor([[-0.3164,  0.1562, -0.1803,  ..., -0.3080,  0.2519,  0.7364],\n",
      "        [-0.3856, -0.0240, -0.2933,  ..., -0.3309,  0.4261,  0.4863]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  1005,  1055,  1012,  1012,  1012, 14388,  2943,  2013,\n",
      "          1996,  3459,  1010,  1037,  3168,  1997, 18378,  2791,  1998,  8277,\n",
      "          2008,  3849,  6413,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023, 27816,  4516,  9099, 23865,  2015,  2256,  3653,  8663,\n",
      "          3401,  3512,  2094,  4432,  1997,  1996,  4151,  2455,  1998,  2049,\n",
      "          4864,  1010,  8669,  1996,  2529,  3375,  6447,  4218,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  1005,  1055,  1012,  1012,  1012, 14388,  2943,  2013,\n",
      "          1996,  3459,  1010,  1037,  3168,  1997, 18378,  2791,  1998,  8277,\n",
      "          2008,  3849,  6413,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023, 27816,  4516,  9099, 23865,  2015,  2256,  3653,  8663,\n",
      "          3401,  3512,  2094,  4432,  1997,  1996,  4151,  2455,  1998,  2049,\n",
      "          4864,  1010,  8669,  1996,  2529,  3375,  6447,  4218,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2444, 0.7556],\n",
      "        [0.2382, 0.7618]]), 'input_ids': tensor([[  101,  2045,  1005,  1055,  1012,  1012,  1012, 14388,  2943,  2013,\n",
      "          1996,  3459,  1010,  1037,  3168,  1997, 18378,  2791,  1998,  8277,\n",
      "          2008,  3849,  6413,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023, 27816,  4516,  9099, 23865,  2015,  2256,  3653,  8663,\n",
      "          3401,  3512,  2094,  4432,  1997,  1996,  4151,  2455,  1998,  2049,\n",
      "          4864,  1010,  8669,  1996,  2529,  3375,  6447,  4218,  1012,   102]]), 'ntok': tensor([25, 30]), 'cls_emb': tensor([[ 0.3336, -0.1447,  0.0754,  ..., -0.5897,  0.4083,  0.3569],\n",
      "        [-0.2854,  0.1443, -0.5002,  ..., -0.2606,  0.3764,  0.2100]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996, 11259,  3997,  1997,  1036,  1036,  3449,  2989,  1005,\n",
      "          1005,  2003,  2008,  2009,  2196, 12386,  3543,  2007,  1996,  4507,\n",
      "          1997,  1996, 11844,  3663,  1012,   102],\n",
      "        [  101, 28925,  1012,  1012,  1012,  7861,  5092, 18389,  1996,  2839,\n",
      "          2007,  2019, 29483, 21279, 25869,  2964,  2050,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996, 11259,  3997,  1997,  1036,  1036,  3449,  2989,  1005,\n",
      "          1005,  2003,  2008,  2009,  2196, 12386,  3543,  2007,  1996,  4507,\n",
      "          1997,  1996, 11844,  3663,  1012,   102],\n",
      "        [  101, 28925,  1012,  1012,  1012,  7861,  5092, 18389,  1996,  2839,\n",
      "          2007,  2019, 29483, 21279, 25869,  2964,  2050,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2471, 0.7529],\n",
      "        [0.2611, 0.7389]]), 'input_ids': tensor([[  101,  1996, 11259,  3997,  1997,  1036,  1036,  3449,  2989,  1005,\n",
      "          1005,  2003,  2008,  2009,  2196, 12386,  3543,  2007,  1996,  4507,\n",
      "          1997,  1996, 11844,  3663,  1012,   102],\n",
      "        [  101, 28925,  1012,  1012,  1012,  7861,  5092, 18389,  1996,  2839,\n",
      "          2007,  2019, 29483, 21279, 25869,  2964,  2050,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([26, 19]), 'cls_emb': tensor([[-0.0420,  0.2143,  0.0043,  ..., -0.0632, -0.0103,  0.8367],\n",
      "        [-0.0237, -0.0711, -0.2354,  ..., -0.3818,  0.5779,  0.1259]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2516,  2025,  2069,  5577,  2049,  2364,  3494,  1010,\n",
      "          2021,  1996, 13971,  2111,  2369,  1996,  4950,  2004,  2092,  1012,\n",
      "           102],\n",
      "        [  101,  2009,  4107,  2210,  3458,  1996, 29089,  6569,  2015,  1997,\n",
      "          3492,  1998,  3635,  3238,  7789,  4024,  1012,   102,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2516,  2025,  2069,  5577,  2049,  2364,  3494,  1010,\n",
      "          2021,  1996, 13971,  2111,  2369,  1996,  4950,  2004,  2092,  1012,\n",
      "           102],\n",
      "        [  101,  2009,  4107,  2210,  3458,  1996, 29089,  6569,  2015,  1997,\n",
      "          3492,  1998,  3635,  3238,  7789,  4024,  1012,   102,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2509, 0.7491],\n",
      "        [0.2677, 0.7323]]), 'input_ids': tensor([[  101,  1996,  2516,  2025,  2069,  5577,  2049,  2364,  3494,  1010,\n",
      "          2021,  1996, 13971,  2111,  2369,  1996,  4950,  2004,  2092,  1012,\n",
      "           102],\n",
      "        [  101,  2009,  4107,  2210,  3458,  1996, 29089,  6569,  2015,  1997,\n",
      "          3492,  1998,  3635,  3238,  7789,  4024,  1012,   102,     0,     0,\n",
      "             0]]), 'ntok': tensor([21, 18]), 'cls_emb': tensor([[-0.2449,  0.1010, -0.1956,  ..., -0.2434,  0.5911,  0.5975],\n",
      "        [-0.0631, -0.0115,  0.2240,  ..., -0.3687,  0.2206,  0.5933]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 10752,  1997, 18856, 17322,  2015,  1998, 18691,  6447,\n",
      "          2008,  3849, 13567,  5476,  3372,  1999,  2049, 21014,  5956,  1998,\n",
      "         23397,  1012,   102],\n",
      "        [  101,  1037, 11259,  1998,  2092,  1011, 19275,  1006,  2005,  1996,\n",
      "          2087,  2112,  1007, 10720,  2121,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 10752,  1997, 18856, 17322,  2015,  1998, 18691,  6447,\n",
      "          2008,  3849, 13567,  5476,  3372,  1999,  2049, 21014,  5956,  1998,\n",
      "         23397,  1012,   102],\n",
      "        [  101,  1037, 11259,  1998,  2092,  1011, 19275,  1006,  2005,  1996,\n",
      "          2087,  2112,  1007, 10720,  2121,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2672, 0.7328],\n",
      "        [0.2739, 0.7261]]), 'input_ids': tensor([[  101,  1037, 10752,  1997, 18856, 17322,  2015,  1998, 18691,  6447,\n",
      "          2008,  3849, 13567,  5476,  3372,  1999,  2049, 21014,  5956,  1998,\n",
      "         23397,  1012,   102],\n",
      "        [  101,  1037, 11259,  1998,  2092,  1011, 19275,  1006,  2005,  1996,\n",
      "          2087,  2112,  1007, 10720,  2121,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([23, 17]), 'cls_emb': tensor([[-0.1936,  0.0045, -0.0874,  ..., -0.4880,  0.4359,  0.3103],\n",
      "        [-0.5307, -0.3641, -0.3038,  ..., -0.2846,  0.2286,  0.3656]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2038,  1037,  2843,  1997,  1996, 21560,  1997, 24201,  2012,\n",
      "          2010,  2190,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055, 22532,  2011,  1037,  6480,  1011,  3149,\n",
      "          2785,  1997,  5436,  1998,  1037,  2599,  3883,  2040,  2003,  2041,\n",
      "          1997,  2014,  5995,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2038,  1037,  2843,  1997,  1996, 21560,  1997, 24201,  2012,\n",
      "          2010,  2190,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055, 22532,  2011,  1037,  6480,  1011,  3149,\n",
      "          2785,  1997,  5436,  1998,  1037,  2599,  3883,  2040,  2003,  2041,\n",
      "          1997,  2014,  5995,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2475, 0.7525],\n",
      "        [0.2730, 0.7270]]), 'input_ids': tensor([[  101,  2038,  1037,  2843,  1997,  1996, 21560,  1997, 24201,  2012,\n",
      "          2010,  2190,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055, 22532,  2011,  1037,  6480,  1011,  3149,\n",
      "          2785,  1997,  5436,  1998,  1037,  2599,  3883,  2040,  2003,  2041,\n",
      "          1997,  2014,  5995,  1012,   102]]), 'ntok': tensor([14, 25]), 'cls_emb': tensor([[-0.4671,  0.1433, -0.1447,  ..., -0.3195,  0.9282, -0.1142],\n",
      "        [-0.1024, -0.3896, -0.1169,  ..., -0.5727,  0.7629,  0.4899]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  5683,  2066,  2019,  2044,  1011,  2082,  2569, 12670,\n",
      "         11741,  2094,  2039,  2007,  2070, 11281,  2569,  3896,  1010,  1998,\n",
      "          3666,  2049, 18672,  2063,  5436,  2685,  7532,  2003,  2055,  2004,\n",
      "         10990,  2004, 16448,  2012,  2019,  8288, 25309,  2005,  6109,  2781,\n",
      "          1012,   102],\n",
      "        [  101,  2005,  1996,  2087,  2112,  1010,  2472,  4776,  1011,  8234,\n",
      "         12170, 21709,  1005,  1055,  2034,  3444,  2003,  1037,  7591,  1010,\n",
      "          4469,  8551,  3981, 11272,  2092,  1011,  6051,  3689,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  5683,  2066,  2019,  2044,  1011,  2082,  2569, 12670,\n",
      "         11741,  2094,  2039,  2007,  2070, 11281,  2569,  3896,  1010,  1998,\n",
      "          3666,  2049, 18672,  2063,  5436,  2685,  7532,  2003,  2055,  2004,\n",
      "         10990,  2004, 16448,  2012,  2019,  8288, 25309,  2005,  6109,  2781,\n",
      "          1012,   102],\n",
      "        [  101,  2005,  1996,  2087,  2112,  1010,  2472,  4776,  1011,  8234,\n",
      "         12170, 21709,  1005,  1055,  2034,  3444,  2003,  1037,  7591,  1010,\n",
      "          4469,  8551,  3981, 11272,  2092,  1011,  6051,  3689,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2426, 0.7574],\n",
      "        [0.2550, 0.7450]]), 'input_ids': tensor([[  101,  2009,  5683,  2066,  2019,  2044,  1011,  2082,  2569, 12670,\n",
      "         11741,  2094,  2039,  2007,  2070, 11281,  2569,  3896,  1010,  1998,\n",
      "          3666,  2049, 18672,  2063,  5436,  2685,  7532,  2003,  2055,  2004,\n",
      "         10990,  2004, 16448,  2012,  2019,  8288, 25309,  2005,  6109,  2781,\n",
      "          1012,   102],\n",
      "        [  101,  2005,  1996,  2087,  2112,  1010,  2472,  4776,  1011,  8234,\n",
      "         12170, 21709,  1005,  1055,  2034,  3444,  2003,  1037,  7591,  1010,\n",
      "          4469,  8551,  3981, 11272,  2092,  1011,  6051,  3689,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([42, 30]), 'cls_emb': tensor([[ 0.2527, -0.0537,  0.1480,  ...,  0.0352,  0.3248,  0.6703],\n",
      "        [-0.3226,  0.0094, -0.4888,  ..., -0.2193,  0.2728,  0.6883]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2720,  1012, 24529,  4886,  2003,  1037,  2200,  2434,  3063,\n",
      "          1999,  2010,  5396,  1010,  1998,  2054,  2051,  2003,  2009,  2045,\n",
      "          1029,   102],\n",
      "        [  101,  6517,  2063,  2003,  2019, 11973,  2298,  2012,  1996,  6801,\n",
      "         15248,  1998, 16265, 23503,  2594,  5394,  1012,   102,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2720,  1012, 24529,  4886,  2003,  1037,  2200,  2434,  3063,\n",
      "          1999,  2010,  5396,  1010,  1998,  2054,  2051,  2003,  2009,  2045,\n",
      "          1029,   102],\n",
      "        [  101,  6517,  2063,  2003,  2019, 11973,  2298,  2012,  1996,  6801,\n",
      "         15248,  1998, 16265, 23503,  2594,  5394,  1012,   102,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2589, 0.7411],\n",
      "        [0.2615, 0.7385]]), 'input_ids': tensor([[  101,  2720,  1012, 24529,  4886,  2003,  1037,  2200,  2434,  3063,\n",
      "          1999,  2010,  5396,  1010,  1998,  2054,  2051,  2003,  2009,  2045,\n",
      "          1029,   102],\n",
      "        [  101,  6517,  2063,  2003,  2019, 11973,  2298,  2012,  1996,  6801,\n",
      "         15248,  1998, 16265, 23503,  2594,  5394,  1012,   102,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([22, 18]), 'cls_emb': tensor([[-0.0398, -0.0686,  0.0404,  ..., -0.2775,  0.4855,  0.8209],\n",
      "        [-0.4756,  0.1187, -0.7294,  ..., -0.1777,  0.7596,  0.4178]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2061, 22808,  1997,  2151,  2785,  1997, 13420,  3669, 18507,\n",
      "          2466,  2008,  2009,  3084,  3152,  2066, 22038,  2595,  1998, 24172,\n",
      "          4053,  4025,  2066, 16465, 15326,  2015,   102],\n",
      "        [  101,  1037,  8616,  1010,  2540, 26675,  2155,  3689,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2061, 22808,  1997,  2151,  2785,  1997, 13420,  3669, 18507,\n",
      "          2466,  2008,  2009,  3084,  3152,  2066, 22038,  2595,  1998, 24172,\n",
      "          4053,  4025,  2066, 16465, 15326,  2015,   102],\n",
      "        [  101,  1037,  8616,  1010,  2540, 26675,  2155,  3689,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2513, 0.7487],\n",
      "        [0.2880, 0.7120]]), 'input_ids': tensor([[  101,  2061, 22808,  1997,  2151,  2785,  1997, 13420,  3669, 18507,\n",
      "          2466,  2008,  2009,  3084,  3152,  2066, 22038,  2595,  1998, 24172,\n",
      "          4053,  4025,  2066, 16465, 15326,  2015,   102],\n",
      "        [  101,  1037,  8616,  1010,  2540, 26675,  2155,  3689,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([27, 10]), 'cls_emb': tensor([[ 0.2406,  0.0430, -0.0856,  ..., -0.0143,  0.5265,  0.6613],\n",
      "        [-0.5686, -0.3747, -0.2193,  ..., -0.5732,  0.3004,  0.3248]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1037,  8892,  8257,  2409,  2011,  1037,\n",
      "         21014, 25055,  2383,  2205,  2172,  4569,  7861, 17327, 21837,  1996,\n",
      "         28616,  4630,  8093,  7361,  2594,  6925,  2000,  2941,  8526,  2009,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  3147,  4977,  2052,  1005,  2310,  2042,  1037,  2521,\n",
      "          2488,  2516,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1037,  8892,  8257,  2409,  2011,  1037,\n",
      "         21014, 25055,  2383,  2205,  2172,  4569,  7861, 17327, 21837,  1996,\n",
      "         28616,  4630,  8093,  7361,  2594,  6925,  2000,  2941,  8526,  2009,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  3147,  4977,  2052,  1005,  2310,  2042,  1037,  2521,\n",
      "          2488,  2516,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2506, 0.7494],\n",
      "        [0.2957, 0.7043]]), 'input_ids': tensor([[  101,  1012,  1012,  1012,  1037,  8892,  8257,  2409,  2011,  1037,\n",
      "         21014, 25055,  2383,  2205,  2172,  4569,  7861, 17327, 21837,  1996,\n",
      "         28616,  4630,  8093,  7361,  2594,  6925,  2000,  2941,  8526,  2009,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  3147,  4977,  2052,  1005,  2310,  2042,  1037,  2521,\n",
      "          2488,  2516,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 14]), 'cls_emb': tensor([[ 0.2183,  0.1423, -0.3443,  ..., -0.1103,  0.4505,  0.7767],\n",
      "        [-0.1568, -0.0799, -0.1483,  ..., -0.2831,  0.3197,  0.1699]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  9020,  2000,  2022,  2119, 16360, 23004,  2135,  6517,  6553,\n",
      "          1998, 24684,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2074, 15640,  2135, 23105,  1011,  1011,\n",
      "          1037,  3185,  2008,  2038,  2035,  1996,  3787,  4072,  2000,  2022,\n",
      "          1037, 17160,  1010,  5994,  2839,  2817,  1010,  2021,  2196,  2515,\n",
      "          2062,  2084, 11969,  1996,  3302,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  9020,  2000,  2022,  2119, 16360, 23004,  2135,  6517,  6553,\n",
      "          1998, 24684,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2074, 15640,  2135, 23105,  1011,  1011,\n",
      "          1037,  3185,  2008,  2038,  2035,  1996,  3787,  4072,  2000,  2022,\n",
      "          1037, 17160,  1010,  5994,  2839,  2817,  1010,  2021,  2196,  2515,\n",
      "          2062,  2084, 11969,  1996,  3302,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2587, 0.7413],\n",
      "        [0.2445, 0.7555]]), 'input_ids': tensor([[  101,  9020,  2000,  2022,  2119, 16360, 23004,  2135,  6517,  6553,\n",
      "          1998, 24684,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2074, 15640,  2135, 23105,  1011,  1011,\n",
      "          1037,  3185,  2008,  2038,  2035,  1996,  3787,  4072,  2000,  2022,\n",
      "          1037, 17160,  1010,  5994,  2839,  2817,  1010,  2021,  2196,  2515,\n",
      "          2062,  2084, 11969,  1996,  3302,  1012,   102]]), 'ntok': tensor([14, 37]), 'cls_emb': tensor([[-0.1296, -0.0500, -0.5262,  ..., -0.2724,  0.3228,  0.2186],\n",
      "        [ 0.1887,  0.0904, -0.2758,  ...,  0.0406,  0.5807,  0.6423]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  1037,  2466,  1997,  2048, 28616,  8873,  3215,\n",
      "          2040,  2079,  1050,  1005,  1056,  3233,  1037,  3382,  2894,  1010,\n",
      "          2021,  2362,  2027,  2024, 12047,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8040, 25293, 12494,  2038,  2000,  2424,  2070,  8103,  2006,\n",
      "          2029,  2000,  6865,  2010, 14516,  2135, 11809,  5691,  1010,  1998,\n",
      "          2009,  2453,  2004,  2092,  2022,  1996, 24501,  2271, 26243,  3370,\n",
      "          1997,  1996,  2690,  1011,  4793,  2839,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  1037,  2466,  1997,  2048, 28616,  8873,  3215,\n",
      "          2040,  2079,  1050,  1005,  1056,  3233,  1037,  3382,  2894,  1010,\n",
      "          2021,  2362,  2027,  2024, 12047,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8040, 25293, 12494,  2038,  2000,  2424,  2070,  8103,  2006,\n",
      "          2029,  2000,  6865,  2010, 14516,  2135, 11809,  5691,  1010,  1998,\n",
      "          2009,  2453,  2004,  2092,  2022,  1996, 24501,  2271, 26243,  3370,\n",
      "          1997,  1996,  2690,  1011,  4793,  2839,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2438, 0.7562],\n",
      "        [0.2576, 0.7424]]), 'input_ids': tensor([[  101,  2023,  2003,  1037,  2466,  1997,  2048, 28616,  8873,  3215,\n",
      "          2040,  2079,  1050,  1005,  1056,  3233,  1037,  3382,  2894,  1010,\n",
      "          2021,  2362,  2027,  2024, 12047,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  8040, 25293, 12494,  2038,  2000,  2424,  2070,  8103,  2006,\n",
      "          2029,  2000,  6865,  2010, 14516,  2135, 11809,  5691,  1010,  1998,\n",
      "          2009,  2453,  2004,  2092,  2022,  1996, 24501,  2271, 26243,  3370,\n",
      "          1997,  1996,  2690,  1011,  4793,  2839,  1012,   102]]), 'ntok': tensor([27, 38]), 'cls_emb': tensor([[ 0.1040,  0.0692, -0.3162,  ..., -0.4078,  0.4391,  0.3943],\n",
      "        [-0.1904,  0.1665, -0.1766,  ...,  0.0749,  0.6824,  0.6659]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996, 10968,  2486,  1997,  2023,  2143,  3849,  2000, 11957,\n",
      "          2039,  2013,  1996,  6565,  7268,  3638,  1997,  1996, 26622,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2006,  2023, 24026,  8476,  1010, 18819, 15049,  2003,  2200,\n",
      "          2172,  1037,  3357,  1999,  1996,  2157,  3257,  1010,  2007,  2049,\n",
      "         12586,  1997,  3581,  2791,  1010,  2942,  3012,  1998, 15398,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996, 10968,  2486,  1997,  2023,  2143,  3849,  2000, 11957,\n",
      "          2039,  2013,  1996,  6565,  7268,  3638,  1997,  1996, 26622,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2006,  2023, 24026,  8476,  1010, 18819, 15049,  2003,  2200,\n",
      "          2172,  1037,  3357,  1999,  1996,  2157,  3257,  1010,  2007,  2049,\n",
      "         12586,  1997,  3581,  2791,  1010,  2942,  3012,  1998, 15398,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2521, 0.7479],\n",
      "        [0.2586, 0.7414]]), 'input_ids': tensor([[  101,  1996, 10968,  2486,  1997,  2023,  2143,  3849,  2000, 11957,\n",
      "          2039,  2013,  1996,  6565,  7268,  3638,  1997,  1996, 26622,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2006,  2023, 24026,  8476,  1010, 18819, 15049,  2003,  2200,\n",
      "          2172,  1037,  3357,  1999,  1996,  2157,  3257,  1010,  2007,  2049,\n",
      "         12586,  1997,  3581,  2791,  1010,  2942,  3012,  1998, 15398,  1012,\n",
      "           102]]), 'ntok': tensor([21, 31]), 'cls_emb': tensor([[-0.0599,  0.0717, -0.0383,  ..., -0.2876,  0.3542,  0.3742],\n",
      "        [-0.1916,  0.1297, -0.4111,  ..., -0.1969,  0.2957,  0.5487]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  5896, 14590,  1999,  1010,  1998,  2720,  1012, 20955,\n",
      "          1005,  1055,  4487, 16173,  5732,  6393,  1998,  3329,  1011, 11920,\n",
      "         17900,  3582,  1012,   102],\n",
      "        [  101,  2017,  4687,  2339,  2438,  2001,  1050,  1005,  1056,  2074,\n",
      "          1037,  2189,  2678,  2738,  2084,  1037,  2440,  1011,  3091,  3185,\n",
      "          1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  5896, 14590,  1999,  1010,  1998,  2720,  1012, 20955,\n",
      "          1005,  1055,  4487, 16173,  5732,  6393,  1998,  3329,  1011, 11920,\n",
      "         17900,  3582,  1012,   102],\n",
      "        [  101,  2017,  4687,  2339,  2438,  2001,  1050,  1005,  1056,  2074,\n",
      "          1037,  2189,  2678,  2738,  2084,  1037,  2440,  1011,  3091,  3185,\n",
      "          1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2694, 0.7306],\n",
      "        [0.2768, 0.7232]]), 'input_ids': tensor([[  101,  1996,  5896, 14590,  1999,  1010,  1998,  2720,  1012, 20955,\n",
      "          1005,  1055,  4487, 16173,  5732,  6393,  1998,  3329,  1011, 11920,\n",
      "         17900,  3582,  1012,   102],\n",
      "        [  101,  2017,  4687,  2339,  2438,  2001,  1050,  1005,  1056,  2074,\n",
      "          1037,  2189,  2678,  2738,  2084,  1037,  2440,  1011,  3091,  3185,\n",
      "          1012,   102,     0,     0]]), 'ntok': tensor([24, 22]), 'cls_emb': tensor([[ 0.1405,  0.2237,  0.4273,  ..., -0.3757,  0.2203,  0.5792],\n",
      "        [ 0.3547, -0.1933, -0.2028,  ..., -0.2968,  0.4289,  0.3133]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2065,  2017,  1005,  2128,  2524,  2039,  2005, 10958,  4609,\n",
      "         11714,  2267,  8562,  1010,  2023,  2003,  2115,  7281,  2157,  2182,\n",
      "          1012,   102],\n",
      "        [  101,  1037,  3435,  1010,  6057,  1010,  3811, 22249,  3185,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2065,  2017,  1005,  2128,  2524,  2039,  2005, 10958,  4609,\n",
      "         11714,  2267,  8562,  1010,  2023,  2003,  2115,  7281,  2157,  2182,\n",
      "          1012,   102],\n",
      "        [  101,  1037,  3435,  1010,  6057,  1010,  3811, 22249,  3185,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2627, 0.7373],\n",
      "        [0.2501, 0.7499]]), 'input_ids': tensor([[  101,  2065,  2017,  1005,  2128,  2524,  2039,  2005, 10958,  4609,\n",
      "         11714,  2267,  8562,  1010,  2023,  2003,  2115,  7281,  2157,  2182,\n",
      "          1012,   102],\n",
      "        [  101,  1037,  3435,  1010,  6057,  1010,  3811, 22249,  3185,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([22, 11]), 'cls_emb': tensor([[-0.0221,  0.0653, -0.2352,  ..., -0.1899,  0.0287,  0.2951],\n",
      "        [-0.6481, -0.6643, -0.1377,  ..., -0.6068,  0.3846,  0.2193]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2204,  2214,  1011, 13405, 18296,  1011,  1998,  1011, 20578,\n",
      "          2003,  2067,   999,   102,     0,     0,     0],\n",
      "        [  101,  2023,  2028,  2003,  5791,  2028,  2000, 13558,  1010,  2130,\n",
      "          2005,  5469,  3185,  5470, 17592,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2204,  2214,  1011, 13405, 18296,  1011,  1998,  1011, 20578,\n",
      "          2003,  2067,   999,   102,     0,     0,     0],\n",
      "        [  101,  2023,  2028,  2003,  5791,  2028,  2000, 13558,  1010,  2130,\n",
      "          2005,  5469,  3185,  5470, 17592,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2804, 0.7196],\n",
      "        [0.2512, 0.7488]]), 'input_ids': tensor([[  101,  2204,  2214,  1011, 13405, 18296,  1011,  1998,  1011, 20578,\n",
      "          2003,  2067,   999,   102,     0,     0,     0],\n",
      "        [  101,  2023,  2028,  2003,  5791,  2028,  2000, 13558,  1010,  2130,\n",
      "          2005,  5469,  3185,  5470, 17592,  1012,   102]]), 'ntok': tensor([14, 17]), 'cls_emb': tensor([[ 0.0759,  0.1106,  0.0337,  ..., -0.1050,  0.1073,  0.4534],\n",
      "        [ 0.2392, -0.3013, -0.0050,  ...,  0.1523,  0.3393,  0.4077]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2005,  2035,  2049,  8052, 26286,  9650,  1010,  1998,  2750,\n",
      "          2019,  2058,  4783, 22397,  2186,  1997,  2353,  1011,  2552, 13675,\n",
      "          2229, 23865,  2891,  1010,  7094, 16480,  2226,  1011, 16480,  2226,\n",
      "          2196,  2428, 16473,  2039,  1037,  2132,  1997,  6832,  5492,  1012,\n",
      "           102],\n",
      "        [  101, 19401,  2135, 16371,  6651,  2094,  1999,  6888, 14841,  6169,\n",
      "          1998,  7982,  1010,  2023,  4574,  3689,  2003, 21688,  2135,  6051,\n",
      "          2011,  1996,  6171, 16004,  8003, 26700,  1998,  1996, 27017,  2021,\n",
      "          3243,  2529,  4068,  2290,  1012,   102,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2005,  2035,  2049,  8052, 26286,  9650,  1010,  1998,  2750,\n",
      "          2019,  2058,  4783, 22397,  2186,  1997,  2353,  1011,  2552, 13675,\n",
      "          2229, 23865,  2891,  1010,  7094, 16480,  2226,  1011, 16480,  2226,\n",
      "          2196,  2428, 16473,  2039,  1037,  2132,  1997,  6832,  5492,  1012,\n",
      "           102],\n",
      "        [  101, 19401,  2135, 16371,  6651,  2094,  1999,  6888, 14841,  6169,\n",
      "          1998,  7982,  1010,  2023,  4574,  3689,  2003, 21688,  2135,  6051,\n",
      "          2011,  1996,  6171, 16004,  8003, 26700,  1998,  1996, 27017,  2021,\n",
      "          3243,  2529,  4068,  2290,  1012,   102,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2489, 0.7511],\n",
      "        [0.2605, 0.7395]]), 'input_ids': tensor([[  101,  2005,  2035,  2049,  8052, 26286,  9650,  1010,  1998,  2750,\n",
      "          2019,  2058,  4783, 22397,  2186,  1997,  2353,  1011,  2552, 13675,\n",
      "          2229, 23865,  2891,  1010,  7094, 16480,  2226,  1011, 16480,  2226,\n",
      "          2196,  2428, 16473,  2039,  1037,  2132,  1997,  6832,  5492,  1012,\n",
      "           102],\n",
      "        [  101, 19401,  2135, 16371,  6651,  2094,  1999,  6888, 14841,  6169,\n",
      "          1998,  7982,  1010,  2023,  4574,  3689,  2003, 21688,  2135,  6051,\n",
      "          2011,  1996,  6171, 16004,  8003, 26700,  1998,  1996, 27017,  2021,\n",
      "          3243,  2529,  4068,  2290,  1012,   102,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([41, 36]), 'cls_emb': tensor([[-0.2165, -0.3248, -0.4117,  ..., -0.3505,  0.3842,  0.6949],\n",
      "        [-0.3674,  0.0360, -0.0955,  ..., -0.4429,  0.1874,  0.4925]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3594,  2152,  4038,  2000, 23408, 11045, 11341, 13433, 23773,\n",
      "          6651,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1997, 19815, 10458,  1010, 11228, 10458,  5691,  2000,\n",
      "          2272,  2247,  1999,  1037,  2146,  1010,  2146,  2051,  1010,  4089,\n",
      "          6538,  2075, 10503,  6965,  2030,  1996,  2500,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3594,  2152,  4038,  2000, 23408, 11045, 11341, 13433, 23773,\n",
      "          6651,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1997, 19815, 10458,  1010, 11228, 10458,  5691,  2000,\n",
      "          2272,  2247,  1999,  1037,  2146,  1010,  2146,  2051,  1010,  4089,\n",
      "          6538,  2075, 10503,  6965,  2030,  1996,  2500,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2449, 0.7551],\n",
      "        [0.2679, 0.7321]]), 'input_ids': tensor([[  101,  3594,  2152,  4038,  2000, 23408, 11045, 11341, 13433, 23773,\n",
      "          6651,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1997, 19815, 10458,  1010, 11228, 10458,  5691,  2000,\n",
      "          2272,  2247,  1999,  1037,  2146,  1010,  2146,  2051,  1010,  4089,\n",
      "          6538,  2075, 10503,  6965,  2030,  1996,  2500,  1012,   102]]), 'ntok': tensor([13, 29]), 'cls_emb': tensor([[-0.4542,  0.1059, -0.7706,  ..., -0.3491,  0.1855,  0.1602],\n",
      "        [-0.1223, -0.2616, -0.1203,  ..., -0.2951,  0.5524,  0.0290]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  5164,  1997,  2128, 14949,  9072,  4356, 18201,  2015,\n",
      "          2241,  1999, 16021, 11514,  3593, 29364,  3012,  1012,   102],\n",
      "        [  101,  2426,  1996,  2095,  1005,  1055,  2087, 23824,  8993,  2015,\n",
      "          1997,  7344, 12516,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  5164,  1997,  2128, 14949,  9072,  4356, 18201,  2015,\n",
      "          2241,  1999, 16021, 11514,  3593, 29364,  3012,  1012,   102],\n",
      "        [  101,  2426,  1996,  2095,  1005,  1055,  2087, 23824,  8993,  2015,\n",
      "          1997,  7344, 12516,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2784, 0.7216],\n",
      "        [0.2722, 0.7278]]), 'input_ids': tensor([[  101,  1037,  5164,  1997,  2128, 14949,  9072,  4356, 18201,  2015,\n",
      "          2241,  1999, 16021, 11514,  3593, 29364,  3012,  1012,   102],\n",
      "        [  101,  2426,  1996,  2095,  1005,  1055,  2087, 23824,  8993,  2015,\n",
      "          1997,  7344, 12516,  1012,   102,     0,     0,     0,     0]]), 'ntok': tensor([19, 15]), 'cls_emb': tensor([[-0.2319,  0.2636, -0.4428,  ..., -0.2755,  0.5033,  0.0841],\n",
      "        [-0.5375, -0.1430, -0.1671,  ..., -0.1555,  0.4511,  0.0861]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185, 11896,  2000,  2444,  2039,  2000,  1996,  7680,\n",
      "          1997,  2049,  3033,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  2365,  1005,  1055,  2282,  2003,  1037, 10911,  1997,\n",
      "          8991, 18724,  2008,  7796,  2015,  2049,  5312,  1997,  4130,  2891,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185, 11896,  2000,  2444,  2039,  2000,  1996,  7680,\n",
      "          1997,  2049,  3033,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  2365,  1005,  1055,  2282,  2003,  1037, 10911,  1997,\n",
      "          8991, 18724,  2008,  7796,  2015,  2049,  5312,  1997,  4130,  2891,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2526, 0.7474],\n",
      "        [0.2539, 0.7461]]), 'input_ids': tensor([[  101,  1996,  3185, 11896,  2000,  2444,  2039,  2000,  1996,  7680,\n",
      "          1997,  2049,  3033,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  2365,  1005,  1055,  2282,  2003,  1037, 10911,  1997,\n",
      "          8991, 18724,  2008,  7796,  2015,  2049,  5312,  1997,  4130,  2891,\n",
      "          1012,   102]]), 'ntok': tensor([15, 22]), 'cls_emb': tensor([[-0.2008,  0.0800, -0.0308,  ..., -0.5575,  0.3869,  0.2985],\n",
      "        [-0.1355,  0.0340, -0.2081,  ..., -0.3413,  0.3314,  0.3402]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  2003,  2498,  5151,  2055,  2023,  2143,  1010,  2021,\n",
      "          2009,  2003,  2204,  2438,  1998,  2097,  3497,  2022, 12315,  2087,\n",
      "          2011, 11279,  1998, 12455,  2040,  2113,  2037,  2126,  2105,  1037,\n",
      "          6982,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2023,  2003,  1037,  3345, 12006,  1997,  2019,  2895,  2143,\n",
      "          1011,  1011,  1037, 24646,  5051, 14116,  3535,  2011,  1996, 16587,\n",
      "          2000,  2486,  1011,  5438,  2508,  5416,  2046,  1996,  2568,  3238,\n",
      "         22038,  2595, 18282,  1998,  5466,  2871,  2086,  1997, 21014,  2381,\n",
      "          2091,  1996, 11848,  1999,  5684,  1997,  4408, 16121,  1998,  5189,\n",
      "         28490,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  2003,  2498,  5151,  2055,  2023,  2143,  1010,  2021,\n",
      "          2009,  2003,  2204,  2438,  1998,  2097,  3497,  2022, 12315,  2087,\n",
      "          2011, 11279,  1998, 12455,  2040,  2113,  2037,  2126,  2105,  1037,\n",
      "          6982,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2023,  2003,  1037,  3345, 12006,  1997,  2019,  2895,  2143,\n",
      "          1011,  1011,  1037, 24646,  5051, 14116,  3535,  2011,  1996, 16587,\n",
      "          2000,  2486,  1011,  5438,  2508,  5416,  2046,  1996,  2568,  3238,\n",
      "         22038,  2595, 18282,  1998,  5466,  2871,  2086,  1997, 21014,  2381,\n",
      "          2091,  1996, 11848,  1999,  5684,  1997,  4408, 16121,  1998,  5189,\n",
      "         28490,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2291, 0.7709],\n",
      "        [0.2511, 0.7489]]), 'input_ids': tensor([[  101,  2045,  2003,  2498,  5151,  2055,  2023,  2143,  1010,  2021,\n",
      "          2009,  2003,  2204,  2438,  1998,  2097,  3497,  2022, 12315,  2087,\n",
      "          2011, 11279,  1998, 12455,  2040,  2113,  2037,  2126,  2105,  1037,\n",
      "          6982,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2023,  2003,  1037,  3345, 12006,  1997,  2019,  2895,  2143,\n",
      "          1011,  1011,  1037, 24646,  5051, 14116,  3535,  2011,  1996, 16587,\n",
      "          2000,  2486,  1011,  5438,  2508,  5416,  2046,  1996,  2568,  3238,\n",
      "         22038,  2595, 18282,  1998,  5466,  2871,  2086,  1997, 21014,  2381,\n",
      "          2091,  1996, 11848,  1999,  5684,  1997,  4408, 16121,  1998,  5189,\n",
      "         28490,  1012,   102]]), 'ntok': tensor([33, 53]), 'cls_emb': tensor([[ 0.0563, -0.4093,  0.0749,  ..., -0.1472,  0.1099,  0.4659],\n",
      "        [ 0.1605,  0.1699, -0.2001,  ...,  0.0467,  0.8713,  0.5428]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  4009,  1006,  2005,  1036,  1036,  2502,  2919,  2293,\n",
      "          1005,  1005,  1007,  2003,  1037,  5024,  2836,  2011, 12098,  6856,\n",
      "          2015,  4922,  1012,   102,     0,     0],\n",
      "        [  101,  2665,  2453,  2215,  2000,  6865,  3031,  2008,  8301,  7308,\n",
      "          1010,  2004, 13742,  2089,  2022,  1996,  2069,  2126,  2000,  3477,\n",
      "          2005,  2010,  2279,  2622,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  4009,  1006,  2005,  1036,  1036,  2502,  2919,  2293,\n",
      "          1005,  1005,  1007,  2003,  1037,  5024,  2836,  2011, 12098,  6856,\n",
      "          2015,  4922,  1012,   102,     0,     0],\n",
      "        [  101,  2665,  2453,  2215,  2000,  6865,  3031,  2008,  8301,  7308,\n",
      "          1010,  2004, 13742,  2089,  2022,  1996,  2069,  2126,  2000,  3477,\n",
      "          2005,  2010,  2279,  2622,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2751, 0.7249],\n",
      "        [0.2481, 0.7519]]), 'input_ids': tensor([[  101,  1996,  4009,  1006,  2005,  1036,  1036,  2502,  2919,  2293,\n",
      "          1005,  1005,  1007,  2003,  1037,  5024,  2836,  2011, 12098,  6856,\n",
      "          2015,  4922,  1012,   102,     0,     0],\n",
      "        [  101,  2665,  2453,  2215,  2000,  6865,  3031,  2008,  8301,  7308,\n",
      "          1010,  2004, 13742,  2089,  2022,  1996,  2069,  2126,  2000,  3477,\n",
      "          2005,  2010,  2279,  2622,  1012,   102]]), 'ntok': tensor([24, 26]), 'cls_emb': tensor([[-0.4122,  0.0937, -0.1891,  ..., -0.2091,  0.3651,  0.7118],\n",
      "        [ 0.2270, -0.0844,  0.1065,  ...,  0.0266,  0.2868,  0.4280]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2028, 22418,  1011,  4632,  2088,  2043,\n",
      "          2130,  6359,  1011, 10874,  2015,  7065,  4747,  3726,  2105,  2177,\n",
      "          7242,  6521,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2295,  2009,  1005,  1055,  2468,  2471, 21707,  2000,  2360,\n",
      "          2061,  1010,  2350, 13970, 12269,  2175,  2000, 11797,  2005,  2941,\n",
      "          9179,  2111,  2040,  2298,  2551,  1011,  2465,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2028, 22418,  1011,  4632,  2088,  2043,\n",
      "          2130,  6359,  1011, 10874,  2015,  7065,  4747,  3726,  2105,  2177,\n",
      "          7242,  6521,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2295,  2009,  1005,  1055,  2468,  2471, 21707,  2000,  2360,\n",
      "          2061,  1010,  2350, 13970, 12269,  2175,  2000, 11797,  2005,  2941,\n",
      "          9179,  2111,  2040,  2298,  2551,  1011,  2465,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2539, 0.7461],\n",
      "        [0.2663, 0.7337]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2028, 22418,  1011,  4632,  2088,  2043,\n",
      "          2130,  6359,  1011, 10874,  2015,  7065,  4747,  3726,  2105,  2177,\n",
      "          7242,  6521,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2295,  2009,  1005,  1055,  2468,  2471, 21707,  2000,  2360,\n",
      "          2061,  1010,  2350, 13970, 12269,  2175,  2000, 11797,  2005,  2941,\n",
      "          9179,  2111,  2040,  2298,  2551,  1011,  2465,  1012,   102]]), 'ntok': tensor([24, 29]), 'cls_emb': tensor([[ 0.2491, -0.0380, -0.1469,  ..., -0.2505,  0.4296,  0.4179],\n",
      "        [ 0.1587,  0.0673, -0.2882,  ..., -0.2889,  0.4252,  0.8010]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2316,  1005,  1055,  8424,  1999,  1996,  2227,  1997,\n",
      "          2880, 22422,  2003, 18988,  1010,  2926,  2005, 12520,  5099, 13046,\n",
      "          1006,  2023,  2028,  2443,  1007,  1012,   102,     0],\n",
      "        [  101,  1996,  3185,  6162,  2015,  2004,  2307,  2019,  4254,  2011,\n",
      "          4363,  2122,  4301,  5023,  2004,  1012,  1012,  1012,  1006, 21864,\n",
      "         12718,  1007,  2106,  2011,  4760,  2068,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2316,  1005,  1055,  8424,  1999,  1996,  2227,  1997,\n",
      "          2880, 22422,  2003, 18988,  1010,  2926,  2005, 12520,  5099, 13046,\n",
      "          1006,  2023,  2028,  2443,  1007,  1012,   102,     0],\n",
      "        [  101,  1996,  3185,  6162,  2015,  2004,  2307,  2019,  4254,  2011,\n",
      "          4363,  2122,  4301,  5023,  2004,  1012,  1012,  1012,  1006, 21864,\n",
      "         12718,  1007,  2106,  2011,  4760,  2068,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2414, 0.7586],\n",
      "        [0.2656, 0.7344]]), 'input_ids': tensor([[  101,  1996,  2316,  1005,  1055,  8424,  1999,  1996,  2227,  1997,\n",
      "          2880, 22422,  2003, 18988,  1010,  2926,  2005, 12520,  5099, 13046,\n",
      "          1006,  2023,  2028,  2443,  1007,  1012,   102,     0],\n",
      "        [  101,  1996,  3185,  6162,  2015,  2004,  2307,  2019,  4254,  2011,\n",
      "          4363,  2122,  4301,  5023,  2004,  1012,  1012,  1012,  1006, 21864,\n",
      "         12718,  1007,  2106,  2011,  4760,  2068,  1012,   102]]), 'ntok': tensor([27, 28]), 'cls_emb': tensor([[ 9.2633e-02,  2.9919e-01, -4.2467e-01,  ..., -1.2752e-01,\n",
      "          2.4396e-01, -2.5801e-01],\n",
      "        [-6.2115e-04,  3.8057e-01, -2.7525e-01,  ..., -5.0821e-01,\n",
      "          2.4649e-01,  6.2614e-01]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2143,  4257,  3210,  2043,  2009,  2323,  4672,  1998,\n",
      "          2003,  2062,  4771,  4495,  1998, 13012, 21031,  2084,  2601,  1010,\n",
      "          5476,  3372, 19817, 16093, 21031,  1012,   102],\n",
      "        [  101, 14855, 23296,  5358,  1012,  1012,  1012,  2404,  1006,  1055,\n",
      "          1007,  1996,  4378,  1999,  1996, 21598,  2597,  1997, 19413,  6961,\n",
      "         25711,  4691,  2006,  2010,  3494,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2143,  4257,  3210,  2043,  2009,  2323,  4672,  1998,\n",
      "          2003,  2062,  4771,  4495,  1998, 13012, 21031,  2084,  2601,  1010,\n",
      "          5476,  3372, 19817, 16093, 21031,  1012,   102],\n",
      "        [  101, 14855, 23296,  5358,  1012,  1012,  1012,  2404,  1006,  1055,\n",
      "          1007,  1996,  4378,  1999,  1996, 21598,  2597,  1997, 19413,  6961,\n",
      "         25711,  4691,  2006,  2010,  3494,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2697, 0.7303],\n",
      "        [0.2750, 0.7250]]), 'input_ids': tensor([[  101,  1996,  2143,  4257,  3210,  2043,  2009,  2323,  4672,  1998,\n",
      "          2003,  2062,  4771,  4495,  1998, 13012, 21031,  2084,  2601,  1010,\n",
      "          5476,  3372, 19817, 16093, 21031,  1012,   102],\n",
      "        [  101, 14855, 23296,  5358,  1012,  1012,  1012,  2404,  1006,  1055,\n",
      "          1007,  1996,  4378,  1999,  1996, 21598,  2597,  1997, 19413,  6961,\n",
      "         25711,  4691,  2006,  2010,  3494,   102,     0]]), 'ntok': tensor([27, 26]), 'cls_emb': tensor([[-0.1215,  0.0400, -0.2334,  ..., -0.3921,  0.3150,  0.5206],\n",
      "        [-0.1219,  0.4548, -0.2123,  ..., -0.4384,  0.3076,  0.4803]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 10424,  2229, 25389, 10486,  1005,  1055,  2601,  1998, 22538,\n",
      "          2075,  4871,  2031,  1037,  2126,  1997, 20228, 14147,  2046,  2115,\n",
      "         27952,  2066,  1996, 10103,  2017,  2018,  1037,  2733,  3283,  2008,\n",
      "         24185,  1050,  1005,  1056,  2175,  2185,  1012,   102],\n",
      "        [  101,  2057,  2113,  1996,  5436,  1005,  1055,  1037,  2210,  4689,\n",
      "          1010,  2021,  2009,  2218,  2026,  3037,  2013,  2707,  2000,  3926,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 10424,  2229, 25389, 10486,  1005,  1055,  2601,  1998, 22538,\n",
      "          2075,  4871,  2031,  1037,  2126,  1997, 20228, 14147,  2046,  2115,\n",
      "         27952,  2066,  1996, 10103,  2017,  2018,  1037,  2733,  3283,  2008,\n",
      "         24185,  1050,  1005,  1056,  2175,  2185,  1012,   102],\n",
      "        [  101,  2057,  2113,  1996,  5436,  1005,  1055,  1037,  2210,  4689,\n",
      "          1010,  2021,  2009,  2218,  2026,  3037,  2013,  2707,  2000,  3926,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2665, 0.7335],\n",
      "        [0.2579, 0.7421]]), 'input_ids': tensor([[  101, 10424,  2229, 25389, 10486,  1005,  1055,  2601,  1998, 22538,\n",
      "          2075,  4871,  2031,  1037,  2126,  1997, 20228, 14147,  2046,  2115,\n",
      "         27952,  2066,  1996, 10103,  2017,  2018,  1037,  2733,  3283,  2008,\n",
      "         24185,  1050,  1005,  1056,  2175,  2185,  1012,   102],\n",
      "        [  101,  2057,  2113,  1996,  5436,  1005,  1055,  1037,  2210,  4689,\n",
      "          1010,  2021,  2009,  2218,  2026,  3037,  2013,  2707,  2000,  3926,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([38, 22]), 'cls_emb': tensor([[ 0.0579,  0.0015, -0.3246,  ..., -0.0582,  0.1765,  0.7340],\n",
      "        [ 0.2152, -0.2565, -0.0492,  ...,  0.0011,  0.5180,  0.4878]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  8040, 20097, 19040,  6771,  1010,\n",
      "          2021,  2043,  2009,  4978,  2049,  2928,  2009,  1005,  1055,  8235,\n",
      "          1012,   102],\n",
      "        [  101,  6684,  1037, 17743,  1010,  2021,  2009, 13999,  7193,  2000,\n",
      "          1037,  2204, 11128,  6960,  1998,  2070,  5875,  2613,  2111,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  8040, 20097, 19040,  6771,  1010,\n",
      "          2021,  2043,  2009,  4978,  2049,  2928,  2009,  1005,  1055,  8235,\n",
      "          1012,   102],\n",
      "        [  101,  6684,  1037, 17743,  1010,  2021,  2009, 13999,  7193,  2000,\n",
      "          1037,  2204, 11128,  6960,  1998,  2070,  5875,  2613,  2111,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2530, 0.7470],\n",
      "        [0.2670, 0.7330]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  8040, 20097, 19040,  6771,  1010,\n",
      "          2021,  2043,  2009,  4978,  2049,  2928,  2009,  1005,  1055,  8235,\n",
      "          1012,   102],\n",
      "        [  101,  6684,  1037, 17743,  1010,  2021,  2009, 13999,  7193,  2000,\n",
      "          1037,  2204, 11128,  6960,  1998,  2070,  5875,  2613,  2111,  1012,\n",
      "           102,     0]]), 'ntok': tensor([22, 21]), 'cls_emb': tensor([[ 0.2499,  0.1412, -0.0408,  ..., -0.2305,  0.1497,  0.8072],\n",
      "        [-0.0494, -0.1027,  0.2263,  ..., -0.2491,  0.3243,  0.5007]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2017, 24185,  1050,  1005,  1056,  2066,  5074,  1010,  2021,\n",
      "          2017,  2097,  2855,  6807,  2032,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2065,  7112,  2061,  4063,  4059,  2232,  1005,  1055,  1036,\n",
      "          5943,  2483,  1005,  2003,  1037,  4945,  2009,  2003,  1037, 14013,\n",
      "          4945,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2017, 24185,  1050,  1005,  1056,  2066,  5074,  1010,  2021,\n",
      "          2017,  2097,  2855,  6807,  2032,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2065,  7112,  2061,  4063,  4059,  2232,  1005,  1055,  1036,\n",
      "          5943,  2483,  1005,  2003,  1037,  4945,  2009,  2003,  1037, 14013,\n",
      "          4945,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2636, 0.7364],\n",
      "        [0.2376, 0.7624]]), 'input_ids': tensor([[  101,  2017, 24185,  1050,  1005,  1056,  2066,  5074,  1010,  2021,\n",
      "          2017,  2097,  2855,  6807,  2032,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2065,  7112,  2061,  4063,  4059,  2232,  1005,  1055,  1036,\n",
      "          5943,  2483,  1005,  2003,  1037,  4945,  2009,  2003,  1037, 14013,\n",
      "          4945,  1012,   102]]), 'ntok': tensor([17, 23]), 'cls_emb': tensor([[-0.1530, -0.1333, -0.4477,  ..., -0.2667,  0.4888,  0.6652],\n",
      "        [-0.2314,  0.1206, -0.3053,  ..., -0.2546,  0.4373,  0.7418]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2011,  3917,  7657,  2010,  3494,  1999,  1037,  2126,  2008,\n",
      "         20014, 22934,  1998,  2130,  6904, 11020, 28184,  2149,  1010,  1998,\n",
      "          2002,  2196, 13416,  1996,  3663,  2000,  3722, 11463,  7716, 14672,\n",
      "          1012,   102],\n",
      "        [  101,  2023, 15544, 19510,  2075,  2088,  2162,  2462,  7191, 23873,\n",
      "          2466,  9144,  2007,  1996,  5192,  2217,  1997,  2137,  3226,  1024,\n",
      "          5762, 18024,  1999,  2049,  9200,  1998,  7578,  3596,  1012,   102,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2011,  3917,  7657,  2010,  3494,  1999,  1037,  2126,  2008,\n",
      "         20014, 22934,  1998,  2130,  6904, 11020, 28184,  2149,  1010,  1998,\n",
      "          2002,  2196, 13416,  1996,  3663,  2000,  3722, 11463,  7716, 14672,\n",
      "          1012,   102],\n",
      "        [  101,  2023, 15544, 19510,  2075,  2088,  2162,  2462,  7191, 23873,\n",
      "          2466,  9144,  2007,  1996,  5192,  2217,  1997,  2137,  3226,  1024,\n",
      "          5762, 18024,  1999,  2049,  9200,  1998,  7578,  3596,  1012,   102,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2330, 0.7670],\n",
      "        [0.2544, 0.7456]]), 'input_ids': tensor([[  101,  2011,  3917,  7657,  2010,  3494,  1999,  1037,  2126,  2008,\n",
      "         20014, 22934,  1998,  2130,  6904, 11020, 28184,  2149,  1010,  1998,\n",
      "          2002,  2196, 13416,  1996,  3663,  2000,  3722, 11463,  7716, 14672,\n",
      "          1012,   102],\n",
      "        [  101,  2023, 15544, 19510,  2075,  2088,  2162,  2462,  7191, 23873,\n",
      "          2466,  9144,  2007,  1996,  5192,  2217,  1997,  2137,  3226,  1024,\n",
      "          5762, 18024,  1999,  2049,  9200,  1998,  7578,  3596,  1012,   102,\n",
      "             0,     0]]), 'ntok': tensor([32, 30]), 'cls_emb': tensor([[-0.1748,  0.1238, -0.8065,  ..., -0.2793,  0.5531,  0.7841],\n",
      "        [-0.0450,  0.1480, -0.5352,  ..., -0.2694,  0.5578,  0.3840]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  3697,  2000,  5674,  1996,  2832,  2008,\n",
      "          2550,  2107,  1037,  5896,  1010,  2021,  2182,  1005,  1055, 16986,\n",
      "          2008, 12509,  8808,  1998,  2104, 27292, 14950,  2209,  1037, 10232,\n",
      "          2535,  1012,   102],\n",
      "        [  101,  2053, 13758, 28702,  2005,  2472,  3520, 27916,  1010,  2040,\n",
      "          7367, 22967,  2013,  7436,  3453,  2000,  7436,  1011,  3045,  4022,\n",
      "          2007,  1037,  5744, 22889,  7416, 13900,  1997,  2192,  1012,   102,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  3697,  2000,  5674,  1996,  2832,  2008,\n",
      "          2550,  2107,  1037,  5896,  1010,  2021,  2182,  1005,  1055, 16986,\n",
      "          2008, 12509,  8808,  1998,  2104, 27292, 14950,  2209,  1037, 10232,\n",
      "          2535,  1012,   102],\n",
      "        [  101,  2053, 13758, 28702,  2005,  2472,  3520, 27916,  1010,  2040,\n",
      "          7367, 22967,  2013,  7436,  3453,  2000,  7436,  1011,  3045,  4022,\n",
      "          2007,  1037,  5744, 22889,  7416, 13900,  1997,  2192,  1012,   102,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2491, 0.7509],\n",
      "        [0.2832, 0.7168]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  3697,  2000,  5674,  1996,  2832,  2008,\n",
      "          2550,  2107,  1037,  5896,  1010,  2021,  2182,  1005,  1055, 16986,\n",
      "          2008, 12509,  8808,  1998,  2104, 27292, 14950,  2209,  1037, 10232,\n",
      "          2535,  1012,   102],\n",
      "        [  101,  2053, 13758, 28702,  2005,  2472,  3520, 27916,  1010,  2040,\n",
      "          7367, 22967,  2013,  7436,  3453,  2000,  7436,  1011,  3045,  4022,\n",
      "          2007,  1037,  5744, 22889,  7416, 13900,  1997,  2192,  1012,   102,\n",
      "             0,     0,     0]]), 'ntok': tensor([33, 30]), 'cls_emb': tensor([[ 0.0799, -0.1075, -0.3480,  ..., -0.2047,  0.4443,  0.5994],\n",
      "        [-0.1184, -0.4803, -0.4411,  ..., -0.4798,  0.6743,  0.3034]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2006,  1996,  2878,  1010,  1996,  3185, 14087, 15966,  1010,\n",
      "          3110,  1998, 19337,  2666,  3567,  8553,  2000, 19079,  2005,  2049,\n",
      "          4297,  7971,  4630, 20392,  2791,  1998,  7221, 23732,  1012,   102],\n",
      "        [  101,  2339,  2191,  1037,  4516,  2055,  2122, 14785,  3439,  4481,\n",
      "          1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2006,  1996,  2878,  1010,  1996,  3185, 14087, 15966,  1010,\n",
      "          3110,  1998, 19337,  2666,  3567,  8553,  2000, 19079,  2005,  2049,\n",
      "          4297,  7971,  4630, 20392,  2791,  1998,  7221, 23732,  1012,   102],\n",
      "        [  101,  2339,  2191,  1037,  4516,  2055,  2122, 14785,  3439,  4481,\n",
      "          1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2408, 0.7592],\n",
      "        [0.2736, 0.7264]]), 'input_ids': tensor([[  101,  2006,  1996,  2878,  1010,  1996,  3185, 14087, 15966,  1010,\n",
      "          3110,  1998, 19337,  2666,  3567,  8553,  2000, 19079,  2005,  2049,\n",
      "          4297,  7971,  4630, 20392,  2791,  1998,  7221, 23732,  1012,   102],\n",
      "        [  101,  2339,  2191,  1037,  4516,  2055,  2122, 14785,  3439,  4481,\n",
      "          1029,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([30, 12]), 'cls_emb': tensor([[-0.1426,  0.1323, -0.3738,  ..., -0.1664,  0.3576,  0.5439],\n",
      "        [-0.2091,  0.4296, -0.7709,  ..., -0.4584,  0.3533,  0.3354]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4445,  6262,  4496, 12729,  2003,  1037,  5171,  6298,  2599,\n",
      "          1010,  2021,  2027,  3288,  1037,  4840,  1010, 21864, 15952, 11084,\n",
      "          2000,  1996,  5675,  1012,   102,     0],\n",
      "        [  101,  2010,  2197,  3185,  2001, 13805,  3973,  6298,  1998,  2440,\n",
      "          1997, 27427, 20806,  3468,  4871,  1010,  2021,  2010,  6745,  2038,\n",
      "          2498,  2183,  2005,  2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4445,  6262,  4496, 12729,  2003,  1037,  5171,  6298,  2599,\n",
      "          1010,  2021,  2027,  3288,  1037,  4840,  1010, 21864, 15952, 11084,\n",
      "          2000,  1996,  5675,  1012,   102,     0],\n",
      "        [  101,  2010,  2197,  3185,  2001, 13805,  3973,  6298,  1998,  2440,\n",
      "          1997, 27427, 20806,  3468,  4871,  1010,  2021,  2010,  6745,  2038,\n",
      "          2498,  2183,  2005,  2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2496, 0.7504],\n",
      "        [0.2384, 0.7616]]), 'input_ids': tensor([[  101,  4445,  6262,  4496, 12729,  2003,  1037,  5171,  6298,  2599,\n",
      "          1010,  2021,  2027,  3288,  1037,  4840,  1010, 21864, 15952, 11084,\n",
      "          2000,  1996,  5675,  1012,   102,     0],\n",
      "        [  101,  2010,  2197,  3185,  2001, 13805,  3973,  6298,  1998,  2440,\n",
      "          1997, 27427, 20806,  3468,  4871,  1010,  2021,  2010,  6745,  2038,\n",
      "          2498,  2183,  2005,  2009,  1012,   102]]), 'ntok': tensor([25, 26]), 'cls_emb': tensor([[-0.4212, -0.4024, -0.6202,  ..., -0.3362,  0.6764,  0.4699],\n",
      "        [-0.0623, -0.1230, -0.1969,  ..., -0.1182,  0.5629,  0.4677]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2515,  6773,  2070, 13432,  4871,  1012,  1012,  1012,  1010,\n",
      "          2021,  5003, 10023,  9067,  3676,  2546,  7906,  2014,  3292,  2013,\n",
      "          1996,  3494,   102],\n",
      "        [  101,  1037, 13940,  3185,  1010,  2209,  2007,  4616,  2008,  2024,\n",
      "          2035,  2104,  9153,  3064,  1998,  7244,  1012,   102,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2515,  6773,  2070, 13432,  4871,  1012,  1012,  1012,  1010,\n",
      "          2021,  5003, 10023,  9067,  3676,  2546,  7906,  2014,  3292,  2013,\n",
      "          1996,  3494,   102],\n",
      "        [  101,  1037, 13940,  3185,  1010,  2209,  2007,  4616,  2008,  2024,\n",
      "          2035,  2104,  9153,  3064,  1998,  7244,  1012,   102,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2543, 0.7457],\n",
      "        [0.2501, 0.7499]]), 'input_ids': tensor([[  101,  2515,  6773,  2070, 13432,  4871,  1012,  1012,  1012,  1010,\n",
      "          2021,  5003, 10023,  9067,  3676,  2546,  7906,  2014,  3292,  2013,\n",
      "          1996,  3494,   102],\n",
      "        [  101,  1037, 13940,  3185,  1010,  2209,  2007,  4616,  2008,  2024,\n",
      "          2035,  2104,  9153,  3064,  1998,  7244,  1012,   102,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([23, 18]), 'cls_emb': tensor([[ 0.0970, -0.1526, -0.4592,  ..., -0.5214,  0.5317,  0.1541],\n",
      "        [-0.3751, -0.2872, -0.0051,  ..., -0.5395,  0.5663,  0.1415]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2028,  1997,  2216,  3598,  4620,  2073,\n",
      "          1996,  5394,  2003,  2358, 19419,  1010,  1996,  2564,  2003,  5776,\n",
      "          1010,  1996,  4268,  2024,  2004, 10140,  2004,  2035,  2131,  1011,\n",
      "          2041,  1998,  1996, 10238,  2114,  3112,  2024,  2146,  2438,  2000,\n",
      "         20014, 27605, 13701,  1010,  2021,  2460,  2438,  2000,  2191,  1037,\n",
      "          3959,  4025,  2825,  1012,   102],\n",
      "        [  101, 11566,  4248,  1011,  3013,  9260,  1998,  1037,  1038,  8017,\n",
      "          2075,  3082,  3384,  2172,  1997,  1996,  2051,  1010, 10272,  3849,\n",
      "          2000,  2022,  2104,  1996, 12492,  2008,  2002,  1005,  1055,  5008,\n",
      "          1996,  6745,  2291,  1997,  1037,  2091,  2678,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2028,  1997,  2216,  3598,  4620,  2073,\n",
      "          1996,  5394,  2003,  2358, 19419,  1010,  1996,  2564,  2003,  5776,\n",
      "          1010,  1996,  4268,  2024,  2004, 10140,  2004,  2035,  2131,  1011,\n",
      "          2041,  1998,  1996, 10238,  2114,  3112,  2024,  2146,  2438,  2000,\n",
      "         20014, 27605, 13701,  1010,  2021,  2460,  2438,  2000,  2191,  1037,\n",
      "          3959,  4025,  2825,  1012,   102],\n",
      "        [  101, 11566,  4248,  1011,  3013,  9260,  1998,  1037,  1038,  8017,\n",
      "          2075,  3082,  3384,  2172,  1997,  1996,  2051,  1010, 10272,  3849,\n",
      "          2000,  2022,  2104,  1996, 12492,  2008,  2002,  1005,  1055,  5008,\n",
      "          1996,  6745,  2291,  1997,  1037,  2091,  2678,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2596, 0.7404],\n",
      "        [0.2438, 0.7562]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2028,  1997,  2216,  3598,  4620,  2073,\n",
      "          1996,  5394,  2003,  2358, 19419,  1010,  1996,  2564,  2003,  5776,\n",
      "          1010,  1996,  4268,  2024,  2004, 10140,  2004,  2035,  2131,  1011,\n",
      "          2041,  1998,  1996, 10238,  2114,  3112,  2024,  2146,  2438,  2000,\n",
      "         20014, 27605, 13701,  1010,  2021,  2460,  2438,  2000,  2191,  1037,\n",
      "          3959,  4025,  2825,  1012,   102],\n",
      "        [  101, 11566,  4248,  1011,  3013,  9260,  1998,  1037,  1038,  8017,\n",
      "          2075,  3082,  3384,  2172,  1997,  1996,  2051,  1010, 10272,  3849,\n",
      "          2000,  2022,  2104,  1996, 12492,  2008,  2002,  1005,  1055,  5008,\n",
      "          1996,  6745,  2291,  1997,  1037,  2091,  2678,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([55, 39]), 'cls_emb': tensor([[ 0.1338, -0.2080, -0.3043,  ..., -0.2255,  0.4512,  0.6704],\n",
      "        [ 0.0670,  0.1476, -0.3686,  ..., -0.0978,  0.6680,  0.2466]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185,  1005,  1055,  4659,  3722,  5436,  1998,  4895,\n",
      "          9006, 24759, 17872, 16561,  2377,  2092,  2007,  1996, 21358,  7011,\n",
      "          3468,  3459,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1996,  2472,  6187,  1050,  1005,  1056,  2079,  2003,\n",
      "          2191,  2593,  1997, 11748, 11382, 23398,  1005,  1055,  2048, 16115,\n",
      "          2015,  5875,  2030,  4276, 11922,  2055,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185,  1005,  1055,  4659,  3722,  5436,  1998,  4895,\n",
      "          9006, 24759, 17872, 16561,  2377,  2092,  2007,  1996, 21358,  7011,\n",
      "          3468,  3459,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1996,  2472,  6187,  1050,  1005,  1056,  2079,  2003,\n",
      "          2191,  2593,  1997, 11748, 11382, 23398,  1005,  1055,  2048, 16115,\n",
      "          2015,  5875,  2030,  4276, 11922,  2055,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2583, 0.7417],\n",
      "        [0.2897, 0.7103]]), 'input_ids': tensor([[  101,  1996,  3185,  1005,  1055,  4659,  3722,  5436,  1998,  4895,\n",
      "          9006, 24759, 17872, 16561,  2377,  2092,  2007,  1996, 21358,  7011,\n",
      "          3468,  3459,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1996,  2472,  6187,  1050,  1005,  1056,  2079,  2003,\n",
      "          2191,  2593,  1997, 11748, 11382, 23398,  1005,  1055,  2048, 16115,\n",
      "          2015,  5875,  2030,  4276, 11922,  2055,  1012,   102]]), 'ntok': tensor([24, 28]), 'cls_emb': tensor([[-0.0955, -0.0229, -0.1035,  ..., -0.2436,  0.5996,  0.4963],\n",
      "        [-0.2079,  0.0214, -0.1658,  ..., -0.2509,  0.5446,  0.6005]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2205,  2411,  1010,  1996, 13972,  2003,  1050,  1005,  1056,\n",
      "         24868,  2000,  8562,  2061,  2172,  2004,  2027,  2024,  2663,  6129,\n",
      "          2067,  1999, 16360, 15916,  7229,  3401,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2307,  9686, 17695,  2923,  4569,  2008,\n",
      "         28667, 29313,  2015,  1037,  2173,  1998,  2051,  2008,  2097,  2196,\n",
      "          4148,  2153,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2205,  2411,  1010,  1996, 13972,  2003,  1050,  1005,  1056,\n",
      "         24868,  2000,  8562,  2061,  2172,  2004,  2027,  2024,  2663,  6129,\n",
      "          2067,  1999, 16360, 15916,  7229,  3401,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2307,  9686, 17695,  2923,  4569,  2008,\n",
      "         28667, 29313,  2015,  1037,  2173,  1998,  2051,  2008,  2097,  2196,\n",
      "          4148,  2153,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2647, 0.7353],\n",
      "        [0.2590, 0.7410]]), 'input_ids': tensor([[  101,  2205,  2411,  1010,  1996, 13972,  2003,  1050,  1005,  1056,\n",
      "         24868,  2000,  8562,  2061,  2172,  2004,  2027,  2024,  2663,  6129,\n",
      "          2067,  1999, 16360, 15916,  7229,  3401,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2307,  9686, 17695,  2923,  4569,  2008,\n",
      "         28667, 29313,  2015,  1037,  2173,  1998,  2051,  2008,  2097,  2196,\n",
      "          4148,  2153,  1012,   102,     0,     0,     0,     0]]), 'ntok': tensor([28, 24]), 'cls_emb': tensor([[ 0.1363,  0.2861, -0.0925,  ...,  0.0848,  0.5566,  0.4160],\n",
      "        [ 0.0586, -0.0893,  0.3326,  ..., -0.5468,  0.3002,  0.5005]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  7644,  2053,  2685,  2005,  2434,  3012,  1010, 15966,  1010,\n",
      "          2030,  4454,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2003,  1050,  1005,  1056,  3053,  2438,  4569,  2182,\n",
      "          1010,  2750,  1996,  3739,  1997,  2070, 16004, 12760,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  7644,  2053,  2685,  2005,  2434,  3012,  1010, 15966,  1010,\n",
      "          2030,  4454,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2003,  1050,  1005,  1056,  3053,  2438,  4569,  2182,\n",
      "          1010,  2750,  1996,  3739,  1997,  2070, 16004, 12760,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2599, 0.7401],\n",
      "        [0.2301, 0.7699]]), 'input_ids': tensor([[  101,  7644,  2053,  2685,  2005,  2434,  3012,  1010, 15966,  1010,\n",
      "          2030,  4454,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  2003,  1050,  1005,  1056,  3053,  2438,  4569,  2182,\n",
      "          1010,  2750,  1996,  3739,  1997,  2070, 16004, 12760,  1012,   102]]), 'ntok': tensor([14, 20]), 'cls_emb': tensor([[-0.7348,  0.0419, -0.2164,  ..., -0.0809,  0.1305,  0.5518],\n",
      "        [ 0.2286,  0.2631, -0.0735,  ..., -0.0091,  0.1891,  0.6331]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 26316,  2135,  1999, 23606,  1998,  9951,  1012,   102],\n",
      "        [  101,  2023,  3185,  2003, 24890,  2075,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 26316,  2135,  1999, 23606,  1998,  9951,  1012,   102],\n",
      "        [  101,  2023,  3185,  2003, 24890,  2075,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2775, 0.7225],\n",
      "        [0.2540, 0.7460]]), 'input_ids': tensor([[  101, 26316,  2135,  1999, 23606,  1998,  9951,  1012,   102],\n",
      "        [  101,  2023,  3185,  2003, 24890,  2075,  1012,   102,     0]]), 'ntok': tensor([9, 8]), 'cls_emb': tensor([[-0.6107,  0.3489, -0.4887,  ..., -0.3842,  0.5215,  0.3206],\n",
      "        [ 0.2139,  0.1242,  0.2075,  ..., -0.3136,  0.1658,  0.4313]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009, 24542,  2015,  2017,  1010,  2017,  6187,  1050,  1005,\n",
      "          1056,  5293,  2009,  1010,  2017, 19837,  2049, 13120,  1998,  2024,\n",
      "          2583,  2000, 10663,  2070,  1997,  1996,  6724,  2015,  2017,  2018,\n",
      "          2096,  3666,  2009,  1012,   102],\n",
      "        [  101,  3520, 27916,  2038,  2468, 10380, 29201, 11069,  2078,  2012,\n",
      "          1996,  2082,  2005,  3730, 16805,  1998,  3733,  3971,  2041,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009, 24542,  2015,  2017,  1010,  2017,  6187,  1050,  1005,\n",
      "          1056,  5293,  2009,  1010,  2017, 19837,  2049, 13120,  1998,  2024,\n",
      "          2583,  2000, 10663,  2070,  1997,  1996,  6724,  2015,  2017,  2018,\n",
      "          2096,  3666,  2009,  1012,   102],\n",
      "        [  101,  3520, 27916,  2038,  2468, 10380, 29201, 11069,  2078,  2012,\n",
      "          1996,  2082,  2005,  3730, 16805,  1998,  3733,  3971,  2041,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2416, 0.7584],\n",
      "        [0.2598, 0.7402]]), 'input_ids': tensor([[  101,  2009, 24542,  2015,  2017,  1010,  2017,  6187,  1050,  1005,\n",
      "          1056,  5293,  2009,  1010,  2017, 19837,  2049, 13120,  1998,  2024,\n",
      "          2583,  2000, 10663,  2070,  1997,  1996,  6724,  2015,  2017,  2018,\n",
      "          2096,  3666,  2009,  1012,   102],\n",
      "        [  101,  3520, 27916,  2038,  2468, 10380, 29201, 11069,  2078,  2012,\n",
      "          1996,  2082,  2005,  3730, 16805,  1998,  3733,  3971,  2041,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 21]), 'cls_emb': tensor([[ 0.0559, -0.2597, -0.1629,  ..., -0.4155,  0.1234,  0.4058],\n",
      "        [-0.3912,  0.1213, -0.2417,  ...,  0.0023,  0.8724,  0.6139]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2028,  1997,  1996,  6047,  4355,  3138,  2006,  3895,  3226,\n",
      "          1045,  1005,  2310,  2464,  1999,  1037,  2146,  2051,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 14434,  1010, 27724,  2075,  1010,  1998,  6361,  1999,  1037,\n",
      "          3019,  1010,  4895, 14821,  2094,  2806,  2008,  3084,  2049,  3494,\n",
      "          4025,  4498, 13359,  2130,  2043,  2049,  5896,  2003,  2025,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2028,  1997,  1996,  6047,  4355,  3138,  2006,  3895,  3226,\n",
      "          1045,  1005,  2310,  2464,  1999,  1037,  2146,  2051,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 14434,  1010, 27724,  2075,  1010,  1998,  6361,  1999,  1037,\n",
      "          3019,  1010,  4895, 14821,  2094,  2806,  2008,  3084,  2049,  3494,\n",
      "          4025,  4498, 13359,  2130,  2043,  2049,  5896,  2003,  2025,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2805, 0.7195],\n",
      "        [0.2529, 0.7471]]), 'input_ids': tensor([[  101,  2028,  1997,  1996,  6047,  4355,  3138,  2006,  3895,  3226,\n",
      "          1045,  1005,  2310,  2464,  1999,  1037,  2146,  2051,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 14434,  1010, 27724,  2075,  1010,  1998,  6361,  1999,  1037,\n",
      "          3019,  1010,  4895, 14821,  2094,  2806,  2008,  3084,  2049,  3494,\n",
      "          4025,  4498, 13359,  2130,  2043,  2049,  5896,  2003,  2025,  1012,\n",
      "           102]]), 'ntok': tensor([20, 31]), 'cls_emb': tensor([[-0.3151,  0.0534, -0.1215,  ..., -0.2913,  0.2436,  0.2357],\n",
      "        [-0.4380, -0.1437, -0.3265,  ..., -0.2570,  0.4617,  0.2295]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2296, 28991,  3366,  8663,  2094,  1997,  1996,  1996,  2047,\n",
      "          3124, 15537,  2017,  2008,  2017,  2071,  2022,  2725,  2242,  2842,\n",
      "          2521,  2062, 22512, 23086,  1012,   102],\n",
      "        [  101,  3310,  1012,  1012,  1012, 22502,  2485,  2000,  3023,  2075,\n",
      "          1999,  1996, 29449,  2015,  1997,  1996, 10165, 12383,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2296, 28991,  3366,  8663,  2094,  1997,  1996,  1996,  2047,\n",
      "          3124, 15537,  2017,  2008,  2017,  2071,  2022,  2725,  2242,  2842,\n",
      "          2521,  2062, 22512, 23086,  1012,   102],\n",
      "        [  101,  3310,  1012,  1012,  1012, 22502,  2485,  2000,  3023,  2075,\n",
      "          1999,  1996, 29449,  2015,  1997,  1996, 10165, 12383,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2528, 0.7472],\n",
      "        [0.2634, 0.7366]]), 'input_ids': tensor([[  101,  2296, 28991,  3366,  8663,  2094,  1997,  1996,  1996,  2047,\n",
      "          3124, 15537,  2017,  2008,  2017,  2071,  2022,  2725,  2242,  2842,\n",
      "          2521,  2062, 22512, 23086,  1012,   102],\n",
      "        [  101,  3310,  1012,  1012,  1012, 22502,  2485,  2000,  3023,  2075,\n",
      "          1999,  1996, 29449,  2015,  1997,  1996, 10165, 12383,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([26, 20]), 'cls_emb': tensor([[ 0.1971,  0.0671, -0.0788,  ..., -0.4008,  0.1091,  0.6436],\n",
      "        [-0.0064,  0.1567, -0.1266,  ..., -0.1722,  0.3256,  0.5516]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4010,  2300,  2104,  1037,  2417,  2958,  2003,  1037, 21864,\n",
      "         15952,  1998, 13433, 25593,  2887,  2143,  2008, 15102,  1996, 17160,\n",
      "          7264,  2090,  2308,  1010,  2300,  1010,  3267,  1010,  1998, 13798,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  3849,  2000,  2033,  1996,  2143,  2003,  2055,  1996,\n",
      "          2396,  1997, 17039,  2111,  2125,  2302,  2412,  5599,  2068, 24447,\n",
      "          2113,  2017,  2031,  2589,  2061,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4010,  2300,  2104,  1037,  2417,  2958,  2003,  1037, 21864,\n",
      "         15952,  1998, 13433, 25593,  2887,  2143,  2008, 15102,  1996, 17160,\n",
      "          7264,  2090,  2308,  1010,  2300,  1010,  3267,  1010,  1998, 13798,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  3849,  2000,  2033,  1996,  2143,  2003,  2055,  1996,\n",
      "          2396,  1997, 17039,  2111,  2125,  2302,  2412,  5599,  2068, 24447,\n",
      "          2113,  2017,  2031,  2589,  2061,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2725, 0.7275],\n",
      "        [0.2455, 0.7545]]), 'input_ids': tensor([[  101,  4010,  2300,  2104,  1037,  2417,  2958,  2003,  1037, 21864,\n",
      "         15952,  1998, 13433, 25593,  2887,  2143,  2008, 15102,  1996, 17160,\n",
      "          7264,  2090,  2308,  1010,  2300,  1010,  3267,  1010,  1998, 13798,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  3849,  2000,  2033,  1996,  2143,  2003,  2055,  1996,\n",
      "          2396,  1997, 17039,  2111,  2125,  2302,  2412,  5599,  2068, 24447,\n",
      "          2113,  2017,  2031,  2589,  2061,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 26]), 'cls_emb': tensor([[-0.0671, -0.2436, -0.8106,  ...,  0.1642,  0.5659,  0.3177],\n",
      "        [ 0.3024, -0.0244,  0.0085,  ..., -0.1829,  0.2689,  0.5924]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2214,  1011,  2433,  3185, 12614,  2012,  2049,  2190,  1012,\n",
      "           102,     0,     0],\n",
      "        [  101,  4332,  9280,  5293, 10880,  5675,  2046,  2242, 13939, 27345,\n",
      "          2075,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2214,  1011,  2433,  3185, 12614,  2012,  2049,  2190,  1012,\n",
      "           102,     0,     0],\n",
      "        [  101,  4332,  9280,  5293, 10880,  5675,  2046,  2242, 13939, 27345,\n",
      "          2075,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2532, 0.7468],\n",
      "        [0.2767, 0.7233]]), 'input_ids': tensor([[  101,  2214,  1011,  2433,  3185, 12614,  2012,  2049,  2190,  1012,\n",
      "           102,     0,     0],\n",
      "        [  101,  4332,  9280,  5293, 10880,  5675,  2046,  2242, 13939, 27345,\n",
      "          2075,  1012,   102]]), 'ntok': tensor([11, 13]), 'cls_emb': tensor([[-0.4649, -0.3352, -0.4018,  ..., -0.2760,  0.5375, -0.1378],\n",
      "        [-0.2571,  0.1045, -0.2646,  ..., -0.5080,  0.1582,  0.4544]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1006,  5623, 17523,  2015,  1007,  2035,  2058,  1996,  2754,\n",
      "          1010,  5613,  1010,  2770,  1010, 18972,  1010,  9587, 14853,  2010,\n",
      "          2227,  1998,  3227, 14962,  1996, 11333, 17413,  5848,  2008,  2716,\n",
      "          2032,  4476,  1999,  1996,  2034,  2173,  1012,   102],\n",
      "        [  101,  1037,  3185,  2008, 15537,  2149,  1997,  2074,  2129, 10990,\n",
      "          1998, 17087,  1996,  5913,  5988,  2064,  2022,  2043,  2009,  1005,\n",
      "          1055,  5411,  2007,  9647,  1998, 22012,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1006,  5623, 17523,  2015,  1007,  2035,  2058,  1996,  2754,\n",
      "          1010,  5613,  1010,  2770,  1010, 18972,  1010,  9587, 14853,  2010,\n",
      "          2227,  1998,  3227, 14962,  1996, 11333, 17413,  5848,  2008,  2716,\n",
      "          2032,  4476,  1999,  1996,  2034,  2173,  1012,   102],\n",
      "        [  101,  1037,  3185,  2008, 15537,  2149,  1997,  2074,  2129, 10990,\n",
      "          1998, 17087,  1996,  5913,  5988,  2064,  2022,  2043,  2009,  1005,\n",
      "          1055,  5411,  2007,  9647,  1998, 22012,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2944, 0.7056],\n",
      "        [0.2409, 0.7591]]), 'input_ids': tensor([[  101,  1006,  5623, 17523,  2015,  1007,  2035,  2058,  1996,  2754,\n",
      "          1010,  5613,  1010,  2770,  1010, 18972,  1010,  9587, 14853,  2010,\n",
      "          2227,  1998,  3227, 14962,  1996, 11333, 17413,  5848,  2008,  2716,\n",
      "          2032,  4476,  1999,  1996,  2034,  2173,  1012,   102],\n",
      "        [  101,  1037,  3185,  2008, 15537,  2149,  1997,  2074,  2129, 10990,\n",
      "          1998, 17087,  1996,  5913,  5988,  2064,  2022,  2043,  2009,  1005,\n",
      "          1055,  5411,  2007,  9647,  1998, 22012,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([38, 28]), 'cls_emb': tensor([[-0.1794,  0.2117,  0.2124,  ..., -0.3441,  0.5490,  0.4511],\n",
      "        [-0.0856, -0.4836, -0.0262,  ..., -0.4585,  0.4180,  0.2835]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 23283,  1996,  6583, 12588, 10928,  2008,  6066, 24882,  2052,\n",
      "          2022,  2130,  4788,  2369,  1996,  4950,  2084,  2002,  2003,  1999,\n",
      "          2392,  1997,  2009,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  1996,  2203,  1010,  2057,  2024,  2187,  2007,  2242,\n",
      "          2066,  2048,  3719,  4458,  1999,  1996,  2305,  2738,  2084,  2151,\n",
      "         20062,  2046,  5637,  2293,  1010,  2822,  2554,  2030,  1996,  3976,\n",
      "          2028, 12778,  2005,  2108,  9841, 21821,  2102,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 23283,  1996,  6583, 12588, 10928,  2008,  6066, 24882,  2052,\n",
      "          2022,  2130,  4788,  2369,  1996,  4950,  2084,  2002,  2003,  1999,\n",
      "          2392,  1997,  2009,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  1996,  2203,  1010,  2057,  2024,  2187,  2007,  2242,\n",
      "          2066,  2048,  3719,  4458,  1999,  1996,  2305,  2738,  2084,  2151,\n",
      "         20062,  2046,  5637,  2293,  1010,  2822,  2554,  2030,  1996,  3976,\n",
      "          2028, 12778,  2005,  2108,  9841, 21821,  2102,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2484, 0.7516],\n",
      "        [0.2370, 0.7630]]), 'input_ids': tensor([[  101, 23283,  1996,  6583, 12588, 10928,  2008,  6066, 24882,  2052,\n",
      "          2022,  2130,  4788,  2369,  1996,  4950,  2084,  2002,  2003,  1999,\n",
      "          2392,  1997,  2009,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1999,  1996,  2203,  1010,  2057,  2024,  2187,  2007,  2242,\n",
      "          2066,  2048,  3719,  4458,  1999,  1996,  2305,  2738,  2084,  2151,\n",
      "         20062,  2046,  5637,  2293,  1010,  2822,  2554,  2030,  1996,  3976,\n",
      "          2028, 12778,  2005,  2108,  9841, 21821,  2102,  1012,   102]]), 'ntok': tensor([25, 39]), 'cls_emb': tensor([[-0.2886,  0.0652, -0.1086,  ..., -0.3646,  0.4968,  0.2021],\n",
      "        [ 0.2430,  0.1585, -0.1826,  ..., -0.2813,  0.5238,  0.6804]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 18318,  7951,  1012,  1012,  1012, 15856,  1037,  2843,  1997,\n",
      "          2943,  2046,  2010, 19957, 16371,  6651,  2094,  7984,  1998, 20626,\n",
      "          2370,  2007,  1037,  3459,  1997, 21864, 15952,  1011,  1011,  2021,\n",
      "          2025, 12991, 13874,  2094,  1011,  1011,  2395,  3494,  1012,   102],\n",
      "        [  101,  2009,  3640,  1996,  2882,  1010,  9414,  4024,  1997,  1037,\n",
      "          6020,  3459,  2652,  6047,  2111, 13463,  1037, 17075,  5436,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 18318,  7951,  1012,  1012,  1012, 15856,  1037,  2843,  1997,\n",
      "          2943,  2046,  2010, 19957, 16371,  6651,  2094,  7984,  1998, 20626,\n",
      "          2370,  2007,  1037,  3459,  1997, 21864, 15952,  1011,  1011,  2021,\n",
      "          2025, 12991, 13874,  2094,  1011,  1011,  2395,  3494,  1012,   102],\n",
      "        [  101,  2009,  3640,  1996,  2882,  1010,  9414,  4024,  1997,  1037,\n",
      "          6020,  3459,  2652,  6047,  2111, 13463,  1037, 17075,  5436,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2524, 0.7476],\n",
      "        [0.2534, 0.7466]]), 'input_ids': tensor([[  101, 18318,  7951,  1012,  1012,  1012, 15856,  1037,  2843,  1997,\n",
      "          2943,  2046,  2010, 19957, 16371,  6651,  2094,  7984,  1998, 20626,\n",
      "          2370,  2007,  1037,  3459,  1997, 21864, 15952,  1011,  1011,  2021,\n",
      "          2025, 12991, 13874,  2094,  1011,  1011,  2395,  3494,  1012,   102],\n",
      "        [  101,  2009,  3640,  1996,  2882,  1010,  9414,  4024,  1997,  1037,\n",
      "          6020,  3459,  2652,  6047,  2111, 13463,  1037, 17075,  5436,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([40, 21]), 'cls_emb': tensor([[-0.0048,  0.0839, -0.4344,  ..., -0.2921,  0.6686,  0.2528],\n",
      "        [-0.1591,  0.0250, -0.0009,  ..., -0.3404,  0.2774,  0.5772]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 17567,  2013,  1996,  3768,  1997,  1037, 17075,  2030,  4012,\n",
      "         28139, 10222, 19307,  7984,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1999,  7781,  1010,  2023, 12266,  2801,  2003,  2521,  2625,\n",
      "          6057,  2084,  1996,  2434,  1010, 15978,  2013,  2686,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 17567,  2013,  1996,  3768,  1997,  1037, 17075,  2030,  4012,\n",
      "         28139, 10222, 19307,  7984,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1999,  7781,  1010,  2023, 12266,  2801,  2003,  2521,  2625,\n",
      "          6057,  2084,  1996,  2434,  1010, 15978,  2013,  2686,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2629, 0.7371],\n",
      "        [0.2484, 0.7516]]), 'input_ids': tensor([[  101, 17567,  2013,  1996,  3768,  1997,  1037, 17075,  2030,  4012,\n",
      "         28139, 10222, 19307,  7984,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1999,  7781,  1010,  2023, 12266,  2801,  2003,  2521,  2625,\n",
      "          6057,  2084,  1996,  2434,  1010, 15978,  2013,  2686,  1012,   102]]), 'ntok': tensor([16, 20]), 'cls_emb': tensor([[-2.6817e-01,  4.6931e-02, -5.5114e-01,  ..., -1.9521e-01,\n",
      "          5.1732e-01,  3.8136e-01],\n",
      "        [-1.6294e-01, -5.6304e-04, -3.0855e-01,  ..., -1.4676e-01,\n",
      "          3.0583e-01,  7.9810e-01]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  8040,  9541,  3762, 20160,  3762, 20160,  1013,  1998, 25741,\n",
      "          2205,  1013,  2017,  2119,  2298,  1998,  2614,  2307,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  6925,  1997,  2000,  2243,  1006,  5557, 21360,  1007,\n",
      "          1010,  1037, 21185, 17522, 15069,  2006,  1996,  4446,  1997,  1051,\n",
      "          1006, 27006, 12914,  2061, 20026, 21046,  1007,  1010,  1996,  2087,\n",
      "          8987,  1997,  4004,  2718,  3549,  1010,  2003,  2205,  8040, 20097,\n",
      "         19040,  2000,  2202,  2907,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  8040,  9541,  3762, 20160,  3762, 20160,  1013,  1998, 25741,\n",
      "          2205,  1013,  2017,  2119,  2298,  1998,  2614,  2307,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  6925,  1997,  2000,  2243,  1006,  5557, 21360,  1007,\n",
      "          1010,  1037, 21185, 17522, 15069,  2006,  1996,  4446,  1997,  1051,\n",
      "          1006, 27006, 12914,  2061, 20026, 21046,  1007,  1010,  1996,  2087,\n",
      "          8987,  1997,  4004,  2718,  3549,  1010,  2003,  2205,  8040, 20097,\n",
      "         19040,  2000,  2202,  2907,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2355, 0.7645],\n",
      "        [0.2658, 0.7342]]), 'input_ids': tensor([[  101,  8040,  9541,  3762, 20160,  3762, 20160,  1013,  1998, 25741,\n",
      "          2205,  1013,  2017,  2119,  2298,  1998,  2614,  2307,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  6925,  1997,  2000,  2243,  1006,  5557, 21360,  1007,\n",
      "          1010,  1037, 21185, 17522, 15069,  2006,  1996,  4446,  1997,  1051,\n",
      "          1006, 27006, 12914,  2061, 20026, 21046,  1007,  1010,  1996,  2087,\n",
      "          8987,  1997,  4004,  2718,  3549,  1010,  2003,  2205,  8040, 20097,\n",
      "         19040,  2000,  2202,  2907,  1012,   102]]), 'ntok': tensor([20, 46]), 'cls_emb': tensor([[ 0.3384, -0.2143,  0.0945,  ..., -0.4118,  0.1949,  0.1753],\n",
      "        [-0.3216,  0.0236, -0.2649,  ..., -0.0140,  0.1945,  0.4102]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2035,  8011,  2015,  2006,  2061,  6970, 22311,  6321,\n",
      "          2009,  1005,  1055,  2066,  3666,  1037, 13736,  3276,  4895, 10371,\n",
      "          1999,  2613,  2051,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 25730,  2965,  2000,  2022,  2019, 25506,  2601, 18312,  2006,\n",
      "         13577,  2166,  1010,  2021,  2049, 19509,  2521, 13467,  1996,  7590,\n",
      "          1997,  3213,  4205, 21213, 22953,  4063,  1998,  2010,  2522,  1011,\n",
      "          2472,  1010,  4116,  1054,  1012, 23063,  1010,  1999,  2037,  3444,\n",
      "          2834,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2035,  8011,  2015,  2006,  2061,  6970, 22311,  6321,\n",
      "          2009,  1005,  1055,  2066,  3666,  1037, 13736,  3276,  4895, 10371,\n",
      "          1999,  2613,  2051,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 25730,  2965,  2000,  2022,  2019, 25506,  2601, 18312,  2006,\n",
      "         13577,  2166,  1010,  2021,  2049, 19509,  2521, 13467,  1996,  7590,\n",
      "          1997,  3213,  4205, 21213, 22953,  4063,  1998,  2010,  2522,  1011,\n",
      "          2472,  1010,  4116,  1054,  1012, 23063,  1010,  1999,  2037,  3444,\n",
      "          2834,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2216, 0.7784],\n",
      "        [0.2714, 0.7286]]), 'input_ids': tensor([[  101,  2009,  2035,  8011,  2015,  2006,  2061,  6970, 22311,  6321,\n",
      "          2009,  1005,  1055,  2066,  3666,  1037, 13736,  3276,  4895, 10371,\n",
      "          1999,  2613,  2051,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 25730,  2965,  2000,  2022,  2019, 25506,  2601, 18312,  2006,\n",
      "         13577,  2166,  1010,  2021,  2049, 19509,  2521, 13467,  1996,  7590,\n",
      "          1997,  3213,  4205, 21213, 22953,  4063,  1998,  2010,  2522,  1011,\n",
      "          2472,  1010,  4116,  1054,  1012, 23063,  1010,  1999,  2037,  3444,\n",
      "          2834,  1012,   102]]), 'ntok': tensor([25, 43]), 'cls_emb': tensor([[ 0.4003,  0.5471,  0.1475,  ..., -0.1500,  0.0409,  0.6633],\n",
      "        [ 0.0748, -0.1085, -0.4363,  ...,  0.0374,  0.7364,  0.4204]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3504,  1998,  5683,  2066,  1037,  2622,  2488, 10897,  2005,\n",
      "          1996,  2235,  3898,  1012,   102],\n",
      "        [  101,  3140,  1010,  5220,  1998, 12246, 24707, 11020, 18537,  1012,\n",
      "           102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3504,  1998,  5683,  2066,  1037,  2622,  2488, 10897,  2005,\n",
      "          1996,  2235,  3898,  1012,   102],\n",
      "        [  101,  3140,  1010,  5220,  1998, 12246, 24707, 11020, 18537,  1012,\n",
      "           102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2482, 0.7518],\n",
      "        [0.2805, 0.7195]]), 'input_ids': tensor([[  101,  3504,  1998,  5683,  2066,  1037,  2622,  2488, 10897,  2005,\n",
      "          1996,  2235,  3898,  1012,   102],\n",
      "        [  101,  3140,  1010,  5220,  1998, 12246, 24707, 11020, 18537,  1012,\n",
      "           102,     0,     0,     0,     0]]), 'ntok': tensor([15, 11]), 'cls_emb': tensor([[-0.0865, -0.0821,  0.5354,  ..., -0.3905, -0.0105,  0.2413],\n",
      "        [-0.6178,  0.2214, -0.5026,  ..., -0.3647,  0.2958,  0.4955]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2008,  2003,  1037, 19394,  2000, 13970,  8180,  1998,  4679,\n",
      "          1012,   102,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2025,  1996,  7209,  6245,  1011,  3690,\n",
      "         20067,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2008,  2003,  1037, 19394,  2000, 13970,  8180,  1998,  4679,\n",
      "          1012,   102,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2025,  1996,  7209,  6245,  1011,  3690,\n",
      "         20067,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2645, 0.7355],\n",
      "        [0.2527, 0.7473]]), 'input_ids': tensor([[  101,  2008,  2003,  1037, 19394,  2000, 13970,  8180,  1998,  4679,\n",
      "          1012,   102,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2025,  1996,  7209,  6245,  1011,  3690,\n",
      "         20067,  3185,  1012,   102]]), 'ntok': tensor([12, 14]), 'cls_emb': tensor([[ 0.1551,  0.2027, -0.2960,  ..., -0.2395,  0.3443,  0.3893],\n",
      "        [ 0.1734,  0.0456, -0.4333,  ..., -0.1538,  0.3788,  0.5038]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 18502,  1996,  3643,  1997,  2049,  7177,  1997, 22796,  3329,\n",
      "          1011,  2287,  2007,  2049,  2625,  1011,  2084,  1011,  7863, 11032,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2839,  1997,  1062,  8004,  4143,  2290,  2003,  2025,\n",
      "         12949,  2764,  2000,  2490,  1037,  2143,  3833,  2105,  2032,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 18502,  1996,  3643,  1997,  2049,  7177,  1997, 22796,  3329,\n",
      "          1011,  2287,  2007,  2049,  2625,  1011,  2084,  1011,  7863, 11032,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2839,  1997,  1062,  8004,  4143,  2290,  2003,  2025,\n",
      "         12949,  2764,  2000,  2490,  1037,  2143,  3833,  2105,  2032,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2662, 0.7338],\n",
      "        [0.2501, 0.7499]]), 'input_ids': tensor([[  101, 18502,  1996,  3643,  1997,  2049,  7177,  1997, 22796,  3329,\n",
      "          1011,  2287,  2007,  2049,  2625,  1011,  2084,  1011,  7863, 11032,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2839,  1997,  1062,  8004,  4143,  2290,  2003,  2025,\n",
      "         12949,  2764,  2000,  2490,  1037,  2143,  3833,  2105,  2032,  1012,\n",
      "           102,     0]]), 'ntok': tensor([22, 21]), 'cls_emb': tensor([[-0.5276,  0.2257, -0.9744,  ..., -0.1806,  0.4158,  0.3661],\n",
      "        [-0.4722,  0.1519, -0.4543,  ..., -0.0655,  0.6313,  0.6039]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2054,  2488,  4471,  2084,  1036,  2293, 15177, 11246,  2546,\n",
      "          1005,  2071,  2402,  2308,  1997,  2151,  2946,  4374,  1029,   102],\n",
      "        [  101,  1037,  5024,  2143,  1012,  1012,  1012,  2021,  2062,  9530,\n",
      "         11020, 11638,  6313,  2084,  2009,  2003,  5621, 18385,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2054,  2488,  4471,  2084,  1036,  2293, 15177, 11246,  2546,\n",
      "          1005,  2071,  2402,  2308,  1997,  2151,  2946,  4374,  1029,   102],\n",
      "        [  101,  1037,  5024,  2143,  1012,  1012,  1012,  2021,  2062,  9530,\n",
      "         11020, 11638,  6313,  2084,  2009,  2003,  5621, 18385,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2568, 0.7432],\n",
      "        [0.2504, 0.7496]]), 'input_ids': tensor([[  101,  2054,  2488,  4471,  2084,  1036,  2293, 15177, 11246,  2546,\n",
      "          1005,  2071,  2402,  2308,  1997,  2151,  2946,  4374,  1029,   102],\n",
      "        [  101,  1037,  5024,  2143,  1012,  1012,  1012,  2021,  2062,  9530,\n",
      "         11020, 11638,  6313,  2084,  2009,  2003,  5621, 18385,  1012,   102]]), 'ntok': tensor([20, 20]), 'cls_emb': tensor([[-0.1654,  0.2657, -0.2640,  ..., -0.3185,  0.2308,  0.6973],\n",
      "        [-0.2605,  0.0937, -0.1538,  ..., -0.3712,  0.3602,  0.6982]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2096,  1006,  2940,  1007,  2038,  4342,  2047, 12225,  1010,\n",
      "          1996, 12225,  2894,  2024,  2025,  2438,  2000, 18340,  2023, 22185,\n",
      "          8362,  2143,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1996,  2190,  2008,  2064,  2022,  2056,  2055,  1996,  2147,\n",
      "          2182,  1997,  4104,  2472, 20404,  1012,  1012,  1012,  2003,  2008,\n",
      "          2002,  5525,  2515,  1050,  1005,  1056,  2031,  2010,  2540,  1999,\n",
      "          2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2096,  1006,  2940,  1007,  2038,  4342,  2047, 12225,  1010,\n",
      "          1996, 12225,  2894,  2024,  2025,  2438,  2000, 18340,  2023, 22185,\n",
      "          8362,  2143,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1996,  2190,  2008,  2064,  2022,  2056,  2055,  1996,  2147,\n",
      "          2182,  1997,  4104,  2472, 20404,  1012,  1012,  1012,  2003,  2008,\n",
      "          2002,  5525,  2515,  1050,  1005,  1056,  2031,  2010,  2540,  1999,\n",
      "          2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2590, 0.7410],\n",
      "        [0.2413, 0.7587]]), 'input_ids': tensor([[  101,  2096,  1006,  2940,  1007,  2038,  4342,  2047, 12225,  1010,\n",
      "          1996, 12225,  2894,  2024,  2025,  2438,  2000, 18340,  2023, 22185,\n",
      "          8362,  2143,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1996,  2190,  2008,  2064,  2022,  2056,  2055,  1996,  2147,\n",
      "          2182,  1997,  4104,  2472, 20404,  1012,  1012,  1012,  2003,  2008,\n",
      "          2002,  5525,  2515,  1050,  1005,  1056,  2031,  2010,  2540,  1999,\n",
      "          2009,  1012,   102]]), 'ntok': tensor([24, 33]), 'cls_emb': tensor([[-0.3927,  0.1125,  0.0250,  ..., -0.1357,  0.3465,  0.5821],\n",
      "        [-0.1239,  0.4743, -0.3119,  ..., -0.2564,  0.5108,  0.5727]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2055,  1037,  8952,  1011,  2066, 18869,  2040,  9590,  2067,\n",
      "          2012,  2014,  6905,  2869,  1010,  2009,  1005,  1055, 18114,  1998,\n",
      "         17087,  2065,  2025,  2784,  1998,  8317,  1012,   102,     0,     0],\n",
      "        [  101,  1996, 10904,  1998, 12266,  2728,  9172,  3383,  2404,  1037,\n",
      "          2210,  2205,  2172,  2540,  2046,  2010,  2034,  2143,  1998,  2106,\n",
      "          1050,  1005,  1056,  3914,  2438,  2005,  2010,  2117,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2055,  1037,  8952,  1011,  2066, 18869,  2040,  9590,  2067,\n",
      "          2012,  2014,  6905,  2869,  1010,  2009,  1005,  1055, 18114,  1998,\n",
      "         17087,  2065,  2025,  2784,  1998,  8317,  1012,   102,     0,     0],\n",
      "        [  101,  1996, 10904,  1998, 12266,  2728,  9172,  3383,  2404,  1037,\n",
      "          2210,  2205,  2172,  2540,  2046,  2010,  2034,  2143,  1998,  2106,\n",
      "          1050,  1005,  1056,  3914,  2438,  2005,  2010,  2117,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2695, 0.7305],\n",
      "        [0.2475, 0.7525]]), 'input_ids': tensor([[  101,  2055,  1037,  8952,  1011,  2066, 18869,  2040,  9590,  2067,\n",
      "          2012,  2014,  6905,  2869,  1010,  2009,  1005,  1055, 18114,  1998,\n",
      "         17087,  2065,  2025,  2784,  1998,  8317,  1012,   102,     0,     0],\n",
      "        [  101,  1996, 10904,  1998, 12266,  2728,  9172,  3383,  2404,  1037,\n",
      "          2210,  2205,  2172,  2540,  2046,  2010,  2034,  2143,  1998,  2106,\n",
      "          1050,  1005,  1056,  3914,  2438,  2005,  2010,  2117,  1012,   102]]), 'ntok': tensor([28, 30]), 'cls_emb': tensor([[-0.2441, -0.3800, -0.1375,  ..., -0.1323,  0.4926,  0.3633],\n",
      "        [-0.0971, -0.3418, -0.7007,  ..., -0.4631,  0.8485,  0.2267]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  5683,  2205,  5675,  2594,  1998,  2205,  5220,  2000,  3965,\n",
      "          1996,  9099, 17603, 18719,  3726, 16959,  2015,  1997,  2220,  5230,\n",
      "          2147,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 20606, 10949,  1997,  2931,  6860,  2003,  1996,  3395,\n",
      "          1997,  2023,  4895, 24572, 11998,  1010,  2659,  1011,  3145,  2143,\n",
      "          2008,  2003,  2061,  2125,  1011,  5365,  2008,  2009,  3849, 13567,\n",
      "          2413,  1999,  2049, 17900,  1998, 17011,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  5683,  2205,  5675,  2594,  1998,  2205,  5220,  2000,  3965,\n",
      "          1996,  9099, 17603, 18719,  3726, 16959,  2015,  1997,  2220,  5230,\n",
      "          2147,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 20606, 10949,  1997,  2931,  6860,  2003,  1996,  3395,\n",
      "          1997,  2023,  4895, 24572, 11998,  1010,  2659,  1011,  3145,  2143,\n",
      "          2008,  2003,  2061,  2125,  1011,  5365,  2008,  2009,  3849, 13567,\n",
      "          2413,  1999,  2049, 17900,  1998, 17011,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2669, 0.7331],\n",
      "        [0.2609, 0.7391]]), 'input_ids': tensor([[  101,  5683,  2205,  5675,  2594,  1998,  2205,  5220,  2000,  3965,\n",
      "          1996,  9099, 17603, 18719,  3726, 16959,  2015,  1997,  2220,  5230,\n",
      "          2147,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996, 20606, 10949,  1997,  2931,  6860,  2003,  1996,  3395,\n",
      "          1997,  2023,  4895, 24572, 11998,  1010,  2659,  1011,  3145,  2143,\n",
      "          2008,  2003,  2061,  2125,  1011,  5365,  2008,  2009,  3849, 13567,\n",
      "          2413,  1999,  2049, 17900,  1998, 17011,  1012,   102]]), 'ntok': tensor([23, 38]), 'cls_emb': tensor([[-0.0260, -0.0739, -0.1155,  ..., -0.3281,  0.2055,  0.3436],\n",
      "        [-0.1194,  0.2110, -0.5034,  ..., -0.4530,  0.3489,  0.6148]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3452,  2200,  2204,  2005,  2054,  2009,  1005,  1055,  2667,\n",
      "          2000,  2079,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2502,  1010,  9882,  1010, 24199, 25430, 11823, 24204,\n",
      "          3917,  2008, 18058,  2049, 20150,  2015,  1999,  2882,  1010,  4895,\n",
      "          9006, 24759, 17872,  4827,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3452,  2200,  2204,  2005,  2054,  2009,  1005,  1055,  2667,\n",
      "          2000,  2079,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2502,  1010,  9882,  1010, 24199, 25430, 11823, 24204,\n",
      "          3917,  2008, 18058,  2049, 20150,  2015,  1999,  2882,  1010,  4895,\n",
      "          9006, 24759, 17872,  4827,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2744, 0.7256],\n",
      "        [0.2619, 0.7381]]), 'input_ids': tensor([[  101,  3452,  2200,  2204,  2005,  2054,  2009,  1005,  1055,  2667,\n",
      "          2000,  2079,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2502,  1010,  9882,  1010, 24199, 25430, 11823, 24204,\n",
      "          3917,  2008, 18058,  2049, 20150,  2015,  1999,  2882,  1010,  4895,\n",
      "          9006, 24759, 17872,  4827,  1012,   102]]), 'ntok': tensor([14, 26]), 'cls_emb': tensor([[-0.1178, -0.0087,  0.0391,  ..., -0.1880,  0.2319,  0.6045],\n",
      "        [-0.5873, -0.2487,  0.0020,  ..., -0.5846,  0.4640,  0.1606]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  3697,  1010, 20998,  2143,  2008,  9020,  2000, 16636,\n",
      "          2062,  9415,  2750,  2049, 23318,  2015,  1998,  4297,  5644, 27870,\n",
      "         14767,  2084,  2079,  2087,  3152,  2084,  2024,  2521,  2062,  4197,\n",
      "          1998,  3154,  1012,   102],\n",
      "        [  101,  1996,  3082,  1011,  4375,  2143,  2003,  2471,  4756,  3085,\n",
      "          2004,  1037,  9509,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  3697,  1010, 20998,  2143,  2008,  9020,  2000, 16636,\n",
      "          2062,  9415,  2750,  2049, 23318,  2015,  1998,  4297,  5644, 27870,\n",
      "         14767,  2084,  2079,  2087,  3152,  2084,  2024,  2521,  2062,  4197,\n",
      "          1998,  3154,  1012,   102],\n",
      "        [  101,  1996,  3082,  1011,  4375,  2143,  2003,  2471,  4756,  3085,\n",
      "          2004,  1037,  9509,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2538, 0.7462],\n",
      "        [0.2657, 0.7343]]), 'input_ids': tensor([[  101,  1037,  3697,  1010, 20998,  2143,  2008,  9020,  2000, 16636,\n",
      "          2062,  9415,  2750,  2049, 23318,  2015,  1998,  4297,  5644, 27870,\n",
      "         14767,  2084,  2079,  2087,  3152,  2084,  2024,  2521,  2062,  4197,\n",
      "          1998,  3154,  1012,   102],\n",
      "        [  101,  1996,  3082,  1011,  4375,  2143,  2003,  2471,  4756,  3085,\n",
      "          2004,  1037,  9509,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 15]), 'cls_emb': tensor([[-0.4306, -0.1313, -0.3625,  ..., -0.4645,  0.5367,  0.3753],\n",
      "        [ 0.0290,  0.3527, -0.1836,  ..., -0.2928,  0.3305,  0.4804]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  5024,  7749,  1997,  1996,  3287,  3054, 15509,  5325,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037, 10103,  3058,  2007,  1037,  2431,  1011,  2719, 15966,\n",
      "          2589,  1037,  2307,  4487, 18116,  7903,  2063,  2011,  1037,  3768,\n",
      "          1997,  4187,  3292,  1998,  1037,  6517,  3404,  1999,  4314,  2840,\n",
      "          2267, 21519,  6293,  2121, 20228, 10450,  8525,  6155,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  5024,  7749,  1997,  1996,  3287,  3054, 15509,  5325,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037, 10103,  3058,  2007,  1037,  2431,  1011,  2719, 15966,\n",
      "          2589,  1037,  2307,  4487, 18116,  7903,  2063,  2011,  1037,  3768,\n",
      "          1997,  4187,  3292,  1998,  1037,  6517,  3404,  1999,  4314,  2840,\n",
      "          2267, 21519,  6293,  2121, 20228, 10450,  8525,  6155,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2771, 0.7229],\n",
      "        [0.3008, 0.6992]]), 'input_ids': tensor([[  101,  1037,  5024,  7749,  1997,  1996,  3287,  3054, 15509,  5325,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037, 10103,  3058,  2007,  1037,  2431,  1011,  2719, 15966,\n",
      "          2589,  1037,  2307,  4487, 18116,  7903,  2063,  2011,  1037,  3768,\n",
      "          1997,  4187,  3292,  1998,  1037,  6517,  3404,  1999,  4314,  2840,\n",
      "          2267, 21519,  6293,  2121, 20228, 10450,  8525,  6155,  1012,   102]]), 'ntok': tensor([12, 40]), 'cls_emb': tensor([[-0.4790, -0.2579, -0.4081,  ..., -0.3611,  0.3804,  0.3370],\n",
      "        [-0.0581,  0.0138, -0.2172,  ..., -0.3488,  0.4221,  0.2339]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  9020,  2000,  9099, 23865,  1996,  3348,  1010,  5850,  1998,\n",
      "          2265,  1011, 13281,  5436,  2046,  2242,  2521, 26108,  1012,   102,\n",
      "             0],\n",
      "        [  101,  2009,  3138,  5848,  2000,  2191,  1037, 22185,  3185,  2055,\n",
      "          1996,  2087,  2002,  5740,  2271,  2158,  2040,  2412,  2973,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  9020,  2000,  9099, 23865,  1996,  3348,  1010,  5850,  1998,\n",
      "          2265,  1011, 13281,  5436,  2046,  2242,  2521, 26108,  1012,   102,\n",
      "             0],\n",
      "        [  101,  2009,  3138,  5848,  2000,  2191,  1037, 22185,  3185,  2055,\n",
      "          1996,  2087,  2002,  5740,  2271,  2158,  2040,  2412,  2973,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2587, 0.7413],\n",
      "        [0.2468, 0.7532]]), 'input_ids': tensor([[  101,  9020,  2000,  9099, 23865,  1996,  3348,  1010,  5850,  1998,\n",
      "          2265,  1011, 13281,  5436,  2046,  2242,  2521, 26108,  1012,   102,\n",
      "             0],\n",
      "        [  101,  2009,  3138,  5848,  2000,  2191,  1037, 22185,  3185,  2055,\n",
      "          1996,  2087,  2002,  5740,  2271,  2158,  2040,  2412,  2973,  1012,\n",
      "           102]]), 'ntok': tensor([20, 21]), 'cls_emb': tensor([[-0.0393, -0.1699, -0.2583,  ..., -0.6444,  0.4139,  0.3023],\n",
      "        [ 0.2010,  0.0264, -0.4501,  ..., -0.2114,  0.3270,  0.3858]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2011,  2893,  2870,  5058,  2039,  1999,  1996, 26749,  1998,\n",
      "         18080,  6447,  1997,  2116,  1997,  1996,  3494,  1010,  1045,  2179,\n",
      "          2870,  5457,  2043,  2009,  2234,  2051,  2000,  2131,  2000,  1996,\n",
      "          2540,  1997,  1996,  3185,  1012,   102],\n",
      "        [  101,  2066,  6506,  1010,  2009,  1005,  1055, 25198,  1998,  2145,\n",
      "         15056,  5622,  2912,  3468,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2011,  2893,  2870,  5058,  2039,  1999,  1996, 26749,  1998,\n",
      "         18080,  6447,  1997,  2116,  1997,  1996,  3494,  1010,  1045,  2179,\n",
      "          2870,  5457,  2043,  2009,  2234,  2051,  2000,  2131,  2000,  1996,\n",
      "          2540,  1997,  1996,  3185,  1012,   102],\n",
      "        [  101,  2066,  6506,  1010,  2009,  1005,  1055, 25198,  1998,  2145,\n",
      "         15056,  5622,  2912,  3468,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2369, 0.7631],\n",
      "        [0.2845, 0.7155]]), 'input_ids': tensor([[  101,  2011,  2893,  2870,  5058,  2039,  1999,  1996, 26749,  1998,\n",
      "         18080,  6447,  1997,  2116,  1997,  1996,  3494,  1010,  1045,  2179,\n",
      "          2870,  5457,  2043,  2009,  2234,  2051,  2000,  2131,  2000,  1996,\n",
      "          2540,  1997,  1996,  3185,  1012,   102],\n",
      "        [  101,  2066,  6506,  1010,  2009,  1005,  1055, 25198,  1998,  2145,\n",
      "         15056,  5622,  2912,  3468,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([36, 16]), 'cls_emb': tensor([[ 0.0853, -0.1329, -0.5852,  ..., -0.1774,  0.2143,  0.4084],\n",
      "        [-0.0486,  0.0924, -0.2463,  ..., -0.0181,  0.2526,  0.5994]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 13191,  2135,  2358,  8516,  4509,  2021,  8053, 10021,  1012,\n",
      "          1012,  1012,  1996,  3861, 11896,  2000,  9699,  2172, 23873,  1010,\n",
      "          4496,  2515,  2009,  3198,  6575,  2438,  3980,  2000, 16114,  2049,\n",
      "          3653, 29048,  2015,  1012,   102],\n",
      "        [  101,  2025,  3599,  1996, 13734,  5042,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 13191,  2135,  2358,  8516,  4509,  2021,  8053, 10021,  1012,\n",
      "          1012,  1012,  1996,  3861, 11896,  2000,  9699,  2172, 23873,  1010,\n",
      "          4496,  2515,  2009,  3198,  6575,  2438,  3980,  2000, 16114,  2049,\n",
      "          3653, 29048,  2015,  1012,   102],\n",
      "        [  101,  2025,  3599,  1996, 13734,  5042,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2378, 0.7622],\n",
      "        [0.2970, 0.7030]]), 'input_ids': tensor([[  101, 13191,  2135,  2358,  8516,  4509,  2021,  8053, 10021,  1012,\n",
      "          1012,  1012,  1996,  3861, 11896,  2000,  9699,  2172, 23873,  1010,\n",
      "          4496,  2515,  2009,  3198,  6575,  2438,  3980,  2000, 16114,  2049,\n",
      "          3653, 29048,  2015,  1012,   102],\n",
      "        [  101,  2025,  3599,  1996, 13734,  5042,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35,  7]), 'cls_emb': tensor([[-0.2476,  0.1311, -0.2654,  ..., -0.3944,  0.4778,  0.8727],\n",
      "        [ 0.0105,  0.1493, -0.0785,  ..., -0.1145,  0.2606,  0.1182]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  3849,  2000,  2022,  2053,  3154,  4130,  2004,  2000,\n",
      "          2073,  1996,  2466,  1005,  1055,  2183,  1010,  2030,  2129,  2146,\n",
      "          2009,  1005,  1055,  2183,  2000,  2202,  2000,  2131,  2045,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 14308, 21354, 23176,  7828,  7301,  2064, 16356,  2571,  2116,\n",
      "          1037, 23655,  2121,  1005,  1055, 11281,  1010,  2021,  2043,  2009,\n",
      "          5366,  1037,  2155,  1997,  2176,  2055,  1002,  2871,  2000,  2156,\n",
      "          1037,  2143,  1999, 12370,  1010,  2339,  5247,  2769,  2006,  1037,\n",
      "          3899,  2066,  2023,  2043,  2017,  2064,  9278,  1037, 21877,  4305,\n",
      "         28637,  2612,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  3849,  2000,  2022,  2053,  3154,  4130,  2004,  2000,\n",
      "          2073,  1996,  2466,  1005,  1055,  2183,  1010,  2030,  2129,  2146,\n",
      "          2009,  1005,  1055,  2183,  2000,  2202,  2000,  2131,  2045,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 14308, 21354, 23176,  7828,  7301,  2064, 16356,  2571,  2116,\n",
      "          1037, 23655,  2121,  1005,  1055, 11281,  1010,  2021,  2043,  2009,\n",
      "          5366,  1037,  2155,  1997,  2176,  2055,  1002,  2871,  2000,  2156,\n",
      "          1037,  2143,  1999, 12370,  1010,  2339,  5247,  2769,  2006,  1037,\n",
      "          3899,  2066,  2023,  2043,  2017,  2064,  9278,  1037, 21877,  4305,\n",
      "         28637,  2612,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2575, 0.7425],\n",
      "        [0.2571, 0.7429]]), 'input_ids': tensor([[  101,  2045,  3849,  2000,  2022,  2053,  3154,  4130,  2004,  2000,\n",
      "          2073,  1996,  2466,  1005,  1055,  2183,  1010,  2030,  2129,  2146,\n",
      "          2009,  1005,  1055,  2183,  2000,  2202,  2000,  2131,  2045,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 14308, 21354, 23176,  7828,  7301,  2064, 16356,  2571,  2116,\n",
      "          1037, 23655,  2121,  1005,  1055, 11281,  1010,  2021,  2043,  2009,\n",
      "          5366,  1037,  2155,  1997,  2176,  2055,  1002,  2871,  2000,  2156,\n",
      "          1037,  2143,  1999, 12370,  1010,  2339,  5247,  2769,  2006,  1037,\n",
      "          3899,  2066,  2023,  2043,  2017,  2064,  9278,  1037, 21877,  4305,\n",
      "         28637,  2612,  1029,   102]]), 'ntok': tensor([31, 54]), 'cls_emb': tensor([[ 0.2689,  0.1349,  0.1873,  ...,  0.0084,  0.2752,  0.7068],\n",
      "        [ 0.2625,  0.0810, -0.3496,  ..., -0.3750,  0.5018,  0.8923]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2450,  1005,  1055, 27263,  2856,  2007, 17011,  2011,\n",
      "          6335,  3148, 15775, 17339,  2078,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2089,  2128, 10830,  7520,  6594,  1997,  1996,  5817, 10102,\n",
      "          2021,  2023,  7214,  2143,  3504,  2081,  2005,  5830,  2738,  2084,\n",
      "          2005,  1996,  2502,  3898,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2450,  1005,  1055, 27263,  2856,  2007, 17011,  2011,\n",
      "          6335,  3148, 15775, 17339,  2078,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2089,  2128, 10830,  7520,  6594,  1997,  1996,  5817, 10102,\n",
      "          2021,  2023,  7214,  2143,  3504,  2081,  2005,  5830,  2738,  2084,\n",
      "          2005,  1996,  2502,  3898,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2765, 0.7235],\n",
      "        [0.2679, 0.7321]]), 'input_ids': tensor([[  101,  1037,  2450,  1005,  1055, 27263,  2856,  2007, 17011,  2011,\n",
      "          6335,  3148, 15775, 17339,  2078,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2089,  2128, 10830,  7520,  6594,  1997,  1996,  5817, 10102,\n",
      "          2021,  2023,  7214,  2143,  3504,  2081,  2005,  5830,  2738,  2084,\n",
      "          2005,  1996,  2502,  3898,  1012,   102]]), 'ntok': tensor([17, 26]), 'cls_emb': tensor([[-0.1548, -0.0474, -0.1696,  ..., -0.2446,  0.2902,  0.5128],\n",
      "        [-0.3525, -0.1707, -0.1778,  ..., -0.5693,  0.5868,  0.1768]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3494,  2145,  2342,  2000,  3853,  2429,  2000,  2070,  2275,\n",
      "          1997, 19337,  2666, 12423,  1998,  4012, 28139, 10222, 19307, 14982,\n",
      "          2015,  1010,  2053,  3043,  2129,  2116,  5850,  2027,  2079,  2030,\n",
      "          2129,  2172,  6018,  6105, 10927,  2854, 13495,  1012,   102],\n",
      "        [  101,  1996,  2203,  2765,  2003,  1037,  2143,  2008,  1005,  1055,\n",
      "          4445,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3494,  2145,  2342,  2000,  3853,  2429,  2000,  2070,  2275,\n",
      "          1997, 19337,  2666, 12423,  1998,  4012, 28139, 10222, 19307, 14982,\n",
      "          2015,  1010,  2053,  3043,  2129,  2116,  5850,  2027,  2079,  2030,\n",
      "          2129,  2172,  6018,  6105, 10927,  2854, 13495,  1012,   102],\n",
      "        [  101,  1996,  2203,  2765,  2003,  1037,  2143,  2008,  1005,  1055,\n",
      "          4445,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2474, 0.7526],\n",
      "        [0.2707, 0.7293]]), 'input_ids': tensor([[  101,  3494,  2145,  2342,  2000,  3853,  2429,  2000,  2070,  2275,\n",
      "          1997, 19337,  2666, 12423,  1998,  4012, 28139, 10222, 19307, 14982,\n",
      "          2015,  1010,  2053,  3043,  2129,  2116,  5850,  2027,  2079,  2030,\n",
      "          2129,  2172,  6018,  6105, 10927,  2854, 13495,  1012,   102],\n",
      "        [  101,  1996,  2203,  2765,  2003,  1037,  2143,  2008,  1005,  1055,\n",
      "          4445,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([39, 13]), 'cls_emb': tensor([[-0.0934,  0.3961, -0.4004,  ..., -0.3536,  0.3095,  0.4712],\n",
      "        [ 0.1964, -0.1865,  0.0331,  ..., -0.4160,  0.7038,  0.5056]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  9020,  2000,  2022,  4086,  1998, 10433,  2135, 17087,  2012,\n",
      "          1996,  2168,  2051,  1012,   102,     0],\n",
      "        [  101, 11797,  1005,  1055,  2143,  2003,  2440,  1997, 13432,  4616,\n",
      "          2013,  2327,  2000,  3953,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  9020,  2000,  2022,  4086,  1998, 10433,  2135, 17087,  2012,\n",
      "          1996,  2168,  2051,  1012,   102,     0],\n",
      "        [  101, 11797,  1005,  1055,  2143,  2003,  2440,  1997, 13432,  4616,\n",
      "          2013,  2327,  2000,  3953,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2579, 0.7421],\n",
      "        [0.2670, 0.7330]]), 'input_ids': tensor([[  101,  9020,  2000,  2022,  4086,  1998, 10433,  2135, 17087,  2012,\n",
      "          1996,  2168,  2051,  1012,   102,     0],\n",
      "        [  101, 11797,  1005,  1055,  2143,  2003,  2440,  1997, 13432,  4616,\n",
      "          2013,  2327,  2000,  3953,  1012,   102]]), 'ntok': tensor([15, 16]), 'cls_emb': tensor([[-0.0856, -0.0706, -0.0573,  ..., -0.4322,  0.3839,  0.3599],\n",
      "        [-0.3214,  0.0267, -0.5038,  ..., -0.4955,  0.3050,  0.6049]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2036,  1010,  4415,  1010,  2307,  4569,\n",
      "          1012,   102],\n",
      "        [  101,  6524,  2038, 25468,  2246,  2061, 22349,  1998, 28378,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2036,  1010,  4415,  1010,  2307,  4569,\n",
      "          1012,   102],\n",
      "        [  101,  6524,  2038, 25468,  2246,  2061, 22349,  1998, 28378,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2579, 0.7421],\n",
      "        [0.2314, 0.7686]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2036,  1010,  4415,  1010,  2307,  4569,\n",
      "          1012,   102],\n",
      "        [  101,  6524,  2038, 25468,  2246,  2061, 22349,  1998, 28378,  1012,\n",
      "           102,     0]]), 'ntok': tensor([12, 11]), 'cls_emb': tensor([[ 0.1202,  0.1351, -0.1171,  ..., -0.3740,  0.1141,  0.5844],\n",
      "        [-0.4608, -0.1830, -0.6293,  ..., -0.1115,  0.3386,  0.5570]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  3849,  2066,  1045,  2031,  2042,  3403,  2026,  2878,\n",
      "          2166,  2005,  2023,  3185,  1998,  2085,  1045,  6187,  1050,  1005,\n",
      "          1056,  3524,  2005,  1996,  8297,  1012,   102],\n",
      "        [  101,  4340,  2000,  2022,  4569,  1010,  1998,  8945,  4609,  5666,\n",
      "          1010,  2007, 18114, 20103,  1010,  1996,  8562,  2106,  1050,  1005,\n",
      "          1056,  3243,  8526,  2023,  4639,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  3849,  2066,  1045,  2031,  2042,  3403,  2026,  2878,\n",
      "          2166,  2005,  2023,  3185,  1998,  2085,  1045,  6187,  1050,  1005,\n",
      "          1056,  3524,  2005,  1996,  8297,  1012,   102],\n",
      "        [  101,  4340,  2000,  2022,  4569,  1010,  1998,  8945,  4609,  5666,\n",
      "          1010,  2007, 18114, 20103,  1010,  1996,  8562,  2106,  1050,  1005,\n",
      "          1056,  3243,  8526,  2023,  4639,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2596, 0.7404],\n",
      "        [0.2663, 0.7337]]), 'input_ids': tensor([[  101,  2009,  3849,  2066,  1045,  2031,  2042,  3403,  2026,  2878,\n",
      "          2166,  2005,  2023,  3185,  1998,  2085,  1045,  6187,  1050,  1005,\n",
      "          1056,  3524,  2005,  1996,  8297,  1012,   102],\n",
      "        [  101,  4340,  2000,  2022,  4569,  1010,  1998,  8945,  4609,  5666,\n",
      "          1010,  2007, 18114, 20103,  1010,  1996,  8562,  2106,  1050,  1005,\n",
      "          1056,  3243,  8526,  2023,  4639,  1012,   102]]), 'ntok': tensor([27, 27]), 'cls_emb': tensor([[ 0.1893, -0.0534,  0.1396,  ...,  0.0519,  0.4862,  0.4805],\n",
      "        [-0.3297, -0.6414, -0.0493,  ..., -0.5966,  0.4768,  0.2679]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2065,  2017, 10667,  2006,  2585,  5003, 11368,  1005,  1055,\n",
      "          2568, 12225,  1012,  1012,  1012,  9278,  2023,  3185,  1998,  5959,\n",
      "           999,   102],\n",
      "        [  101, 21657,  2135,  6057,  1010,  2049,  3494,  2035,  1996,  2062,\n",
      "          7244,  2005, 11193,  2000, 12063,  2030,  3986,  4697,  3209,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2065,  2017, 10667,  2006,  2585,  5003, 11368,  1005,  1055,\n",
      "          2568, 12225,  1012,  1012,  1012,  9278,  2023,  3185,  1998,  5959,\n",
      "           999,   102],\n",
      "        [  101, 21657,  2135,  6057,  1010,  2049,  3494,  2035,  1996,  2062,\n",
      "          7244,  2005, 11193,  2000, 12063,  2030,  3986,  4697,  3209,  1012,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2423, 0.7577],\n",
      "        [0.2905, 0.7095]]), 'input_ids': tensor([[  101,  2065,  2017, 10667,  2006,  2585,  5003, 11368,  1005,  1055,\n",
      "          2568, 12225,  1012,  1012,  1012,  9278,  2023,  3185,  1998,  5959,\n",
      "           999,   102],\n",
      "        [  101, 21657,  2135,  6057,  1010,  2049,  3494,  2035,  1996,  2062,\n",
      "          7244,  2005, 11193,  2000, 12063,  2030,  3986,  4697,  3209,  1012,\n",
      "           102,     0]]), 'ntok': tensor([22, 21]), 'cls_emb': tensor([[ 0.2956, -0.1867,  0.2057,  ..., -0.2066,  0.1561,  0.5367],\n",
      "        [-0.3950, -0.0778, -0.5199,  ..., -0.2777,  0.3032,  0.3221]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 18058,  1996,  2168,  2214,  2168,  2214,  1010, 16985,  3064,\n",
      "          2039,  2007,  3763, 13109, 12462,  1998,  2357,  2041,  2011,  5365,\n",
      "          2377,  3022,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2515,  1050,  1005,  1056,  3749,  2172,  4661,  1043, 29521,\n",
      "          3969, 24913,  1010, 10958,  4609, 11714,  2653,  1998,  1037,  2186,\n",
      "          1997, 12077,  2275,  4109,  1012,  1012,  1012,  2008,  5333,  1996,\n",
      "          3347,  2006, 19551,  3898,  4808,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 18058,  1996,  2168,  2214,  2168,  2214,  1010, 16985,  3064,\n",
      "          2039,  2007,  3763, 13109, 12462,  1998,  2357,  2041,  2011,  5365,\n",
      "          2377,  3022,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2515,  1050,  1005,  1056,  3749,  2172,  4661,  1043, 29521,\n",
      "          3969, 24913,  1010, 10958,  4609, 11714,  2653,  1998,  1037,  2186,\n",
      "          1997, 12077,  2275,  4109,  1012,  1012,  1012,  2008,  5333,  1996,\n",
      "          3347,  2006, 19551,  3898,  4808,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2759, 0.7241],\n",
      "        [0.2857, 0.7143]]), 'input_ids': tensor([[  101, 18058,  1996,  2168,  2214,  2168,  2214,  1010, 16985,  3064,\n",
      "          2039,  2007,  3763, 13109, 12462,  1998,  2357,  2041,  2011,  5365,\n",
      "          2377,  3022,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2515,  1050,  1005,  1056,  3749,  2172,  4661,  1043, 29521,\n",
      "          3969, 24913,  1010, 10958,  4609, 11714,  2653,  1998,  1037,  2186,\n",
      "          1997, 12077,  2275,  4109,  1012,  1012,  1012,  2008,  5333,  1996,\n",
      "          3347,  2006, 19551,  3898,  4808,  1012,   102]]), 'ntok': tensor([24, 37]), 'cls_emb': tensor([[-0.2519, -0.1551,  0.3486,  ..., -0.5024,  0.6632,  0.1859],\n",
      "        [ 0.0924,  0.0935, -0.0031,  ..., -0.3887,  0.5261,  0.2801]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2081,  2033,  2215,  2000, 16255,  2818,  2026,  2159,\n",
      "          2041,  1997,  2026,  2132,  1998, 10055,  2068,  2012,  1996,  3898,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2143,  1005,  1055,  4616,  2024, 26162,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2081,  2033,  2215,  2000, 16255,  2818,  2026,  2159,\n",
      "          2041,  1997,  2026,  2132,  1998, 10055,  2068,  2012,  1996,  3898,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2143,  1005,  1055,  4616,  2024, 26162,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2830, 0.7170],\n",
      "        [0.2496, 0.7504]]), 'input_ids': tensor([[  101,  2009,  2081,  2033,  2215,  2000, 16255,  2818,  2026,  2159,\n",
      "          2041,  1997,  2026,  2132,  1998, 10055,  2068,  2012,  1996,  3898,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2143,  1005,  1055,  4616,  2024, 26162,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([22, 10]), 'cls_emb': tensor([[ 0.1651,  0.1273, -0.1561,  ..., -0.2398,  0.4440,  0.3940],\n",
      "        [ 0.0898,  0.2007, -0.2118,  ..., -0.4660,  0.2179,  0.1100]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  6854,  1010,  2009,  1005,  1055,  2025, 10021,  4569,  4983,\n",
      "          2017,  5959,  2428,  2919,  5691,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2919,  2518,  2043,  1037,  3185,\n",
      "          2038,  2055,  2004,  2172,  9415,  2004,  2049,  2203,  6495,  1038,\n",
      "          4135, 25918, 15934,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  6854,  1010,  2009,  1005,  1055,  2025, 10021,  4569,  4983,\n",
      "          2017,  5959,  2428,  2919,  5691,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2919,  2518,  2043,  1037,  3185,\n",
      "          2038,  2055,  2004,  2172,  9415,  2004,  2049,  2203,  6495,  1038,\n",
      "          4135, 25918, 15934,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2415, 0.7585],\n",
      "        [0.2535, 0.7465]]), 'input_ids': tensor([[  101,  6854,  1010,  2009,  1005,  1055,  2025, 10021,  4569,  4983,\n",
      "          2017,  5959,  2428,  2919,  5691,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2919,  2518,  2043,  1037,  3185,\n",
      "          2038,  2055,  2004,  2172,  9415,  2004,  2049,  2203,  6495,  1038,\n",
      "          4135, 25918, 15934,  1012,   102]]), 'ntok': tensor([17, 25]), 'cls_emb': tensor([[ 0.4691, -0.0491, -0.0181,  ..., -0.0061,  0.2503,  0.5455],\n",
      "        [ 0.2994,  0.2092, -0.4313,  ..., -0.1276,  0.2643,  0.5046]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1045, 25353,  8737, 25457,  4371,  2007,  1996, 24525,  1997,\n",
      "          2122,  2945,  1010,  2021,  1996,  3185,  2515,  1050,  1005,  1056,\n",
      "          2079,  1037,  2200,  2204,  3105, 16636,  2075,  1996,  3277,  2012,\n",
      "          2192,  1012,   102],\n",
      "        [  101,  1996,  2896,  2115, 10908,  1010,  1996,  2062,  2017,  1005,\n",
      "          2222,  5959,  2009,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1045, 25353,  8737, 25457,  4371,  2007,  1996, 24525,  1997,\n",
      "          2122,  2945,  1010,  2021,  1996,  3185,  2515,  1050,  1005,  1056,\n",
      "          2079,  1037,  2200,  2204,  3105, 16636,  2075,  1996,  3277,  2012,\n",
      "          2192,  1012,   102],\n",
      "        [  101,  1996,  2896,  2115, 10908,  1010,  1996,  2062,  2017,  1005,\n",
      "          2222,  5959,  2009,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2572, 0.7428],\n",
      "        [0.2403, 0.7597]]), 'input_ids': tensor([[  101,  1045, 25353,  8737, 25457,  4371,  2007,  1996, 24525,  1997,\n",
      "          2122,  2945,  1010,  2021,  1996,  3185,  2515,  1050,  1005,  1056,\n",
      "          2079,  1037,  2200,  2204,  3105, 16636,  2075,  1996,  3277,  2012,\n",
      "          2192,  1012,   102],\n",
      "        [  101,  1996,  2896,  2115, 10908,  1010,  1996,  2062,  2017,  1005,\n",
      "          2222,  5959,  2009,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([33, 15]), 'cls_emb': tensor([[ 0.0315, -0.1253, -0.2864,  ..., -0.1314,  0.2560,  0.5072],\n",
      "        [ 0.4115,  0.0030,  0.0532,  ..., -0.5116,  0.0162,  0.3314]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2295,  6890,  1998, 25124,  2191, 18988,  4073,  2000,  7200,\n",
      "          2166,  2046,  1996,  4487,  2015,  5558, 18447,  2098,  1010,  5292,\n",
      "         21890, 26154,  5896,  2011,  6108,  8040,  5886,  6799,  1998,  2585,\n",
      "          6902,  2078,  1010,  4445,  1996,  5889,  4496,  2472, 14435, 15876,\n",
      "         19422,  2378,  2064,  2191,  2009,  2062,  2084,  4906,  7699, 14036,\n",
      "          1012,   102],\n",
      "        [  101,  1037,  2442,  1011,  2156,  2005,  1996,  2585,  5003, 11368,\n",
      "         29550,  1998,  2005,  3087,  2040,  9120,  2015,  9414,  1010,  2358,\n",
      "          8516,  4509,  3185, 12614,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2295,  6890,  1998, 25124,  2191, 18988,  4073,  2000,  7200,\n",
      "          2166,  2046,  1996,  4487,  2015,  5558, 18447,  2098,  1010,  5292,\n",
      "         21890, 26154,  5896,  2011,  6108,  8040,  5886,  6799,  1998,  2585,\n",
      "          6902,  2078,  1010,  4445,  1996,  5889,  4496,  2472, 14435, 15876,\n",
      "         19422,  2378,  2064,  2191,  2009,  2062,  2084,  4906,  7699, 14036,\n",
      "          1012,   102],\n",
      "        [  101,  1037,  2442,  1011,  2156,  2005,  1996,  2585,  5003, 11368,\n",
      "         29550,  1998,  2005,  3087,  2040,  9120,  2015,  9414,  1010,  2358,\n",
      "          8516,  4509,  3185, 12614,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2551, 0.7449],\n",
      "        [0.2431, 0.7569]]), 'input_ids': tensor([[  101,  2295,  6890,  1998, 25124,  2191, 18988,  4073,  2000,  7200,\n",
      "          2166,  2046,  1996,  4487,  2015,  5558, 18447,  2098,  1010,  5292,\n",
      "         21890, 26154,  5896,  2011,  6108,  8040,  5886,  6799,  1998,  2585,\n",
      "          6902,  2078,  1010,  4445,  1996,  5889,  4496,  2472, 14435, 15876,\n",
      "         19422,  2378,  2064,  2191,  2009,  2062,  2084,  4906,  7699, 14036,\n",
      "          1012,   102],\n",
      "        [  101,  1037,  2442,  1011,  2156,  2005,  1996,  2585,  5003, 11368,\n",
      "         29550,  1998,  2005,  3087,  2040,  9120,  2015,  9414,  1010,  2358,\n",
      "          8516,  4509,  3185, 12614,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([52, 26]), 'cls_emb': tensor([[-0.1856,  0.2395, -0.4591,  ..., -0.1202,  0.4893,  0.6209],\n",
      "        [-0.4717, -0.0716, -0.1605,  ..., -0.5052,  0.4531,  0.2448]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 14397,  5740,  2003,  8235,  2004,  1996,  3637,  1011, 17676,\n",
      "         19568,  2121,  1010,  2010,  4852,  4929,  9961,  2004,  2172, 25953,\n",
      "          4818,  2004,  2009,  2003,  3558,  1012,   102,     0],\n",
      "        [  101,  1036,  2139,  9152,  3217,  1012,  1012,  1012,  2003,  1037,\n",
      "          2310, 17728,  3468,  3120,  1997, 18006,  6896,  2008,  2023,  5365,\n",
      "          9530, 18886, 21789, 20347,  2105,  1012,  1005,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 14397,  5740,  2003,  8235,  2004,  1996,  3637,  1011, 17676,\n",
      "         19568,  2121,  1010,  2010,  4852,  4929,  9961,  2004,  2172, 25953,\n",
      "          4818,  2004,  2009,  2003,  3558,  1012,   102,     0],\n",
      "        [  101,  1036,  2139,  9152,  3217,  1012,  1012,  1012,  2003,  1037,\n",
      "          2310, 17728,  3468,  3120,  1997, 18006,  6896,  2008,  2023,  5365,\n",
      "          9530, 18886, 21789, 20347,  2105,  1012,  1005,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2326, 0.7674],\n",
      "        [0.3176, 0.6824]]), 'input_ids': tensor([[  101, 14397,  5740,  2003,  8235,  2004,  1996,  3637,  1011, 17676,\n",
      "         19568,  2121,  1010,  2010,  4852,  4929,  9961,  2004,  2172, 25953,\n",
      "          4818,  2004,  2009,  2003,  3558,  1012,   102,     0],\n",
      "        [  101,  1036,  2139,  9152,  3217,  1012,  1012,  1012,  2003,  1037,\n",
      "          2310, 17728,  3468,  3120,  1997, 18006,  6896,  2008,  2023,  5365,\n",
      "          9530, 18886, 21789, 20347,  2105,  1012,  1005,   102]]), 'ntok': tensor([27, 28]), 'cls_emb': tensor([[-0.2993, -0.0323, -0.2469,  ..., -0.1362,  0.8072,  0.5708],\n",
      "        [ 0.4035,  0.1775, -0.1861,  ..., -0.3079,  0.5015,  0.4956]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 28616, 15707, 26942,  2594,  3538,  1997, 10882, 24658,\n",
      "          2008,  4740,  2000,  3413,  2993,  2125,  2004,  5099,  1010,  2402,\n",
      "          4639,  4024,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049,  2466,  2089,  2022,  1037,  4595,  2086,  2214,  1010,\n",
      "          2021,  2339,  2106,  2009,  2031,  2000,  4025,  2066,  2009,  2165,\n",
      "          2178,  4595,  2000,  2425,  2009,  2000,  2149,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 28616, 15707, 26942,  2594,  3538,  1997, 10882, 24658,\n",
      "          2008,  4740,  2000,  3413,  2993,  2125,  2004,  5099,  1010,  2402,\n",
      "          4639,  4024,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049,  2466,  2089,  2022,  1037,  4595,  2086,  2214,  1010,\n",
      "          2021,  2339,  2106,  2009,  2031,  2000,  4025,  2066,  2009,  2165,\n",
      "          2178,  4595,  2000,  2425,  2009,  2000,  2149,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2562, 0.7438],\n",
      "        [0.2478, 0.7522]]), 'input_ids': tensor([[  101,  1037, 28616, 15707, 26942,  2594,  3538,  1997, 10882, 24658,\n",
      "          2008,  4740,  2000,  3413,  2993,  2125,  2004,  5099,  1010,  2402,\n",
      "          4639,  4024,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2049,  2466,  2089,  2022,  1037,  4595,  2086,  2214,  1010,\n",
      "          2021,  2339,  2106,  2009,  2031,  2000,  4025,  2066,  2009,  2165,\n",
      "          2178,  4595,  2000,  2425,  2009,  2000,  2149,  1029,   102]]), 'ntok': tensor([24, 29]), 'cls_emb': tensor([[-0.3511, -0.0639, -0.3383,  ..., -0.3480,  0.8668,  0.2380],\n",
      "        [ 0.4732,  0.1269, -0.1688,  ...,  0.1200,  0.3595,  0.3422]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3046,  2004,  1045,  2089,  1010,  1045,  6187,  1050,  1005,\n",
      "          1056,  2228,  1997,  1037,  2309,  2204,  3114,  2000,  2156,  2023,\n",
      "          3185,  1010,  2130,  2295,  3071,  1999,  2026,  2177,  4654, 18532,\n",
      "         17822, 17191,  2135,  6626,  1010,  1036,  4067,  2017,   999,  1005,\n",
      "           102],\n",
      "        [  101,  1996,  3185,  2003,  3376,  2000, 27541,  1998, 24255,  2028,\n",
      "          1999,  1037,  3168,  1997,  8680,  5998,  1011,  1011,  5110,  1998,\n",
      "          6058,  1011,  1011,  2008,  1005,  1055,  2035,  2205,  4678,  1999,\n",
      "          5365,  1005,  1055,  2038, 17579,  5453,  1012,   102,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3046,  2004,  1045,  2089,  1010,  1045,  6187,  1050,  1005,\n",
      "          1056,  2228,  1997,  1037,  2309,  2204,  3114,  2000,  2156,  2023,\n",
      "          3185,  1010,  2130,  2295,  3071,  1999,  2026,  2177,  4654, 18532,\n",
      "         17822, 17191,  2135,  6626,  1010,  1036,  4067,  2017,   999,  1005,\n",
      "           102],\n",
      "        [  101,  1996,  3185,  2003,  3376,  2000, 27541,  1998, 24255,  2028,\n",
      "          1999,  1037,  3168,  1997,  8680,  5998,  1011,  1011,  5110,  1998,\n",
      "          6058,  1011,  1011,  2008,  1005,  1055,  2035,  2205,  4678,  1999,\n",
      "          5365,  1005,  1055,  2038, 17579,  5453,  1012,   102,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.3302, 0.6698],\n",
      "        [0.2479, 0.7521]]), 'input_ids': tensor([[  101,  3046,  2004,  1045,  2089,  1010,  1045,  6187,  1050,  1005,\n",
      "          1056,  2228,  1997,  1037,  2309,  2204,  3114,  2000,  2156,  2023,\n",
      "          3185,  1010,  2130,  2295,  3071,  1999,  2026,  2177,  4654, 18532,\n",
      "         17822, 17191,  2135,  6626,  1010,  1036,  4067,  2017,   999,  1005,\n",
      "           102],\n",
      "        [  101,  1996,  3185,  2003,  3376,  2000, 27541,  1998, 24255,  2028,\n",
      "          1999,  1037,  3168,  1997,  8680,  5998,  1011,  1011,  5110,  1998,\n",
      "          6058,  1011,  1011,  2008,  1005,  1055,  2035,  2205,  4678,  1999,\n",
      "          5365,  1005,  1055,  2038, 17579,  5453,  1012,   102,     0,     0,\n",
      "             0]]), 'ntok': tensor([41, 38]), 'cls_emb': tensor([[ 0.3894,  0.2613,  0.1085,  ...,  0.3417,  0.5948,  0.6973],\n",
      "        [ 0.0574,  0.0152, -0.2471,  ..., -0.1648,  0.3682,  0.5065]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  7401,  1997, 21864, 26891,  7971,  1010, 18080,  3012,\n",
      "          1010,  1998,  3056,  3633,  1005, 11765,  2000,  2292,  2009,  2035,\n",
      "          6865,  2041,  1010,  1998,  4365,  1996,  8465,  1012,   102],\n",
      "        [  101, 11164,  3594,  2014,  2227,  1998,  2014,  2303,  2653,  2000,\n",
      "          3288,  2149, 22822, 23062,  1005,  1055,  3969,  1010,  2130,  2295,\n",
      "          1996,  2839,  2003,  2471,  3294,  2757,  9739,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  7401,  1997, 21864, 26891,  7971,  1010, 18080,  3012,\n",
      "          1010,  1998,  3056,  3633,  1005, 11765,  2000,  2292,  2009,  2035,\n",
      "          6865,  2041,  1010,  1998,  4365,  1996,  8465,  1012,   102],\n",
      "        [  101, 11164,  3594,  2014,  2227,  1998,  2014,  2303,  2653,  2000,\n",
      "          3288,  2149, 22822, 23062,  1005,  1055,  3969,  1010,  2130,  2295,\n",
      "          1996,  2839,  2003,  2471,  3294,  2757,  9739,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2714, 0.7286],\n",
      "        [0.2443, 0.7557]]), 'input_ids': tensor([[  101,  1037,  7401,  1997, 21864, 26891,  7971,  1010, 18080,  3012,\n",
      "          1010,  1998,  3056,  3633,  1005, 11765,  2000,  2292,  2009,  2035,\n",
      "          6865,  2041,  1010,  1998,  4365,  1996,  8465,  1012,   102],\n",
      "        [  101, 11164,  3594,  2014,  2227,  1998,  2014,  2303,  2653,  2000,\n",
      "          3288,  2149, 22822, 23062,  1005,  1055,  3969,  1010,  2130,  2295,\n",
      "          1996,  2839,  2003,  2471,  3294,  2757,  9739,  1012,   102]]), 'ntok': tensor([29, 29]), 'cls_emb': tensor([[-0.3560, -0.1970, -0.5966,  ..., -0.2501,  0.4467,  0.3183],\n",
      "        [-0.3510, -0.2776, -0.6829,  ..., -0.0752,  0.7579,  0.3693]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2612,  1997,  1037, 23760, 18647,  3786,  1011,  5338,  3923,\n",
      "          2530,  1010,  2009,  1005,  1055,  2019,  4895, 28139,  6528, 20771,\n",
      "          1010, 24846,  2135,  4197, 14704,  1997,  2166,  1012,   102],\n",
      "        [  101,  2026,  4301,  2020,  4208,  2006,  1996,  3494,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2612,  1997,  1037, 23760, 18647,  3786,  1011,  5338,  3923,\n",
      "          2530,  1010,  2009,  1005,  1055,  2019,  4895, 28139,  6528, 20771,\n",
      "          1010, 24846,  2135,  4197, 14704,  1997,  2166,  1012,   102],\n",
      "        [  101,  2026,  4301,  2020,  4208,  2006,  1996,  3494,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2558, 0.7442],\n",
      "        [0.2666, 0.7334]]), 'input_ids': tensor([[  101,  2612,  1997,  1037, 23760, 18647,  3786,  1011,  5338,  3923,\n",
      "          2530,  1010,  2009,  1005,  1055,  2019,  4895, 28139,  6528, 20771,\n",
      "          1010, 24846,  2135,  4197, 14704,  1997,  2166,  1012,   102],\n",
      "        [  101,  2026,  4301,  2020,  4208,  2006,  1996,  3494,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([29, 10]), 'cls_emb': tensor([[-0.0375,  0.0863, -0.3745,  ..., -0.4363,  0.5871,  0.3596],\n",
      "        [-0.1132, -0.1288, -0.3227,  ..., -0.2370,  0.4163,  0.4128]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2061,  1010,  2205,  1010,  2003,  2023,  4038,  2055, 10256,\n",
      "          3226, 13249,  2075,  1999,  2651,  1005,  1055,  2047,  6768,  1012,\n",
      "           102],\n",
      "        [  101,  2005, 29400,  1010,  1996,  2466,  2003,  2074,  2205, 11754,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2061,  1010,  2205,  1010,  2003,  2023,  4038,  2055, 10256,\n",
      "          3226, 13249,  2075,  1999,  2651,  1005,  1055,  2047,  6768,  1012,\n",
      "           102],\n",
      "        [  101,  2005, 29400,  1010,  1996,  2466,  2003,  2074,  2205, 11754,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2641, 0.7359],\n",
      "        [0.2658, 0.7342]]), 'input_ids': tensor([[  101,  2061,  1010,  2205,  1010,  2003,  2023,  4038,  2055, 10256,\n",
      "          3226, 13249,  2075,  1999,  2651,  1005,  1055,  2047,  6768,  1012,\n",
      "           102],\n",
      "        [  101,  2005, 29400,  1010,  1996,  2466,  2003,  2074,  2205, 11754,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([21, 12]), 'cls_emb': tensor([[-0.2514, -0.2406, -0.0351,  ..., -0.3963,  0.4256,  0.3810],\n",
      "        [ 0.1051, -0.0493, -0.2256,  ..., -0.1093,  0.2815,  0.4591]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  1037,  3045,  7241,  4038,  2008,  3065, 16485,\n",
      "          2064,  2404,  7132, 11680,  1998,  8053,  7132, 23541,  2006,  1996,\n",
      "          6462,  1010,  2074,  2004,  4089,  2004,  2037, 14562,  5973,  2842,\n",
      "          1999,  1996,  2088,  1012,   102,     0,     0,     0],\n",
      "        [  101,  2012,  1996,  2200,  2560,  1010,  2065,  2017,  2079,  1050,\n",
      "          1005,  1056,  2113,  2505,  2055,  4315, 14615,  2050,  2043,  2017,\n",
      "          3328,  2046,  1996,  4258,  1010,  2017, 24185,  1050,  1005,  1056,\n",
      "          2113,  2172,  2062,  2043,  2017,  2681,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  1037,  3045,  7241,  4038,  2008,  3065, 16485,\n",
      "          2064,  2404,  7132, 11680,  1998,  8053,  7132, 23541,  2006,  1996,\n",
      "          6462,  1010,  2074,  2004,  4089,  2004,  2037, 14562,  5973,  2842,\n",
      "          1999,  1996,  2088,  1012,   102,     0,     0,     0],\n",
      "        [  101,  2012,  1996,  2200,  2560,  1010,  2065,  2017,  2079,  1050,\n",
      "          1005,  1056,  2113,  2505,  2055,  4315, 14615,  2050,  2043,  2017,\n",
      "          3328,  2046,  1996,  4258,  1010,  2017, 24185,  1050,  1005,  1056,\n",
      "          2113,  2172,  2062,  2043,  2017,  2681,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2543, 0.7457],\n",
      "        [0.2854, 0.7146]]), 'input_ids': tensor([[  101,  2023,  2003,  1037,  3045,  7241,  4038,  2008,  3065, 16485,\n",
      "          2064,  2404,  7132, 11680,  1998,  8053,  7132, 23541,  2006,  1996,\n",
      "          6462,  1010,  2074,  2004,  4089,  2004,  2037, 14562,  5973,  2842,\n",
      "          1999,  1996,  2088,  1012,   102,     0,     0,     0],\n",
      "        [  101,  2012,  1996,  2200,  2560,  1010,  2065,  2017,  2079,  1050,\n",
      "          1005,  1056,  2113,  2505,  2055,  4315, 14615,  2050,  2043,  2017,\n",
      "          3328,  2046,  1996,  4258,  1010,  2017, 24185,  1050,  1005,  1056,\n",
      "          2113,  2172,  2062,  2043,  2017,  2681,  1012,   102]]), 'ntok': tensor([35, 38]), 'cls_emb': tensor([[ 0.0073, -0.0279,  0.0516,  ..., -0.3000,  0.5099,  0.4357],\n",
      "        [ 0.1207,  0.1026, -0.2297,  ..., -0.0521,  0.3013,  0.8978]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  4289,  4152,  2109,  2190,  1012,  1012,  1012,  2000,\n",
      "          5425,  1996, 14849,  2075,  7535,  4719,  2011,  9587,  3406, 16458,\n",
      "          1998,  1038, 22984,  8195,  1010,  3005,  7250,  2594,  2980, 16168,\n",
      "          4726,  5681,  4515,  1999,  5923,  1011, 14527, 11224, 22264,  1012,\n",
      "           102],\n",
      "        [  101,  2503,  1996,  2143,  1005,  1055,  4736,  1011,  6113,  5436,\n",
      "          2045,  2003,  1037, 11519,  7191,  2667,  2000,  2131,  2041,  1010,\n",
      "          2021,  2009,  1005,  1055,  2025,  2008,  1010,  2009,  1005,  1055,\n",
      "          1996,  6980,  2008,  7906,  2017,  1999,  2115,  2835,  1012,   102,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  4289,  4152,  2109,  2190,  1012,  1012,  1012,  2000,\n",
      "          5425,  1996, 14849,  2075,  7535,  4719,  2011,  9587,  3406, 16458,\n",
      "          1998,  1038, 22984,  8195,  1010,  3005,  7250,  2594,  2980, 16168,\n",
      "          4726,  5681,  4515,  1999,  5923,  1011, 14527, 11224, 22264,  1012,\n",
      "           102],\n",
      "        [  101,  2503,  1996,  2143,  1005,  1055,  4736,  1011,  6113,  5436,\n",
      "          2045,  2003,  1037, 11519,  7191,  2667,  2000,  2131,  2041,  1010,\n",
      "          2021,  2009,  1005,  1055,  2025,  2008,  1010,  2009,  1005,  1055,\n",
      "          1996,  6980,  2008,  7906,  2017,  1999,  2115,  2835,  1012,   102,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2375, 0.7625],\n",
      "        [0.2507, 0.7493]]), 'input_ids': tensor([[  101,  1996,  4289,  4152,  2109,  2190,  1012,  1012,  1012,  2000,\n",
      "          5425,  1996, 14849,  2075,  7535,  4719,  2011,  9587,  3406, 16458,\n",
      "          1998,  1038, 22984,  8195,  1010,  3005,  7250,  2594,  2980, 16168,\n",
      "          4726,  5681,  4515,  1999,  5923,  1011, 14527, 11224, 22264,  1012,\n",
      "           102],\n",
      "        [  101,  2503,  1996,  2143,  1005,  1055,  4736,  1011,  6113,  5436,\n",
      "          2045,  2003,  1037, 11519,  7191,  2667,  2000,  2131,  2041,  1010,\n",
      "          2021,  2009,  1005,  1055,  2025,  2008,  1010,  2009,  1005,  1055,\n",
      "          1996,  6980,  2008,  7906,  2017,  1999,  2115,  2835,  1012,   102,\n",
      "             0]]), 'ntok': tensor([41, 40]), 'cls_emb': tensor([[ 0.0990, -0.2389,  0.1906,  ..., -0.5512,  0.5242,  0.2361],\n",
      "        [ 0.1928, -0.0988, -0.3861,  ..., -0.2507,  0.3969,  0.5390]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045, 11276,  2000,  2022,  1037,  9855,  6105,  1010,  2061,\n",
      "          2008,  3968,  7641,  2064,  2031,  2010, 22837,  1012,   102],\n",
      "        [  101,  2919,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045, 11276,  2000,  2022,  1037,  9855,  6105,  1010,  2061,\n",
      "          2008,  3968,  7641,  2064,  2031,  2010, 22837,  1012,   102],\n",
      "        [  101,  2919,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2726, 0.7274],\n",
      "        [0.2603, 0.7397]]), 'input_ids': tensor([[  101,  2045, 11276,  2000,  2022,  1037,  9855,  6105,  1010,  2061,\n",
      "          2008,  3968,  7641,  2064,  2031,  2010, 22837,  1012,   102],\n",
      "        [  101,  2919,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([19,  4]), 'cls_emb': tensor([[-0.1399,  0.3225,  0.1658,  ..., -0.3097,  0.4554,  0.5266],\n",
      "        [-0.3225,  0.2053, -0.3629,  ..., -0.3253,  0.4272,  0.2773]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2008, 28844,  2098,  2204,  2097,  1997,  1996,  3008,  1998,\n",
      "          1036, 15784,  1005, 25871,  1005,  1055, 13366, 10893,  3370,  1997,\n",
      "         13059,  1010,  2191,  1996,  2143,  7244,  2750,  2070,  2079,  6392,\n",
      "          6824,  2015,  1012,   102],\n",
      "        [  101,  4212, 15981,  2046,  1996,  4696,  1997,  2204,  5236,  4569,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2008, 28844,  2098,  2204,  2097,  1997,  1996,  3008,  1998,\n",
      "          1036, 15784,  1005, 25871,  1005,  1055, 13366, 10893,  3370,  1997,\n",
      "         13059,  1010,  2191,  1996,  2143,  7244,  2750,  2070,  2079,  6392,\n",
      "          6824,  2015,  1012,   102],\n",
      "        [  101,  4212, 15981,  2046,  1996,  4696,  1997,  2204,  5236,  4569,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2549, 0.7451],\n",
      "        [0.2711, 0.7289]]), 'input_ids': tensor([[  101,  2008, 28844,  2098,  2204,  2097,  1997,  1996,  3008,  1998,\n",
      "          1036, 15784,  1005, 25871,  1005,  1055, 13366, 10893,  3370,  1997,\n",
      "         13059,  1010,  2191,  1996,  2143,  7244,  2750,  2070,  2079,  6392,\n",
      "          6824,  2015,  1012,   102],\n",
      "        [  101,  4212, 15981,  2046,  1996,  4696,  1997,  2204,  5236,  4569,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 12]), 'cls_emb': tensor([[ 0.0748,  0.0028, -0.1579,  ..., -0.3462,  0.4734,  0.3749],\n",
      "        [ 0.0539,  0.0449, -0.1616,  ..., -0.2739,  0.2723,  0.4051]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019,  2396,  3993,  1010,  9414,  2143,  2008, 12237,  2306,\n",
      "          1996, 25722,  1997,  1037,  2092,  1011,  2511,  6907,  1012,   102],\n",
      "        [  101,  6047,  1010, 26422,  1998,  1038,  9863,  7999,  2135,  6057,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019,  2396,  3993,  1010,  9414,  2143,  2008, 12237,  2306,\n",
      "          1996, 25722,  1997,  1037,  2092,  1011,  2511,  6907,  1012,   102],\n",
      "        [  101,  6047,  1010, 26422,  1998,  1038,  9863,  7999,  2135,  6057,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2620, 0.7380],\n",
      "        [0.2562, 0.7438]]), 'input_ids': tensor([[  101,  2019,  2396,  3993,  1010,  9414,  2143,  2008, 12237,  2306,\n",
      "          1996, 25722,  1997,  1037,  2092,  1011,  2511,  6907,  1012,   102],\n",
      "        [  101,  6047,  1010, 26422,  1998,  1038,  9863,  7999,  2135,  6057,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([20, 12]), 'cls_emb': tensor([[-0.3261, -0.2134,  0.0348,  ..., -0.4229,  0.4672,  0.2593],\n",
      "        [-0.5779, -0.1078, -0.5709,  ..., -0.5973,  0.1500,  0.7967]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1998,  1996, 10800,  1010,  1999,  1996,  2203,  1010,  2003,\n",
      "          2498,  2047,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  2025,  1996,  6151,  2483, 29462,  5409,  8362,\n",
      "          3185,  2412,  1010,  2021,  2009,  1005,  1055,  5121,  2025,  1037,\n",
      "          3410,  1011,  1996,  2502, 10916,  2003,  1996,  4378,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1998,  1996, 10800,  1010,  1999,  1996,  2203,  1010,  2003,\n",
      "          2498,  2047,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  2025,  1996,  6151,  2483, 29462,  5409,  8362,\n",
      "          3185,  2412,  1010,  2021,  2009,  1005,  1055,  5121,  2025,  1037,\n",
      "          3410,  1011,  1996,  2502, 10916,  2003,  1996,  4378,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2511, 0.7489],\n",
      "        [0.2516, 0.7484]]), 'input_ids': tensor([[  101,  1998,  1996, 10800,  1010,  1999,  1996,  2203,  1010,  2003,\n",
      "          2498,  2047,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  2003,  2025,  1996,  6151,  2483, 29462,  5409,  8362,\n",
      "          3185,  2412,  1010,  2021,  2009,  1005,  1055,  5121,  2025,  1037,\n",
      "          3410,  1011,  1996,  2502, 10916,  2003,  1996,  4378,  1012,   102]]), 'ntok': tensor([14, 30]), 'cls_emb': tensor([[-0.0137,  0.1160, -0.1507,  ..., -0.1148,  0.2156,  0.6348],\n",
      "        [-0.1095,  0.3481, -0.0588,  ..., -0.1634,  0.7142,  0.7007]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2025,  2069,  2003, 16382,  2567,  2004,  6057,  1010,  2065,\n",
      "          2025,  2062,  2061,  1010,  2084,  2119,  5899,  4204,  3152,  1010,\n",
      "          2021,  2009,  1005,  1055,  2036,  2028,  1997,  1996, 25670,  1010,\n",
      "          7842,  2615, 14356, 11867, 21511,  2015,  2000,  2272,  2247,  1999,\n",
      "          2070,  2051,  1012,   102],\n",
      "        [  101,  2000,  2360,  2023,  2001,  2589,  2488,  1999, 18463,  1005,\n",
      "          1055,  2070,  2066,  2009,  2980,  2003,  2066,  3038,  1996,  3103,\n",
      "          9466,  1999,  1996,  2264,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2025,  2069,  2003, 16382,  2567,  2004,  6057,  1010,  2065,\n",
      "          2025,  2062,  2061,  1010,  2084,  2119,  5899,  4204,  3152,  1010,\n",
      "          2021,  2009,  1005,  1055,  2036,  2028,  1997,  1996, 25670,  1010,\n",
      "          7842,  2615, 14356, 11867, 21511,  2015,  2000,  2272,  2247,  1999,\n",
      "          2070,  2051,  1012,   102],\n",
      "        [  101,  2000,  2360,  2023,  2001,  2589,  2488,  1999, 18463,  1005,\n",
      "          1055,  2070,  2066,  2009,  2980,  2003,  2066,  3038,  1996,  3103,\n",
      "          9466,  1999,  1996,  2264,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2475, 0.7525],\n",
      "        [0.2602, 0.7398]]), 'input_ids': tensor([[  101,  2025,  2069,  2003, 16382,  2567,  2004,  6057,  1010,  2065,\n",
      "          2025,  2062,  2061,  1010,  2084,  2119,  5899,  4204,  3152,  1010,\n",
      "          2021,  2009,  1005,  1055,  2036,  2028,  1997,  1996, 25670,  1010,\n",
      "          7842,  2615, 14356, 11867, 21511,  2015,  2000,  2272,  2247,  1999,\n",
      "          2070,  2051,  1012,   102],\n",
      "        [  101,  2000,  2360,  2023,  2001,  2589,  2488,  1999, 18463,  1005,\n",
      "          1055,  2070,  2066,  2009,  2980,  2003,  2066,  3038,  1996,  3103,\n",
      "          9466,  1999,  1996,  2264,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([44, 26]), 'cls_emb': tensor([[-0.0938, -0.1443, -0.0056,  ...,  0.0602,  0.4646,  0.4309],\n",
      "        [-0.0846, -0.0282, -0.1246,  ..., -0.2511,  0.2888,  0.6945]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2972,  3185,  2003,  2055,  1037, 11771,  1010,  6517,\n",
      "          2158,  2108, 11771,  1998,  6517,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2023,  2051,  2720,  1012,  7641,  2003,  2667,  2242,  1999,\n",
      "          1996,  3235,  8040,  5668,  6810,  2395,  1011,  2613,  2923,  5549,\n",
      "          1010,  2021,  2010,  2969,  1011,  4953, 23069,  3012,  9109,  2032,\n",
      "          2039,  2153,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2972,  3185,  2003,  2055,  1037, 11771,  1010,  6517,\n",
      "          2158,  2108, 11771,  1998,  6517,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2023,  2051,  2720,  1012,  7641,  2003,  2667,  2242,  1999,\n",
      "          1996,  3235,  8040,  5668,  6810,  2395,  1011,  2613,  2923,  5549,\n",
      "          1010,  2021,  2010,  2969,  1011,  4953, 23069,  3012,  9109,  2032,\n",
      "          2039,  2153,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2485, 0.7515],\n",
      "        [0.2492, 0.7508]]), 'input_ids': tensor([[  101,  1996,  2972,  3185,  2003,  2055,  1037, 11771,  1010,  6517,\n",
      "          2158,  2108, 11771,  1998,  6517,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2023,  2051,  2720,  1012,  7641,  2003,  2667,  2242,  1999,\n",
      "          1996,  3235,  8040,  5668,  6810,  2395,  1011,  2613,  2923,  5549,\n",
      "          1010,  2021,  2010,  2969,  1011,  4953, 23069,  3012,  9109,  2032,\n",
      "          2039,  2153,  1012,   102]]), 'ntok': tensor([17, 34]), 'cls_emb': tensor([[ 0.0634,  0.0446,  0.0858,  ..., -0.1342,  0.7103,  0.3932],\n",
      "        [ 0.0642,  0.1636, -0.0395,  ..., -0.1027,  0.5113,  0.6835]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2566, 28687,  1999,  2049,  4432,  1997, 17235, 13013,  3919,\n",
      "          3550,  2088,  4331,  2004,  1037,  2047,  2396,  2433,  1010,  2021,\n",
      "          2521,  2205, 18856, 16814,  2100,  1010,  2106, 28804,  1998, 12279,\n",
      "          2094,  2007,  5019,  2008,  4025,  3432,  2019,  5665,  4906,  2005,\n",
      "          2023,  3185,  1012,   102],\n",
      "        [  101,  1996,  2190,  7195,  2089,  2074,  2022,  2542,  2092,  2138,\n",
      "          2023,  2143,  1010,  4406,  2060,  4241,  9335, 17241,  1010,  2003,\n",
      "          2521,  2062, 28834,  2000,  1037,  8813,  2084,  1037, 12401,  7173,\n",
      "          6251,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2566, 28687,  1999,  2049,  4432,  1997, 17235, 13013,  3919,\n",
      "          3550,  2088,  4331,  2004,  1037,  2047,  2396,  2433,  1010,  2021,\n",
      "          2521,  2205, 18856, 16814,  2100,  1010,  2106, 28804,  1998, 12279,\n",
      "          2094,  2007,  5019,  2008,  4025,  3432,  2019,  5665,  4906,  2005,\n",
      "          2023,  3185,  1012,   102],\n",
      "        [  101,  1996,  2190,  7195,  2089,  2074,  2022,  2542,  2092,  2138,\n",
      "          2023,  2143,  1010,  4406,  2060,  4241,  9335, 17241,  1010,  2003,\n",
      "          2521,  2062, 28834,  2000,  1037,  8813,  2084,  1037, 12401,  7173,\n",
      "          6251,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2662, 0.7338],\n",
      "        [0.2522, 0.7478]]), 'input_ids': tensor([[  101,  2566, 28687,  1999,  2049,  4432,  1997, 17235, 13013,  3919,\n",
      "          3550,  2088,  4331,  2004,  1037,  2047,  2396,  2433,  1010,  2021,\n",
      "          2521,  2205, 18856, 16814,  2100,  1010,  2106, 28804,  1998, 12279,\n",
      "          2094,  2007,  5019,  2008,  4025,  3432,  2019,  5665,  4906,  2005,\n",
      "          2023,  3185,  1012,   102],\n",
      "        [  101,  1996,  2190,  7195,  2089,  2074,  2022,  2542,  2092,  2138,\n",
      "          2023,  2143,  1010,  4406,  2060,  4241,  9335, 17241,  1010,  2003,\n",
      "          2521,  2062, 28834,  2000,  1037,  8813,  2084,  1037, 12401,  7173,\n",
      "          6251,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([44, 33]), 'cls_emb': tensor([[-0.0928, -0.1189, -0.1682,  ..., -0.0410,  0.6456,  0.4563],\n",
      "        [-0.1083, -0.1960, -0.0224,  ..., -0.1325,  0.4506,  0.5748]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185, 19821,  2066,  2261,  2500,  2129,  1996,  5995,\n",
      "          1998, 25291,  1997,  6832, 20893,  2507,  1996,  3558,  2552,  2035,\n",
      "          1997,  2049,  3574,  1998,  2087,  1997,  2049,  5165,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2320,  1006,  5035,  1007,  4269,  2000,  2058, 13068,  1996,\n",
      "          5213,  9887,  1998, 17395,  1011,  1998,  1011, 11147, 19240,  2015,\n",
      "          1010,  2017,  2089,  5630,  2009,  1005,  1055,  2205,  2152,  1037,\n",
      "          3976,  2000,  3477,  2005,  1037, 22349,  3861,  2695, 11522,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185, 19821,  2066,  2261,  2500,  2129,  1996,  5995,\n",
      "          1998, 25291,  1997,  6832, 20893,  2507,  1996,  3558,  2552,  2035,\n",
      "          1997,  2049,  3574,  1998,  2087,  1997,  2049,  5165,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2320,  1006,  5035,  1007,  4269,  2000,  2058, 13068,  1996,\n",
      "          5213,  9887,  1998, 17395,  1011,  1998,  1011, 11147, 19240,  2015,\n",
      "          1010,  2017,  2089,  5630,  2009,  1005,  1055,  2205,  2152,  1037,\n",
      "          3976,  2000,  3477,  2005,  1037, 22349,  3861,  2695, 11522,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2348, 0.7652],\n",
      "        [0.2530, 0.7470]]), 'input_ids': tensor([[  101,  1996,  3185, 19821,  2066,  2261,  2500,  2129,  1996,  5995,\n",
      "          1998, 25291,  1997,  6832, 20893,  2507,  1996,  3558,  2552,  2035,\n",
      "          1997,  2049,  3574,  1998,  2087,  1997,  2049,  5165,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2320,  1006,  5035,  1007,  4269,  2000,  2058, 13068,  1996,\n",
      "          5213,  9887,  1998, 17395,  1011,  1998,  1011, 11147, 19240,  2015,\n",
      "          1010,  2017,  2089,  5630,  2009,  1005,  1055,  2205,  2152,  1037,\n",
      "          3976,  2000,  3477,  2005,  1037, 22349,  3861,  2695, 11522,  1012,\n",
      "           102]]), 'ntok': tensor([30, 41]), 'cls_emb': tensor([[-0.1913, -0.1195, -0.0010,  ..., -0.4170,  0.3302,  0.4214],\n",
      "        [ 0.0147, -0.2664, -0.1540,  ..., -0.3692,  0.0731,  0.4837]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2035,  2008,  1005,  1055,  4394,  2003,  1996, 11867, 12162,\n",
      "          7231,  3012,  1010,  2434,  3012,  1998, 12208,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1996,  2143, 14087,  1999,  2236,  3579,  2009,  3084,\n",
      "          2039,  2005,  1999, 15398,  1010,  2004,  2522, 11890, 13094,  2050,\n",
      "          9020,  2000,  2424,  1996,  8079,  1997,  3246,  1999,  1996,  2433,\n",
      "          1997,  7268,  2895,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2035,  2008,  1005,  1055,  4394,  2003,  1996, 11867, 12162,\n",
      "          7231,  3012,  1010,  2434,  3012,  1998, 12208,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1996,  2143, 14087,  1999,  2236,  3579,  2009,  3084,\n",
      "          2039,  2005,  1999, 15398,  1010,  2004,  2522, 11890, 13094,  2050,\n",
      "          9020,  2000,  2424,  1996,  8079,  1997,  3246,  1999,  1996,  2433,\n",
      "          1997,  7268,  2895,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2556, 0.7444],\n",
      "        [0.2532, 0.7468]]), 'input_ids': tensor([[  101,  2035,  2008,  1005,  1055,  4394,  2003,  1996, 11867, 12162,\n",
      "          7231,  3012,  1010,  2434,  3012,  1998, 12208,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1996,  2143, 14087,  1999,  2236,  3579,  2009,  3084,\n",
      "          2039,  2005,  1999, 15398,  1010,  2004,  2522, 11890, 13094,  2050,\n",
      "          9020,  2000,  2424,  1996,  8079,  1997,  3246,  1999,  1996,  2433,\n",
      "          1997,  7268,  2895,  1012,   102]]), 'ntok': tensor([19, 35]), 'cls_emb': tensor([[ 0.0214,  0.2033, -0.0072,  ..., -0.4718,  0.2489,  0.4876],\n",
      "        [-0.3726, -0.1026, -0.5308,  ..., -0.5820,  0.5942,  0.3619]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996, 17522,  1011,  2010,  3406,  1011,  2576, 15326,  2003,\n",
      "          2409,  1999, 17300, 22215,  1012,  1012,  1012,  1006,  1998,  1007,\n",
      "          3167, 12492,  2003, 21933, 23808,  6820, 10985,  2007, 13433, 23773,\n",
      "         11656,  1012,   102],\n",
      "        [  101,  2026,  4668,  1999,  1037,  2773,  1024, 10520,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996, 17522,  1011,  2010,  3406,  1011,  2576, 15326,  2003,\n",
      "          2409,  1999, 17300, 22215,  1012,  1012,  1012,  1006,  1998,  1007,\n",
      "          3167, 12492,  2003, 21933, 23808,  6820, 10985,  2007, 13433, 23773,\n",
      "         11656,  1012,   102],\n",
      "        [  101,  2026,  4668,  1999,  1037,  2773,  1024, 10520,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2397, 0.7603],\n",
      "        [0.3054, 0.6946]]), 'input_ids': tensor([[  101,  1996, 17522,  1011,  2010,  3406,  1011,  2576, 15326,  2003,\n",
      "          2409,  1999, 17300, 22215,  1012,  1012,  1012,  1006,  1998,  1007,\n",
      "          3167, 12492,  2003, 21933, 23808,  6820, 10985,  2007, 13433, 23773,\n",
      "         11656,  1012,   102],\n",
      "        [  101,  2026,  4668,  1999,  1037,  2773,  1024, 10520,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([33, 10]), 'cls_emb': tensor([[-0.3189,  0.3324, -0.4929,  ..., -0.5971,  0.3430,  0.7344],\n",
      "        [-0.3926, -0.2704, -0.5703,  ..., -0.0716,  0.4143,  0.3414]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  8317, 10874,  2007,  1037, 15958, 11867, 14659,  2100,\n",
      "         18458,  1998,  2019,  2682,  1011,  2779,  3459,  1010,  3364,  3021,\n",
      "         27765,  1005,  1055,  9855,  2834,  2003,  1037, 17109, 14704,  1997,\n",
      "          7788,  3541, 25988,  1012,   102],\n",
      "        [  101,  9781,  2100,  1010,  8040, 22444,  7096,  9096,  1998, 21425,\n",
      "          1010,  2021,  2145,  9020,  2000,  2022,  2785,  1997,  2540,  9028,\n",
      "          6562,  1010,  9690,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  8317, 10874,  2007,  1037, 15958, 11867, 14659,  2100,\n",
      "         18458,  1998,  2019,  2682,  1011,  2779,  3459,  1010,  3364,  3021,\n",
      "         27765,  1005,  1055,  9855,  2834,  2003,  1037, 17109, 14704,  1997,\n",
      "          7788,  3541, 25988,  1012,   102],\n",
      "        [  101,  9781,  2100,  1010,  8040, 22444,  7096,  9096,  1998, 21425,\n",
      "          1010,  2021,  2145,  9020,  2000,  2022,  2785,  1997,  2540,  9028,\n",
      "          6562,  1010,  9690,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2621, 0.7379],\n",
      "        [0.2542, 0.7458]]), 'input_ids': tensor([[  101,  1037,  8317, 10874,  2007,  1037, 15958, 11867, 14659,  2100,\n",
      "         18458,  1998,  2019,  2682,  1011,  2779,  3459,  1010,  3364,  3021,\n",
      "         27765,  1005,  1055,  9855,  2834,  2003,  1037, 17109, 14704,  1997,\n",
      "          7788,  3541, 25988,  1012,   102],\n",
      "        [  101,  9781,  2100,  1010,  8040, 22444,  7096,  9096,  1998, 21425,\n",
      "          1010,  2021,  2145,  9020,  2000,  2022,  2785,  1997,  2540,  9028,\n",
      "          6562,  1010,  9690,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 25]), 'cls_emb': tensor([[ 0.0108, -0.0571, -0.4300,  ..., -0.3505,  0.5704,  0.4032],\n",
      "        [ 0.2295, -0.1082, -0.3582,  ..., -0.1725,  0.4577,  0.7812]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2498,  1005,  1055,  2012,  8406,  1010,  2074,  1037,  9792,\n",
      "          2100,  3313,  1011,  2892,  2017,  2064,  5437,  1037,  3542,  2185,\n",
      "          1011,  1011,  2145,  1010,  1996, 13819,  3157,  8603,  2003,  7167,\n",
      "          1997,  4569,  1012,   102],\n",
      "        [  101,  2521,  2062, 28575,  1998, 12479,  2084,  1996, 20610,  1010,\n",
      "          5356,  1011,  1999,  2838, 20814,  2038,  2081,  2013,  2049,  2060,\n",
      "          6579,  2694,  2186,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2498,  1005,  1055,  2012,  8406,  1010,  2074,  1037,  9792,\n",
      "          2100,  3313,  1011,  2892,  2017,  2064,  5437,  1037,  3542,  2185,\n",
      "          1011,  1011,  2145,  1010,  1996, 13819,  3157,  8603,  2003,  7167,\n",
      "          1997,  4569,  1012,   102],\n",
      "        [  101,  2521,  2062, 28575,  1998, 12479,  2084,  1996, 20610,  1010,\n",
      "          5356,  1011,  1999,  2838, 20814,  2038,  2081,  2013,  2049,  2060,\n",
      "          6579,  2694,  2186,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2744, 0.7256],\n",
      "        [0.2938, 0.7062]]), 'input_ids': tensor([[  101,  2498,  1005,  1055,  2012,  8406,  1010,  2074,  1037,  9792,\n",
      "          2100,  3313,  1011,  2892,  2017,  2064,  5437,  1037,  3542,  2185,\n",
      "          1011,  1011,  2145,  1010,  1996, 13819,  3157,  8603,  2003,  7167,\n",
      "          1997,  4569,  1012,   102],\n",
      "        [  101,  2521,  2062, 28575,  1998, 12479,  2084,  1996, 20610,  1010,\n",
      "          5356,  1011,  1999,  2838, 20814,  2038,  2081,  2013,  2049,  2060,\n",
      "          6579,  2694,  2186,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 25]), 'cls_emb': tensor([[ 0.1693, -0.1340,  0.0519,  ..., -0.1590,  0.2493,  0.5824],\n",
      "        [-0.3272, -0.2321, -0.2026,  ..., -0.1697,  0.4393,  0.5007]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1997,  2607,  1010,  2011,  2062,  7863, 11702,  2009,  1005,\n",
      "          1055,  2145,  3243,  2919,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2004,  1996,  2048,  5260,  1010,  2474, 21604,  1998, 10667,\n",
      "          5620,  2024, 11951,  1998,  2031,  6370,  2119,  2004,  2814,  1998,\n",
      "         10205,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1997,  2607,  1010,  2011,  2062,  7863, 11702,  2009,  1005,\n",
      "          1055,  2145,  3243,  2919,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2004,  1996,  2048,  5260,  1010,  2474, 21604,  1998, 10667,\n",
      "          5620,  2024, 11951,  1998,  2031,  6370,  2119,  2004,  2814,  1998,\n",
      "         10205,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2602, 0.7398],\n",
      "        [0.2551, 0.7449]]), 'input_ids': tensor([[  101,  1997,  2607,  1010,  2011,  2062,  7863, 11702,  2009,  1005,\n",
      "          1055,  2145,  3243,  2919,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2004,  1996,  2048,  5260,  1010,  2474, 21604,  1998, 10667,\n",
      "          5620,  2024, 11951,  1998,  2031,  6370,  2119,  2004,  2814,  1998,\n",
      "         10205,  1012,   102]]), 'ntok': tensor([16, 23]), 'cls_emb': tensor([[ 0.0068,  0.1254, -0.1602,  ..., -0.0279,  0.2298,  0.7219],\n",
      "        [-0.4074, -0.1717, -0.0777,  ..., -0.2206,  0.6785,  0.1934]])}\n",
      "encoded input is: {'input_ids': tensor([[ 101, 2009, 3640, 2019, 7481, 2298, 2012, 1037, 2451, 2358, 3089, 6455,\n",
      "         2000, 8133, 2993, 1999, 2047, 5286, 1012,  102],\n",
      "        [ 101, 2023, 3185, 3849, 2000, 2031, 2042, 2517, 2478, 5506, 1011, 5622,\n",
      "         5910, 1012,  102,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[ 101, 2009, 3640, 2019, 7481, 2298, 2012, 1037, 2451, 2358, 3089, 6455,\n",
      "         2000, 8133, 2993, 1999, 2047, 5286, 1012,  102],\n",
      "        [ 101, 2023, 3185, 3849, 2000, 2031, 2042, 2517, 2478, 5506, 1011, 5622,\n",
      "         5910, 1012,  102,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2468, 0.7532],\n",
      "        [0.2710, 0.7290]]), 'input_ids': tensor([[ 101, 2009, 3640, 2019, 7481, 2298, 2012, 1037, 2451, 2358, 3089, 6455,\n",
      "         2000, 8133, 2993, 1999, 2047, 5286, 1012,  102],\n",
      "        [ 101, 2023, 3185, 3849, 2000, 2031, 2042, 2517, 2478, 5506, 1011, 5622,\n",
      "         5910, 1012,  102,    0,    0,    0,    0,    0]]), 'ntok': tensor([20, 15]), 'cls_emb': tensor([[-0.0289, -0.2158,  0.0429,  ..., -0.2052,  0.2978,  0.2398],\n",
      "        [-0.1173,  0.0828, -0.0295,  ..., -0.2886,  0.4309,  0.7176]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  5853,  1997,  2543,  3504,  2004,  2065,  2009,  2001,  2081,\n",
      "          2302,  2172,  2245,  1011,  1011,  1998,  2003,  2190,  3427,  2008,\n",
      "          2126,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3235,  1998,  6437,  2024,  3375,  3494,  1011,  1011,  2823,\n",
      "          8616,  1010,  2823,  4854,  1011,  1011,  1998,  1996, 10059,  4616,\n",
      "          2011, 21313, 24185,  3363,  3334,  1998,  6819,  3726,  2912,  7367,\n",
      "         15150,  7317,  2191,  2037,  8069,  1998,  9135,  2015, 14954,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  5853,  1997,  2543,  3504,  2004,  2065,  2009,  2001,  2081,\n",
      "          2302,  2172,  2245,  1011,  1011,  1998,  2003,  2190,  3427,  2008,\n",
      "          2126,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3235,  1998,  6437,  2024,  3375,  3494,  1011,  1011,  2823,\n",
      "          8616,  1010,  2823,  4854,  1011,  1011,  1998,  1996, 10059,  4616,\n",
      "          2011, 21313, 24185,  3363,  3334,  1998,  6819,  3726,  2912,  7367,\n",
      "         15150,  7317,  2191,  2037,  8069,  1998,  9135,  2015, 14954,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2493, 0.7507],\n",
      "        [0.2434, 0.7566]]), 'input_ids': tensor([[  101,  5853,  1997,  2543,  3504,  2004,  2065,  2009,  2001,  2081,\n",
      "          2302,  2172,  2245,  1011,  1011,  1998,  2003,  2190,  3427,  2008,\n",
      "          2126,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3235,  1998,  6437,  2024,  3375,  3494,  1011,  1011,  2823,\n",
      "          8616,  1010,  2823,  4854,  1011,  1011,  1998,  1996, 10059,  4616,\n",
      "          2011, 21313, 24185,  3363,  3334,  1998,  6819,  3726,  2912,  7367,\n",
      "         15150,  7317,  2191,  2037,  8069,  1998,  9135,  2015, 14954,  1012,\n",
      "           102]]), 'ntok': tensor([23, 41]), 'cls_emb': tensor([[-0.0106,  0.0206, -0.0372,  ...,  0.0414,  0.2700,  0.6908],\n",
      "        [-0.3291,  0.1890, -0.2377,  ..., -0.0807,  0.4200,  0.4806]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2025,  2008, 18577, 23776,  2003,  1050,\n",
      "          1005,  1056,  6057,  2070,  1997,  1996,  2051,  1011,  1011,  2009,\n",
      "          2074,  2003,  1050,  1005,  1056,  2151,  4569, 14862,  2084,  2919,\n",
      "          7761,  2840,  5691,  2024,  2035,  2011,  3209,  1010,  2302,  2035,\n",
      "          1051, 14728,  5484,  2243,  1005,  1055, 17727,  4509, 15476,  3672,\n",
      "          3370,  1012,   102],\n",
      "        [  101,  1045,  1005,  1040,  2031,  2000,  2360,  1996,  2732,  1998,\n",
      "          2472,  2024,  1996,  2502,  3471,  2182,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2025,  2008, 18577, 23776,  2003,  1050,\n",
      "          1005,  1056,  6057,  2070,  1997,  1996,  2051,  1011,  1011,  2009,\n",
      "          2074,  2003,  1050,  1005,  1056,  2151,  4569, 14862,  2084,  2919,\n",
      "          7761,  2840,  5691,  2024,  2035,  2011,  3209,  1010,  2302,  2035,\n",
      "          1051, 14728,  5484,  2243,  1005,  1055, 17727,  4509, 15476,  3672,\n",
      "          3370,  1012,   102],\n",
      "        [  101,  1045,  1005,  1040,  2031,  2000,  2360,  1996,  2732,  1998,\n",
      "          2472,  2024,  1996,  2502,  3471,  2182,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2550, 0.7450],\n",
      "        [0.2621, 0.7379]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2025,  2008, 18577, 23776,  2003,  1050,\n",
      "          1005,  1056,  6057,  2070,  1997,  1996,  2051,  1011,  1011,  2009,\n",
      "          2074,  2003,  1050,  1005,  1056,  2151,  4569, 14862,  2084,  2919,\n",
      "          7761,  2840,  5691,  2024,  2035,  2011,  3209,  1010,  2302,  2035,\n",
      "          1051, 14728,  5484,  2243,  1005,  1055, 17727,  4509, 15476,  3672,\n",
      "          3370,  1012,   102],\n",
      "        [  101,  1045,  1005,  1040,  2031,  2000,  2360,  1996,  2732,  1998,\n",
      "          2472,  2024,  1996,  2502,  3471,  2182,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([53, 18]), 'cls_emb': tensor([[ 0.2156,  0.1575, -0.4734,  ...,  0.0753,  0.7672,  0.7855],\n",
      "        [ 0.0568,  0.2293, -0.3912,  ..., -0.2451,  0.6719,  0.3750]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 21358, 21031,  3600,  1998,  4027,  2024,  2204, 12403, 18807,\n",
      "          5826,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3251,  2017,  2066,  9680,  2189,  2030,  8840,  8988,  2063,\n",
      "          2009,  1010,  2017,  6187,  1050,  1005,  1056,  9772,  2593,  1996,\n",
      "         13800,  3279,  1997,  2048,  2402,  2273,  1999,  1996,  3539,  1997,\n",
      "          2037,  5848,  2030,  1996,  2373,  1997,  2023,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 21358, 21031,  3600,  1998,  4027,  2024,  2204, 12403, 18807,\n",
      "          5826,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3251,  2017,  2066,  9680,  2189,  2030,  8840,  8988,  2063,\n",
      "          2009,  1010,  2017,  6187,  1050,  1005,  1056,  9772,  2593,  1996,\n",
      "         13800,  3279,  1997,  2048,  2402,  2273,  1999,  1996,  3539,  1997,\n",
      "          2037,  5848,  2030,  1996,  2373,  1997,  2023,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2691, 0.7309],\n",
      "        [0.2479, 0.7521]]), 'input_ids': tensor([[  101, 21358, 21031,  3600,  1998,  4027,  2024,  2204, 12403, 18807,\n",
      "          5826,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3251,  2017,  2066,  9680,  2189,  2030,  8840,  8988,  2063,\n",
      "          2009,  1010,  2017,  6187,  1050,  1005,  1056,  9772,  2593,  1996,\n",
      "         13800,  3279,  1997,  2048,  2402,  2273,  1999,  1996,  3539,  1997,\n",
      "          2037,  5848,  2030,  1996,  2373,  1997,  2023,  3185,  1012,   102]]), 'ntok': tensor([13, 40]), 'cls_emb': tensor([[-0.5303,  0.1728, -0.1549,  ..., -0.1648,  0.6054,  0.2416],\n",
      "        [ 0.1835, -0.1069, -0.4547,  ..., -0.1482,  0.4846,  0.3329]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2025,  2144,  2887, 12127, 21616, 13970,  7352, 10830,  1005,\n",
      "          1055,  2743,  2031,  1996,  9576,  2854,  1997,  4337,  1998,  1996,\n",
      "         28699,  3334,  1997,  2331,  2042,  5107,  3550,  2007,  2107, 22534,\n",
      "          9026,  3126,  1012,   102],\n",
      "        [  101,  1037,  2011,  1011,  1996,  1011,  3616,  3947,  2008, 24185,\n",
      "          1050,  1005,  1056,  2079,  2172,  2000, 11598,  1996,  6329,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2025,  2144,  2887, 12127, 21616, 13970,  7352, 10830,  1005,\n",
      "          1055,  2743,  2031,  1996,  9576,  2854,  1997,  4337,  1998,  1996,\n",
      "         28699,  3334,  1997,  2331,  2042,  5107,  3550,  2007,  2107, 22534,\n",
      "          9026,  3126,  1012,   102],\n",
      "        [  101,  1037,  2011,  1011,  1996,  1011,  3616,  3947,  2008, 24185,\n",
      "          1050,  1005,  1056,  2079,  2172,  2000, 11598,  1996,  6329,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2458, 0.7542],\n",
      "        [0.2700, 0.7300]]), 'input_ids': tensor([[  101,  2025,  2144,  2887, 12127, 21616, 13970,  7352, 10830,  1005,\n",
      "          1055,  2743,  2031,  1996,  9576,  2854,  1997,  4337,  1998,  1996,\n",
      "         28699,  3334,  1997,  2331,  2042,  5107,  3550,  2007,  2107, 22534,\n",
      "          9026,  3126,  1012,   102],\n",
      "        [  101,  1037,  2011,  1011,  1996,  1011,  3616,  3947,  2008, 24185,\n",
      "          1050,  1005,  1056,  2079,  2172,  2000, 11598,  1996,  6329,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 21]), 'cls_emb': tensor([[-0.0928, -0.0324, -0.5508,  ..., -0.0660,  0.2196,  0.3618],\n",
      "        [-0.2787, -0.2553, -0.1298,  ..., -0.2787,  0.4316,  0.3366]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019,  5681,  6057,  1010,  2021,  3452, 14401,  1010,  3869,\n",
      "          1011,  2041,  1011,  1997,  1011,  2300,  2466,  1012,   102,     0],\n",
      "        [  101,  8235,  2135, 15102,  1996,  4736,  2090,  2206,  2028,  1005,\n",
      "          1055,  2540,  1998,  2206,  1996,  7670,  1997,  4535,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019,  5681,  6057,  1010,  2021,  3452, 14401,  1010,  3869,\n",
      "          1011,  2041,  1011,  1997,  1011,  2300,  2466,  1012,   102,     0],\n",
      "        [  101,  8235,  2135, 15102,  1996,  4736,  2090,  2206,  2028,  1005,\n",
      "          1055,  2540,  1998,  2206,  1996,  7670,  1997,  4535,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2761, 0.7239],\n",
      "        [0.2585, 0.7415]]), 'input_ids': tensor([[  101,  2019,  5681,  6057,  1010,  2021,  3452, 14401,  1010,  3869,\n",
      "          1011,  2041,  1011,  1997,  1011,  2300,  2466,  1012,   102,     0],\n",
      "        [  101,  8235,  2135, 15102,  1996,  4736,  2090,  2206,  2028,  1005,\n",
      "          1055,  2540,  1998,  2206,  1996,  7670,  1997,  4535,  1012,   102]]), 'ntok': tensor([19, 20]), 'cls_emb': tensor([[-0.4205, -0.5674, -0.6462,  ..., -0.0663,  0.5794,  0.3155],\n",
      "        [-0.3026,  0.1083, -0.6747,  ..., -0.1020,  0.2758,  0.2658]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2750,  1996,  1016,  1011,  1040,  7284,  1010,  1996,  3748,\n",
      "         16337,  9766,  2015,  3185,  3084,  2005,  1037, 10889, 21014,  3325,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  3544,  2008,  2242,  2038,  2042,  2439,  1999,  1996,\n",
      "          5449,  2000,  1996,  3898,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2750,  1996,  1016,  1011,  1040,  7284,  1010,  1996,  3748,\n",
      "         16337,  9766,  2015,  3185,  3084,  2005,  1037, 10889, 21014,  3325,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  3544,  2008,  2242,  2038,  2042,  2439,  1999,  1996,\n",
      "          5449,  2000,  1996,  3898,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2345, 0.7655],\n",
      "        [0.2626, 0.7374]]), 'input_ids': tensor([[  101,  2750,  1996,  1016,  1011,  1040,  7284,  1010,  1996,  3748,\n",
      "         16337,  9766,  2015,  3185,  3084,  2005,  1037, 10889, 21014,  3325,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  3544,  2008,  2242,  2038,  2042,  2439,  1999,  1996,\n",
      "          5449,  2000,  1996,  3898,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([22, 16]), 'cls_emb': tensor([[ 0.0244, -0.2424,  0.0405,  ..., -0.1532,  0.3953,  0.4296],\n",
      "        [-0.0751,  0.3601, -0.0047,  ..., -0.1998,  0.2852,  0.6762]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2035,  5683,  2066,  1037, 18446, 18750, 11080,  2908,\n",
      "         27762,  3308,  1012,   102,     0,     0],\n",
      "        [  101,  1996,  2143, 13281,  2046,  1037,  9940,  2008,  2071,  2599,\n",
      "          1037,  2158,  2408,  4693,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2035,  5683,  2066,  1037, 18446, 18750, 11080,  2908,\n",
      "         27762,  3308,  1012,   102,     0,     0],\n",
      "        [  101,  1996,  2143, 13281,  2046,  1037,  9940,  2008,  2071,  2599,\n",
      "          1037,  2158,  2408,  4693,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2490, 0.7510],\n",
      "        [0.2583, 0.7417]]), 'input_ids': tensor([[  101,  2009,  2035,  5683,  2066,  1037, 18446, 18750, 11080,  2908,\n",
      "         27762,  3308,  1012,   102,     0,     0],\n",
      "        [  101,  1996,  2143, 13281,  2046,  1037,  9940,  2008,  2071,  2599,\n",
      "          1037,  2158,  2408,  4693,  1012,   102]]), 'ntok': tensor([14, 16]), 'cls_emb': tensor([[ 0.1970,  0.6663,  0.3028,  ..., -0.1482,  0.1284,  0.6574],\n",
      "        [ 0.0452,  0.1373,  0.0059,  ..., -0.5195,  0.3716,  0.4687]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4830, 17644,  2015,  2007,  2049,  3929,  1011,  2517,  3494,\n",
      "          1010,  2049,  4340,  2358,  8516,  4509,  2791,  1006,  2029,  2467,\n",
      "         14623,  2000,  3494,  1998,  2466,  1007,  1998,  5206,  4907,  2243,\n",
      "          5172,  1005,  1055,  2190,  6050,  1999,  2086,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2147,  2011,  2019,  3063,  2061,\n",
      "          1999,  2491,  1997,  2119,  2010,  5396,  1998,  2010,  4471,  2008,\n",
      "          2002,  2064, 17727, 12298,  5562,  2066,  1037,  4166,  2386,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4830, 17644,  2015,  2007,  2049,  3929,  1011,  2517,  3494,\n",
      "          1010,  2049,  4340,  2358,  8516,  4509,  2791,  1006,  2029,  2467,\n",
      "         14623,  2000,  3494,  1998,  2466,  1007,  1998,  5206,  4907,  2243,\n",
      "          5172,  1005,  1055,  2190,  6050,  1999,  2086,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2147,  2011,  2019,  3063,  2061,\n",
      "          1999,  2491,  1997,  2119,  2010,  5396,  1998,  2010,  4471,  2008,\n",
      "          2002,  2064, 17727, 12298,  5562,  2066,  1037,  4166,  2386,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2585, 0.7415],\n",
      "        [0.2446, 0.7554]]), 'input_ids': tensor([[  101,  4830, 17644,  2015,  2007,  2049,  3929,  1011,  2517,  3494,\n",
      "          1010,  2049,  4340,  2358,  8516,  4509,  2791,  1006,  2029,  2467,\n",
      "         14623,  2000,  3494,  1998,  2466,  1007,  1998,  5206,  4907,  2243,\n",
      "          5172,  1005,  1055,  2190,  6050,  1999,  2086,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2147,  2011,  2019,  3063,  2061,\n",
      "          1999,  2491,  1997,  2119,  2010,  5396,  1998,  2010,  4471,  2008,\n",
      "          2002,  2064, 17727, 12298,  5562,  2066,  1037,  4166,  2386,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([39, 31]), 'cls_emb': tensor([[-0.2955, -0.0905, -0.0482,  ..., -0.3531,  0.4576,  0.1664],\n",
      "        [ 0.0898,  0.0796, -0.3172,  ..., -0.1787,  0.2084,  0.7747]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1996,  6370,  2090,  1996,  2308,  1998,\n",
      "          1996,  2852, 14511,  3496,  1011, 11065, 15966,  1998,  4702,  4509,\n",
      "         21877, 18719, 26725,  1997,  4698,  7306,  2008,  3084,  2023,  1036,\n",
      "          1036,  2048, 20429,  1998,  1037,  6715,  1005,  1005,  4569,  1012,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 11065,  5765,  2003,  3350,  2008,  1996, 16248,  2100, 10243,\n",
      "          1012,  1011,  1011,  2848,  1998,  6173,  1011,  1011,  1998,  2037,\n",
      "          4435,  1997,  3898,  4038,  2024,  1059, 21030,  6774,  2000,  2019,\n",
      "          2203,  1010,  2247,  2007,  2665,  1005,  1055,  2431,  1011, 18627,\n",
      "          3185,  2476,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1996,  6370,  2090,  1996,  2308,  1998,\n",
      "          1996,  2852, 14511,  3496,  1011, 11065, 15966,  1998,  4702,  4509,\n",
      "         21877, 18719, 26725,  1997,  4698,  7306,  2008,  3084,  2023,  1036,\n",
      "          1036,  2048, 20429,  1998,  1037,  6715,  1005,  1005,  4569,  1012,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 11065,  5765,  2003,  3350,  2008,  1996, 16248,  2100, 10243,\n",
      "          1012,  1011,  1011,  2848,  1998,  6173,  1011,  1011,  1998,  2037,\n",
      "          4435,  1997,  3898,  4038,  2024,  1059, 21030,  6774,  2000,  2019,\n",
      "          2203,  1010,  2247,  2007,  2665,  1005,  1055,  2431,  1011, 18627,\n",
      "          3185,  2476,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2662, 0.7338],\n",
      "        [0.2396, 0.7604]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1996,  6370,  2090,  1996,  2308,  1998,\n",
      "          1996,  2852, 14511,  3496,  1011, 11065, 15966,  1998,  4702,  4509,\n",
      "         21877, 18719, 26725,  1997,  4698,  7306,  2008,  3084,  2023,  1036,\n",
      "          1036,  2048, 20429,  1998,  1037,  6715,  1005,  1005,  4569,  1012,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 11065,  5765,  2003,  3350,  2008,  1996, 16248,  2100, 10243,\n",
      "          1012,  1011,  1011,  2848,  1998,  6173,  1011,  1011,  1998,  2037,\n",
      "          4435,  1997,  3898,  4038,  2024,  1059, 21030,  6774,  2000,  2019,\n",
      "          2203,  1010,  2247,  2007,  2665,  1005,  1055,  2431,  1011, 18627,\n",
      "          3185,  2476,  1012,   102]]), 'ntok': tensor([41, 44]), 'cls_emb': tensor([[-0.0218,  0.2810,  0.2373,  ..., -0.2533,  0.4785,  0.7008],\n",
      "        [-0.3509,  0.1783, -0.5158,  ..., -0.1306,  0.8153,  0.4429]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2440,  2088,  2038,  2042,  3591,  2006, 18182,  1010,\n",
      "          2025,  2070,  2186,  1997,  5362, 14336,  5436,  2685,  2311,  2000,\n",
      "          1037,  6986,  5813,  1012,   102],\n",
      "        [  101, 15876,  7106, 10063,  2119,  1996,  5580,  1011, 13041,  1998,\n",
      "          1996, 18329,  3168,  1997,  8892, 13905,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2440,  2088,  2038,  2042,  3591,  2006, 18182,  1010,\n",
      "          2025,  2070,  2186,  1997,  5362, 14336,  5436,  2685,  2311,  2000,\n",
      "          1037,  6986,  5813,  1012,   102],\n",
      "        [  101, 15876,  7106, 10063,  2119,  1996,  5580,  1011, 13041,  1998,\n",
      "          1996, 18329,  3168,  1997,  8892, 13905,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2863, 0.7137],\n",
      "        [0.2445, 0.7555]]), 'input_ids': tensor([[  101,  1037,  2440,  2088,  2038,  2042,  3591,  2006, 18182,  1010,\n",
      "          2025,  2070,  2186,  1997,  5362, 14336,  5436,  2685,  2311,  2000,\n",
      "          1037,  6986,  5813,  1012,   102],\n",
      "        [  101, 15876,  7106, 10063,  2119,  1996,  5580,  1011, 13041,  1998,\n",
      "          1996, 18329,  3168,  1997,  8892, 13905,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([25, 18]), 'cls_emb': tensor([[-0.3270, -0.1903,  0.0940,  ..., -0.3966,  0.6849,  0.6731],\n",
      "        [-0.2213,  0.1907, -0.4111,  ..., -0.6006,  0.6147,  0.3148]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2028,  1997,  1996,  2062,  9414,  2336,  1005,  1055,  5691,\n",
      "          2000,  2718, 12370,  2023,  2095,  1012,   102,     0],\n",
      "        [  101,  1996,  2143,  5363,  2205,  2524,  2000,  2022,  6057,  1998,\n",
      "          5363,  2205,  2524,  2000,  2022,  5099,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2028,  1997,  1996,  2062,  9414,  2336,  1005,  1055,  5691,\n",
      "          2000,  2718, 12370,  2023,  2095,  1012,   102,     0],\n",
      "        [  101,  1996,  2143,  5363,  2205,  2524,  2000,  2022,  6057,  1998,\n",
      "          5363,  2205,  2524,  2000,  2022,  5099,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2673, 0.7327],\n",
      "        [0.2619, 0.7381]]), 'input_ids': tensor([[  101,  2028,  1997,  1996,  2062,  9414,  2336,  1005,  1055,  5691,\n",
      "          2000,  2718, 12370,  2023,  2095,  1012,   102,     0],\n",
      "        [  101,  1996,  2143,  5363,  2205,  2524,  2000,  2022,  6057,  1998,\n",
      "          5363,  2205,  2524,  2000,  2022,  5099,  1012,   102]]), 'ntok': tensor([17, 18]), 'cls_emb': tensor([[-0.3768, -0.4105, -0.0999,  ..., -0.2733,  0.7320,  0.0317],\n",
      "        [-0.1118, -0.1366,  0.0549,  ..., -0.3475,  0.4099,  0.3178]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 18158,  4779,  1005,  1055,  2836, 23283,  2014,  2373,  2320,\n",
      "          2153,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2065,  2017,  2903,  2151,  1997,  2023,  1010,  1045,  2064,\n",
      "          2191,  2017,  1037,  2613,  3066,  2006,  2187,  7840,  4372,  4948,\n",
      "          4518,  2008,  2097,  3313,  1999,  3643,  1037,  2733,  2013,  5958,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 18158,  4779,  1005,  1055,  2836, 23283,  2014,  2373,  2320,\n",
      "          2153,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2065,  2017,  2903,  2151,  1997,  2023,  1010,  1045,  2064,\n",
      "          2191,  2017,  1037,  2613,  3066,  2006,  2187,  7840,  4372,  4948,\n",
      "          4518,  2008,  2097,  3313,  1999,  3643,  1037,  2733,  2013,  5958,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2584, 0.7416],\n",
      "        [0.2433, 0.7567]]), 'input_ids': tensor([[  101, 18158,  4779,  1005,  1055,  2836, 23283,  2014,  2373,  2320,\n",
      "          2153,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2065,  2017,  2903,  2151,  1997,  2023,  1010,  1045,  2064,\n",
      "          2191,  2017,  1037,  2613,  3066,  2006,  2187,  7840,  4372,  4948,\n",
      "          4518,  2008,  2097,  3313,  1999,  3643,  1037,  2733,  2013,  5958,\n",
      "          1012,   102]]), 'ntok': tensor([13, 32]), 'cls_emb': tensor([[-0.1481, -0.2674, -0.4590,  ..., -0.2615,  0.4851,  0.4473],\n",
      "        [ 0.2149,  0.0132, -0.0363,  ..., -0.2143,  0.4251,  0.5896]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4740,  2011,  2023,  7241,  2143,  2000, 17727,  8445,  1037,\n",
      "          4471,  2024,  2061,  3082,  1011,  4375,  2008,  2027,  2612, 16405,\n",
      "         29033,  1996,  4378,  1012,   102],\n",
      "        [  101,  2053,  2028,  2021,  1037, 20462,  5905,  1997,  2070,  5621,\n",
      "          2002,  5740,  2271,  4126,  2323,  2031,  2000,  4133,  2083,  1996,\n",
      "          3040,  1997, 14249,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4740,  2011,  2023,  7241,  2143,  2000, 17727,  8445,  1037,\n",
      "          4471,  2024,  2061,  3082,  1011,  4375,  2008,  2027,  2612, 16405,\n",
      "         29033,  1996,  4378,  1012,   102],\n",
      "        [  101,  2053,  2028,  2021,  1037, 20462,  5905,  1997,  2070,  5621,\n",
      "          2002,  5740,  2271,  4126,  2323,  2031,  2000,  4133,  2083,  1996,\n",
      "          3040,  1997, 14249,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2481, 0.7519],\n",
      "        [0.2572, 0.7428]]), 'input_ids': tensor([[  101,  4740,  2011,  2023,  7241,  2143,  2000, 17727,  8445,  1037,\n",
      "          4471,  2024,  2061,  3082,  1011,  4375,  2008,  2027,  2612, 16405,\n",
      "         29033,  1996,  4378,  1012,   102],\n",
      "        [  101,  2053,  2028,  2021,  1037, 20462,  5905,  1997,  2070,  5621,\n",
      "          2002,  5740,  2271,  4126,  2323,  2031,  2000,  4133,  2083,  1996,\n",
      "          3040,  1997, 14249,  1012,   102]]), 'ntok': tensor([25, 25]), 'cls_emb': tensor([[-0.1824,  0.3326, -0.4854,  ..., -0.2225,  0.4097,  0.5294],\n",
      "        [-0.1445,  0.1876, -0.6114,  ..., -0.1516,  0.2460,  0.4491]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  6524,  2038,  2061,  2172,  2769,  5359,  2061,  2210,  4024,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4202,  3544,  2000,  2031, 10676,  2010,  2972,  5166,  2006,\n",
      "          6050,  2916,  1998,  2018,  2498,  2187,  2058,  2005, 13198,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  6524,  2038,  2061,  2172,  2769,  5359,  2061,  2210,  4024,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4202,  3544,  2000,  2031, 10676,  2010,  2972,  5166,  2006,\n",
      "          6050,  2916,  1998,  2018,  2498,  2187,  2058,  2005, 13198,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2407, 0.7593],\n",
      "        [0.2769, 0.7231]]), 'input_ids': tensor([[  101,  6524,  2038,  2061,  2172,  2769,  5359,  2061,  2210,  4024,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  4202,  3544,  2000,  2031, 10676,  2010,  2972,  5166,  2006,\n",
      "          6050,  2916,  1998,  2018,  2498,  2187,  2058,  2005, 13198,  1012,\n",
      "           102]]), 'ntok': tensor([12, 21]), 'cls_emb': tensor([[-0.0476,  0.4919, -0.2860,  ..., -0.1501,  0.3192,  0.3711],\n",
      "        [-0.4970,  0.1865, -0.6196,  ..., -0.0748,  0.9669,  0.2593]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1036,  1036,  1996,  2051,  3698,  1005,  1005,  2003,  1037,\n",
      "          3185,  2008,  2038,  2053,  3037,  1999,  2993,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037, 10958, 15780,  2426,  3522,  7726,  3152,  1024,  2009,\n",
      "          1005,  1055,  1037,  4038,  2440,  1997,  7132,  8562,  2008,  9610,\n",
      "          6155,  1996, 18691,  3012,  1997,  2049, 10191,  1005,  1055, 24525,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1036,  1036,  1996,  2051,  3698,  1005,  1005,  2003,  1037,\n",
      "          3185,  2008,  2038,  2053,  3037,  1999,  2993,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037, 10958, 15780,  2426,  3522,  7726,  3152,  1024,  2009,\n",
      "          1005,  1055,  1037,  4038,  2440,  1997,  7132,  8562,  2008,  9610,\n",
      "          6155,  1996, 18691,  3012,  1997,  2049, 10191,  1005,  1055, 24525,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2566, 0.7434],\n",
      "        [0.2593, 0.7407]]), 'input_ids': tensor([[  101,  1036,  1036,  1996,  2051,  3698,  1005,  1005,  2003,  1037,\n",
      "          3185,  2008,  2038,  2053,  3037,  1999,  2993,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037, 10958, 15780,  2426,  3522,  7726,  3152,  1024,  2009,\n",
      "          1005,  1055,  1037,  4038,  2440,  1997,  7132,  8562,  2008,  9610,\n",
      "          6155,  1996, 18691,  3012,  1997,  2049, 10191,  1005,  1055, 24525,\n",
      "          1012,   102]]), 'ntok': tensor([19, 32]), 'cls_emb': tensor([[ 0.0397,  0.1830,  0.0292,  ..., -0.4348,  0.4788,  0.5546],\n",
      "        [-0.2126, -0.1373, -0.4697,  ..., -0.2598,  0.3972,  0.3457]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1013,  2021, 16847,  1010,  2017,  1005,  2128,  2205, 23176,\n",
      "          1013,  5965,  6732,  2002,  1005,  1055,  7823,  1013,  1998,  2310,\n",
      "         19145,  1011, 10166,  1010,  2017,  1005,  2310,  2439,  3635,   999,\n",
      "           102],\n",
      "        [  101,  1996,  2200,  6210,  1997,  1996,  1036,  2235,  1005,  3185,\n",
      "          1010,  2021,  2009,  2003,  1037,  2204,  9085,  2962,  2005,  2472,\n",
      "         11867,  2890,  7474,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1013,  2021, 16847,  1010,  2017,  1005,  2128,  2205, 23176,\n",
      "          1013,  5965,  6732,  2002,  1005,  1055,  7823,  1013,  1998,  2310,\n",
      "         19145,  1011, 10166,  1010,  2017,  1005,  2310,  2439,  3635,   999,\n",
      "           102],\n",
      "        [  101,  1996,  2200,  6210,  1997,  1996,  1036,  2235,  1005,  3185,\n",
      "          1010,  2021,  2009,  2003,  1037,  2204,  9085,  2962,  2005,  2472,\n",
      "         11867,  2890,  7474,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2999, 0.7001],\n",
      "        [0.2630, 0.7370]]), 'input_ids': tensor([[  101,  1013,  2021, 16847,  1010,  2017,  1005,  2128,  2205, 23176,\n",
      "          1013,  5965,  6732,  2002,  1005,  1055,  7823,  1013,  1998,  2310,\n",
      "         19145,  1011, 10166,  1010,  2017,  1005,  2310,  2439,  3635,   999,\n",
      "           102],\n",
      "        [  101,  1996,  2200,  6210,  1997,  1996,  1036,  2235,  1005,  3185,\n",
      "          1010,  2021,  2009,  2003,  1037,  2204,  9085,  2962,  2005,  2472,\n",
      "         11867,  2890,  7474,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([31, 25]), 'cls_emb': tensor([[ 0.0288, -0.3309,  0.0158,  ..., -0.0258,  0.0108,  0.4261],\n",
      "        [-0.3133, -0.0957, -0.0657,  ..., -0.2084,  0.6683,  0.5330]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2066,  2296,  2919,  2801,  2008,  1005,\n",
      "          1055,  2412,  2908,  2046,  2019,  2044,  1011,  2082,  2569,  9227,\n",
      "          1999,  2028,  2173,  1010, 15718,  2216, 12217,  3454,  1005, 13554,\n",
      "          2791,  1998,  2061, 21850, 10074,  3370,  1006,  1998,  2040,  2354,\n",
      "          2027,  2130,  2018,  2151,  1029,  1007,  1012,   102],\n",
      "        [  101, 27017,  1010,  2092,  1011,  6051,  1010,  1998, 22126,  2856,\n",
      "          1024,  2585, 12988,  2239,  1005,  1055,  4830, 14227,  2121,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2066,  2296,  2919,  2801,  2008,  1005,\n",
      "          1055,  2412,  2908,  2046,  2019,  2044,  1011,  2082,  2569,  9227,\n",
      "          1999,  2028,  2173,  1010, 15718,  2216, 12217,  3454,  1005, 13554,\n",
      "          2791,  1998,  2061, 21850, 10074,  3370,  1006,  1998,  2040,  2354,\n",
      "          2027,  2130,  2018,  2151,  1029,  1007,  1012,   102],\n",
      "        [  101, 27017,  1010,  2092,  1011,  6051,  1010,  1998, 22126,  2856,\n",
      "          1024,  2585, 12988,  2239,  1005,  1055,  4830, 14227,  2121,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2653, 0.7347],\n",
      "        [0.3115, 0.6885]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2066,  2296,  2919,  2801,  2008,  1005,\n",
      "          1055,  2412,  2908,  2046,  2019,  2044,  1011,  2082,  2569,  9227,\n",
      "          1999,  2028,  2173,  1010, 15718,  2216, 12217,  3454,  1005, 13554,\n",
      "          2791,  1998,  2061, 21850, 10074,  3370,  1006,  1998,  2040,  2354,\n",
      "          2027,  2130,  2018,  2151,  1029,  1007,  1012,   102],\n",
      "        [  101, 27017,  1010,  2092,  1011,  6051,  1010,  1998, 22126,  2856,\n",
      "          1024,  2585, 12988,  2239,  1005,  1055,  4830, 14227,  2121,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([48, 21]), 'cls_emb': tensor([[ 0.0886,  0.2273, -0.1029,  ..., -0.1579,  0.6859,  0.8457],\n",
      "        [-0.1833, -0.4070,  0.0122,  ..., -0.0658,  0.3574,  0.3423]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  6187,  1050,  1005,  1056,  5630,  2065,  2009,  4122,\n",
      "          2000,  2022,  1037,  6547,  1013, 10874,  1010,  1037,  7472,  2030,\n",
      "          1037,  4038,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3825,  1999,  2440,  2003,  2061, 26729,  1010,  1999,  2755,\n",
      "          1010,  2008,  2049,  2087, 17026,  3496,  2003,  2028,  2008,  3594,\n",
      "         15281,  2013,  4422,  2139, 23985,  1005,  1055, 18982, 10732,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  6187,  1050,  1005,  1056,  5630,  2065,  2009,  4122,\n",
      "          2000,  2022,  1037,  6547,  1013, 10874,  1010,  1037,  7472,  2030,\n",
      "          1037,  4038,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3825,  1999,  2440,  2003,  2061, 26729,  1010,  1999,  2755,\n",
      "          1010,  2008,  2049,  2087, 17026,  3496,  2003,  2028,  2008,  3594,\n",
      "         15281,  2013,  4422,  2139, 23985,  1005,  1055, 18982, 10732,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2799, 0.7201],\n",
      "        [0.2502, 0.7498]]), 'input_ids': tensor([[  101,  2009,  6187,  1050,  1005,  1056,  5630,  2065,  2009,  4122,\n",
      "          2000,  2022,  1037,  6547,  1013, 10874,  1010,  1037,  7472,  2030,\n",
      "          1037,  4038,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3825,  1999,  2440,  2003,  2061, 26729,  1010,  1999,  2755,\n",
      "          1010,  2008,  2049,  2087, 17026,  3496,  2003,  2028,  2008,  3594,\n",
      "         15281,  2013,  4422,  2139, 23985,  1005,  1055, 18982, 10732,  1012,\n",
      "           102]]), 'ntok': tensor([24, 31]), 'cls_emb': tensor([[-0.1246, -0.2430,  0.2663,  ..., -0.4924,  0.5572,  0.6587],\n",
      "        [ 0.0177, -0.2194, -0.4589,  ...,  0.3102,  0.7473,  0.5711]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 19429,  2050,  1999,  2296,  3168,  1010,  1996,  9231,\n",
      "         23555,  2102,  2553, 19584,  2051,  2090,  1037,  3371,  1011,  2011,\n",
      "          1011,  3371,  4070,  1997,  1996,  2329,  2457,  1005,  1055,  4469,\n",
      "         20562,  7433,  2208,  1998,  1996,  6939,  1005,  1055,  3331,  1011,\n",
      "          2132,  8643,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2209,  1999,  1996,  2087,  3442,  1011,\n",
      "          4320,  4827,  1010,  2007,  2210,  8562,  2000,  2422,  2368,  2477,\n",
      "          2039,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 19429,  2050,  1999,  2296,  3168,  1010,  1996,  9231,\n",
      "         23555,  2102,  2553, 19584,  2051,  2090,  1037,  3371,  1011,  2011,\n",
      "          1011,  3371,  4070,  1997,  1996,  2329,  2457,  1005,  1055,  4469,\n",
      "         20562,  7433,  2208,  1998,  1996,  6939,  1005,  1055,  3331,  1011,\n",
      "          2132,  8643,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2209,  1999,  1996,  2087,  3442,  1011,\n",
      "          4320,  4827,  1010,  2007,  2210,  8562,  2000,  2422,  2368,  2477,\n",
      "          2039,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2349, 0.7651],\n",
      "        [0.2589, 0.7411]]), 'input_ids': tensor([[  101,  1037, 19429,  2050,  1999,  2296,  3168,  1010,  1996,  9231,\n",
      "         23555,  2102,  2553, 19584,  2051,  2090,  1037,  3371,  1011,  2011,\n",
      "          1011,  3371,  4070,  1997,  1996,  2329,  2457,  1005,  1055,  4469,\n",
      "         20562,  7433,  2208,  1998,  1996,  6939,  1005,  1055,  3331,  1011,\n",
      "          2132,  8643,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2209,  1999,  1996,  2087,  3442,  1011,\n",
      "          4320,  4827,  1010,  2007,  2210,  8562,  2000,  2422,  2368,  2477,\n",
      "          2039,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([44, 23]), 'cls_emb': tensor([[-0.1097,  0.0220, -0.7031,  ..., -0.2584,  0.6217,  0.6652],\n",
      "        [ 0.1044,  0.0535, -0.0098,  ..., -0.2668,  0.4060,  0.6945]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 12873,  3185,  2007, 12873,  3494,  2725, 12873,  2477,\n",
      "          1998,  2017,  2031,  2000,  2022,  2428, 12873,  2025,  2000,  2156,\n",
      "          2073,  2023,  2003,  2183,  1012,   102],\n",
      "        [  101,  2007,  8990,  2053,  5875,  3787,  2005,  2019,  4378,  2000,\n",
      "          3579,  2006,  1010,  9295,  3681,  2003,  1037,  6420,  1011,  9686,\n",
      "         20110,  2080, 14280,  4119,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 12873,  3185,  2007, 12873,  3494,  2725, 12873,  2477,\n",
      "          1998,  2017,  2031,  2000,  2022,  2428, 12873,  2025,  2000,  2156,\n",
      "          2073,  2023,  2003,  2183,  1012,   102],\n",
      "        [  101,  2007,  8990,  2053,  5875,  3787,  2005,  2019,  4378,  2000,\n",
      "          3579,  2006,  1010,  9295,  3681,  2003,  1037,  6420,  1011,  9686,\n",
      "         20110,  2080, 14280,  4119,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2595, 0.7405],\n",
      "        [0.2959, 0.7041]]), 'input_ids': tensor([[  101,  1037, 12873,  3185,  2007, 12873,  3494,  2725, 12873,  2477,\n",
      "          1998,  2017,  2031,  2000,  2022,  2428, 12873,  2025,  2000,  2156,\n",
      "          2073,  2023,  2003,  2183,  1012,   102],\n",
      "        [  101,  2007,  8990,  2053,  5875,  3787,  2005,  2019,  4378,  2000,\n",
      "          3579,  2006,  1010,  9295,  3681,  2003,  1037,  6420,  1011,  9686,\n",
      "         20110,  2080, 14280,  4119,  1012,   102]]), 'ntok': tensor([26, 26]), 'cls_emb': tensor([[ 0.3201, -0.2321, -0.1940,  ..., -0.5179,  0.1914,  0.4386],\n",
      "        [-0.3204, -0.2743,  0.1984,  ..., -0.2864,  0.4386,  0.4679]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  9742,  2007,  3494,  1998,  3397,  2070, 26162,  5312,  1012,\n",
      "           102,     0],\n",
      "        [  101,  2004,  4895, 19763, 19968,  2100,  2004,  2049,  2516,  6083,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  9742,  2007,  3494,  1998,  3397,  2070, 26162,  5312,  1012,\n",
      "           102,     0],\n",
      "        [  101,  2004,  4895, 19763, 19968,  2100,  2004,  2049,  2516,  6083,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2478, 0.7522],\n",
      "        [0.2757, 0.7243]]), 'input_ids': tensor([[  101,  9742,  2007,  3494,  1998,  3397,  2070, 26162,  5312,  1012,\n",
      "           102,     0],\n",
      "        [  101,  2004,  4895, 19763, 19968,  2100,  2004,  2049,  2516,  6083,\n",
      "          1012,   102]]), 'ntok': tensor([11, 12]), 'cls_emb': tensor([[-0.7738, -0.2473, -0.2413,  ..., -0.0695,  0.4130,  0.2160],\n",
      "        [-0.1941,  0.0524,  0.0009,  ..., -0.3681,  0.1527,  0.4877]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2066,  3666,  1037, 10103,  2081,  5771,\n",
      "          1012,   102,     0,     0],\n",
      "        [  101,  7162,  3189,  2003,  3599,  2054,  1996,  2516,  7127,  1010,\n",
      "          1037,  3189,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2066,  3666,  1037, 10103,  2081,  5771,\n",
      "          1012,   102,     0,     0],\n",
      "        [  101,  7162,  3189,  2003,  3599,  2054,  1996,  2516,  7127,  1010,\n",
      "          1037,  3189,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2297, 0.7704],\n",
      "        [0.2611, 0.7389]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2066,  3666,  1037, 10103,  2081,  5771,\n",
      "          1012,   102,     0,     0],\n",
      "        [  101,  7162,  3189,  2003,  3599,  2054,  1996,  2516,  7127,  1010,\n",
      "          1037,  3189,  1012,   102]]), 'ntok': tensor([12, 14]), 'cls_emb': tensor([[ 0.2834,  0.3262, -0.0151,  ..., -0.1935,  0.2573,  0.7572],\n",
      "        [-0.1157,  0.1587, -0.2952,  ..., -0.1439,  0.3203,  0.6339]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2524,  2000,  2066,  1037,  2143,  2055,\n",
      "          1037,  3124,  2040,  2003, 12580,  4406,  3085,  1010,  1998, 12342,\n",
      "          2099,  1010,  4626,  2745, 19881,  2004,  2019, 12520,  2329,  8362,\n",
      "         15543,  7143,  2005,  1037,  5510,  1997,  4476,  1998,  7280,  1010,\n",
      "          2003,  5121,  2008,  1012,   102],\n",
      "        [  101,  2019, 14036,  1010, 14231,  1010,  2895,  1011,  3561,  4126,\n",
      "          2466,  2007,  2019, 10305,  2540,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2524,  2000,  2066,  1037,  2143,  2055,\n",
      "          1037,  3124,  2040,  2003, 12580,  4406,  3085,  1010,  1998, 12342,\n",
      "          2099,  1010,  4626,  2745, 19881,  2004,  2019, 12520,  2329,  8362,\n",
      "         15543,  7143,  2005,  1037,  5510,  1997,  4476,  1998,  7280,  1010,\n",
      "          2003,  5121,  2008,  1012,   102],\n",
      "        [  101,  2019, 14036,  1010, 14231,  1010,  2895,  1011,  3561,  4126,\n",
      "          2466,  2007,  2019, 10305,  2540,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2554, 0.7446],\n",
      "        [0.2610, 0.7390]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2524,  2000,  2066,  1037,  2143,  2055,\n",
      "          1037,  3124,  2040,  2003, 12580,  4406,  3085,  1010,  1998, 12342,\n",
      "          2099,  1010,  4626,  2745, 19881,  2004,  2019, 12520,  2329,  8362,\n",
      "         15543,  7143,  2005,  1037,  5510,  1997,  4476,  1998,  7280,  1010,\n",
      "          2003,  5121,  2008,  1012,   102],\n",
      "        [  101,  2019, 14036,  1010, 14231,  1010,  2895,  1011,  3561,  4126,\n",
      "          2466,  2007,  2019, 10305,  2540,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([45, 17]), 'cls_emb': tensor([[ 0.0187, -0.1305, -0.4934,  ...,  0.0575,  0.4794,  0.6053],\n",
      "        [-0.6806, -0.5677, -0.3538,  ..., -0.7126,  0.4540,  0.2215]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2005,  2023,  3114,  1998,  2023,  3114,  2069,  1011,  1011,\n",
      "          1996,  2373,  1997,  2049,  2219, 26261,  4215, 24333,  1010,  7570,\n",
      "          3012,  1011,  2000,  3012, 20488,  1011,  1011,  9295,  3681, 17210,\n",
      "          1037,  3101,  1012,   102],\n",
      "        [  101,  2009,  2074,  2089, 18708,  1037,  2261,  3920,  3185,  3995,\n",
      "          2545,  2000,  3191, 13636,  1005,  1055,  2338,  1010,  2029,  2003,\n",
      "          1037,  8813,  1999,  1998,  1997,  2993,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2005,  2023,  3114,  1998,  2023,  3114,  2069,  1011,  1011,\n",
      "          1996,  2373,  1997,  2049,  2219, 26261,  4215, 24333,  1010,  7570,\n",
      "          3012,  1011,  2000,  3012, 20488,  1011,  1011,  9295,  3681, 17210,\n",
      "          1037,  3101,  1012,   102],\n",
      "        [  101,  2009,  2074,  2089, 18708,  1037,  2261,  3920,  3185,  3995,\n",
      "          2545,  2000,  3191, 13636,  1005,  1055,  2338,  1010,  2029,  2003,\n",
      "          1037,  8813,  1999,  1998,  1997,  2993,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2345, 0.7655],\n",
      "        [0.2406, 0.7594]]), 'input_ids': tensor([[  101,  2005,  2023,  3114,  1998,  2023,  3114,  2069,  1011,  1011,\n",
      "          1996,  2373,  1997,  2049,  2219, 26261,  4215, 24333,  1010,  7570,\n",
      "          3012,  1011,  2000,  3012, 20488,  1011,  1011,  9295,  3681, 17210,\n",
      "          1037,  3101,  1012,   102],\n",
      "        [  101,  2009,  2074,  2089, 18708,  1037,  2261,  3920,  3185,  3995,\n",
      "          2545,  2000,  3191, 13636,  1005,  1055,  2338,  1010,  2029,  2003,\n",
      "          1037,  8813,  1999,  1998,  1997,  2993,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 28]), 'cls_emb': tensor([[ 0.1431,  0.0375, -0.1543,  ..., -0.2393,  0.2475,  0.4808],\n",
      "        [ 0.1383, -0.2002, -0.1597,  ..., -0.2228,  0.3091,  0.5251]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 10468,  1037, 10763,  2186,  1997,  4100,  1011, 19641,  1006,\n",
      "          1998,  4100,  1011, 18920,  1007,  9680,  2015,  2090,  1996,  3340,\n",
      "          1012,   102],\n",
      "        [  101,  1012,  1012,  1012,  2007,  1036,  1036,  1996, 15803,  4767,\n",
      "          1005,  1005,  2057,  2709,  2000,  1996,  2062,  3151,  2895,  6907,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 10468,  1037, 10763,  2186,  1997,  4100,  1011, 19641,  1006,\n",
      "          1998,  4100,  1011, 18920,  1007,  9680,  2015,  2090,  1996,  3340,\n",
      "          1012,   102],\n",
      "        [  101,  1012,  1012,  1012,  2007,  1036,  1036,  1996, 15803,  4767,\n",
      "          1005,  1005,  2057,  2709,  2000,  1996,  2062,  3151,  2895,  6907,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2794, 0.7206],\n",
      "        [0.2477, 0.7523]]), 'input_ids': tensor([[  101, 10468,  1037, 10763,  2186,  1997,  4100,  1011, 19641,  1006,\n",
      "          1998,  4100,  1011, 18920,  1007,  9680,  2015,  2090,  1996,  3340,\n",
      "          1012,   102],\n",
      "        [  101,  1012,  1012,  1012,  2007,  1036,  1036,  1996, 15803,  4767,\n",
      "          1005,  1005,  2057,  2709,  2000,  1996,  2062,  3151,  2895,  6907,\n",
      "          1012,   102]]), 'ntok': tensor([22, 22]), 'cls_emb': tensor([[-0.1864, -0.0229, -0.0158,  ..., -0.1491,  0.5219,  0.3936],\n",
      "        [-0.0955,  0.0634, -0.3048,  ..., -0.4226,  0.4908,  0.5825]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2061,  2204,  2008,  2049, 21660,  1010,\n",
      "         12853, 15966,  2064, 19319,  2025,  2069,  1999, 23606,  2082,  5453,\n",
      "          1010,  2021,  2130,  6291,  6262,  1005,  1055,  3185,  6789,  1012,\n",
      "           102],\n",
      "        [  101, 16769,  2015,  2006,  2049,  2219, 15921,  1997,  3356,  1011,\n",
      "         19116, 25545,  2819,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2061,  2204,  2008,  2049, 21660,  1010,\n",
      "         12853, 15966,  2064, 19319,  2025,  2069,  1999, 23606,  2082,  5453,\n",
      "          1010,  2021,  2130,  6291,  6262,  1005,  1055,  3185,  6789,  1012,\n",
      "           102],\n",
      "        [  101, 16769,  2015,  2006,  2049,  2219, 15921,  1997,  3356,  1011,\n",
      "         19116, 25545,  2819,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2541, 0.7459],\n",
      "        [0.2746, 0.7254]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2061,  2204,  2008,  2049, 21660,  1010,\n",
      "         12853, 15966,  2064, 19319,  2025,  2069,  1999, 23606,  2082,  5453,\n",
      "          1010,  2021,  2130,  6291,  6262,  1005,  1055,  3185,  6789,  1012,\n",
      "           102],\n",
      "        [  101, 16769,  2015,  2006,  2049,  2219, 15921,  1997,  3356,  1011,\n",
      "         19116, 25545,  2819,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([31, 15]), 'cls_emb': tensor([[ 0.1715, -0.0825, -0.1648,  ..., -0.1227,  0.2306,  0.6982],\n",
      "        [-0.2458, -0.1154, -0.2764,  ..., -0.0664,  0.4919,  0.2747]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2096,  2045,  1005,  1055,  2242, 23807,  3973,  6057,  2055,\n",
      "          2909,  4938, 10239,  3038,  1036,  2131,  1999,  1996,  2482,  1010,\n",
      "          7743,  1010,  1005,  2023,  6128,  7987, 12722, 18826,  2537,  2038,\n",
      "          2210,  2842,  2000,  3749,   102],\n",
      "        [  101,  1037, 10377,  2075,  2147,  1997,  2396,  2005,  2069,  1996,\n",
      "          2087,  5776,  1998,  4119,  1011,  7501,  3185,  3995,  2545,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2096,  2045,  1005,  1055,  2242, 23807,  3973,  6057,  2055,\n",
      "          2909,  4938, 10239,  3038,  1036,  2131,  1999,  1996,  2482,  1010,\n",
      "          7743,  1010,  1005,  2023,  6128,  7987, 12722, 18826,  2537,  2038,\n",
      "          2210,  2842,  2000,  3749,   102],\n",
      "        [  101,  1037, 10377,  2075,  2147,  1997,  2396,  2005,  2069,  1996,\n",
      "          2087,  5776,  1998,  4119,  1011,  7501,  3185,  3995,  2545,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2395, 0.7605],\n",
      "        [0.2633, 0.7367]]), 'input_ids': tensor([[  101,  2096,  2045,  1005,  1055,  2242, 23807,  3973,  6057,  2055,\n",
      "          2909,  4938, 10239,  3038,  1036,  2131,  1999,  1996,  2482,  1010,\n",
      "          7743,  1010,  1005,  2023,  6128,  7987, 12722, 18826,  2537,  2038,\n",
      "          2210,  2842,  2000,  3749,   102],\n",
      "        [  101,  1037, 10377,  2075,  2147,  1997,  2396,  2005,  2069,  1996,\n",
      "          2087,  5776,  1998,  4119,  1011,  7501,  3185,  3995,  2545,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 21]), 'cls_emb': tensor([[ 2.0408e-04,  1.5236e-01, -3.4545e-01,  ..., -6.6190e-02,\n",
      "          5.7551e-01,  7.4282e-01],\n",
      "        [-2.8290e-01, -5.3051e-02, -9.1299e-02,  ..., -3.6537e-01,\n",
      "          4.6911e-01,  2.8052e-01]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2856,  1999,  1037,  6773,  1011,  2011,  1011,  3616,  5450,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1047,  1011,  2539, 20397,  2256,  6937,  7268,  3571,  1997,\n",
      "          4517, 11513,  2000,  9699, 10036,  5365,  6980,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2856,  1999,  1037,  6773,  1011,  2011,  1011,  3616,  5450,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1047,  1011,  2539, 20397,  2256,  6937,  7268,  3571,  1997,\n",
      "          4517, 11513,  2000,  9699, 10036,  5365,  6980,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2578, 0.7422],\n",
      "        [0.2359, 0.7641]]), 'input_ids': tensor([[  101,  2856,  1999,  1037,  6773,  1011,  2011,  1011,  3616,  5450,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1047,  1011,  2539, 20397,  2256,  6937,  7268,  3571,  1997,\n",
      "          4517, 11513,  2000,  9699, 10036,  5365,  6980,  1012,   102]]), 'ntok': tensor([12, 19]), 'cls_emb': tensor([[-0.4075,  0.1712, -0.4512,  ..., -0.2621,  0.3527,  0.6746],\n",
      "        [-0.0526,  0.1349, -0.3162,  ..., -0.3836,  0.6503,  0.2063]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2012,  2049,  2190,  1010,  3035,  2003,  3409,  2100,  4569,\n",
      "          2066,  1996,  6320,  3976,  5469, 10002,  1997,  1996,  1005, 20341,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2172,  2062,  6832,  4990,  2084,\n",
      "          2054, 11004,  8067,  5802,  2038,  2445,  2149,  1999,  2010,  2627,\n",
      "          2048,  5691,  1010,  1998,  9406,  1010,  9085,  1999,  2005,  5503,\n",
      "         12688,  1010,  2003,  1996,  3819,  3364,  2000,  2202,  2149,  2006,\n",
      "          1996,  4440,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2012,  2049,  2190,  1010,  3035,  2003,  3409,  2100,  4569,\n",
      "          2066,  1996,  6320,  3976,  5469, 10002,  1997,  1996,  1005, 20341,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2172,  2062,  6832,  4990,  2084,\n",
      "          2054, 11004,  8067,  5802,  2038,  2445,  2149,  1999,  2010,  2627,\n",
      "          2048,  5691,  1010,  1998,  9406,  1010,  9085,  1999,  2005,  5503,\n",
      "         12688,  1010,  2003,  1996,  3819,  3364,  2000,  2202,  2149,  2006,\n",
      "          1996,  4440,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2710, 0.7290],\n",
      "        [0.2417, 0.7583]]), 'input_ids': tensor([[  101,  2012,  2049,  2190,  1010,  3035,  2003,  3409,  2100,  4569,\n",
      "          2066,  1996,  6320,  3976,  5469, 10002,  1997,  1996,  1005, 20341,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  1037,  2172,  2062,  6832,  4990,  2084,\n",
      "          2054, 11004,  8067,  5802,  2038,  2445,  2149,  1999,  2010,  2627,\n",
      "          2048,  5691,  1010,  1998,  9406,  1010,  9085,  1999,  2005,  5503,\n",
      "         12688,  1010,  2003,  1996,  3819,  3364,  2000,  2202,  2149,  2006,\n",
      "          1996,  4440,  1012,   102]]), 'ntok': tensor([22, 44]), 'cls_emb': tensor([[ 0.0696, -0.2848,  0.0240,  ..., -0.1388,  0.4986,  0.3596],\n",
      "        [-0.0157, -0.0052, -0.4603,  ..., -0.1590,  0.7407,  0.2145]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3737,  1997,  1996,  2396,  4117,  2007,  1996,  8562,\n",
      "          1998,  4454,  1997,  1996,  5896,  3499,  1996, 16587,  2000,  2556,\n",
      "          1996, 10213,  4471,  1997, 17213,  2302,  2009,  2412,  3352, 25250,\n",
      "          2100,  2030, 23353,  2100,  1012,   102],\n",
      "        [  101,  4658,  1029,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3737,  1997,  1996,  2396,  4117,  2007,  1996,  8562,\n",
      "          1998,  4454,  1997,  1996,  5896,  3499,  1996, 16587,  2000,  2556,\n",
      "          1996, 10213,  4471,  1997, 17213,  2302,  2009,  2412,  3352, 25250,\n",
      "          2100,  2030, 23353,  2100,  1012,   102],\n",
      "        [  101,  4658,  1029,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2485, 0.7515],\n",
      "        [0.3013, 0.6987]]), 'input_ids': tensor([[  101,  1996,  3737,  1997,  1996,  2396,  4117,  2007,  1996,  8562,\n",
      "          1998,  4454,  1997,  1996,  5896,  3499,  1996, 16587,  2000,  2556,\n",
      "          1996, 10213,  4471,  1997, 17213,  2302,  2009,  2412,  3352, 25250,\n",
      "          2100,  2030, 23353,  2100,  1012,   102],\n",
      "        [  101,  4658,  1029,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([36,  4]), 'cls_emb': tensor([[-0.0262,  0.1281, -0.3035,  ..., -0.2617,  0.6681, -0.1447],\n",
      "        [ 0.1072, -0.0847,  0.0080,  ..., -0.3851,  0.1956,  0.4047]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3972, 15735, 13453,  6057,  1010,  3435,  1998,  6065,  1010,\n",
      "          7801,  2000,  1996,  4895,  5498, 10711,  3064,  1010,  1998,  2440,\n",
      "          1997, 20096,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2130,  2007,  1037,  2665, 22338,  1998,  1037,  7123,  1997,\n",
      "          2543,  1011,  2417,  8457, 18395,  5266,  2010,  3244,  1010,  2174,\n",
      "          1010, 11382, 23398,  3849,  2000,  2022, 20540,  1010,  2738,  2084,\n",
      "          3772,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3972, 15735, 13453,  6057,  1010,  3435,  1998,  6065,  1010,\n",
      "          7801,  2000,  1996,  4895,  5498, 10711,  3064,  1010,  1998,  2440,\n",
      "          1997, 20096,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2130,  2007,  1037,  2665, 22338,  1998,  1037,  7123,  1997,\n",
      "          2543,  1011,  2417,  8457, 18395,  5266,  2010,  3244,  1010,  2174,\n",
      "          1010, 11382, 23398,  3849,  2000,  2022, 20540,  1010,  2738,  2084,\n",
      "          3772,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2826, 0.7174],\n",
      "        [0.2400, 0.7600]]), 'input_ids': tensor([[  101,  3972, 15735, 13453,  6057,  1010,  3435,  1998,  6065,  1010,\n",
      "          7801,  2000,  1996,  4895,  5498, 10711,  3064,  1010,  1998,  2440,\n",
      "          1997, 20096,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2130,  2007,  1037,  2665, 22338,  1998,  1037,  7123,  1997,\n",
      "          2543,  1011,  2417,  8457, 18395,  5266,  2010,  3244,  1010,  2174,\n",
      "          1010, 11382, 23398,  3849,  2000,  2022, 20540,  1010,  2738,  2084,\n",
      "          3772,  1012,   102]]), 'ntok': tensor([23, 33]), 'cls_emb': tensor([[-0.5290, -0.3976, -0.1708,  ..., -0.4139,  0.2544,  0.2597],\n",
      "        [ 0.0594, -0.1844, -0.6152,  ..., -0.0374,  0.4037,  0.1934]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2466,  1998,  1996,  6860, 10951,  1999,  2107,  1037,\n",
      "          2126,  2008,  2017,  1005,  2128,  3666,  1037,  7815,  3850,  2738,\n",
      "          2084,  1037,  9519,  1997,  1996, 11139,  1998, 12482,  2008, 12673,\n",
      "         13506, 28956,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2012,  1037,  2051,  2043,  2431,  1996,  2061,  1011,  2170,\n",
      "          2613,  5691,  2024,  2210,  2062,  2084,  2444,  1011,  2895, 13941,\n",
      "          1010,  2009,  1005,  1055, 27150,  2000,  2156,  1037,  9476,  2008,\n",
      "          4282,  2054,  2009,  2003,  1010,  1998,  4282,  1996,  2433,  1005,\n",
      "          1055,  2381,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2466,  1998,  1996,  6860, 10951,  1999,  2107,  1037,\n",
      "          2126,  2008,  2017,  1005,  2128,  3666,  1037,  7815,  3850,  2738,\n",
      "          2084,  1037,  9519,  1997,  1996, 11139,  1998, 12482,  2008, 12673,\n",
      "         13506, 28956,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2012,  1037,  2051,  2043,  2431,  1996,  2061,  1011,  2170,\n",
      "          2613,  5691,  2024,  2210,  2062,  2084,  2444,  1011,  2895, 13941,\n",
      "          1010,  2009,  1005,  1055, 27150,  2000,  2156,  1037,  9476,  2008,\n",
      "          4282,  2054,  2009,  2003,  1010,  1998,  4282,  1996,  2433,  1005,\n",
      "          1055,  2381,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2546, 0.7454],\n",
      "        [0.2293, 0.7707]]), 'input_ids': tensor([[  101,  1996,  2466,  1998,  1996,  6860, 10951,  1999,  2107,  1037,\n",
      "          2126,  2008,  2017,  1005,  2128,  3666,  1037,  7815,  3850,  2738,\n",
      "          2084,  1037,  9519,  1997,  1996, 11139,  1998, 12482,  2008, 12673,\n",
      "         13506, 28956,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2012,  1037,  2051,  2043,  2431,  1996,  2061,  1011,  2170,\n",
      "          2613,  5691,  2024,  2210,  2062,  2084,  2444,  1011,  2895, 13941,\n",
      "          1010,  2009,  1005,  1055, 27150,  2000,  2156,  1037,  9476,  2008,\n",
      "          4282,  2054,  2009,  2003,  1010,  1998,  4282,  1996,  2433,  1005,\n",
      "          1055,  2381,  1012,   102]]), 'ntok': tensor([34, 44]), 'cls_emb': tensor([[ 0.1925,  0.0622, -0.1189,  ..., -0.3238,  0.5132,  0.7177],\n",
      "        [ 0.1786, -0.0174, -0.5031,  ..., -0.0254,  0.4567,  0.7650]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2214,  1011,  2088,  1011,  6010,  1011,  2047, 20437,\n",
      "          2003, 27523, 12789,  3064,  1999,  1996,  3185,  1005,  1055,  6050,\n",
      "          1010,  1037,  6569,  3993,  1041,  4246, 14499,  1997, 12532, 16046,\n",
      "          2008,  1010,  2011,  1996,  2203,  1997, 19183,  5030,  1010,  2741,\n",
      "          2026,  4382, 23990,  2041,  1997,  1996,  4258,  1012,   102],\n",
      "        [  101,  3557,  1012,  1012,  1012,  2515,  3749,  1037, 12077,  2433,\n",
      "          1997, 25869,  2964,  2050,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2214,  1011,  2088,  1011,  6010,  1011,  2047, 20437,\n",
      "          2003, 27523, 12789,  3064,  1999,  1996,  3185,  1005,  1055,  6050,\n",
      "          1010,  1037,  6569,  3993,  1041,  4246, 14499,  1997, 12532, 16046,\n",
      "          2008,  1010,  2011,  1996,  2203,  1997, 19183,  5030,  1010,  2741,\n",
      "          2026,  4382, 23990,  2041,  1997,  1996,  4258,  1012,   102],\n",
      "        [  101,  3557,  1012,  1012,  1012,  2515,  3749,  1037, 12077,  2433,\n",
      "          1997, 25869,  2964,  2050,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2661, 0.7339],\n",
      "        [0.2734, 0.7266]]), 'input_ids': tensor([[  101,  1996,  2214,  1011,  2088,  1011,  6010,  1011,  2047, 20437,\n",
      "          2003, 27523, 12789,  3064,  1999,  1996,  3185,  1005,  1055,  6050,\n",
      "          1010,  1037,  6569,  3993,  1041,  4246, 14499,  1997, 12532, 16046,\n",
      "          2008,  1010,  2011,  1996,  2203,  1997, 19183,  5030,  1010,  2741,\n",
      "          2026,  4382, 23990,  2041,  1997,  1996,  4258,  1012,   102],\n",
      "        [  101,  3557,  1012,  1012,  1012,  2515,  3749,  1037, 12077,  2433,\n",
      "          1997, 25869,  2964,  2050,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([49, 16]), 'cls_emb': tensor([[ 0.2203, -0.2615, -0.1425,  ..., -0.3403,  0.4334,  0.3985],\n",
      "        [ 0.1318, -0.1475, -0.3305,  ..., -0.3792,  0.4907,  0.4730]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2049,  2092,  1997, 16337,  1998, 29387,  1006,  1998,  3722,\n",
      "          8438,  1007,  2038,  2146,  2042, 20228, 20824,  2098,  2011,  2714,\n",
      "          2573,  3794,  1996, 12369,  1998,  8595,  2023,  3861,  2061, 19194,\n",
      "          2135, 14087,  1012,   102],\n",
      "        [  101,  7930,  1037, 17160,  8115,  2013,  3246,  1998,  7327,  8458,\n",
      "         11069,  2000,  4507,  1998,  4487, 27572, 24117,  3672,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2049,  2092,  1997, 16337,  1998, 29387,  1006,  1998,  3722,\n",
      "          8438,  1007,  2038,  2146,  2042, 20228, 20824,  2098,  2011,  2714,\n",
      "          2573,  3794,  1996, 12369,  1998,  8595,  2023,  3861,  2061, 19194,\n",
      "          2135, 14087,  1012,   102],\n",
      "        [  101,  7930,  1037, 17160,  8115,  2013,  3246,  1998,  7327,  8458,\n",
      "         11069,  2000,  4507,  1998,  4487, 27572, 24117,  3672,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2313, 0.7687],\n",
      "        [0.2673, 0.7327]]), 'input_ids': tensor([[  101,  2049,  2092,  1997, 16337,  1998, 29387,  1006,  1998,  3722,\n",
      "          8438,  1007,  2038,  2146,  2042, 20228, 20824,  2098,  2011,  2714,\n",
      "          2573,  3794,  1996, 12369,  1998,  8595,  2023,  3861,  2061, 19194,\n",
      "          2135, 14087,  1012,   102],\n",
      "        [  101,  7930,  1037, 17160,  8115,  2013,  3246,  1998,  7327,  8458,\n",
      "         11069,  2000,  4507,  1998,  4487, 27572, 24117,  3672,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 20]), 'cls_emb': tensor([[-0.2678, -0.0023, -0.3483,  ..., -0.5529,  0.1819,  0.6019],\n",
      "        [-0.1972,  0.2025,  0.1060,  ..., -0.5154,  0.4915,  0.1315]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3529,  7354,  2515,  1050,  1005,  1056,  3710,  2039,  1037,\n",
      "          2878,  2843,  1997, 11680,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4066,  1997,  2143,  2008,  3084,  2033,  3335, 19625,\n",
      "          1010,  2021,  2036,  2514, 21931,  2008,  2045,  1005,  1055,  3246,\n",
      "          2005,  2759,  5988,  2664,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3529,  7354,  2515,  1050,  1005,  1056,  3710,  2039,  1037,\n",
      "          2878,  2843,  1997, 11680,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4066,  1997,  2143,  2008,  3084,  2033,  3335, 19625,\n",
      "          1010,  2021,  2036,  2514, 21931,  2008,  2045,  1005,  1055,  3246,\n",
      "          2005,  2759,  5988,  2664,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2800, 0.7200],\n",
      "        [0.2742, 0.7258]]), 'input_ids': tensor([[  101,  3529,  7354,  2515,  1050,  1005,  1056,  3710,  2039,  1037,\n",
      "          2878,  2843,  1997, 11680,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4066,  1997,  2143,  2008,  3084,  2033,  3335, 19625,\n",
      "          1010,  2021,  2036,  2514, 21931,  2008,  2045,  1005,  1055,  3246,\n",
      "          2005,  2759,  5988,  2664,  1012,   102]]), 'ntok': tensor([16, 26]), 'cls_emb': tensor([[ 0.1154,  0.0175,  0.0943,  ..., -0.1102,  0.6237,  0.1687],\n",
      "        [-0.0931, -0.2771, -0.1029,  ..., -0.2753,  0.6105,  0.3952]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4569,  1010, 11238,  1998, 16668,  5099,  2978,  1997, 21014,\n",
      "          4024,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  1060, 26722,  3957,  1996,  2855,  2315, 20593,  1010,\n",
      "         17255,  1998, 12136, 15569, 11189,  4204,  2008,  2421,  9313,  3997,\n",
      "          1998,  9138,  1011,  7504,  2159,  1010,  2029,  6854,  2079,  1050,\n",
      "          1005,  1056,  9585,  2068,  2000,  5860, 11795, 13109,  5714,  6508,\n",
      "          9000,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4569,  1010, 11238,  1998, 16668,  5099,  2978,  1997, 21014,\n",
      "          4024,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  1060, 26722,  3957,  1996,  2855,  2315, 20593,  1010,\n",
      "         17255,  1998, 12136, 15569, 11189,  4204,  2008,  2421,  9313,  3997,\n",
      "          1998,  9138,  1011,  7504,  2159,  1010,  2029,  6854,  2079,  1050,\n",
      "          1005,  1056,  9585,  2068,  2000,  5860, 11795, 13109,  5714,  6508,\n",
      "          9000,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2483, 0.7517],\n",
      "        [0.2515, 0.7485]]), 'input_ids': tensor([[  101,  4569,  1010, 11238,  1998, 16668,  5099,  2978,  1997, 21014,\n",
      "          4024,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  1060, 26722,  3957,  1996,  2855,  2315, 20593,  1010,\n",
      "         17255,  1998, 12136, 15569, 11189,  4204,  2008,  2421,  9313,  3997,\n",
      "          1998,  9138,  1011,  7504,  2159,  1010,  2029,  6854,  2079,  1050,\n",
      "          1005,  1056,  9585,  2068,  2000,  5860, 11795, 13109,  5714,  6508,\n",
      "          9000,  2015,  1012,   102]]), 'ntok': tensor([13, 44]), 'cls_emb': tensor([[-0.4070, -0.0948,  0.1409,  ..., -0.5220,  0.4609,  0.0538],\n",
      "        [-0.6056, -0.2548, -0.2300,  ...,  0.4919,  0.4437,  0.2959]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3748, 16337,  9766,  2015,  3185,  2003,  1037, 22193,\n",
      "          4474,  1012,   102],\n",
      "        [  101, 20432,  2015,  2011,  4346,  2204,  1010, 17133,  2194,  1012,\n",
      "           102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3748, 16337,  9766,  2015,  3185,  2003,  1037, 22193,\n",
      "          4474,  1012,   102],\n",
      "        [  101, 20432,  2015,  2011,  4346,  2204,  1010, 17133,  2194,  1012,\n",
      "           102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2512, 0.7488],\n",
      "        [0.2273, 0.7727]]), 'input_ids': tensor([[  101,  1996,  3748, 16337,  9766,  2015,  3185,  2003,  1037, 22193,\n",
      "          4474,  1012,   102],\n",
      "        [  101, 20432,  2015,  2011,  4346,  2204,  1010, 17133,  2194,  1012,\n",
      "           102,     0,     0]]), 'ntok': tensor([13, 11]), 'cls_emb': tensor([[ 0.1763, -0.0121,  0.1972,  ..., -0.2805,  0.4497,  0.1984],\n",
      "        [-0.5909,  0.4165, -0.3629,  ..., -0.2206,  0.0518,  0.2951]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 19441,  3833,  1010,  3811,  6523, 24271,  2143,  1010,\n",
      "          1998,  2019,  8740,  2850, 18436,  2709,  2000,  2433,  2008,  2064,\n",
      "         18579,  4133,  2426,  3744,  1011, 12776,  2643,  4232,  1005,  1055,\n",
      "         10418,  2147,  1012,   102],\n",
      "        [  101,  2054,  2001,  2320,  2434,  2038,  2042,  2522,  1011, 12132,\n",
      "          2061,  4703,  2008,  2009,  2085,  3849, 14662,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 19441,  3833,  1010,  3811,  6523, 24271,  2143,  1010,\n",
      "          1998,  2019,  8740,  2850, 18436,  2709,  2000,  2433,  2008,  2064,\n",
      "         18579,  4133,  2426,  3744,  1011, 12776,  2643,  4232,  1005,  1055,\n",
      "         10418,  2147,  1012,   102],\n",
      "        [  101,  2054,  2001,  2320,  2434,  2038,  2042,  2522,  1011, 12132,\n",
      "          2061,  4703,  2008,  2009,  2085,  3849, 14662,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2636, 0.7364],\n",
      "        [0.2590, 0.7410]]), 'input_ids': tensor([[  101,  1037, 19441,  3833,  1010,  3811,  6523, 24271,  2143,  1010,\n",
      "          1998,  2019,  8740,  2850, 18436,  2709,  2000,  2433,  2008,  2064,\n",
      "         18579,  4133,  2426,  3744,  1011, 12776,  2643,  4232,  1005,  1055,\n",
      "         10418,  2147,  1012,   102],\n",
      "        [  101,  2054,  2001,  2320,  2434,  2038,  2042,  2522,  1011, 12132,\n",
      "          2061,  4703,  2008,  2009,  2085,  3849, 14662,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 19]), 'cls_emb': tensor([[-0.1839, -0.1270, -0.5311,  ..., -0.2601,  0.3551,  0.3947],\n",
      "        [-0.1213,  0.0962, -0.1843,  ...,  0.0189,  0.1602,  0.8235]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2466,  1998,  3252,  2024,  2092,  1011, 10189,  2098,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6097,  3527,  4381,  1010,  3005, 15536,  6199,  2100,  2670,\n",
      "         11084,  2038, 14453,  9442,  3821,  1012,  1012,  1012,  7545,  2019,\n",
      "          7078, 15544, 19510,  2075, 10652,  2000,  2014,  2535,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2466,  1998,  3252,  2024,  2092,  1011, 10189,  2098,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6097,  3527,  4381,  1010,  3005, 15536,  6199,  2100,  2670,\n",
      "         11084,  2038, 14453,  9442,  3821,  1012,  1012,  1012,  7545,  2019,\n",
      "          7078, 15544, 19510,  2075, 10652,  2000,  2014,  2535,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2391, 0.7609],\n",
      "        [0.2643, 0.7357]]), 'input_ids': tensor([[  101,  1996,  2466,  1998,  3252,  2024,  2092,  1011, 10189,  2098,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6097,  3527,  4381,  1010,  3005, 15536,  6199,  2100,  2670,\n",
      "         11084,  2038, 14453,  9442,  3821,  1012,  1012,  1012,  7545,  2019,\n",
      "          7078, 15544, 19510,  2075, 10652,  2000,  2014,  2535,  1012,   102]]), 'ntok': tensor([12, 30]), 'cls_emb': tensor([[-0.3875, -0.0109, -0.1240,  ..., -0.2438, -0.2175,  0.5738],\n",
      "        [-0.2957, -0.1763, -0.4138,  ..., -0.4592,  0.5350,  0.1748]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019, 23824, 21014, 27284,  1998,  2461,  1011,  5863,  2008,\n",
      "          5681,  2003,  2062,  5875,  1999,  4145,  2084,  1999,  7781,  1012,\n",
      "           102],\n",
      "        [  101,  1996,  2117,  2746,  1997,  4302, 10693,  2003,  1037,  2143,\n",
      "          2521,  6020,  2000,  2049,  8646,  1012,   102,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019, 23824, 21014, 27284,  1998,  2461,  1011,  5863,  2008,\n",
      "          5681,  2003,  2062,  5875,  1999,  4145,  2084,  1999,  7781,  1012,\n",
      "           102],\n",
      "        [  101,  1996,  2117,  2746,  1997,  4302, 10693,  2003,  1037,  2143,\n",
      "          2521,  6020,  2000,  2049,  8646,  1012,   102,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2661, 0.7339],\n",
      "        [0.2758, 0.7242]]), 'input_ids': tensor([[  101,  2019, 23824, 21014, 27284,  1998,  2461,  1011,  5863,  2008,\n",
      "          5681,  2003,  2062,  5875,  1999,  4145,  2084,  1999,  7781,  1012,\n",
      "           102],\n",
      "        [  101,  1996,  2117,  2746,  1997,  4302, 10693,  2003,  1037,  2143,\n",
      "          2521,  6020,  2000,  2049,  8646,  1012,   102,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([21, 17]), 'cls_emb': tensor([[-0.3464, -0.3077,  0.0460,  ..., -0.3022,  0.6429,  0.1255],\n",
      "        [-0.2208, -0.2863,  0.1254,  ..., -0.0379,  0.3865,  0.6698]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2065,  2017,  2064,  4308,  1996,  5931,  4180,  1010,  2009,\n",
      "          1005,  1055,  4276,  9361,  2041,  2005,  1996,  4616,  2894,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  4010,  1010,  6057,  1010, 11973,  2143,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2065,  2017,  2064,  4308,  1996,  5931,  4180,  1010,  2009,\n",
      "          1005,  1055,  4276,  9361,  2041,  2005,  1996,  4616,  2894,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  4010,  1010,  6057,  1010, 11973,  2143,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2395, 0.7605],\n",
      "        [0.2636, 0.7364]]), 'input_ids': tensor([[  101,  2065,  2017,  2064,  4308,  1996,  5931,  4180,  1010,  2009,\n",
      "          1005,  1055,  4276,  9361,  2041,  2005,  1996,  4616,  2894,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  4010,  1010,  6057,  1010, 11973,  2143,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([21, 10]), 'cls_emb': tensor([[ 0.1893, -0.1539, -0.1043,  ..., -0.1594,  0.0021, -0.0266],\n",
      "        [-0.5802, -0.3431, -0.3143,  ..., -0.6645,  0.2784,  0.4434]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1045,  1005,  2222,  6655,  1996,  2678,  2208,  2003,  1037,\n",
      "          2843,  2062,  4569,  2084,  1996,  2143,  1012,   102],\n",
      "        [  101,  1996,  2190,  2143,  2055,  3598,  2000,  2718, 12370,  2144,\n",
      "          2492,  1997,  5544,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1045,  1005,  2222,  6655,  1996,  2678,  2208,  2003,  1037,\n",
      "          2843,  2062,  4569,  2084,  1996,  2143,  1012,   102],\n",
      "        [  101,  1996,  2190,  2143,  2055,  3598,  2000,  2718, 12370,  2144,\n",
      "          2492,  1997,  5544,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2711, 0.7289],\n",
      "        [0.2890, 0.7110]]), 'input_ids': tensor([[  101,  1045,  1005,  2222,  6655,  1996,  2678,  2208,  2003,  1037,\n",
      "          2843,  2062,  4569,  2084,  1996,  2143,  1012,   102],\n",
      "        [  101,  1996,  2190,  2143,  2055,  3598,  2000,  2718, 12370,  2144,\n",
      "          2492,  1997,  5544,  1012,   102,     0,     0,     0]]), 'ntok': tensor([18, 15]), 'cls_emb': tensor([[ 0.2456, -0.1501, -0.0440,  ..., -0.2069,  0.5098,  0.4733],\n",
      "        [-0.4258, -0.1391, -0.1654,  ..., -0.1344,  0.6434,  0.2632]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2003,  2307,  2621,  4569,  2000,  3422,  7779,  1998,\n",
      "          2010,  8937,  9659, 17523,  2125,  1037, 21864, 15952,  3459,  1997,\n",
      "          3494,  1012,   102],\n",
      "        [  101,  3143,  3768,  1997,  2434,  3012,  1010, 12266,  2791,  2030,\n",
      "          2130,  5710,  3947,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2003,  2307,  2621,  4569,  2000,  3422,  7779,  1998,\n",
      "          2010,  8937,  9659, 17523,  2125,  1037, 21864, 15952,  3459,  1997,\n",
      "          3494,  1012,   102],\n",
      "        [  101,  3143,  3768,  1997,  2434,  3012,  1010, 12266,  2791,  2030,\n",
      "          2130,  5710,  3947,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2289, 0.7711],\n",
      "        [0.2731, 0.7269]]), 'input_ids': tensor([[  101,  2009,  2003,  2307,  2621,  4569,  2000,  3422,  7779,  1998,\n",
      "          2010,  8937,  9659, 17523,  2125,  1037, 21864, 15952,  3459,  1997,\n",
      "          3494,  1012,   102],\n",
      "        [  101,  3143,  3768,  1997,  2434,  3012,  1010, 12266,  2791,  2030,\n",
      "          2130,  5710,  3947,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([23, 14]), 'cls_emb': tensor([[ 0.1476,  0.2213,  0.2499,  ..., -0.1734,  0.2924,  0.3707],\n",
      "        [-0.4033,  0.1109, -0.5816,  ..., -0.3485, -0.0306,  0.4283]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 12476,  7329,  1010,  3052, 17904, 17363,  1010,  1998,  8680,\n",
      "          2645,  5019,  5587,  2039,  2000,  2178,  1036, 12656, 21177,  1012,\n",
      "          1005,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2035,  1011,  1999,  1011,  2035,  1010,  1996,  2143,  2003,\n",
      "          2019, 22249,  1998, 19597,  2409,  6925,  1997,  1037,  2111,  2040,\n",
      "          2444,  2426,  2149,  1010,  2021,  2025,  9352,  2007,  2149,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 12476,  7329,  1010,  3052, 17904, 17363,  1010,  1998,  8680,\n",
      "          2645,  5019,  5587,  2039,  2000,  2178,  1036, 12656, 21177,  1012,\n",
      "          1005,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2035,  1011,  1999,  1011,  2035,  1010,  1996,  2143,  2003,\n",
      "          2019, 22249,  1998, 19597,  2409,  6925,  1997,  1037,  2111,  2040,\n",
      "          2444,  2426,  2149,  1010,  2021,  2025,  9352,  2007,  2149,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2462, 0.7538],\n",
      "        [0.2428, 0.7572]]), 'input_ids': tensor([[  101, 12476,  7329,  1010,  3052, 17904, 17363,  1010,  1998,  8680,\n",
      "          2645,  5019,  5587,  2039,  2000,  2178,  1036, 12656, 21177,  1012,\n",
      "          1005,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2035,  1011,  1999,  1011,  2035,  1010,  1996,  2143,  2003,\n",
      "          2019, 22249,  1998, 19597,  2409,  6925,  1997,  1037,  2111,  2040,\n",
      "          2444,  2426,  2149,  1010,  2021,  2025,  9352,  2007,  2149,  1012,\n",
      "           102]]), 'ntok': tensor([22, 31]), 'cls_emb': tensor([[ 0.6989,  0.3411, -0.0109,  ..., -0.1521,  0.5951,  0.7480],\n",
      "        [ 0.2302,  0.0582, -0.1077,  ..., -0.2393,  0.4289,  0.4374]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2718,  1998,  3335,  2004,  2521,  2004,  1996,  4038,  3632,\n",
      "          1998,  1037,  2502, 15589,  1005,  3335,  1999,  1996,  2126,  1997,\n",
      "          2466,  1012,   102],\n",
      "        [  101,  2205,  2172,  1997,  2009,  5683,  4895, 14876,  7874,  2098,\n",
      "          1998,  2104, 24844, 18349,  5669,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2718,  1998,  3335,  2004,  2521,  2004,  1996,  4038,  3632,\n",
      "          1998,  1037,  2502, 15589,  1005,  3335,  1999,  1996,  2126,  1997,\n",
      "          2466,  1012,   102],\n",
      "        [  101,  2205,  2172,  1997,  2009,  5683,  4895, 14876,  7874,  2098,\n",
      "          1998,  2104, 24844, 18349,  5669,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2667, 0.7333],\n",
      "        [0.2640, 0.7360]]), 'input_ids': tensor([[  101,  2718,  1998,  3335,  2004,  2521,  2004,  1996,  4038,  3632,\n",
      "          1998,  1037,  2502, 15589,  1005,  3335,  1999,  1996,  2126,  1997,\n",
      "          2466,  1012,   102],\n",
      "        [  101,  2205,  2172,  1997,  2009,  5683,  4895, 14876,  7874,  2098,\n",
      "          1998,  2104, 24844, 18349,  5669,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([23, 17]), 'cls_emb': tensor([[-0.2509, -0.1219, -0.1228,  ..., -0.4106,  0.3516,  0.3378],\n",
      "        [ 0.0441,  0.2009,  0.0100,  ..., -0.1692,  0.2091,  0.4783]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2784,  1998, 15902,  2143,  1012,   102,     0],\n",
      "        [  101,  2021,  2009,  2071,  2031,  2042,  4788,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2784,  1998, 15902,  2143,  1012,   102,     0],\n",
      "        [  101,  2021,  2009,  2071,  2031,  2042,  4788,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2768, 0.7232],\n",
      "        [0.2837, 0.7163]]), 'input_ids': tensor([[  101,  1037,  2784,  1998, 15902,  2143,  1012,   102,     0],\n",
      "        [  101,  2021,  2009,  2071,  2031,  2042,  4788,  1012,   102]]), 'ntok': tensor([8, 9]), 'cls_emb': tensor([[-0.2599, -0.1973, -0.2012,  ..., -0.3558,  0.3329,  0.3356],\n",
      "        [ 0.0313,  0.0111, -0.4767,  ..., -0.3008,  0.1669,  0.5917]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2008,  1005,  1055,  5760, 10975,  1044, 18863,  1012,   102],\n",
      "        [  101,  1037, 16267,  6057, 24040,  2000,  2919,  5248,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2008,  1005,  1055,  5760, 10975,  1044, 18863,  1012,   102],\n",
      "        [  101,  1037, 16267,  6057, 24040,  2000,  2919,  5248,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2769, 0.7231],\n",
      "        [0.2825, 0.7175]]), 'input_ids': tensor([[  101,  2008,  1005,  1055,  5760, 10975,  1044, 18863,  1012,   102],\n",
      "        [  101,  1037, 16267,  6057, 24040,  2000,  2919,  5248,  1012,   102]]), 'ntok': tensor([10, 10]), 'cls_emb': tensor([[ 0.1917,  0.1510, -0.0069,  ..., -0.2862,  0.3767,  0.7288],\n",
      "        [-0.5376, -0.1801, -0.6772,  ..., -0.1937,  0.3894,  0.4492]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2017,  1005,  2222, 12008, 29279,  1998,  4756, 23558,  1998,\n",
      "          4298,  1010,  3666,  1996, 21177,  1997,  1037, 10015,  2402, 14804,\n",
      "         29449,  2075,  9652,  1999,  1037, 11808,  2712,  1010,  8328,  2019,\n",
      "          9413, 17884,  7697,  1012,   102],\n",
      "        [  101,  5622, 14517,  2050,  2404,  2006,  2382,  7038,  2005,  1996,\n",
      "          2535,  1010,  1998,  2038,  3294,  8590,  2370,  2013,  2010,  5744,\n",
      "          1010,  2204, 23510,  3022,  3746,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2017,  1005,  2222, 12008, 29279,  1998,  4756, 23558,  1998,\n",
      "          4298,  1010,  3666,  1996, 21177,  1997,  1037, 10015,  2402, 14804,\n",
      "         29449,  2075,  9652,  1999,  1037, 11808,  2712,  1010,  8328,  2019,\n",
      "          9413, 17884,  7697,  1012,   102],\n",
      "        [  101,  5622, 14517,  2050,  2404,  2006,  2382,  7038,  2005,  1996,\n",
      "          2535,  1010,  1998,  2038,  3294,  8590,  2370,  2013,  2010,  5744,\n",
      "          1010,  2204, 23510,  3022,  3746,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2501, 0.7499],\n",
      "        [0.2728, 0.7272]]), 'input_ids': tensor([[  101,  2017,  1005,  2222, 12008, 29279,  1998,  4756, 23558,  1998,\n",
      "          4298,  1010,  3666,  1996, 21177,  1997,  1037, 10015,  2402, 14804,\n",
      "         29449,  2075,  9652,  1999,  1037, 11808,  2712,  1010,  8328,  2019,\n",
      "          9413, 17884,  7697,  1012,   102],\n",
      "        [  101,  5622, 14517,  2050,  2404,  2006,  2382,  7038,  2005,  1996,\n",
      "          2535,  1010,  1998,  2038,  3294,  8590,  2370,  2013,  2010,  5744,\n",
      "          1010,  2204, 23510,  3022,  3746,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 27]), 'cls_emb': tensor([[ 0.3192, -0.2824, -0.0936,  ..., -0.4613, -0.0313,  0.5020],\n",
      "        [-0.6080, -0.3826, -0.4040,  ..., -0.0044,  0.7522,  0.2859]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 11693, 19231,  2075, 17624,  1997, 19351,  2140,  6087,\n",
      "          1998, 26418,  4509,  4038,  2013,  6373,  1012,   102],\n",
      "        [  101,  2009, 16481,  3243, 17075,  2004,  2019,  6387,  1010, 28902,\n",
      "          2839,  2817,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 11693, 19231,  2075, 17624,  1997, 19351,  2140,  6087,\n",
      "          1998, 26418,  4509,  4038,  2013,  6373,  1012,   102],\n",
      "        [  101,  2009, 16481,  3243, 17075,  2004,  2019,  6387,  1010, 28902,\n",
      "          2839,  2817,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2875, 0.7125],\n",
      "        [0.2678, 0.7322]]), 'input_ids': tensor([[  101,  1037, 11693, 19231,  2075, 17624,  1997, 19351,  2140,  6087,\n",
      "          1998, 26418,  4509,  4038,  2013,  6373,  1012,   102],\n",
      "        [  101,  2009, 16481,  3243, 17075,  2004,  2019,  6387,  1010, 28902,\n",
      "          2839,  2817,  1012,   102,     0,     0,     0,     0]]), 'ntok': tensor([18, 14]), 'cls_emb': tensor([[-0.2433, -0.2946, -0.2855,  ..., -0.5025,  0.2812,  0.3380],\n",
      "        [-0.0842, -0.1111, -0.1790,  ..., -0.3718,  0.2592,  0.5224]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019,  4895, 14244, 25933, 27887,  2213,  1997,  3743,  2739,\n",
      "          1998, 21209,  2015,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12580, 11158,  1999, 11084,  1010, 15966,  1998, 11028,  1010,\n",
      "         10704, 28378,  2072,  1005,  1055,  9231, 10085, 23584,  2003,  2019,\n",
      "         26137,  2135,  2919,  2143,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019,  4895, 14244, 25933, 27887,  2213,  1997,  3743,  2739,\n",
      "          1998, 21209,  2015,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12580, 11158,  1999, 11084,  1010, 15966,  1998, 11028,  1010,\n",
      "         10704, 28378,  2072,  1005,  1055,  9231, 10085, 23584,  2003,  2019,\n",
      "         26137,  2135,  2919,  2143,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.3011, 0.6989],\n",
      "        [0.2383, 0.7617]]), 'input_ids': tensor([[  101,  2019,  4895, 14244, 25933, 27887,  2213,  1997,  3743,  2739,\n",
      "          1998, 21209,  2015,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101, 12580, 11158,  1999, 11084,  1010, 15966,  1998, 11028,  1010,\n",
      "         10704, 28378,  2072,  1005,  1055,  9231, 10085, 23584,  2003,  2019,\n",
      "         26137,  2135,  2919,  2143,  1012,   102]]), 'ntok': tensor([15, 26]), 'cls_emb': tensor([[-0.5335, -0.1412, -0.3913,  ..., -0.3569,  0.3995,  0.1781],\n",
      "        [-0.1975, -0.1010, -0.1658,  ..., -0.1563,  0.5221,  0.6644]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1998,  2008,  3727,  1037,  4920,  1999,  1996,  2415,  1997,\n",
      "          1996,  5474,  2239,  2712,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996, 11874, 12266,  2135, 15113,  2015,  1996,  2892,  1011,\n",
      "          3451,  5966,  2090, 26522,  2015,  1998, 23178,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1998,  2008,  3727,  1037,  4920,  1999,  1996,  2415,  1997,\n",
      "          1996,  5474,  2239,  2712,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996, 11874, 12266,  2135, 15113,  2015,  1996,  2892,  1011,\n",
      "          3451,  5966,  2090, 26522,  2015,  1998, 23178,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.3044, 0.6956],\n",
      "        [0.2474, 0.7526]]), 'input_ids': tensor([[  101,  1998,  2008,  3727,  1037,  4920,  1999,  1996,  2415,  1997,\n",
      "          1996,  5474,  2239,  2712,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996, 11874, 12266,  2135, 15113,  2015,  1996,  2892,  1011,\n",
      "          3451,  5966,  2090, 26522,  2015,  1998, 23178,  2015,  1012,   102]]), 'ntok': tensor([16, 20]), 'cls_emb': tensor([[ 0.0031,  0.0803, -0.0053,  ..., -0.4630,  0.5178,  0.8761],\n",
      "        [-0.3403,  0.3618, -0.2572,  ..., -0.4453,  0.3232,  0.4076]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 23528,  3790,  4332,  2010,  8200,  1036, 14154, 11563,  2075,\n",
      "          1005,  2806,  2046,  2242,  2008,  2071,  2428,  2393,  3154,  2039,\n",
      "          1996,  2553,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1037,  8242,  2438,  7472,  2007,  7789,  2104,  8091,  5582,\n",
      "          2015,  1010,  1996,  2785,  1997,  3185,  2008, 20432,  2015,  2130,\n",
      "          2004,  2009,  4332, 24890, 15787, 21425,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 23528,  3790,  4332,  2010,  8200,  1036, 14154, 11563,  2075,\n",
      "          1005,  2806,  2046,  2242,  2008,  2071,  2428,  2393,  3154,  2039,\n",
      "          1996,  2553,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1037,  8242,  2438,  7472,  2007,  7789,  2104,  8091,  5582,\n",
      "          2015,  1010,  1996,  2785,  1997,  3185,  2008, 20432,  2015,  2130,\n",
      "          2004,  2009,  4332, 24890, 15787, 21425,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2512, 0.7488],\n",
      "        [0.2660, 0.7340]]), 'input_ids': tensor([[  101, 23528,  3790,  4332,  2010,  8200,  1036, 14154, 11563,  2075,\n",
      "          1005,  2806,  2046,  2242,  2008,  2071,  2428,  2393,  3154,  2039,\n",
      "          1996,  2553,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1037,  8242,  2438,  7472,  2007,  7789,  2104,  8091,  5582,\n",
      "          2015,  1010,  1996,  2785,  1997,  3185,  2008, 20432,  2015,  2130,\n",
      "          2004,  2009,  4332, 24890, 15787, 21425,  1012,   102]]), 'ntok': tensor([24, 28]), 'cls_emb': tensor([[-0.3433,  0.0537, -0.3103,  ..., -0.3708,  0.5547,  0.5451],\n",
      "        [-0.1498, -0.5006, -0.1319,  ..., -0.5719,  0.5188,  0.4024]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2054,  2428,  3084,  2009,  2569,  2003,  2008,  2009,  8005,\n",
      "          2149,  2046,  2049,  2088,  1010,  3957,  2149,  1037,  5394,  3005,\n",
      "          6114,  1998, 10911,  2015,  2057,  2064,  3745,  1010, 20626,  2032,\n",
      "          2007,  5875,  3494,  1998, 10255,  2149,  2041,  1997,  1996,  4258,\n",
      "          3110,  2057,  1005,  2310,  4207,  1037,  2307,  6172,  1012,   102],\n",
      "        [  101,  2007,  1996,  6453,  1997,  2070, 25085,  2135, 19142, 24584,\n",
      "          2015,  2011, 26170,  1996, 21751,  2004,  6890,  1005,  1055,  5795,\n",
      "          1010,  2045,  2003,  1050,  1005,  1056,  1037,  2417, 21564,  2075,\n",
      "          2617,  2182,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2054,  2428,  3084,  2009,  2569,  2003,  2008,  2009,  8005,\n",
      "          2149,  2046,  2049,  2088,  1010,  3957,  2149,  1037,  5394,  3005,\n",
      "          6114,  1998, 10911,  2015,  2057,  2064,  3745,  1010, 20626,  2032,\n",
      "          2007,  5875,  3494,  1998, 10255,  2149,  2041,  1997,  1996,  4258,\n",
      "          3110,  2057,  1005,  2310,  4207,  1037,  2307,  6172,  1012,   102],\n",
      "        [  101,  2007,  1996,  6453,  1997,  2070, 25085,  2135, 19142, 24584,\n",
      "          2015,  2011, 26170,  1996, 21751,  2004,  6890,  1005,  1055,  5795,\n",
      "          1010,  2045,  2003,  1050,  1005,  1056,  1037,  2417, 21564,  2075,\n",
      "          2617,  2182,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2451, 0.7549],\n",
      "        [0.2458, 0.7542]]), 'input_ids': tensor([[  101,  2054,  2428,  3084,  2009,  2569,  2003,  2008,  2009,  8005,\n",
      "          2149,  2046,  2049,  2088,  1010,  3957,  2149,  1037,  5394,  3005,\n",
      "          6114,  1998, 10911,  2015,  2057,  2064,  3745,  1010, 20626,  2032,\n",
      "          2007,  5875,  3494,  1998, 10255,  2149,  2041,  1997,  1996,  4258,\n",
      "          3110,  2057,  1005,  2310,  4207,  1037,  2307,  6172,  1012,   102],\n",
      "        [  101,  2007,  1996,  6453,  1997,  2070, 25085,  2135, 19142, 24584,\n",
      "          2015,  2011, 26170,  1996, 21751,  2004,  6890,  1005,  1055,  5795,\n",
      "          1010,  2045,  2003,  1050,  1005,  1056,  1037,  2417, 21564,  2075,\n",
      "          2617,  2182,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([50, 34]), 'cls_emb': tensor([[-0.0824, -0.1011, -0.0763,  ..., -0.1311,  0.3470,  0.6138],\n",
      "        [-0.1191,  0.1749, -0.4582,  ..., -0.0844,  0.4925,  0.4772]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2383,  2018,  1996,  2204,  3168,  2000,  3459,  5889,  2040,\n",
      "          2024,  1010,  3227,  4092,  1010, 28456,  2011,  1996,  3185,  1011,\n",
      "          2183,  2270,  1010,  1047,  6806,  9496,  2059,  4152, 27547,  4616,\n",
      "          2013,  2068,  2035,  1012,   102],\n",
      "        [  101,  1012,  1012,  1012,  1037, 11771,  7700,  1997,  3331,  4641,\n",
      "          1998,  4087, 21025, 29325,  4509,  2008,  2097,  2079,  2210,  2000,\n",
      "          5083,  1996, 11603,  3426,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2383,  2018,  1996,  2204,  3168,  2000,  3459,  5889,  2040,\n",
      "          2024,  1010,  3227,  4092,  1010, 28456,  2011,  1996,  3185,  1011,\n",
      "          2183,  2270,  1010,  1047,  6806,  9496,  2059,  4152, 27547,  4616,\n",
      "          2013,  2068,  2035,  1012,   102],\n",
      "        [  101,  1012,  1012,  1012,  1037, 11771,  7700,  1997,  3331,  4641,\n",
      "          1998,  4087, 21025, 29325,  4509,  2008,  2097,  2079,  2210,  2000,\n",
      "          5083,  1996, 11603,  3426,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2580, 0.7420],\n",
      "        [0.2485, 0.7515]]), 'input_ids': tensor([[  101,  2383,  2018,  1996,  2204,  3168,  2000,  3459,  5889,  2040,\n",
      "          2024,  1010,  3227,  4092,  1010, 28456,  2011,  1996,  3185,  1011,\n",
      "          2183,  2270,  1010,  1047,  6806,  9496,  2059,  4152, 27547,  4616,\n",
      "          2013,  2068,  2035,  1012,   102],\n",
      "        [  101,  1012,  1012,  1012,  1037, 11771,  7700,  1997,  3331,  4641,\n",
      "          1998,  4087, 21025, 29325,  4509,  2008,  2097,  2079,  2210,  2000,\n",
      "          5083,  1996, 11603,  3426,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 26]), 'cls_emb': tensor([[-0.2743,  0.0038, -0.4053,  ..., -0.1821,  0.4867,  0.5405],\n",
      "        [-0.0203,  0.2193,  0.0656,  ..., -0.4028,  0.6828,  0.4459]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1997,  1996,  3737,  1997,  1037,  8276,\n",
      "          6676,  4811,  3185,  1011,  2416,  2420,  1010,  2698,  6385,  1010,\n",
      "          2672,  1010,  2030,  2008, 21794, 21876, 12661,  1012,   102],\n",
      "        [  101,  2065,  2017,  5959,  2062, 16465, 22092,  2007,  5875,  4736,\n",
      "          2098,  3494,  1025,  2023,  2028,  2003,  2005,  2017,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1997,  1996,  3737,  1997,  1037,  8276,\n",
      "          6676,  4811,  3185,  1011,  2416,  2420,  1010,  2698,  6385,  1010,\n",
      "          2672,  1010,  2030,  2008, 21794, 21876, 12661,  1012,   102],\n",
      "        [  101,  2065,  2017,  5959,  2062, 16465, 22092,  2007,  5875,  4736,\n",
      "          2098,  3494,  1025,  2023,  2028,  2003,  2005,  2017,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2633, 0.7367],\n",
      "        [0.2488, 0.7512]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1997,  1996,  3737,  1997,  1037,  8276,\n",
      "          6676,  4811,  3185,  1011,  2416,  2420,  1010,  2698,  6385,  1010,\n",
      "          2672,  1010,  2030,  2008, 21794, 21876, 12661,  1012,   102],\n",
      "        [  101,  2065,  2017,  5959,  2062, 16465, 22092,  2007,  5875,  4736,\n",
      "          2098,  3494,  1025,  2023,  2028,  2003,  2005,  2017,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([29, 20]), 'cls_emb': tensor([[-0.0371, -0.0407, -0.3087,  ..., -0.1668,  0.5605,  0.7186],\n",
      "        [-0.3073, -0.4683, -0.1019,  ..., -0.1507,  0.2028,  0.6004]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2087, 20625,  2135, 18847,  2669,  3560,  2143,  1997,\n",
      "          1996,  2095,  1010, 19144,  2069,  2005,  1996, 21025,  7382,  6799,\n",
      "          1997,  2108,  6361,  2004,  1037,  2309, 29505,  6584,  1011,  3371,\n",
      "          2202,  1012,   102],\n",
      "        [  101,  2009, 17210,  2000,  2022,  2464,  2011,  3087,  2007,  2130,\n",
      "          1037,  4458,  3037,  1999,  1996,  2824, 20300,  1996,  2088,  3458,\n",
      "          2037,  2219, 24484,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2087, 20625,  2135, 18847,  2669,  3560,  2143,  1997,\n",
      "          1996,  2095,  1010, 19144,  2069,  2005,  1996, 21025,  7382,  6799,\n",
      "          1997,  2108,  6361,  2004,  1037,  2309, 29505,  6584,  1011,  3371,\n",
      "          2202,  1012,   102],\n",
      "        [  101,  2009, 17210,  2000,  2022,  2464,  2011,  3087,  2007,  2130,\n",
      "          1037,  4458,  3037,  1999,  1996,  2824, 20300,  1996,  2088,  3458,\n",
      "          2037,  2219, 24484,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2789, 0.7211],\n",
      "        [0.2275, 0.7725]]), 'input_ids': tensor([[  101,  1996,  2087, 20625,  2135, 18847,  2669,  3560,  2143,  1997,\n",
      "          1996,  2095,  1010, 19144,  2069,  2005,  1996, 21025,  7382,  6799,\n",
      "          1997,  2108,  6361,  2004,  1037,  2309, 29505,  6584,  1011,  3371,\n",
      "          2202,  1012,   102],\n",
      "        [  101,  2009, 17210,  2000,  2022,  2464,  2011,  3087,  2007,  2130,\n",
      "          1037,  4458,  3037,  1999,  1996,  2824, 20300,  1996,  2088,  3458,\n",
      "          2037,  2219, 24484,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([33, 25]), 'cls_emb': tensor([[-0.2354, -0.0839, -0.1689,  ..., -0.1965,  0.7466,  0.3121],\n",
      "        [ 0.1000,  0.3239, -0.1432,  ..., -0.3087,  0.0234,  0.5978]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1999,  2019,  3947,  1010,  1045,  8343,  1010,  2025,  2000,\n",
      "          2125, 10497,  2011,  6037,  2593,  2205,  3809,  2030,  2205,  2422,\n",
      "         27693,  1010,  2009,  2125, 10497,  2015,  2011,  2074,  2108,  4299,\n",
      "          2100,  1011,  9378,  2100,  1012,   102],\n",
      "        [  101,  2053,  2126,  1045,  2064,  2903,  2023,  7170,  1997, 18015,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1999,  2019,  3947,  1010,  1045,  8343,  1010,  2025,  2000,\n",
      "          2125, 10497,  2011,  6037,  2593,  2205,  3809,  2030,  2205,  2422,\n",
      "         27693,  1010,  2009,  2125, 10497,  2015,  2011,  2074,  2108,  4299,\n",
      "          2100,  1011,  9378,  2100,  1012,   102],\n",
      "        [  101,  2053,  2126,  1045,  2064,  2903,  2023,  7170,  1997, 18015,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2383, 0.7617],\n",
      "        [0.2579, 0.7421]]), 'input_ids': tensor([[  101,  1999,  2019,  3947,  1010,  1045,  8343,  1010,  2025,  2000,\n",
      "          2125, 10497,  2011,  6037,  2593,  2205,  3809,  2030,  2205,  2422,\n",
      "         27693,  1010,  2009,  2125, 10497,  2015,  2011,  2074,  2108,  4299,\n",
      "          2100,  1011,  9378,  2100,  1012,   102],\n",
      "        [  101,  2053,  2126,  1045,  2064,  2903,  2023,  7170,  1997, 18015,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([36, 12]), 'cls_emb': tensor([[ 0.1140,  0.1330, -0.3377,  ...,  0.0703, -0.0679,  0.8126],\n",
      "        [ 0.1756,  0.4493,  0.0571,  ...,  0.0549,  0.3348,  0.0603]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  2003,  1037,  8313,  1997,  3375,  4784,  2182,  1010,\n",
      "          1998,  5346,  2008, 28089,  2784,  2368,  2068,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  7891,  3444,  2003,  1037,  2502,  3066,  1010,  5262,\n",
      "          1011,  1011,  2012,  2560,  1996,  2353,  1011,  2190,  1010,  1998,\n",
      "          2672,  2130,  1037, 18624,  2682,  1996,  3025,  5479,  1011,  2039,\n",
      "          1010,  6141, 11527,  1005,  1055,  2732, 10313,  6819,  1024,  1996,\n",
      "          6151,  2483,  3597, 25896,  2406,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  2003,  1037,  8313,  1997,  3375,  4784,  2182,  1010,\n",
      "          1998,  5346,  2008, 28089,  2784,  2368,  2068,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  7891,  3444,  2003,  1037,  2502,  3066,  1010,  5262,\n",
      "          1011,  1011,  2012,  2560,  1996,  2353,  1011,  2190,  1010,  1998,\n",
      "          2672,  2130,  1037, 18624,  2682,  1996,  3025,  5479,  1011,  2039,\n",
      "          1010,  6141, 11527,  1005,  1055,  2732, 10313,  6819,  1024,  1996,\n",
      "          6151,  2483,  3597, 25896,  2406,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2507, 0.7493],\n",
      "        [0.2409, 0.7591]]), 'input_ids': tensor([[  101,  2045,  2003,  1037,  8313,  1997,  3375,  4784,  2182,  1010,\n",
      "          1998,  5346,  2008, 28089,  2784,  2368,  2068,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2023,  7891,  3444,  2003,  1037,  2502,  3066,  1010,  5262,\n",
      "          1011,  1011,  2012,  2560,  1996,  2353,  1011,  2190,  1010,  1998,\n",
      "          2672,  2130,  1037, 18624,  2682,  1996,  3025,  5479,  1011,  2039,\n",
      "          1010,  6141, 11527,  1005,  1055,  2732, 10313,  6819,  1024,  1996,\n",
      "          6151,  2483,  3597, 25896,  2406,  1012,   102]]), 'ntok': tensor([19, 47]), 'cls_emb': tensor([[ 0.0644,  0.2538, -0.5044,  ..., -0.3452,  0.1667,  0.6504],\n",
      "        [-0.0661, -0.1433,  0.0323,  ...,  0.2677,  0.5395,  0.2663]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2025,  2069,  4895, 11263, 10695,  2100,  1010,  2021,  2091,\n",
      "         15950, 16360, 14774,  3372,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2573,  2524,  2000,  5323,  8352,  3494,  1010,  2021,  2059,\n",
      "          2038,  2498,  4840,  2030,  3391,  5875,  2000,  2360,  2055,  2068,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2025,  2069,  4895, 11263, 10695,  2100,  1010,  2021,  2091,\n",
      "         15950, 16360, 14774,  3372,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2573,  2524,  2000,  5323,  8352,  3494,  1010,  2021,  2059,\n",
      "          2038,  2498,  4840,  2030,  3391,  5875,  2000,  2360,  2055,  2068,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2834, 0.7166],\n",
      "        [0.2657, 0.7343]]), 'input_ids': tensor([[  101,  2025,  2069,  4895, 11263, 10695,  2100,  1010,  2021,  2091,\n",
      "         15950, 16360, 14774,  3372,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2573,  2524,  2000,  5323,  8352,  3494,  1010,  2021,  2059,\n",
      "          2038,  2498,  4840,  2030,  3391,  5875,  2000,  2360,  2055,  2068,\n",
      "          1012,   102]]), 'ntok': tensor([16, 22]), 'cls_emb': tensor([[-0.3694,  0.0873, -0.2684,  ..., -0.1385,  0.2809,  0.4483],\n",
      "        [-0.4084,  0.0628, -0.4246,  ..., -0.3472,  0.4945,  0.2618]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2074,  2028,  2919,  2801,  2044,  2178,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  4332,  2061,  4895, 29278,  5856,  3567,\n",
      "          6321, 13012,  2618,  1999,  2049,  2197,  2184,  2781,  2008,  3087,\n",
      "          2302,  1037, 13313,  4086, 11868,  2097,  3497,  2175,  2046,  5699,\n",
      "          5213,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2074,  2028,  2919,  2801,  2044,  2178,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  4332,  2061,  4895, 29278,  5856,  3567,\n",
      "          6321, 13012,  2618,  1999,  2049,  2197,  2184,  2781,  2008,  3087,\n",
      "          2302,  1037, 13313,  4086, 11868,  2097,  3497,  2175,  2046,  5699,\n",
      "          5213,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2675, 0.7325],\n",
      "        [0.2638, 0.7362]]), 'input_ids': tensor([[  101,  2074,  2028,  2919,  2801,  2044,  2178,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  4332,  2061,  4895, 29278,  5856,  3567,\n",
      "          6321, 13012,  2618,  1999,  2049,  2197,  2184,  2781,  2008,  3087,\n",
      "          2302,  1037, 13313,  4086, 11868,  2097,  3497,  2175,  2046,  5699,\n",
      "          5213,  1012,   102]]), 'ntok': tensor([ 9, 33]), 'cls_emb': tensor([[-0.0197,  0.0390, -0.2943,  ..., -0.1193,  0.2397,  0.3877],\n",
      "        [ 0.3851, -0.0201,  0.3997,  ..., -0.2326,  0.4258,  0.2779]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2010,  4038, 10345,  2024,  2411, 28425,  2098,  2030,  2074,\n",
      "          5810, 13587,  1010, 10174,  2000, 27895,  7135,  7239,  1010,  2302,\n",
      "          2206,  2039,  2006,  1037,  6748,  2504,  1012,   102,     0,     0],\n",
      "        [  101,  1006,  1050, 29667,  2015,  1007,  2856,  1996,  2754,  2544,\n",
      "          1997,  3449,  2989,  1010,  1998,  4152,  2986,  4616,  2013,  2010,\n",
      "          2048,  5260,  2040,  7940,  1996,  3494,  2006,  2754,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2010,  4038, 10345,  2024,  2411, 28425,  2098,  2030,  2074,\n",
      "          5810, 13587,  1010, 10174,  2000, 27895,  7135,  7239,  1010,  2302,\n",
      "          2206,  2039,  2006,  1037,  6748,  2504,  1012,   102,     0,     0],\n",
      "        [  101,  1006,  1050, 29667,  2015,  1007,  2856,  1996,  2754,  2544,\n",
      "          1997,  3449,  2989,  1010,  1998,  4152,  2986,  4616,  2013,  2010,\n",
      "          2048,  5260,  2040,  7940,  1996,  3494,  2006,  2754,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2462, 0.7538],\n",
      "        [0.2682, 0.7318]]), 'input_ids': tensor([[  101,  2010,  4038, 10345,  2024,  2411, 28425,  2098,  2030,  2074,\n",
      "          5810, 13587,  1010, 10174,  2000, 27895,  7135,  7239,  1010,  2302,\n",
      "          2206,  2039,  2006,  1037,  6748,  2504,  1012,   102,     0,     0],\n",
      "        [  101,  1006,  1050, 29667,  2015,  1007,  2856,  1996,  2754,  2544,\n",
      "          1997,  3449,  2989,  1010,  1998,  4152,  2986,  4616,  2013,  2010,\n",
      "          2048,  5260,  2040,  7940,  1996,  3494,  2006,  2754,  1012,   102]]), 'ntok': tensor([28, 30]), 'cls_emb': tensor([[-0.1928,  0.3805, -0.4117,  ..., -0.1810,  0.5917,  0.6523],\n",
      "        [-0.6262,  0.5416, -0.2122,  ..., -0.3613,  0.5609,  0.1221]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 25430, 11823, 24204,  2989,  6925,  1997,  2293,  1010,\n",
      "         14583,  1010,  7195,  1998,  2682,  2035,  1010,  4752,  1012,   102],\n",
      "        [  101,  2005,  3185, 10205,  2004,  2092,  2004,  3850, 10205,  1010,\n",
      "          2000, 15782,  2003,  1037,  2613,  7438,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 25430, 11823, 24204,  2989,  6925,  1997,  2293,  1010,\n",
      "         14583,  1010,  7195,  1998,  2682,  2035,  1010,  4752,  1012,   102],\n",
      "        [  101,  2005,  3185, 10205,  2004,  2092,  2004,  3850, 10205,  1010,\n",
      "          2000, 15782,  2003,  1037,  2613,  7438,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2855, 0.7145],\n",
      "        [0.2328, 0.7672]]), 'input_ids': tensor([[  101,  1037, 25430, 11823, 24204,  2989,  6925,  1997,  2293,  1010,\n",
      "         14583,  1010,  7195,  1998,  2682,  2035,  1010,  4752,  1012,   102],\n",
      "        [  101,  2005,  3185, 10205,  2004,  2092,  2004,  3850, 10205,  1010,\n",
      "          2000, 15782,  2003,  1037,  2613,  7438,  1012,   102,     0,     0]]), 'ntok': tensor([20, 18]), 'cls_emb': tensor([[-0.1795, -0.0496, -0.2281,  ..., -0.2672,  0.2686,  0.4474],\n",
      "        [-0.0419, -0.2708,  0.0373,  ..., -0.3096,  0.4679,  0.3737]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2143,  2003,  4251,  1010,  8701,  1998,  4895, 29278,\n",
      "         18150, 10880,  1012,   102],\n",
      "        [  101,  2045,  2003,  2053,  5165,  1999,  3666,  1037,  2775,  9015,\n",
      "          1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2143,  2003,  4251,  1010,  8701,  1998,  4895, 29278,\n",
      "         18150, 10880,  1012,   102],\n",
      "        [  101,  2045,  2003,  2053,  5165,  1999,  3666,  1037,  2775,  9015,\n",
      "          1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2705, 0.7295],\n",
      "        [0.2524, 0.7476]]), 'input_ids': tensor([[  101,  1996,  2143,  2003,  4251,  1010,  8701,  1998,  4895, 29278,\n",
      "         18150, 10880,  1012,   102],\n",
      "        [  101,  2045,  2003,  2053,  5165,  1999,  3666,  1037,  2775,  9015,\n",
      "          1012,   102,     0,     0]]), 'ntok': tensor([14, 12]), 'cls_emb': tensor([[ 0.1282,  0.2119, -0.0103,  ..., -0.4316,  0.2658,  0.5173],\n",
      "        [-0.0099,  0.2391, -0.4856,  ..., -0.0766,  0.2880,  0.6229]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4463,  1060,  2003, 13567,  3424,  1011, 11534,  2937,  1024,\n",
      "          3157, 25815,  1998,  4278,  2086,  2101,  1010,  1996, 13496,  2024,\n",
      "          3904,  1996,  7968,  2099,  1998,  4463,  2145,  8563,  2006,  8285,\n",
      "          1011,  4405,  1012,   102],\n",
      "        [  101, 11065,  5765,  2004, 20781,  2015,  2000, 21699,  2882,  2474,\n",
      "         19170,  4890,  2021,  4832,  7979,  1997,  2498,  2062,  2084, 11612,\n",
      "         11933,  1997,  2115,  2051,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4463,  1060,  2003, 13567,  3424,  1011, 11534,  2937,  1024,\n",
      "          3157, 25815,  1998,  4278,  2086,  2101,  1010,  1996, 13496,  2024,\n",
      "          3904,  1996,  7968,  2099,  1998,  4463,  2145,  8563,  2006,  8285,\n",
      "          1011,  4405,  1012,   102],\n",
      "        [  101, 11065,  5765,  2004, 20781,  2015,  2000, 21699,  2882,  2474,\n",
      "         19170,  4890,  2021,  4832,  7979,  1997,  2498,  2062,  2084, 11612,\n",
      "         11933,  1997,  2115,  2051,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2637, 0.7363],\n",
      "        [0.2465, 0.7535]]), 'input_ids': tensor([[  101,  4463,  1060,  2003, 13567,  3424,  1011, 11534,  2937,  1024,\n",
      "          3157, 25815,  1998,  4278,  2086,  2101,  1010,  1996, 13496,  2024,\n",
      "          3904,  1996,  7968,  2099,  1998,  4463,  2145,  8563,  2006,  8285,\n",
      "          1011,  4405,  1012,   102],\n",
      "        [  101, 11065,  5765,  2004, 20781,  2015,  2000, 21699,  2882,  2474,\n",
      "         19170,  4890,  2021,  4832,  7979,  1997,  2498,  2062,  2084, 11612,\n",
      "         11933,  1997,  2115,  2051,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 26]), 'cls_emb': tensor([[-0.5109, -0.1540, -0.0612,  ..., -0.2058,  1.1708,  0.2880],\n",
      "        [-0.1733,  0.1023, -0.2169,  ..., -0.2638,  0.5557,  0.2905]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1006,  1040,  1007,  1051,  2229,  1050,  1005,  1056,  8572,\n",
      "          2108,  2004, 18856,  6977,  2075,  2030, 25250,  2100,  2004,  5662,\n",
      "         11295,  3017,  5691,  1011,  1011,  2672,  1996, 16587,  2113,  2008,\n",
      "          1996,  3497,  4378,  2097,  2525,  2022,  2426,  1996, 11633,  1012,\n",
      "           102],\n",
      "        [  101, 14962,  2055,  5020,  8310,  1997, 15743,  2618,  1010,  6896,\n",
      "          1998,  5848,  1010,  4218,  8044, 21009, 12411,  2004,  1037, 12127,\n",
      "          1997,  6196,  4022,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1006,  1040,  1007,  1051,  2229,  1050,  1005,  1056,  8572,\n",
      "          2108,  2004, 18856,  6977,  2075,  2030, 25250,  2100,  2004,  5662,\n",
      "         11295,  3017,  5691,  1011,  1011,  2672,  1996, 16587,  2113,  2008,\n",
      "          1996,  3497,  4378,  2097,  2525,  2022,  2426,  1996, 11633,  1012,\n",
      "           102],\n",
      "        [  101, 14962,  2055,  5020,  8310,  1997, 15743,  2618,  1010,  6896,\n",
      "          1998,  5848,  1010,  4218,  8044, 21009, 12411,  2004,  1037, 12127,\n",
      "          1997,  6196,  4022,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2542, 0.7458],\n",
      "        [0.2495, 0.7505]]), 'input_ids': tensor([[  101,  1006,  1040,  1007,  1051,  2229,  1050,  1005,  1056,  8572,\n",
      "          2108,  2004, 18856,  6977,  2075,  2030, 25250,  2100,  2004,  5662,\n",
      "         11295,  3017,  5691,  1011,  1011,  2672,  1996, 16587,  2113,  2008,\n",
      "          1996,  3497,  4378,  2097,  2525,  2022,  2426,  1996, 11633,  1012,\n",
      "           102],\n",
      "        [  101, 14962,  2055,  5020,  8310,  1997, 15743,  2618,  1010,  6896,\n",
      "          1998,  5848,  1010,  4218,  8044, 21009, 12411,  2004,  1037, 12127,\n",
      "          1997,  6196,  4022,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([41, 25]), 'cls_emb': tensor([[ 0.3615,  0.0428,  0.2701,  ..., -0.2545,  0.6317,  0.6040],\n",
      "        [-0.1727,  0.0304, -0.7478,  ..., -0.1507,  0.5623,  0.1225]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1036,  4089,  2026,  3601,  2005,  2028,  1997,  1996,  2095,\n",
      "          1005,  1055,  2190,  3152,  1012,  1005,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2200,  2146,  3185,  1010, 10634,  1999, 14082,  1010,\n",
      "          2007,  4498,  2205,  2172,  3579,  2006,  7954,  7547,  1998,  1045,\n",
      "         23296,  9541,  2810,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1036,  4089,  2026,  3601,  2005,  2028,  1997,  1996,  2095,\n",
      "          1005,  1055,  2190,  3152,  1012,  1005,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2200,  2146,  3185,  1010, 10634,  1999, 14082,  1010,\n",
      "          2007,  4498,  2205,  2172,  3579,  2006,  7954,  7547,  1998,  1045,\n",
      "         23296,  9541,  2810,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2875, 0.7125],\n",
      "        [0.2711, 0.7289]]), 'input_ids': tensor([[  101,  1036,  4089,  2026,  3601,  2005,  2028,  1997,  1996,  2095,\n",
      "          1005,  1055,  2190,  3152,  1012,  1005,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2200,  2146,  3185,  1010, 10634,  1999, 14082,  1010,\n",
      "          2007,  4498,  2205,  2172,  3579,  2006,  7954,  7547,  1998,  1045,\n",
      "         23296,  9541,  2810,  1012,   102]]), 'ntok': tensor([17, 25]), 'cls_emb': tensor([[ 0.1777,  0.2768, -0.1869,  ..., -0.1670,  0.6309,  0.6993],\n",
      "        [-0.2367, -0.5262, -0.3138,  ..., -0.2457,  0.7518,  0.3819]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2004,  1037,  2034,  1011,  2051,  2472,  1010, 27765,  2038,\n",
      "         10410,  2242,  1999,  2370,  2004,  2019,  3364,  2008,  3640, 25737,\n",
      "          3723,  2007,  2049,  2601,  3969,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  6723,  4524,  1997, 11541,  2008,\n",
      "          2079,  1050,  1005,  1056,  5587,  2039,  2000,  1037,  2878,  2843,\n",
      "          1997,  3168,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2004,  1037,  2034,  1011,  2051,  2472,  1010, 27765,  2038,\n",
      "         10410,  2242,  1999,  2370,  2004,  2019,  3364,  2008,  3640, 25737,\n",
      "          3723,  2007,  2049,  2601,  3969,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  6723,  4524,  1997, 11541,  2008,\n",
      "          2079,  1050,  1005,  1056,  5587,  2039,  2000,  1037,  2878,  2843,\n",
      "          1997,  3168,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2421, 0.7579],\n",
      "        [0.2577, 0.7423]]), 'input_ids': tensor([[  101,  2004,  1037,  2034,  1011,  2051,  2472,  1010, 27765,  2038,\n",
      "         10410,  2242,  1999,  2370,  2004,  2019,  3364,  2008,  3640, 25737,\n",
      "          3723,  2007,  2049,  2601,  3969,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  6723,  4524,  1997, 11541,  2008,\n",
      "          2079,  1050,  1005,  1056,  5587,  2039,  2000,  1037,  2878,  2843,\n",
      "          1997,  3168,  1012,   102,     0,     0,     0]]), 'ntok': tensor([27, 24]), 'cls_emb': tensor([[-0.4157, -0.0419, -0.7823,  ..., -0.2489,  0.3660,  0.3358],\n",
      "        [ 0.2482,  0.0649, -0.2796,  ..., -0.1623,  0.4657,  0.3809]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2612,  1997,  6318,  9231, 10085, 23584,  2013,  4401,  1010,\n",
      "         18062, 17848,  2323,  2031,  5023,  2009,  2013,  3071,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 25927, 13663,  2271,  1998,  3653,  6528, 20771,  1010,  1996,\n",
      "          3635,  1997,  2300,  2003, 23263,  4159,  1010,  2445,  1996,  3082,\n",
      "          1011,  4375,  2791,  1997,  2009,  3689,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2612,  1997,  6318,  9231, 10085, 23584,  2013,  4401,  1010,\n",
      "         18062, 17848,  2323,  2031,  5023,  2009,  2013,  3071,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 25927, 13663,  2271,  1998,  3653,  6528, 20771,  1010,  1996,\n",
      "          3635,  1997,  2300,  2003, 23263,  4159,  1010,  2445,  1996,  3082,\n",
      "          1011,  4375,  2791,  1997,  2009,  3689,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2462, 0.7538],\n",
      "        [0.2718, 0.7282]]), 'input_ids': tensor([[  101,  2612,  1997,  6318,  9231, 10085, 23584,  2013,  4401,  1010,\n",
      "         18062, 17848,  2323,  2031,  5023,  2009,  2013,  3071,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 25927, 13663,  2271,  1998,  3653,  6528, 20771,  1010,  1996,\n",
      "          3635,  1997,  2300,  2003, 23263,  4159,  1010,  2445,  1996,  3082,\n",
      "          1011,  4375,  2791,  1997,  2009,  3689,  1012,   102]]), 'ntok': tensor([20, 28]), 'cls_emb': tensor([[-0.4715, -0.1454, -0.4902,  ..., -0.2353,  0.3171,  0.8278],\n",
      "        [-0.3859,  0.0086, -0.4085,  ..., -0.3681,  0.2803,  0.6815]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 10462,  1010,  2023,  2003,  3144,  2004,  1037,  2143,  1010,\n",
      "          2096,  2012,  1996,  2168,  2051,  2108,  1037,  2087,  7244, 28667,\n",
      "          5644, 18688,  3370,  1997,  1996,  5220, 17743,  1012,   102],\n",
      "        [  101,  2045,  2038,  2467,  2042,  2242,  5622,  2912,  3468,  2055,\n",
      "          1996, 13410,  2139,  6517,  2063,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 10462,  1010,  2023,  2003,  3144,  2004,  1037,  2143,  1010,\n",
      "          2096,  2012,  1996,  2168,  2051,  2108,  1037,  2087,  7244, 28667,\n",
      "          5644, 18688,  3370,  1997,  1996,  5220, 17743,  1012,   102],\n",
      "        [  101,  2045,  2038,  2467,  2042,  2242,  5622,  2912,  3468,  2055,\n",
      "          1996, 13410,  2139,  6517,  2063,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2506, 0.7494],\n",
      "        [0.2285, 0.7715]]), 'input_ids': tensor([[  101, 10462,  1010,  2023,  2003,  3144,  2004,  1037,  2143,  1010,\n",
      "          2096,  2012,  1996,  2168,  2051,  2108,  1037,  2087,  7244, 28667,\n",
      "          5644, 18688,  3370,  1997,  1996,  5220, 17743,  1012,   102],\n",
      "        [  101,  2045,  2038,  2467,  2042,  2242,  5622,  2912,  3468,  2055,\n",
      "          1996, 13410,  2139,  6517,  2063,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([29, 17]), 'cls_emb': tensor([[-0.4405,  0.1941, -0.4028,  ..., -0.3814,  0.3448,  0.5360],\n",
      "        [ 0.0674,  0.0270, -0.5694,  ..., -0.3523,  0.3821,  0.8902]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  8562,  2003,  3140,  1998,  3082,  1011,  4375,  1010,\n",
      "          1998,  5681,  3432, 16010,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2302,  2412,  3352,  2106, 28804,  1010,  2472,  5828, 12385,\n",
      "          6906,  6739,  2135, 25308,  2015,  2023,  9974,  2594,  2466,  1997,\n",
      "          4372, 27898,  6970, 16570, 10708, 19801,  1998,  3375, 16561,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  8562,  2003,  3140,  1998,  3082,  1011,  4375,  1010,\n",
      "          1998,  5681,  3432, 16010,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2302,  2412,  3352,  2106, 28804,  1010,  2472,  5828, 12385,\n",
      "          6906,  6739,  2135, 25308,  2015,  2023,  9974,  2594,  2466,  1997,\n",
      "          4372, 27898,  6970, 16570, 10708, 19801,  1998,  3375, 16561,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2540, 0.7460],\n",
      "        [0.2504, 0.7496]]), 'input_ids': tensor([[  101,  1996,  8562,  2003,  3140,  1998,  3082,  1011,  4375,  1010,\n",
      "          1998,  5681,  3432, 16010,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2302,  2412,  3352,  2106, 28804,  1010,  2472,  5828, 12385,\n",
      "          6906,  6739,  2135, 25308,  2015,  2023,  9974,  2594,  2466,  1997,\n",
      "          4372, 27898,  6970, 16570, 10708, 19801,  1998,  3375, 16561,  1012,\n",
      "           102]]), 'ntok': tensor([16, 31]), 'cls_emb': tensor([[-0.1807,  0.1457, -0.4633,  ..., -0.0085,  0.6270,  0.4524],\n",
      "        [-0.3154,  0.2256, -0.2381,  ..., -0.5566,  0.5066,  0.4558]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2112,  4576,  2083,  3666,  2023, 17266,  7507, 11467,  1010,\n",
      "         10957,  1011,  8288,  1011,  6910,  9530,  3597,  7542,  1010,  2017,\n",
      "          5382,  2008,  2009,  2003,  2081,  2039,  1997,  2093,  4178,  1997,\n",
      "          1037,  5837,  2694,  2265,  1012,   102],\n",
      "        [  101,  2005,  1996,  2087,  2112,  1010,  2009,  1005,  1055,  1037,\n",
      "          2147,  1997,  4297, 10497, 17302, 11067,  1010,  9602,  3154,  1997,\n",
      "          6181,  1011, 12181,  9597,  1998,  4248,  7300,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2112,  4576,  2083,  3666,  2023, 17266,  7507, 11467,  1010,\n",
      "         10957,  1011,  8288,  1011,  6910,  9530,  3597,  7542,  1010,  2017,\n",
      "          5382,  2008,  2009,  2003,  2081,  2039,  1997,  2093,  4178,  1997,\n",
      "          1037,  5837,  2694,  2265,  1012,   102],\n",
      "        [  101,  2005,  1996,  2087,  2112,  1010,  2009,  1005,  1055,  1037,\n",
      "          2147,  1997,  4297, 10497, 17302, 11067,  1010,  9602,  3154,  1997,\n",
      "          6181,  1011, 12181,  9597,  1998,  4248,  7300,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2440, 0.7560],\n",
      "        [0.2733, 0.7267]]), 'input_ids': tensor([[  101,  2112,  4576,  2083,  3666,  2023, 17266,  7507, 11467,  1010,\n",
      "         10957,  1011,  8288,  1011,  6910,  9530,  3597,  7542,  1010,  2017,\n",
      "          5382,  2008,  2009,  2003,  2081,  2039,  1997,  2093,  4178,  1997,\n",
      "          1037,  5837,  2694,  2265,  1012,   102],\n",
      "        [  101,  2005,  1996,  2087,  2112,  1010,  2009,  1005,  1055,  1037,\n",
      "          2147,  1997,  4297, 10497, 17302, 11067,  1010,  9602,  3154,  1997,\n",
      "          6181,  1011, 12181,  9597,  1998,  4248,  7300,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([36, 29]), 'cls_emb': tensor([[-0.0449, -0.0454, -0.0916,  ..., -0.1409,  0.5897,  0.6947],\n",
      "        [ 0.2182, -0.0129, -0.2257,  ...,  0.0943,  0.2415,  0.8867]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2569,  3896,  1998,  2116,  5019,  1997,  3635, 24913,\n",
      "          2298,  2004,  2204,  2030,  2488,  2084,  1999,  1996,  2434,  1010,\n",
      "          2096,  1996,  7436,  1011,  3045,  2614,  1998,  2508, 24084,  2099,\n",
      "          1005,  1055, 20996, 18161,  3556,  2191,  2204,  2224,  1997,  1996,\n",
      "          2002,  6199,  2100,  5746,  2291,  1012,   102],\n",
      "        [  101,  2025,  2144, 19343,  2288, 28842,  2038,  1037,  2350,  2713,\n",
      "          2042,  2061,  9145,  2000,  4133,  2083,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2569,  3896,  1998,  2116,  5019,  1997,  3635, 24913,\n",
      "          2298,  2004,  2204,  2030,  2488,  2084,  1999,  1996,  2434,  1010,\n",
      "          2096,  1996,  7436,  1011,  3045,  2614,  1998,  2508, 24084,  2099,\n",
      "          1005,  1055, 20996, 18161,  3556,  2191,  2204,  2224,  1997,  1996,\n",
      "          2002,  6199,  2100,  5746,  2291,  1012,   102],\n",
      "        [  101,  2025,  2144, 19343,  2288, 28842,  2038,  1037,  2350,  2713,\n",
      "          2042,  2061,  9145,  2000,  4133,  2083,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2418, 0.7582],\n",
      "        [0.2423, 0.7577]]), 'input_ids': tensor([[  101,  1996,  2569,  3896,  1998,  2116,  5019,  1997,  3635, 24913,\n",
      "          2298,  2004,  2204,  2030,  2488,  2084,  1999,  1996,  2434,  1010,\n",
      "          2096,  1996,  7436,  1011,  3045,  2614,  1998,  2508, 24084,  2099,\n",
      "          1005,  1055, 20996, 18161,  3556,  2191,  2204,  2224,  1997,  1996,\n",
      "          2002,  6199,  2100,  5746,  2291,  1012,   102],\n",
      "        [  101,  2025,  2144, 19343,  2288, 28842,  2038,  1037,  2350,  2713,\n",
      "          2042,  2061,  9145,  2000,  4133,  2083,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([47, 18]), 'cls_emb': tensor([[-0.4088, -0.0606, -0.2853,  ..., -0.4371,  0.8397,  0.3195],\n",
      "        [-0.0029,  0.0434, -0.2688,  ..., -0.1245, -0.0018,  0.2341]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185,  2003,  2054,  6433,  2043,  2017,  6271,  2039,\n",
      "          2235, 14629,  2000,  2184,  2335,  2037,  3019,  2946,  1010,  1998,\n",
      "          2009,  9932,  1050,  1005,  1056,  3492,  1012,   102],\n",
      "        [  101,  2057,  2031,  1050,  1005,  1056,  2464,  2107,  7632,  8017,\n",
      "          3012,  2144,  2360,  2009,  2003,  1050,  1005,  1056,  2061,   999,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185,  2003,  2054,  6433,  2043,  2017,  6271,  2039,\n",
      "          2235, 14629,  2000,  2184,  2335,  2037,  3019,  2946,  1010,  1998,\n",
      "          2009,  9932,  1050,  1005,  1056,  3492,  1012,   102],\n",
      "        [  101,  2057,  2031,  1050,  1005,  1056,  2464,  2107,  7632,  8017,\n",
      "          3012,  2144,  2360,  2009,  2003,  1050,  1005,  1056,  2061,   999,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2618, 0.7382],\n",
      "        [0.2617, 0.7383]]), 'input_ids': tensor([[  101,  1996,  3185,  2003,  2054,  6433,  2043,  2017,  6271,  2039,\n",
      "          2235, 14629,  2000,  2184,  2335,  2037,  3019,  2946,  1010,  1998,\n",
      "          2009,  9932,  1050,  1005,  1056,  3492,  1012,   102],\n",
      "        [  101,  2057,  2031,  1050,  1005,  1056,  2464,  2107,  7632,  8017,\n",
      "          3012,  2144,  2360,  2009,  2003,  1050,  1005,  1056,  2061,   999,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([28, 21]), 'cls_emb': tensor([[ 0.0977, -0.0494,  0.1278,  ..., -0.2183,  0.6546,  0.5985],\n",
      "        [ 0.2973,  0.2641,  0.0090,  ...,  0.0289,  0.2291,  0.6103]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2000,  2655,  1996,  2060,  2217,  1997,  6014,  1036,  1036,\n",
      "         10439,  8095,  2075,  1005,  1005,  2052,  2022,  2000,  2104,  4355,\n",
      "         21499,  2074,  2129,  4795,  4024,  2015,  2066,  2009,  2064,  2022,\n",
      "          1012,   102],\n",
      "        [  101,  2498,  2003,  6730,  1999,  2023,  9535,  1011, 18396,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2000,  2655,  1996,  2060,  2217,  1997,  6014,  1036,  1036,\n",
      "         10439,  8095,  2075,  1005,  1005,  2052,  2022,  2000,  2104,  4355,\n",
      "         21499,  2074,  2129,  4795,  4024,  2015,  2066,  2009,  2064,  2022,\n",
      "          1012,   102],\n",
      "        [  101,  2498,  2003,  6730,  1999,  2023,  9535,  1011, 18396,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2432, 0.7568],\n",
      "        [0.2741, 0.7259]]), 'input_ids': tensor([[  101,  2000,  2655,  1996,  2060,  2217,  1997,  6014,  1036,  1036,\n",
      "         10439,  8095,  2075,  1005,  1005,  2052,  2022,  2000,  2104,  4355,\n",
      "         21499,  2074,  2129,  4795,  4024,  2015,  2066,  2009,  2064,  2022,\n",
      "          1012,   102],\n",
      "        [  101,  2498,  2003,  6730,  1999,  2023,  9535,  1011, 18396,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 11]), 'cls_emb': tensor([[ 0.3371,  0.3726, -0.3623,  ..., -0.1962,  0.3108,  0.6603],\n",
      "        [ 0.0106,  0.2020, -0.1257,  ..., -0.1890,  0.1858,  0.5989]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  5683,  5292, 21890, 26154,  1010,  2004,  2065,  1996,  4898,\n",
      "         20706,  2245,  2027,  2071,  6162,  2019,  2250,  1997, 15762, 11867,\n",
      "         12162,  7231,  3012,  2011,  3432, 15021,  1999,  7167,  1997,  3494,\n",
      "          2725, 10021,  4933,  1998, 18385,  1996,  8962,  1012,   102],\n",
      "        [  101,  5363,  2000,  5587,  2070, 17688,  2000,  2049, 21864, 15952,\n",
      "         23541,  2021,  1996,  5510,  2003,  2035,  2205,  5220,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  5683,  5292, 21890, 26154,  1010,  2004,  2065,  1996,  4898,\n",
      "         20706,  2245,  2027,  2071,  6162,  2019,  2250,  1997, 15762, 11867,\n",
      "         12162,  7231,  3012,  2011,  3432, 15021,  1999,  7167,  1997,  3494,\n",
      "          2725, 10021,  4933,  1998, 18385,  1996,  8962,  1012,   102],\n",
      "        [  101,  5363,  2000,  5587,  2070, 17688,  2000,  2049, 21864, 15952,\n",
      "         23541,  2021,  1996,  5510,  2003,  2035,  2205,  5220,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2622, 0.7378],\n",
      "        [0.2444, 0.7556]]), 'input_ids': tensor([[  101,  5683,  5292, 21890, 26154,  1010,  2004,  2065,  1996,  4898,\n",
      "         20706,  2245,  2027,  2071,  6162,  2019,  2250,  1997, 15762, 11867,\n",
      "         12162,  7231,  3012,  2011,  3432, 15021,  1999,  7167,  1997,  3494,\n",
      "          2725, 10021,  4933,  1998, 18385,  1996,  8962,  1012,   102],\n",
      "        [  101,  5363,  2000,  5587,  2070, 17688,  2000,  2049, 21864, 15952,\n",
      "         23541,  2021,  1996,  5510,  2003,  2035,  2205,  5220,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([39, 20]), 'cls_emb': tensor([[-0.0325, -0.0777, -0.1502,  ..., -0.5410,  0.6163,  0.3426],\n",
      "        [-0.2657,  0.1732,  0.1483,  ..., -0.4150,  0.2763,  0.3465]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2012,  2049,  5409,  1010,  2009, 17727,  4135,  6155,  1999,\n",
      "          1037,  2186,  1997,  2200,  2919,  2569,  3896,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2007,  7371,  4114,  8122,  1010,  3365, 28945,  1998,  1037,\n",
      "          5377,  3341,  1997,  6980,  1010,  4679,  1005,  1055,  2143,  2003,\n",
      "          2028,  1997,  2526,  1005,  1055,  5994,  2135,  4639, 20096,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2012,  2049,  5409,  1010,  2009, 17727,  4135,  6155,  1999,\n",
      "          1037,  2186,  1997,  2200,  2919,  2569,  3896,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2007,  7371,  4114,  8122,  1010,  3365, 28945,  1998,  1037,\n",
      "          5377,  3341,  1997,  6980,  1010,  4679,  1005,  1055,  2143,  2003,\n",
      "          2028,  1997,  2526,  1005,  1055,  5994,  2135,  4639, 20096,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2574, 0.7426],\n",
      "        [0.2755, 0.7245]]), 'input_ids': tensor([[  101,  2012,  2049,  5409,  1010,  2009, 17727,  4135,  6155,  1999,\n",
      "          1037,  2186,  1997,  2200,  2919,  2569,  3896,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2007,  7371,  4114,  8122,  1010,  3365, 28945,  1998,  1037,\n",
      "          5377,  3341,  1997,  6980,  1010,  4679,  1005,  1055,  2143,  2003,\n",
      "          2028,  1997,  2526,  1005,  1055,  5994,  2135,  4639, 20096,  1012,\n",
      "           102]]), 'ntok': tensor([19, 31]), 'cls_emb': tensor([[ 0.0511,  0.1072,  0.0749,  ...,  0.0177,  0.2611,  0.5284],\n",
      "        [-0.2860, -0.1995, -0.4047,  ..., -0.2877,  0.5462,  0.5913]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2307,  7241,  3459,  6187,  1050,  1005,  1056,  6336,\n",
      "          2023,  2540, 26675,  6960,  2041,  1997,  1996,  5220,  1012,   102],\n",
      "        [  101,  1037,  4010,  2021, 12689, 13804,  2006,  6860,  1010,  2155,\n",
      "          1998, 12242,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2307,  7241,  3459,  6187,  1050,  1005,  1056,  6336,\n",
      "          2023,  2540, 26675,  6960,  2041,  1997,  1996,  5220,  1012,   102],\n",
      "        [  101,  1037,  4010,  2021, 12689, 13804,  2006,  6860,  1010,  2155,\n",
      "          1998, 12242,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2701, 0.7299],\n",
      "        [0.2773, 0.7227]]), 'input_ids': tensor([[  101,  1037,  2307,  7241,  3459,  6187,  1050,  1005,  1056,  6336,\n",
      "          2023,  2540, 26675,  6960,  2041,  1997,  1996,  5220,  1012,   102],\n",
      "        [  101,  1037,  4010,  2021, 12689, 13804,  2006,  6860,  1010,  2155,\n",
      "          1998, 12242,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([20, 14]), 'cls_emb': tensor([[-0.1217, -0.1586,  0.0921,  ..., -0.4681,  0.1789,  0.3272],\n",
      "        [-0.8243, -0.2254, -0.3614,  ..., -0.3095,  0.1758,  0.6056]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2012,  2335,  1010,  1996, 23873,  2003, 14412,  4502,  3468,\n",
      "          1010,  2021,  2011,  1996,  2203,  2045,  1005,  1055,  1037,  3168,\n",
      "          2008,  1996, 13675,  5602,  1997,  1996,  6547, 25484,  2006,  1037,\n",
      "          4087,  3012,  2008, 18859, 13675,  2098, 15859,  3723,  1998,  3727,\n",
      "          1996, 13972, 11171,  2011,  1996,  5949,  1997,  4022,  1012,   102],\n",
      "        [  101,  2096,  1996,  6319,  4763,  2399,  2089,  2031,  2275,  2047,\n",
      "          4781,  2005, 16959,  2015,  1010, 23873,  1010,  1998, 13638,  2005,\n",
      "          2678,  2399,  1010,  1996,  3185,  2428,  2069, 21645,  1999,  1996,\n",
      "          2353,  1997,  2122,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2012,  2335,  1010,  1996, 23873,  2003, 14412,  4502,  3468,\n",
      "          1010,  2021,  2011,  1996,  2203,  2045,  1005,  1055,  1037,  3168,\n",
      "          2008,  1996, 13675,  5602,  1997,  1996,  6547, 25484,  2006,  1037,\n",
      "          4087,  3012,  2008, 18859, 13675,  2098, 15859,  3723,  1998,  3727,\n",
      "          1996, 13972, 11171,  2011,  1996,  5949,  1997,  4022,  1012,   102],\n",
      "        [  101,  2096,  1996,  6319,  4763,  2399,  2089,  2031,  2275,  2047,\n",
      "          4781,  2005, 16959,  2015,  1010, 23873,  1010,  1998, 13638,  2005,\n",
      "          2678,  2399,  1010,  1996,  3185,  2428,  2069, 21645,  1999,  1996,\n",
      "          2353,  1997,  2122,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2401, 0.7599],\n",
      "        [0.2455, 0.7545]]), 'input_ids': tensor([[  101,  2012,  2335,  1010,  1996, 23873,  2003, 14412,  4502,  3468,\n",
      "          1010,  2021,  2011,  1996,  2203,  2045,  1005,  1055,  1037,  3168,\n",
      "          2008,  1996, 13675,  5602,  1997,  1996,  6547, 25484,  2006,  1037,\n",
      "          4087,  3012,  2008, 18859, 13675,  2098, 15859,  3723,  1998,  3727,\n",
      "          1996, 13972, 11171,  2011,  1996,  5949,  1997,  4022,  1012,   102],\n",
      "        [  101,  2096,  1996,  6319,  4763,  2399,  2089,  2031,  2275,  2047,\n",
      "          4781,  2005, 16959,  2015,  1010, 23873,  1010,  1998, 13638,  2005,\n",
      "          2678,  2399,  1010,  1996,  3185,  2428,  2069, 21645,  1999,  1996,\n",
      "          2353,  1997,  2122,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([50, 35]), 'cls_emb': tensor([[ 0.1138,  0.0709, -0.2178,  ..., -0.2243,  0.3274,  0.6586],\n",
      "        [ 0.0718, -0.0377,  0.0256,  ..., -0.0890,  0.4671,  0.5609]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17431,  5024,  1998, 28797, 17251,\n",
      "          2778,  2139,  2486,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2472,  4080, 27969, 25778,  1012,  1012,  1012, 16691,  1037,\n",
      "         24639,  4824,  1997,  1996, 21864, 19987,  1997,  4476,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17431,  5024,  1998, 28797, 17251,\n",
      "          2778,  2139,  2486,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2472,  4080, 27969, 25778,  1012,  1012,  1012, 16691,  1037,\n",
      "         24639,  4824,  1997,  1996, 21864, 19987,  1997,  4476,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2640, 0.7360],\n",
      "        [0.2502, 0.7498]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17431,  5024,  1998, 28797, 17251,\n",
      "          2778,  2139,  2486,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2472,  4080, 27969, 25778,  1012,  1012,  1012, 16691,  1037,\n",
      "         24639,  4824,  1997,  1996, 21864, 19987,  1997,  4476,  1012,   102]]), 'ntok': tensor([15, 20]), 'cls_emb': tensor([[ 0.2218,  0.2918, -0.2065,  ..., -0.1049,  0.2212,  0.6502],\n",
      "        [-0.1516,  0.4679, -0.1533,  ..., -0.2185,  0.5492,  0.4952]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2043,  4190, 10179, 20722,  2080,  2633, 13354,  5999,  2019,\n",
      "         29348,  2839,  2397,  1999,  1996,  3185,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101,  1996,  3211,  5104,  2097,  2763,  2994, 11770,  2012,  1996,\n",
      "         10556, 23057, 12269, 16186,  1997,  2502,  1010, 14231,  3494,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2043,  4190, 10179, 20722,  2080,  2633, 13354,  5999,  2019,\n",
      "         29348,  2839,  2397,  1999,  1996,  3185,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101,  1996,  3211,  5104,  2097,  2763,  2994, 11770,  2012,  1996,\n",
      "         10556, 23057, 12269, 16186,  1997,  2502,  1010, 14231,  3494,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2958, 0.7042],\n",
      "        [0.2740, 0.7260]]), 'input_ids': tensor([[  101,  2043,  4190, 10179, 20722,  2080,  2633, 13354,  5999,  2019,\n",
      "         29348,  2839,  2397,  1999,  1996,  3185,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101,  1996,  3211,  5104,  2097,  2763,  2994, 11770,  2012,  1996,\n",
      "         10556, 23057, 12269, 16186,  1997,  2502,  1010, 14231,  3494,  1012,\n",
      "           102]]), 'ntok': tensor([18, 21]), 'cls_emb': tensor([[-0.3142, -0.3376, -0.2975,  ..., -0.1567,  0.5824,  0.5239],\n",
      "        [ 0.2929,  0.0636,  0.4192,  ..., -0.2032,  0.3281,  0.4869]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4717,  7416,  2003, 13310,  8462,  2135,  6542,  1998,  2146,\n",
      "          1011,  3612,  2098,  1010,  2004,  2065,  8206,  3012,  2993,  5393,\n",
      "         11268,  8630,  3012,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  3248,  2066,  8307, 11867, 13231,  2094,\n",
      "          6721,  5312,  1997,  1037,  3782,  2600,  9410,  2046,  2054,  2003,\n",
      "          4728,  1037, 18856, 17322,  1011, 21834,  2094,  2021,  2969,  1011,\n",
      "          3809,  8645, 10874,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4717,  7416,  2003, 13310,  8462,  2135,  6542,  1998,  2146,\n",
      "          1011,  3612,  2098,  1010,  2004,  2065,  8206,  3012,  2993,  5393,\n",
      "         11268,  8630,  3012,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  3248,  2066,  8307, 11867, 13231,  2094,\n",
      "          6721,  5312,  1997,  1037,  3782,  2600,  9410,  2046,  2054,  2003,\n",
      "          4728,  1037, 18856, 17322,  1011, 21834,  2094,  2021,  2969,  1011,\n",
      "          3809,  8645, 10874,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2412, 0.7588],\n",
      "        [0.2709, 0.7291]]), 'input_ids': tensor([[  101,  4717,  7416,  2003, 13310,  8462,  2135,  6542,  1998,  2146,\n",
      "          1011,  3612,  2098,  1010,  2004,  2065,  8206,  3012,  2993,  5393,\n",
      "         11268,  8630,  3012,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  3248,  2066,  8307, 11867, 13231,  2094,\n",
      "          6721,  5312,  1997,  1037,  3782,  2600,  9410,  2046,  2054,  2003,\n",
      "          4728,  1037, 18856, 17322,  1011, 21834,  2094,  2021,  2969,  1011,\n",
      "          3809,  8645, 10874,  1012,   102]]), 'ntok': tensor([25, 35]), 'cls_emb': tensor([[-0.3346,  0.1523, -0.6358,  ..., -0.2147,  0.6591,  0.4457],\n",
      "        [ 0.2138, -0.2108, -0.2690,  ..., -0.1769,  0.7131,  0.6760]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019,  2058,  6633, 21890,  4588,  1010,  2052,  1011,  2022,\n",
      "         11333, 17413,  1010,  4821,  6945,  6313,  3348,  2521,  3401,  1012,\n",
      "           102],\n",
      "        [  101,  2009,  2035,  9909,  2039,  2000,  2204,  4569,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019,  2058,  6633, 21890,  4588,  1010,  2052,  1011,  2022,\n",
      "         11333, 17413,  1010,  4821,  6945,  6313,  3348,  2521,  3401,  1012,\n",
      "           102],\n",
      "        [  101,  2009,  2035,  9909,  2039,  2000,  2204,  4569,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2612, 0.7388],\n",
      "        [0.2387, 0.7613]]), 'input_ids': tensor([[  101,  2019,  2058,  6633, 21890,  4588,  1010,  2052,  1011,  2022,\n",
      "         11333, 17413,  1010,  4821,  6945,  6313,  3348,  2521,  3401,  1012,\n",
      "           102],\n",
      "        [  101,  2009,  2035,  9909,  2039,  2000,  2204,  4569,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([21, 10]), 'cls_emb': tensor([[-0.4623,  0.0014, -0.4740,  ..., -0.3695,  0.5415,  0.1417],\n",
      "        [ 0.4118,  0.1759,  0.2754,  ..., -0.3346, -0.0390,  0.3625]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3251,  3213,  1011,  2472,  4776, 25749,  1005,  1055,  2143,\n",
      "          2003,  1037,  5745,  2466,  1010,  2019,  4070,  1997,  1037,  6091,\n",
      "         12554,  1010,  1037,  4440,  2091,  3638,  4644,  1010,  2035,  2093,\n",
      "          2030,  3904,  1997,  1996,  2682,  1010,  2009,  2003,  2004, 23182,\n",
      "          2004,  2009,  2003, 20161,  1012,   102],\n",
      "        [  101,  2178,  1999,  1011,  2115,  1011,  2227,  2813,  5004,  1999,\n",
      "          1996,  2896, 11143,  2081,  2011,  2111,  2040,  2031,  2196,  7042,\n",
      "          2216,  5132,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3251,  3213,  1011,  2472,  4776, 25749,  1005,  1055,  2143,\n",
      "          2003,  1037,  5745,  2466,  1010,  2019,  4070,  1997,  1037,  6091,\n",
      "         12554,  1010,  1037,  4440,  2091,  3638,  4644,  1010,  2035,  2093,\n",
      "          2030,  3904,  1997,  1996,  2682,  1010,  2009,  2003,  2004, 23182,\n",
      "          2004,  2009,  2003, 20161,  1012,   102],\n",
      "        [  101,  2178,  1999,  1011,  2115,  1011,  2227,  2813,  5004,  1999,\n",
      "          1996,  2896, 11143,  2081,  2011,  2111,  2040,  2031,  2196,  7042,\n",
      "          2216,  5132,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2446, 0.7554],\n",
      "        [0.2861, 0.7139]]), 'input_ids': tensor([[  101,  3251,  3213,  1011,  2472,  4776, 25749,  1005,  1055,  2143,\n",
      "          2003,  1037,  5745,  2466,  1010,  2019,  4070,  1997,  1037,  6091,\n",
      "         12554,  1010,  1037,  4440,  2091,  3638,  4644,  1010,  2035,  2093,\n",
      "          2030,  3904,  1997,  1996,  2682,  1010,  2009,  2003,  2004, 23182,\n",
      "          2004,  2009,  2003, 20161,  1012,   102],\n",
      "        [  101,  2178,  1999,  1011,  2115,  1011,  2227,  2813,  5004,  1999,\n",
      "          1996,  2896, 11143,  2081,  2011,  2111,  2040,  2031,  2196,  7042,\n",
      "          2216,  5132,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([46, 24]), 'cls_emb': tensor([[-0.0601, -0.0165, -0.3524,  ..., -0.2800,  0.3801,  0.8643],\n",
      "        [-0.2296, -0.0701, -0.0563,  ..., -0.2449,  0.2246,  0.5247]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2200,  2092,  1011,  2081,  1010,  6057,  1998, 14036,\n",
      "          3861,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  4276,  3773,  2074,  2006,  1996,  3978,\n",
      "          1997,  1996,  9866,  1010,  1998,  2012,  2335,  1010,  1996, 19828,\n",
      "         27451,  1010,  1997,  1996,  2336,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2200,  2092,  1011,  2081,  1010,  6057,  1998, 14036,\n",
      "          3861,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  4276,  3773,  2074,  2006,  1996,  3978,\n",
      "          1997,  1996,  9866,  1010,  1998,  2012,  2335,  1010,  1996, 19828,\n",
      "         27451,  1010,  1997,  1996,  2336,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2591, 0.7409],\n",
      "        [0.2441, 0.7559]]), 'input_ids': tensor([[  101,  1037,  2200,  2092,  1011,  2081,  1010,  6057,  1998, 14036,\n",
      "          3861,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  4276,  3773,  2074,  2006,  1996,  3978,\n",
      "          1997,  1996,  9866,  1010,  1998,  2012,  2335,  1010,  1996, 19828,\n",
      "         27451,  1010,  1997,  1996,  2336,  1012,   102]]), 'ntok': tensor([13, 27]), 'cls_emb': tensor([[-0.6650, -0.3201, -0.1288,  ..., -0.5108,  0.1366,  0.4798],\n",
      "        [ 0.2475,  0.1824, -0.2684,  ..., -0.3642,  0.2865,  0.5561]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2750,  2049,  2516,  1010,  8595,  1011,  7144,  2293,  2003,\n",
      "          2196,  3082,  1011,  4375,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2065,  2472,  2745, 23268,  3366,  2069, 23105,  2135, 19821,\n",
      "          2010,  3494,  1010,  2002,  2515,  1050,  1005,  1056,  2907,  2068,\n",
      "          1999, 17152,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2750,  2049,  2516,  1010,  8595,  1011,  7144,  2293,  2003,\n",
      "          2196,  3082,  1011,  4375,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2065,  2472,  2745, 23268,  3366,  2069, 23105,  2135, 19821,\n",
      "          2010,  3494,  1010,  2002,  2515,  1050,  1005,  1056,  2907,  2068,\n",
      "          1999, 17152,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2533, 0.7467],\n",
      "        [0.2522, 0.7478]]), 'input_ids': tensor([[  101,  2750,  2049,  2516,  1010,  8595,  1011,  7144,  2293,  2003,\n",
      "          2196,  3082,  1011,  4375,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2065,  2472,  2745, 23268,  3366,  2069, 23105,  2135, 19821,\n",
      "          2010,  3494,  1010,  2002,  2515,  1050,  1005,  1056,  2907,  2068,\n",
      "          1999, 17152,  1012,   102]]), 'ntok': tensor([16, 24]), 'cls_emb': tensor([[-0.0793, -0.0363, -0.6526,  ..., -0.1050,  0.2947,  0.5979],\n",
      "        [-0.1895,  0.1864, -0.5522,  ..., -0.1721,  0.6483,  0.5929]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055, 27150,  2000,  2156,  1037,  2611,  1011,\n",
      "          2373,  3185,  2008,  2515,  1050,  1005,  1056,  2514,  2009,  2038,\n",
      "          2000,  6011,  2505,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  2143,  2089,  3711,  6248,  1999,  2049,  7984,  2433,\n",
      "          1012,  1012,  1012,  2021,  2009,  3632,  6748,  2084,  2008,  1010,\n",
      "          2000,  8050,  9804,  2008,  2421,  1996, 11619,  1997,  1996,  3234,\n",
      "          8998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055, 27150,  2000,  2156,  1037,  2611,  1011,\n",
      "          2373,  3185,  2008,  2515,  1050,  1005,  1056,  2514,  2009,  2038,\n",
      "          2000,  6011,  2505,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  2143,  2089,  3711,  6248,  1999,  2049,  7984,  2433,\n",
      "          1012,  1012,  1012,  2021,  2009,  3632,  6748,  2084,  2008,  1010,\n",
      "          2000,  8050,  9804,  2008,  2421,  1996, 11619,  1997,  1996,  3234,\n",
      "          8998,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2489, 0.7511],\n",
      "        [0.2655, 0.7345]]), 'input_ids': tensor([[  101,  2009,  1005,  1055, 27150,  2000,  2156,  1037,  2611,  1011,\n",
      "          2373,  3185,  2008,  2515,  1050,  1005,  1056,  2514,  2009,  2038,\n",
      "          2000,  6011,  2505,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  2143,  2089,  3711,  6248,  1999,  2049,  7984,  2433,\n",
      "          1012,  1012,  1012,  2021,  2009,  3632,  6748,  2084,  2008,  1010,\n",
      "          2000,  8050,  9804,  2008,  2421,  1996, 11619,  1997,  1996,  3234,\n",
      "          8998,   102]]), 'ntok': tensor([25, 32]), 'cls_emb': tensor([[ 0.3251,  0.0680, -0.0848,  ..., -0.2519,  0.3673,  0.4147],\n",
      "        [-0.2862,  0.0178, -0.6237,  ..., -0.1105,  0.5994,  0.4682]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2174,  2009,  2089,  3531,  2216,  2040,  2293,  5691,  2008,\n",
      "          1038,  8017,  2063,  2007,  3769,  2774,  1010,  2402,  2671,  4349,\n",
      "          4599,  2097,  2358, 25377,  2185,  1999, 12721,  1012,   102],\n",
      "        [  101,  2004, 29364,  2004,  2009,  2003,  7221,  2389,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2174,  2009,  2089,  3531,  2216,  2040,  2293,  5691,  2008,\n",
      "          1038,  8017,  2063,  2007,  3769,  2774,  1010,  2402,  2671,  4349,\n",
      "          4599,  2097,  2358, 25377,  2185,  1999, 12721,  1012,   102],\n",
      "        [  101,  2004, 29364,  2004,  2009,  2003,  7221,  2389,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2345, 0.7655],\n",
      "        [0.2735, 0.7265]]), 'input_ids': tensor([[  101,  2174,  2009,  2089,  3531,  2216,  2040,  2293,  5691,  2008,\n",
      "          1038,  8017,  2063,  2007,  3769,  2774,  1010,  2402,  2671,  4349,\n",
      "          4599,  2097,  2358, 25377,  2185,  1999, 12721,  1012,   102],\n",
      "        [  101,  2004, 29364,  2004,  2009,  2003,  7221,  2389,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([29, 10]), 'cls_emb': tensor([[ 0.1790, -0.0362, -0.0367,  ..., -0.2893,  0.4378,  0.5085],\n",
      "        [-0.2857,  0.1244, -0.2055,  ..., -0.2030,  0.2627,  0.6074]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  9327,  1012,  1012,  1012,  2038,  2589,  2019,  6429,  3105,\n",
      "          1997,  2893, 12689,  4616,  2013,  2010,  3701,  2512, 21572,  7959,\n",
      "         28231,  2389,  3459,  1012,   102],\n",
      "        [  101,  6058,  1011,  2686, 23176,  2015,  2453,  2293,  2023,  2143,\n",
      "          1010,  2021,  2500,  2097,  2424,  2049, 26552, 23852,  1012,   102,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  9327,  1012,  1012,  1012,  2038,  2589,  2019,  6429,  3105,\n",
      "          1997,  2893, 12689,  4616,  2013,  2010,  3701,  2512, 21572,  7959,\n",
      "         28231,  2389,  3459,  1012,   102],\n",
      "        [  101,  6058,  1011,  2686, 23176,  2015,  2453,  2293,  2023,  2143,\n",
      "          1010,  2021,  2500,  2097,  2424,  2049, 26552, 23852,  1012,   102,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2437, 0.7563],\n",
      "        [0.2298, 0.7702]]), 'input_ids': tensor([[  101,  9327,  1012,  1012,  1012,  2038,  2589,  2019,  6429,  3105,\n",
      "          1997,  2893, 12689,  4616,  2013,  2010,  3701,  2512, 21572,  7959,\n",
      "         28231,  2389,  3459,  1012,   102],\n",
      "        [  101,  6058,  1011,  2686, 23176,  2015,  2453,  2293,  2023,  2143,\n",
      "          1010,  2021,  2500,  2097,  2424,  2049, 26552, 23852,  1012,   102,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([25, 20]), 'cls_emb': tensor([[-0.2321,  0.0790, -0.3348,  ..., -0.5300,  0.8840, -0.0303],\n",
      "        [ 0.2340, -0.1374,  0.1065,  ..., -0.3298,  0.3680,  0.3974]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 21696,  1998,  8262,  1005,  1055,  3945,  2005,  2019,  4895,\n",
      "          2243, 19779,  3085,  2627,  3084,  2005,  1037, 20161,  4706,  6317,\n",
      "          2466,  1010,  2021,  6845, 10421,  8005,  2125,  1037, 15708,  2121,\n",
      "          7577,  1999,  6664,  1024,  2002,  3084,  2653,  7916,  1012,   102],\n",
      "        [  101,  2062,  1059, 10606,  2100,  2091,  2121,  2084,  2522, 12171,\n",
      "          2271, 18252,  8570,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 21696,  1998,  8262,  1005,  1055,  3945,  2005,  2019,  4895,\n",
      "          2243, 19779,  3085,  2627,  3084,  2005,  1037, 20161,  4706,  6317,\n",
      "          2466,  1010,  2021,  6845, 10421,  8005,  2125,  1037, 15708,  2121,\n",
      "          7577,  1999,  6664,  1024,  2002,  3084,  2653,  7916,  1012,   102],\n",
      "        [  101,  2062,  1059, 10606,  2100,  2091,  2121,  2084,  2522, 12171,\n",
      "          2271, 18252,  8570,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2458, 0.7542],\n",
      "        [0.2937, 0.7063]]), 'input_ids': tensor([[  101, 21696,  1998,  8262,  1005,  1055,  3945,  2005,  2019,  4895,\n",
      "          2243, 19779,  3085,  2627,  3084,  2005,  1037, 20161,  4706,  6317,\n",
      "          2466,  1010,  2021,  6845, 10421,  8005,  2125,  1037, 15708,  2121,\n",
      "          7577,  1999,  6664,  1024,  2002,  3084,  2653,  7916,  1012,   102],\n",
      "        [  101,  2062,  1059, 10606,  2100,  2091,  2121,  2084,  2522, 12171,\n",
      "          2271, 18252,  8570,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([40, 15]), 'cls_emb': tensor([[-0.4188,  0.1335, -0.2903,  ..., -0.2731,  0.6280,  0.6945],\n",
      "        [-0.4430,  0.0702, -0.2247,  ..., -0.0228,  0.4195,  0.1986]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  2024,  3432,  2205,  2116,  4784,  8274,  2105,  1011,\n",
      "          1011,  2112,  2521,  3401,  1010,  2112,  8058,  4303,  1010,  2112,\n",
      "          3769,  2678,  1011,  1011,  1998,  2664,  7989,  2000, 18077,  2068,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2178, 26729,  1010,  3102,  1011,  2011,\n",
      "          1011,  3616, 17312,  1010,  3143,  2007,  6085,  1011,  4857,  3494,\n",
      "          1998,  6659,  1010, 26136,  1011, 14887,  7982,  1012,   102,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  2024,  3432,  2205,  2116,  4784,  8274,  2105,  1011,\n",
      "          1011,  2112,  2521,  3401,  1010,  2112,  8058,  4303,  1010,  2112,\n",
      "          3769,  2678,  1011,  1011,  1998,  2664,  7989,  2000, 18077,  2068,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2178, 26729,  1010,  3102,  1011,  2011,\n",
      "          1011,  3616, 17312,  1010,  3143,  2007,  6085,  1011,  4857,  3494,\n",
      "          1998,  6659,  1010, 26136,  1011, 14887,  7982,  1012,   102,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2505, 0.7495],\n",
      "        [0.2785, 0.7215]]), 'input_ids': tensor([[  101,  2045,  2024,  3432,  2205,  2116,  4784,  8274,  2105,  1011,\n",
      "          1011,  2112,  2521,  3401,  1010,  2112,  8058,  4303,  1010,  2112,\n",
      "          3769,  2678,  1011,  1011,  1998,  2664,  7989,  2000, 18077,  2068,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2178, 26729,  1010,  3102,  1011,  2011,\n",
      "          1011,  3616, 17312,  1010,  3143,  2007,  6085,  1011,  4857,  3494,\n",
      "          1998,  6659,  1010, 26136,  1011, 14887,  7982,  1012,   102,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 29]), 'cls_emb': tensor([[ 0.4181,  0.5477, -0.0202,  ..., -0.0443,  0.5626,  0.7101],\n",
      "        [ 0.3909, -0.1213, -0.2000,  ...,  0.0139,  0.6558,  0.4184]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2054, 27343,  2051,  1997,  5684,  2013, 14518,  2060, 10874,\n",
      "          2015,  2003,  2049, 10318,  5142,  2007,  1996,  8465,  1997,  2616,\n",
      "          1998,  2007,  1996,  8552,  6699,  4762,  2075,  9452,  4490,  1012,\n",
      "           102],\n",
      "        [  101,  1045,  2079,  1050,  1005,  1056,  2568,  2383,  2026,  8072,\n",
      "         18886,  3070,  2015,  2766,  1010,  2021,  2079,  1050,  1005,  1056,\n",
      "          7438,  2033,  2066,  1037,  7966,  1012,   102,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2054, 27343,  2051,  1997,  5684,  2013, 14518,  2060, 10874,\n",
      "          2015,  2003,  2049, 10318,  5142,  2007,  1996,  8465,  1997,  2616,\n",
      "          1998,  2007,  1996,  8552,  6699,  4762,  2075,  9452,  4490,  1012,\n",
      "           102],\n",
      "        [  101,  1045,  2079,  1050,  1005,  1056,  2568,  2383,  2026,  8072,\n",
      "         18886,  3070,  2015,  2766,  1010,  2021,  2079,  1050,  1005,  1056,\n",
      "          7438,  2033,  2066,  1037,  7966,  1012,   102,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2521, 0.7479],\n",
      "        [0.2669, 0.7331]]), 'input_ids': tensor([[  101,  2054, 27343,  2051,  1997,  5684,  2013, 14518,  2060, 10874,\n",
      "          2015,  2003,  2049, 10318,  5142,  2007,  1996,  8465,  1997,  2616,\n",
      "          1998,  2007,  1996,  8552,  6699,  4762,  2075,  9452,  4490,  1012,\n",
      "           102],\n",
      "        [  101,  1045,  2079,  1050,  1005,  1056,  2568,  2383,  2026,  8072,\n",
      "         18886,  3070,  2015,  2766,  1010,  2021,  2079,  1050,  1005,  1056,\n",
      "          7438,  2033,  2066,  1037,  7966,  1012,   102,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([31, 27]), 'cls_emb': tensor([[-0.1467, -0.0393, -0.6263,  ..., -0.0528,  0.3842,  0.6921],\n",
      "        [ 0.1317,  0.4357, -0.2027,  ...,  0.1584,  0.4648,  0.6083]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185,  1005,  1055, 14830,  2486,  2145,  5683,  2066,\n",
      "          2019,  9200, 12226, 18711,  1999,  2115,  4308,  1012,   102,     0],\n",
      "        [  101,  2012,  2560,  2028,  3496,  2003,  2061, 19424,  2008,  7193,\n",
      "          2089,  2022,  2524,  4508,  2000,  9279,  2037,  6265,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185,  1005,  1055, 14830,  2486,  2145,  5683,  2066,\n",
      "          2019,  9200, 12226, 18711,  1999,  2115,  4308,  1012,   102,     0],\n",
      "        [  101,  2012,  2560,  2028,  3496,  2003,  2061, 19424,  2008,  7193,\n",
      "          2089,  2022,  2524,  4508,  2000,  9279,  2037,  6265,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2516, 0.7484],\n",
      "        [0.2486, 0.7514]]), 'input_ids': tensor([[  101,  1996,  3185,  1005,  1055, 14830,  2486,  2145,  5683,  2066,\n",
      "          2019,  9200, 12226, 18711,  1999,  2115,  4308,  1012,   102,     0],\n",
      "        [  101,  2012,  2560,  2028,  3496,  2003,  2061, 19424,  2008,  7193,\n",
      "          2089,  2022,  2524,  4508,  2000,  9279,  2037,  6265,  1012,   102]]), 'ntok': tensor([19, 20]), 'cls_emb': tensor([[ 0.5118,  0.1274,  0.0923,  ..., -0.1891,  0.1566,  0.2942],\n",
      "        [ 0.0539, -0.0629, -0.2145,  ..., -0.0240,  0.3252,  0.5496]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2038, 11084,  2000,  8622,  1010,  1998,  4406,  2116,\n",
      "          6298, 22092,  1010,  2009,  2515,  2025,  7344,  3686,  2593,  5907,\n",
      "          1999,  1996,  4378,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019, 22534,  1010, 24199,  3861,  2008,  1005,  1055, 14036,\n",
      "          2135,  6051,  1010, 12047,  2135,  2915,  1998, 13940,  2438,  2000,\n",
      "         15770,  2087,  1997,  2049, 10894,  1011,  3371,  3091,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2038, 11084,  2000,  8622,  1010,  1998,  4406,  2116,\n",
      "          6298, 22092,  1010,  2009,  2515,  2025,  7344,  3686,  2593,  5907,\n",
      "          1999,  1996,  4378,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019, 22534,  1010, 24199,  3861,  2008,  1005,  1055, 14036,\n",
      "          2135,  6051,  1010, 12047,  2135,  2915,  1998, 13940,  2438,  2000,\n",
      "         15770,  2087,  1997,  2049, 10894,  1011,  3371,  3091,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2554, 0.7446],\n",
      "        [0.2542, 0.7458]]), 'input_ids': tensor([[  101,  2009,  2038, 11084,  2000,  8622,  1010,  1998,  4406,  2116,\n",
      "          6298, 22092,  1010,  2009,  2515,  2025,  7344,  3686,  2593,  5907,\n",
      "          1999,  1996,  4378,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019, 22534,  1010, 24199,  3861,  2008,  1005,  1055, 14036,\n",
      "          2135,  6051,  1010, 12047,  2135,  2915,  1998, 13940,  2438,  2000,\n",
      "         15770,  2087,  1997,  2049, 10894,  1011,  3371,  3091,  1012,   102]]), 'ntok': tensor([25, 30]), 'cls_emb': tensor([[-0.3787, -0.1828, -0.3501,  ..., -0.3158,  0.3920,  0.9640],\n",
      "        [-0.2539, -0.2291,  0.1638,  ..., -0.3742,  0.4369,  0.2515]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 17565,  1037,  3371,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3594,  4629,  8562,  1998, 12369,  2046,  2529,  3267,  2000,\n",
      "         11628,  2465,  4736,  1010, 20274, 29479,  1010,  1996,  6147,  1997,\n",
      "          6860,  1998,  4424,  4767,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 17565,  1037,  3371,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3594,  4629,  8562,  1998, 12369,  2046,  2529,  3267,  2000,\n",
      "         11628,  2465,  4736,  1010, 20274, 29479,  1010,  1996,  6147,  1997,\n",
      "          6860,  1998,  4424,  4767,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2652, 0.7348],\n",
      "        [0.2516, 0.7484]]), 'input_ids': tensor([[  101,  1037, 17565,  1037,  3371,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3594,  4629,  8562,  1998, 12369,  2046,  2529,  3267,  2000,\n",
      "         11628,  2465,  4736,  1010, 20274, 29479,  1010,  1996,  6147,  1997,\n",
      "          6860,  1998,  4424,  4767,  1012,   102]]), 'ntok': tensor([ 7, 26]), 'cls_emb': tensor([[-0.2403, -0.3291, -0.3732,  ..., -0.3309,  0.3149,  0.1588],\n",
      "        [-0.5203,  0.1971, -1.2465,  ..., -0.2822,  0.2053, -0.0758]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2506,  2204,  6370,  2090, 11425,  1998, 12022,  2072,\n",
      "          2003,  2054,  7906,  2023,  3621, 15640,  8297,  2183,  1010,  2007,\n",
      "          2438, 19142,  7221,  3334,  1011,  1011, 10190,  2135,  8364,  1011,\n",
      "          2489,  1011,  1011,  2000,  2562,  2119,  4268,  1998,  3008, 21474,\n",
      "          1012,   102],\n",
      "        [  101,  1045,  1005,  1049,  2074,  2205, 11471,  2000,  2729,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2506,  2204,  6370,  2090, 11425,  1998, 12022,  2072,\n",
      "          2003,  2054,  7906,  2023,  3621, 15640,  8297,  2183,  1010,  2007,\n",
      "          2438, 19142,  7221,  3334,  1011,  1011, 10190,  2135,  8364,  1011,\n",
      "          2489,  1011,  1011,  2000,  2562,  2119,  4268,  1998,  3008, 21474,\n",
      "          1012,   102],\n",
      "        [  101,  1045,  1005,  1049,  2074,  2205, 11471,  2000,  2729,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2743, 0.7257],\n",
      "        [0.2680, 0.7320]]), 'input_ids': tensor([[  101,  1996,  2506,  2204,  6370,  2090, 11425,  1998, 12022,  2072,\n",
      "          2003,  2054,  7906,  2023,  3621, 15640,  8297,  2183,  1010,  2007,\n",
      "          2438, 19142,  7221,  3334,  1011,  1011, 10190,  2135,  8364,  1011,\n",
      "          2489,  1011,  1011,  2000,  2562,  2119,  4268,  1998,  3008, 21474,\n",
      "          1012,   102],\n",
      "        [  101,  1045,  1005,  1049,  2074,  2205, 11471,  2000,  2729,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([42, 11]), 'cls_emb': tensor([[ 0.1100, -0.1926,  0.0945,  ..., -0.1027,  0.4696,  0.3213],\n",
      "        [ 0.3723,  0.3162, -0.0397,  ...,  0.0557,  0.3035,  0.4450]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2028,  1997,  1996,  2062, 29348, 13941,  2017,  2097,  2156,\n",
      "          2023,  1010,  2030,  2151,  1010,  2095,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2028, 17752,  1997,  1037,  2839,  2817,\n",
      "          1011,  1011,  2025,  1997, 25419,  2030,  9082,  2021,  1997,  1996,\n",
      "          4310,  3276,  2090,  2068,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2028,  1997,  1996,  2062, 29348, 13941,  2017,  2097,  2156,\n",
      "          2023,  1010,  2030,  2151,  1010,  2095,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2028, 17752,  1997,  1037,  2839,  2817,\n",
      "          1011,  1011,  2025,  1997, 25419,  2030,  9082,  2021,  1997,  1996,\n",
      "          4310,  3276,  2090,  2068,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2536, 0.7464],\n",
      "        [0.2503, 0.7497]]), 'input_ids': tensor([[  101,  2028,  1997,  1996,  2062, 29348, 13941,  2017,  2097,  2156,\n",
      "          2023,  1010,  2030,  2151,  1010,  2095,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2028, 17752,  1997,  1037,  2839,  2817,\n",
      "          1011,  1011,  2025,  1997, 25419,  2030,  9082,  2021,  1997,  1996,\n",
      "          4310,  3276,  2090,  2068,  1012,   102]]), 'ntok': tensor([18, 26]), 'cls_emb': tensor([[-0.3703, -0.2040, -0.1955,  ..., -0.3147,  0.4436,  0.5778],\n",
      "        [-0.0779,  0.0410, -0.4019,  ..., -0.3193,  0.7014,  0.5932]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  5829,  2855,  1010,  4748, 26692, 14626,  1010,  1998,\n",
      "          2302, 28554,  1025,  2009,  2515,  1050,  1005,  1056,  2507,  2017,\n",
      "          2051,  2000,  8339,  2006,  1996, 27118, 22758,  1011,  1011,  1998,\n",
      "          1996,  3147,  2162,  6052,  2791,  1011,  1011,  1997,  2049, 18458,\n",
      "          1012,   102],\n",
      "        [  101,  1045,  2572,  3374,  2008,  1045,  2001,  4039,  2000,  2131,\n",
      "          1996,  2440,  7987, 16671,  1997,  1996,  4038,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  5829,  2855,  1010,  4748, 26692, 14626,  1010,  1998,\n",
      "          2302, 28554,  1025,  2009,  2515,  1050,  1005,  1056,  2507,  2017,\n",
      "          2051,  2000,  8339,  2006,  1996, 27118, 22758,  1011,  1011,  1998,\n",
      "          1996,  3147,  2162,  6052,  2791,  1011,  1011,  1997,  2049, 18458,\n",
      "          1012,   102],\n",
      "        [  101,  1045,  2572,  3374,  2008,  1045,  2001,  4039,  2000,  2131,\n",
      "          1996,  2440,  7987, 16671,  1997,  1996,  4038,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2557, 0.7443],\n",
      "        [0.2509, 0.7491]]), 'input_ids': tensor([[  101,  2009,  5829,  2855,  1010,  4748, 26692, 14626,  1010,  1998,\n",
      "          2302, 28554,  1025,  2009,  2515,  1050,  1005,  1056,  2507,  2017,\n",
      "          2051,  2000,  8339,  2006,  1996, 27118, 22758,  1011,  1011,  1998,\n",
      "          1996,  3147,  2162,  6052,  2791,  1011,  1011,  1997,  2049, 18458,\n",
      "          1012,   102],\n",
      "        [  101,  1045,  2572,  3374,  2008,  1045,  2001,  4039,  2000,  2131,\n",
      "          1996,  2440,  7987, 16671,  1997,  1996,  4038,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([42, 19]), 'cls_emb': tensor([[-0.1321,  0.0791, -0.4150,  ..., -0.1113,  0.4031,  0.6119],\n",
      "        [ 0.0845,  0.0595, -0.1520,  ..., -0.0319,  0.3775,  0.6675]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2204,  3538,  1997,  2147,  2062,  2411,  2084,  2025,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2096,  1996,  4784,  2055, 21416,  1011,  2938, 18924,  2024,\n",
      "          2521,  2013,  3117,  1010,  2027,  1005,  2128,  3591,  2007,  1037,\n",
      "         24639,  2601,  8562,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2204,  3538,  1997,  2147,  2062,  2411,  2084,  2025,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2096,  1996,  4784,  2055, 21416,  1011,  2938, 18924,  2024,\n",
      "          2521,  2013,  3117,  1010,  2027,  1005,  2128,  3591,  2007,  1037,\n",
      "         24639,  2601,  8562,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2800, 0.7200],\n",
      "        [0.2475, 0.7525]]), 'input_ids': tensor([[  101,  1037,  2204,  3538,  1997,  2147,  2062,  2411,  2084,  2025,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2096,  1996,  4784,  2055, 21416,  1011,  2938, 18924,  2024,\n",
      "          2521,  2013,  3117,  1010,  2027,  1005,  2128,  3591,  2007,  1037,\n",
      "         24639,  2601,  8562,  1012,   102]]), 'ntok': tensor([12, 25]), 'cls_emb': tensor([[-0.2775,  0.1323, -0.2775,  ..., -0.2069,  0.2722,  0.1941],\n",
      "        [-0.0960,  0.2777, -0.4384,  ..., -0.3997,  0.6161,  0.2665]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2798,  1005, 14036,  2143, 11906,  7367,  2378,  8151,  1005,\n",
      "          1055,  2709,  2000,  3233,  1011,  2039,  4038,  2044,  1996, 10236,\n",
      "          1997,  2010,  8987, 13130,  1010,  4077, 10587,  4783,  5021,  5922,\n",
      "          1005,  4740,  2000,  2131,  2010,  2915,  2012,  1996,  2502,  2051,\n",
      "          1012,   102],\n",
      "        [  101,  2019,  4654, 26415, 15172, 28971, 10874,  1011, 15587,  1010,\n",
      "          7162,  3189, 21438,  1996,  2190,  1997,  2974,  2105,  1037, 13940,\n",
      "          2466,  1010, 12771,  1037, 15544, 19510,  2075,  1010,  8187, 20014,\n",
      "          6132, 11787,  9686, 17695,  2923,  6172,  1997,  1996,  2034,  2344,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2798,  1005, 14036,  2143, 11906,  7367,  2378,  8151,  1005,\n",
      "          1055,  2709,  2000,  3233,  1011,  2039,  4038,  2044,  1996, 10236,\n",
      "          1997,  2010,  8987, 13130,  1010,  4077, 10587,  4783,  5021,  5922,\n",
      "          1005,  4740,  2000,  2131,  2010,  2915,  2012,  1996,  2502,  2051,\n",
      "          1012,   102],\n",
      "        [  101,  2019,  4654, 26415, 15172, 28971, 10874,  1011, 15587,  1010,\n",
      "          7162,  3189, 21438,  1996,  2190,  1997,  2974,  2105,  1037, 13940,\n",
      "          2466,  1010, 12771,  1037, 15544, 19510,  2075,  1010,  8187, 20014,\n",
      "          6132, 11787,  9686, 17695,  2923,  6172,  1997,  1996,  2034,  2344,\n",
      "           102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2722, 0.7278],\n",
      "        [0.2674, 0.7326]]), 'input_ids': tensor([[  101,  2798,  1005, 14036,  2143, 11906,  7367,  2378,  8151,  1005,\n",
      "          1055,  2709,  2000,  3233,  1011,  2039,  4038,  2044,  1996, 10236,\n",
      "          1997,  2010,  8987, 13130,  1010,  4077, 10587,  4783,  5021,  5922,\n",
      "          1005,  4740,  2000,  2131,  2010,  2915,  2012,  1996,  2502,  2051,\n",
      "          1012,   102],\n",
      "        [  101,  2019,  4654, 26415, 15172, 28971, 10874,  1011, 15587,  1010,\n",
      "          7162,  3189, 21438,  1996,  2190,  1997,  2974,  2105,  1037, 13940,\n",
      "          2466,  1010, 12771,  1037, 15544, 19510,  2075,  1010,  8187, 20014,\n",
      "          6132, 11787,  9686, 17695,  2923,  6172,  1997,  1996,  2034,  2344,\n",
      "           102,     0]]), 'ntok': tensor([42, 41]), 'cls_emb': tensor([[-0.0878,  0.2291, -0.2788,  ..., -0.1225,  0.7483,  0.5181],\n",
      "        [-0.0879, -0.3973, -0.0504,  ..., -0.4267,  0.6808,  0.0845]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 17950,  5159,  1010, 26106,  2135,  4895,  5054,  7292, 15758,\n",
      "          4038,  1011,  3689,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2143,  1005,  1055, 28425,  2098,  4471,  2003,  2025,\n",
      "          3271,  2011,  1996,  4857, 23191,  2015,  1010,  3904,  9048, 16173,\n",
      "          2102,  5436,  1998,  3653,  6528, 20771,  5107,  2806,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 17950,  5159,  1010, 26106,  2135,  4895,  5054,  7292, 15758,\n",
      "          4038,  1011,  3689,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2143,  1005,  1055, 28425,  2098,  4471,  2003,  2025,\n",
      "          3271,  2011,  1996,  4857, 23191,  2015,  1010,  3904,  9048, 16173,\n",
      "          2102,  5436,  1998,  3653,  6528, 20771,  5107,  2806,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2722, 0.7278],\n",
      "        [0.2457, 0.7543]]), 'input_ids': tensor([[  101, 17950,  5159,  1010, 26106,  2135,  4895,  5054,  7292, 15758,\n",
      "          4038,  1011,  3689,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2143,  1005,  1055, 28425,  2098,  4471,  2003,  2025,\n",
      "          3271,  2011,  1996,  4857, 23191,  2015,  1010,  3904,  9048, 16173,\n",
      "          2102,  5436,  1998,  3653,  6528, 20771,  5107,  2806,  1012,   102]]), 'ntok': tensor([15, 30]), 'cls_emb': tensor([[-0.5906, -0.0303, -0.2487,  ..., -0.4115,  0.3463,  0.4001],\n",
      "        [ 0.1699,  0.0183, -0.3332,  ...,  0.0144,  0.7397,  0.3108]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 21986,  9096,  6298,  4038,  2008,  2038,  1996,  8595,\n",
      "          1997,  1037,  2204, 13130,  1010,  2096,  5378, 17077,  2092,  1011,\n",
      "          6851,  3494,  1012,   102],\n",
      "        [  101,  2323,  2031,  2042,  2619,  2842,  1011,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 21986,  9096,  6298,  4038,  2008,  2038,  1996,  8595,\n",
      "          1997,  1037,  2204, 13130,  1010,  2096,  5378, 17077,  2092,  1011,\n",
      "          6851,  3494,  1012,   102],\n",
      "        [  101,  2323,  2031,  2042,  2619,  2842,  1011,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2597, 0.7403],\n",
      "        [0.2768, 0.7232]]), 'input_ids': tensor([[  101,  1037, 21986,  9096,  6298,  4038,  2008,  2038,  1996,  8595,\n",
      "          1997,  1037,  2204, 13130,  1010,  2096,  5378, 17077,  2092,  1011,\n",
      "          6851,  3494,  1012,   102],\n",
      "        [  101,  2323,  2031,  2042,  2619,  2842,  1011,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([24,  8]), 'cls_emb': tensor([[-0.4336, -0.4376, -0.2772,  ..., -0.3676,  0.9109,  0.3245],\n",
      "        [-0.2072,  0.0223, -0.0597,  ..., -0.1730,  0.1108,  0.3673]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 19340,  2015,  1998, 11867, 26878,  2015,  2006,  2049,  2219,\n",
      "          2695,  5302, 25888,  9530,  3401,  4183,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  7006,  2332,  2001,  1037, 17197,  3112,  2043,  2009,\n",
      "          2001,  2207,  2809,  2086,  3283,  1010,  2021,  2006, 10047,  8528,\n",
      "          2009,  3849,  2488,  1010,  2025,  2074,  7046,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 19340,  2015,  1998, 11867, 26878,  2015,  2006,  2049,  2219,\n",
      "          2695,  5302, 25888,  9530,  3401,  4183,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  7006,  2332,  2001,  1037, 17197,  3112,  2043,  2009,\n",
      "          2001,  2207,  2809,  2086,  3283,  1010,  2021,  2006, 10047,  8528,\n",
      "          2009,  3849,  2488,  1010,  2025,  2074,  7046,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2734, 0.7266],\n",
      "        [0.2579, 0.7421]]), 'input_ids': tensor([[  101, 19340,  2015,  1998, 11867, 26878,  2015,  2006,  2049,  2219,\n",
      "          2695,  5302, 25888,  9530,  3401,  4183,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  7006,  2332,  2001,  1037, 17197,  3112,  2043,  2009,\n",
      "          2001,  2207,  2809,  2086,  3283,  1010,  2021,  2006, 10047,  8528,\n",
      "          2009,  3849,  2488,  1010,  2025,  2074,  7046,  1012,   102]]), 'ntok': tensor([18, 29]), 'cls_emb': tensor([[-0.2773,  0.3009, -0.0266,  ..., -0.3660,  0.5773,  0.3164],\n",
      "        [-0.0171, -0.3670,  0.3115,  ..., -0.2067,  0.6221,  0.2309]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2471, 18201,  2015,  2006,  2049,  2219, 13638,  1012,   102,\n",
      "             0],\n",
      "        [  101,  1037,  8348,  2066,  3904,  2017,  1005,  2310,  2464,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2471, 18201,  2015,  2006,  2049,  2219, 13638,  1012,   102,\n",
      "             0],\n",
      "        [  101,  1037,  8348,  2066,  3904,  2017,  1005,  2310,  2464,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2675, 0.7325],\n",
      "        [0.2734, 0.7266]]), 'input_ids': tensor([[  101,  2471, 18201,  2015,  2006,  2049,  2219, 13638,  1012,   102,\n",
      "             0],\n",
      "        [  101,  1037,  8348,  2066,  3904,  2017,  1005,  2310,  2464,  1012,\n",
      "           102]]), 'ntok': tensor([10, 11]), 'cls_emb': tensor([[-0.5939,  0.0018, -0.1114,  ...,  0.1176,  0.4021,  0.1691],\n",
      "        [-0.3360, -0.1103, -0.4320,  ..., -0.4195,  0.0964,  0.5014]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 13012,  2618,  1010,  7221,  2389,  1010, 18856, 17322,  2094,\n",
      "          1010,  3262,  1999,  7245,  6132,  3512,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 10047, 16862,  2075,  2149,  1999,  1996, 10866,  2135,  1999,\n",
      "         15338,  3512,  1010, 16265,  6975,  2088,  1997,  5099,  1011,  6154,\n",
      "         23837,  1010,  1996,  2622,  2003,  8742,  2389,  1998,  7065, 10581,\n",
      "          7062,  1010,  2130,  2065, 20291,  3084,  2017,  2009,  2818,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 13012,  2618,  1010,  7221,  2389,  1010, 18856, 17322,  2094,\n",
      "          1010,  3262,  1999,  7245,  6132,  3512,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 10047, 16862,  2075,  2149,  1999,  1996, 10866,  2135,  1999,\n",
      "         15338,  3512,  1010, 16265,  6975,  2088,  1997,  5099,  1011,  6154,\n",
      "         23837,  1010,  1996,  2622,  2003,  8742,  2389,  1998,  7065, 10581,\n",
      "          7062,  1010,  2130,  2065, 20291,  3084,  2017,  2009,  2818,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2610, 0.7390],\n",
      "        [0.2428, 0.7572]]), 'input_ids': tensor([[  101, 13012,  2618,  1010,  7221,  2389,  1010, 18856, 17322,  2094,\n",
      "          1010,  3262,  1999,  7245,  6132,  3512,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 10047, 16862,  2075,  2149,  1999,  1996, 10866,  2135,  1999,\n",
      "         15338,  3512,  1010, 16265,  6975,  2088,  1997,  5099,  1011,  6154,\n",
      "         23837,  1010,  1996,  2622,  2003,  8742,  2389,  1998,  7065, 10581,\n",
      "          7062,  1010,  2130,  2065, 20291,  3084,  2017,  2009,  2818,  1012,\n",
      "           102]]), 'ntok': tensor([18, 41]), 'cls_emb': tensor([[-0.6445,  0.1424, -0.3376,  ..., -0.4201,  0.2161,  0.1224],\n",
      "        [ 0.1997,  0.1472, -0.0549,  ..., -0.1261,  0.2835,  0.2320]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185,  2038,  2019, 16514,  4654, 21436,  6651,  2008,\n",
      "          2097,  8526,  3087,  2007,  1037,  4458,  3037,  1999,  1996, 17260,\n",
      "          1013, 14175,  3226,  1010,  1996,  1048,  1012,  1037,  1012,  3509,\n",
      "          3496,  1998,  1996, 28575,  1006,  1998,  2823,  6206,  1007,  3971,\n",
      "          4268,  2064,  2191,  1037, 14705,  2041,  1997,  1996, 10214,  1997,\n",
      "          6001,  1012,   102],\n",
      "        [  101,  8038, 22332,  6806,  1998, 11895,  4328,  9759,  1012,  1012,\n",
      "          1012,  3443, 11973, 23191,  2015,  1999, 17189,  4648,  1005,  1055,\n",
      "         17133,  1998, 22249,  3451,  4666,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185,  2038,  2019, 16514,  4654, 21436,  6651,  2008,\n",
      "          2097,  8526,  3087,  2007,  1037,  4458,  3037,  1999,  1996, 17260,\n",
      "          1013, 14175,  3226,  1010,  1996,  1048,  1012,  1037,  1012,  3509,\n",
      "          3496,  1998,  1996, 28575,  1006,  1998,  2823,  6206,  1007,  3971,\n",
      "          4268,  2064,  2191,  1037, 14705,  2041,  1997,  1996, 10214,  1997,\n",
      "          6001,  1012,   102],\n",
      "        [  101,  8038, 22332,  6806,  1998, 11895,  4328,  9759,  1012,  1012,\n",
      "          1012,  3443, 11973, 23191,  2015,  1999, 17189,  4648,  1005,  1055,\n",
      "         17133,  1998, 22249,  3451,  4666,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2677, 0.7323],\n",
      "        [0.2547, 0.7453]]), 'input_ids': tensor([[  101,  1996,  3185,  2038,  2019, 16514,  4654, 21436,  6651,  2008,\n",
      "          2097,  8526,  3087,  2007,  1037,  4458,  3037,  1999,  1996, 17260,\n",
      "          1013, 14175,  3226,  1010,  1996,  1048,  1012,  1037,  1012,  3509,\n",
      "          3496,  1998,  1996, 28575,  1006,  1998,  2823,  6206,  1007,  3971,\n",
      "          4268,  2064,  2191,  1037, 14705,  2041,  1997,  1996, 10214,  1997,\n",
      "          6001,  1012,   102],\n",
      "        [  101,  8038, 22332,  6806,  1998, 11895,  4328,  9759,  1012,  1012,\n",
      "          1012,  3443, 11973, 23191,  2015,  1999, 17189,  4648,  1005,  1055,\n",
      "         17133,  1998, 22249,  3451,  4666,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([53, 27]), 'cls_emb': tensor([[ 0.3216, -0.1995,  0.0188,  ..., -0.0763,  0.4256,  0.3874],\n",
      "        [ 0.2920,  0.2468, -0.1425,  ..., -0.1876,  0.8421,  0.1993]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  3748, 16524,  4933,  1010,  2021,  8235,  1998,\n",
      "          1996,  4950,  2074,  2785,  1997,  7719,  2045,  1998, 11082,  2017,\n",
      "          2298,  2012,  2023,  1998,  2049,  2066,  2017,  1005,  2128,  2183,\n",
      "          2013,  2028,  2282,  2000,  1996,  2279,  1998,  3904,  1997,  2068,\n",
      "          2031,  2151,  7189,  2000,  1996,  2060,  1012,   102],\n",
      "        [  101,  2045,  2003,  2200,  2210, 14436,  2030, 25809,  1010,  1998,\n",
      "          2295,  1045,  2066,  1996, 17109,  4784,  1010,  2027,  2024,  2025,\n",
      "          6472,  2007,  2505,  2062,  2084,  2566, 11263, 12273,  7062,  8066,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  3748, 16524,  4933,  1010,  2021,  8235,  1998,\n",
      "          1996,  4950,  2074,  2785,  1997,  7719,  2045,  1998, 11082,  2017,\n",
      "          2298,  2012,  2023,  1998,  2049,  2066,  2017,  1005,  2128,  2183,\n",
      "          2013,  2028,  2282,  2000,  1996,  2279,  1998,  3904,  1997,  2068,\n",
      "          2031,  2151,  7189,  2000,  1996,  2060,  1012,   102],\n",
      "        [  101,  2045,  2003,  2200,  2210, 14436,  2030, 25809,  1010,  1998,\n",
      "          2295,  1045,  2066,  1996, 17109,  4784,  1010,  2027,  2024,  2025,\n",
      "          6472,  2007,  2505,  2062,  2084,  2566, 11263, 12273,  7062,  8066,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2427, 0.7573],\n",
      "        [0.2369, 0.7631]]), 'input_ids': tensor([[  101,  2023,  2003,  3748, 16524,  4933,  1010,  2021,  8235,  1998,\n",
      "          1996,  4950,  2074,  2785,  1997,  7719,  2045,  1998, 11082,  2017,\n",
      "          2298,  2012,  2023,  1998,  2049,  2066,  2017,  1005,  2128,  2183,\n",
      "          2013,  2028,  2282,  2000,  1996,  2279,  1998,  3904,  1997,  2068,\n",
      "          2031,  2151,  7189,  2000,  1996,  2060,  1012,   102],\n",
      "        [  101,  2045,  2003,  2200,  2210, 14436,  2030, 25809,  1010,  1998,\n",
      "          2295,  1045,  2066,  1996, 17109,  4784,  1010,  2027,  2024,  2025,\n",
      "          6472,  2007,  2505,  2062,  2084,  2566, 11263, 12273,  7062,  8066,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([48, 32]), 'cls_emb': tensor([[ 0.3789,  0.1789, -0.0384,  ..., -0.2828,  0.4393,  0.5345],\n",
      "        [ 0.2572,  0.1187, -0.1089,  ...,  0.1339,  0.1601,  0.6801]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  9366,  2008,  8647,  3121,  2003,  1996,  4569, 15580,\n",
      "          2102,  2518,  1999,  1996,  2088,  3632,  4498, 16655, 18684, 25089,\n",
      "          1999,  2023, 19828,  2135,  4895, 11263, 10695,  2100,  4038,  1012,\n",
      "           102],\n",
      "        [  101,  2204,  2482, 29515,  1010,  2307,  2954,  5019,  1010,  1998,\n",
      "          1037,  8200, 12586,  1997,  2647,  1010,  2137,  1998,  4004,  8092,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  9366,  2008,  8647,  3121,  2003,  1996,  4569, 15580,\n",
      "          2102,  2518,  1999,  1996,  2088,  3632,  4498, 16655, 18684, 25089,\n",
      "          1999,  2023, 19828,  2135,  4895, 11263, 10695,  2100,  4038,  1012,\n",
      "           102],\n",
      "        [  101,  2204,  2482, 29515,  1010,  2307,  2954,  5019,  1010,  1998,\n",
      "          1037,  8200, 12586,  1997,  2647,  1010,  2137,  1998,  4004,  8092,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2363, 0.7637],\n",
      "        [0.2558, 0.7442]]), 'input_ids': tensor([[  101,  1996,  9366,  2008,  8647,  3121,  2003,  1996,  4569, 15580,\n",
      "          2102,  2518,  1999,  1996,  2088,  3632,  4498, 16655, 18684, 25089,\n",
      "          1999,  2023, 19828,  2135,  4895, 11263, 10695,  2100,  4038,  1012,\n",
      "           102],\n",
      "        [  101,  2204,  2482, 29515,  1010,  2307,  2954,  5019,  1010,  1998,\n",
      "          1037,  8200, 12586,  1997,  2647,  1010,  2137,  1998,  4004,  8092,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([31, 22]), 'cls_emb': tensor([[ 0.0465,  0.1789, -0.3440,  ..., -0.1076,  0.5351,  0.5393],\n",
      "        [-0.7796, -0.2161, -1.0203,  ..., -0.3224,  0.5303,  0.2146]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2197,  2322,  2781,  2024,  5399,  2417, 21564,  2075,\n",
      "          1010,  2021,  2087,  1997,  1996,  3185,  2003,  1996,  2168,  9454,\n",
      "          2137,  2346,  1011,  4440,  2852,  5937,  2057,  1005,  2310,  2464,\n",
      "          2077,  1011,  2069,  2023,  2051,  2017,  2031,  2000,  3191,  1996,\n",
      "          2521,  2102, 13198,   102],\n",
      "        [  101,  2130,  1999,  2049,  2087,  6945,  6313,  5019,  1010,  2845,\n",
      "         15745,  2003,  2033,  6491, 11124,  6774,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2197,  2322,  2781,  2024,  5399,  2417, 21564,  2075,\n",
      "          1010,  2021,  2087,  1997,  1996,  3185,  2003,  1996,  2168,  9454,\n",
      "          2137,  2346,  1011,  4440,  2852,  5937,  2057,  1005,  2310,  2464,\n",
      "          2077,  1011,  2069,  2023,  2051,  2017,  2031,  2000,  3191,  1996,\n",
      "          2521,  2102, 13198,   102],\n",
      "        [  101,  2130,  1999,  2049,  2087,  6945,  6313,  5019,  1010,  2845,\n",
      "         15745,  2003,  2033,  6491, 11124,  6774,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2718, 0.7282],\n",
      "        [0.2382, 0.7618]]), 'input_ids': tensor([[  101,  1996,  2197,  2322,  2781,  2024,  5399,  2417, 21564,  2075,\n",
      "          1010,  2021,  2087,  1997,  1996,  3185,  2003,  1996,  2168,  9454,\n",
      "          2137,  2346,  1011,  4440,  2852,  5937,  2057,  1005,  2310,  2464,\n",
      "          2077,  1011,  2069,  2023,  2051,  2017,  2031,  2000,  3191,  1996,\n",
      "          2521,  2102, 13198,   102],\n",
      "        [  101,  2130,  1999,  2049,  2087,  6945,  6313,  5019,  1010,  2845,\n",
      "         15745,  2003,  2033,  6491, 11124,  6774,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([44, 18]), 'cls_emb': tensor([[ 0.4579,  0.1080, -0.2438,  ..., -0.0102,  0.7513,  0.3818],\n",
      "        [ 0.0395,  0.0752, -0.2655,  ..., -0.4304,  0.0911,  0.6783]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2007,  2049, 28844,  2098,  5365,  3019,  2964,  1998,  1996,\n",
      "          1999, 10288,  6525,  3468,  6019,  1997,  2049,  3494,  2646,  3002,\n",
      "          9021,  1010,  3612, 28014,  2545,  2003,  2498,  2021,  1037, 15875,\n",
      "          1011,  4086,  7815,  1012,   102],\n",
      "        [  101,  3227,  1010, 20940, 14399,  7347,  2097, 13883,  2115, 18575,\n",
      "          3367, 21233,  2055,  2108,  1037,  2367,  2785,  1997,  2051, 20174,\n",
      "          1010,  2096, 11361,  4288,  6365,  2781,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2007,  2049, 28844,  2098,  5365,  3019,  2964,  1998,  1996,\n",
      "          1999, 10288,  6525,  3468,  6019,  1997,  2049,  3494,  2646,  3002,\n",
      "          9021,  1010,  3612, 28014,  2545,  2003,  2498,  2021,  1037, 15875,\n",
      "          1011,  4086,  7815,  1012,   102],\n",
      "        [  101,  3227,  1010, 20940, 14399,  7347,  2097, 13883,  2115, 18575,\n",
      "          3367, 21233,  2055,  2108,  1037,  2367,  2785,  1997,  2051, 20174,\n",
      "          1010,  2096, 11361,  4288,  6365,  2781,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2475, 0.7525],\n",
      "        [0.2582, 0.7418]]), 'input_ids': tensor([[  101,  2007,  2049, 28844,  2098,  5365,  3019,  2964,  1998,  1996,\n",
      "          1999, 10288,  6525,  3468,  6019,  1997,  2049,  3494,  2646,  3002,\n",
      "          9021,  1010,  3612, 28014,  2545,  2003,  2498,  2021,  1037, 15875,\n",
      "          1011,  4086,  7815,  1012,   102],\n",
      "        [  101,  3227,  1010, 20940, 14399,  7347,  2097, 13883,  2115, 18575,\n",
      "          3367, 21233,  2055,  2108,  1037,  2367,  2785,  1997,  2051, 20174,\n",
      "          1010,  2096, 11361,  4288,  6365,  2781,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 28]), 'cls_emb': tensor([[-0.0364, -0.0624, -0.1046,  ..., -0.0952,  0.3462,  0.4636],\n",
      "        [ 0.2895,  0.0033,  0.1641,  ..., -0.3666,  0.5533,  0.3339]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2242, 17793,  2000,  1037,  2887,  5650,  2083,  1996,  2559,\n",
      "          3221,  1010,  3272,  2008,  2009,  3849,  2000,  2202,  2993,  2521,\n",
      "          2062,  5667,  1012,   102],\n",
      "        [  101,  2821,  2272,  2006,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2242, 17793,  2000,  1037,  2887,  5650,  2083,  1996,  2559,\n",
      "          3221,  1010,  3272,  2008,  2009,  3849,  2000,  2202,  2993,  2521,\n",
      "          2062,  5667,  1012,   102],\n",
      "        [  101,  2821,  2272,  2006,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2602, 0.7398],\n",
      "        [0.2845, 0.7155]]), 'input_ids': tensor([[  101,  2242, 17793,  2000,  1037,  2887,  5650,  2083,  1996,  2559,\n",
      "          3221,  1010,  3272,  2008,  2009,  3849,  2000,  2202,  2993,  2521,\n",
      "          2062,  5667,  1012,   102],\n",
      "        [  101,  2821,  2272,  2006,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([24,  6]), 'cls_emb': tensor([[ 0.1741, -0.3109, -0.4001,  ...,  0.0852,  0.1776,  0.6840],\n",
      "        [ 0.1041, -0.0544,  0.0085,  ..., -0.1128,  0.2499,  0.3619]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 14434,  1010,  4800,  1011,  8789,  2293,  2466,  1998,\n",
      "         16596,  1011, 10882,  6547,  1010,  5943,  2483,  2003,  1037,  2245,\n",
      "          1011,  4013, 22776,  1010, 20161,  2143,  2008,  4473,  1996,  8079,\n",
      "          1997,  1996,  9647,  2000, 16216, 27512,  3686,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2069,  2024,  1996,  2569,  3896,  1998,  7984,  4834,\n",
      "          2172,  5301,  1010,  1998,  3817, 22603,  2062, 14868, 20865,  3512,\n",
      "          2023,  2051,  2105,  2004,  4302,  1010,  2021,  1996,  2143,  9530,\n",
      "         25243,  2015,  1996,  3894,  1997,  3166,  1046,  1012,  1047,  1012,\n",
      "          5216,  2989,  1005,  1055,  2808,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 14434,  1010,  4800,  1011,  8789,  2293,  2466,  1998,\n",
      "         16596,  1011, 10882,  6547,  1010,  5943,  2483,  2003,  1037,  2245,\n",
      "          1011,  4013, 22776,  1010, 20161,  2143,  2008,  4473,  1996,  8079,\n",
      "          1997,  1996,  9647,  2000, 16216, 27512,  3686,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2069,  2024,  1996,  2569,  3896,  1998,  7984,  4834,\n",
      "          2172,  5301,  1010,  1998,  3817, 22603,  2062, 14868, 20865,  3512,\n",
      "          2023,  2051,  2105,  2004,  4302,  1010,  2021,  1996,  2143,  9530,\n",
      "         25243,  2015,  1996,  3894,  1997,  3166,  1046,  1012,  1047,  1012,\n",
      "          5216,  2989,  1005,  1055,  2808,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2604, 0.7396],\n",
      "        [0.2348, 0.7652]]), 'input_ids': tensor([[  101,  1037, 14434,  1010,  4800,  1011,  8789,  2293,  2466,  1998,\n",
      "         16596,  1011, 10882,  6547,  1010,  5943,  2483,  2003,  1037,  2245,\n",
      "          1011,  4013, 22776,  1010, 20161,  2143,  2008,  4473,  1996,  8079,\n",
      "          1997,  1996,  9647,  2000, 16216, 27512,  3686,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2069,  2024,  1996,  2569,  3896,  1998,  7984,  4834,\n",
      "          2172,  5301,  1010,  1998,  3817, 22603,  2062, 14868, 20865,  3512,\n",
      "          2023,  2051,  2105,  2004,  4302,  1010,  2021,  1996,  2143,  9530,\n",
      "         25243,  2015,  1996,  3894,  1997,  3166,  1046,  1012,  1047,  1012,\n",
      "          5216,  2989,  1005,  1055,  2808,  1012,   102]]), 'ntok': tensor([39, 47]), 'cls_emb': tensor([[ 0.0632, -0.0190, -0.2609,  ..., -0.1879,  0.4407,  0.3037],\n",
      "        [-0.1306, -0.0944, -0.2110,  ..., -0.3523,  0.5778,  0.4002]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  3154,  1996, 16587,  2020,  1050,  1005,\n",
      "          1056,  2469,  2073,  2027,  2359,  2037,  2466,  2000,  2175,  1010,\n",
      "          1998,  2130,  2062,  3154,  2008,  2027,  3768,  1996,  4813,  2000,\n",
      "          2131,  2149,  2000,  2023,  6151, 15141, 25089,  7688,  1012,   102],\n",
      "        [  101,  1006,  1056,  1007,  2010, 11693, 19231,  2075,  6995, 28458,\n",
      "          1010,  2200,  2172,  2049,  2219,  2852, 14511,  1998, 10059,  2210,\n",
      "          2143,  1010,  2038,  2070,  7244,  2477,  2000,  2360,  2055,  2054,\n",
      "          2003,  2590,  1999,  2166,  1998,  2339,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  3154,  1996, 16587,  2020,  1050,  1005,\n",
      "          1056,  2469,  2073,  2027,  2359,  2037,  2466,  2000,  2175,  1010,\n",
      "          1998,  2130,  2062,  3154,  2008,  2027,  3768,  1996,  4813,  2000,\n",
      "          2131,  2149,  2000,  2023,  6151, 15141, 25089,  7688,  1012,   102],\n",
      "        [  101,  1006,  1056,  1007,  2010, 11693, 19231,  2075,  6995, 28458,\n",
      "          1010,  2200,  2172,  2049,  2219,  2852, 14511,  1998, 10059,  2210,\n",
      "          2143,  1010,  2038,  2070,  7244,  2477,  2000,  2360,  2055,  2054,\n",
      "          2003,  2590,  1999,  2166,  1998,  2339,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2866, 0.7134],\n",
      "        [0.2622, 0.7378]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  3154,  1996, 16587,  2020,  1050,  1005,\n",
      "          1056,  2469,  2073,  2027,  2359,  2037,  2466,  2000,  2175,  1010,\n",
      "          1998,  2130,  2062,  3154,  2008,  2027,  3768,  1996,  4813,  2000,\n",
      "          2131,  2149,  2000,  2023,  6151, 15141, 25089,  7688,  1012,   102],\n",
      "        [  101,  1006,  1056,  1007,  2010, 11693, 19231,  2075,  6995, 28458,\n",
      "          1010,  2200,  2172,  2049,  2219,  2852, 14511,  1998, 10059,  2210,\n",
      "          2143,  1010,  2038,  2070,  7244,  2477,  2000,  2360,  2055,  2054,\n",
      "          2003,  2590,  1999,  2166,  1998,  2339,  1012,   102,     0,     0]]), 'ntok': tensor([40, 38]), 'cls_emb': tensor([[ 0.1984,  0.1190, -0.1393,  ..., -0.1260,  0.6750,  0.2954],\n",
      "        [-0.3815,  0.2136, -0.2643,  ..., -0.4819,  0.3382,  0.6573]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2130,  2006,  2216,  4678,  6642,  2043,  1996, 11185,  6762,\n",
      "          8038, 15810,  2075,  1010,  4679,  1005,  1055,  2192,  2411,  5683,\n",
      "         12422,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006, 15775, 17339,  2078,  1005,  1055,  1007,  5848,  3658,\n",
      "          1999,  2019, 23408, 24755,  6024,  1010,  8321,  8089,  1997,  1037,\n",
      "          8200, 23689, 17301,  1998,  1999,  1996, 17133,  1010, 13359,  7982,\n",
      "          2016,  9005,  2005,  2014,  3494,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2130,  2006,  2216,  4678,  6642,  2043,  1996, 11185,  6762,\n",
      "          8038, 15810,  2075,  1010,  4679,  1005,  1055,  2192,  2411,  5683,\n",
      "         12422,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006, 15775, 17339,  2078,  1005,  1055,  1007,  5848,  3658,\n",
      "          1999,  2019, 23408, 24755,  6024,  1010,  8321,  8089,  1997,  1037,\n",
      "          8200, 23689, 17301,  1998,  1999,  1996, 17133,  1010, 13359,  7982,\n",
      "          2016,  9005,  2005,  2014,  3494,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2689, 0.7311],\n",
      "        [0.2530, 0.7470]]), 'input_ids': tensor([[  101,  2130,  2006,  2216,  4678,  6642,  2043,  1996, 11185,  6762,\n",
      "          8038, 15810,  2075,  1010,  4679,  1005,  1055,  2192,  2411,  5683,\n",
      "         12422,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006, 15775, 17339,  2078,  1005,  1055,  1007,  5848,  3658,\n",
      "          1999,  2019, 23408, 24755,  6024,  1010,  8321,  8089,  1997,  1037,\n",
      "          8200, 23689, 17301,  1998,  1999,  1996, 17133,  1010, 13359,  7982,\n",
      "          2016,  9005,  2005,  2014,  3494,  1012,   102]]), 'ntok': tensor([23, 37]), 'cls_emb': tensor([[-0.3625, -0.4759, -0.5449,  ...,  0.1932,  0.3609,  0.4584],\n",
      "        [-0.1695,  0.0179, -0.8030,  ..., -0.2958,  0.0410,  0.5063]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 15875,  4086, 23069,  3012,  1010, 22902, 20699,  1998,  1037,\n",
      "         20996, 26863,  2026,  7361,  2594,  3193,  1997,  2166,  1999,  1996,\n",
      "         25755,  1011,  3690,  5900,  7160, 25174,  2023,  6789,  1012,   102],\n",
      "        [  101,  2009, 18708,  2015,  1037,  5719,  1998,  6171, 17087,  7073,\n",
      "          1997,  1996,  2190,  5691,  2004, 15447,  1036,  3861,  3065,  1012,\n",
      "          1005,   102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 15875,  4086, 23069,  3012,  1010, 22902, 20699,  1998,  1037,\n",
      "         20996, 26863,  2026,  7361,  2594,  3193,  1997,  2166,  1999,  1996,\n",
      "         25755,  1011,  3690,  5900,  7160, 25174,  2023,  6789,  1012,   102],\n",
      "        [  101,  2009, 18708,  2015,  1037,  5719,  1998,  6171, 17087,  7073,\n",
      "          1997,  1996,  2190,  5691,  2004, 15447,  1036,  3861,  3065,  1012,\n",
      "          1005,   102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2397, 0.7603],\n",
      "        [0.2438, 0.7562]]), 'input_ids': tensor([[  101, 15875,  4086, 23069,  3012,  1010, 22902, 20699,  1998,  1037,\n",
      "         20996, 26863,  2026,  7361,  2594,  3193,  1997,  2166,  1999,  1996,\n",
      "         25755,  1011,  3690,  5900,  7160, 25174,  2023,  6789,  1012,   102],\n",
      "        [  101,  2009, 18708,  2015,  1037,  5719,  1998,  6171, 17087,  7073,\n",
      "          1997,  1996,  2190,  5691,  2004, 15447,  1036,  3861,  3065,  1012,\n",
      "          1005,   102,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([30, 22]), 'cls_emb': tensor([[-0.2865,  0.0530, -0.4493,  ..., -0.1522,  0.5684,  0.5966],\n",
      "        [ 0.0420,  0.1006,  0.1425,  ..., -0.3770,  0.4947,  0.4320]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3794,  1037, 20754, 23182,  2836,  2013,  1996,  2307,  3817,\n",
      "          8740,  2618, 19231,  1010,  1036,  1036,  6517,  2063,  1005,  1005,\n",
      "          4472,  1996,  2168,  2558,  2004, 23699,  2078,  1005,  1055,  1036,\n",
      "          1036, 21864, 12718,  1005,  1005,  2007,  2062,  4895, 21678,  2989,\n",
      "          2135, 12689,  3463,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  3957,  2017,  1996,  6706,  8187,  1997,  2166,  1999,  1037,\n",
      "          3376,  2103,  7021,  2083,  1996,  2159,  1997,  1037,  2839,  2040,\n",
      "          1010,  1999,  8741,  1997, 13800,  3279,  1998,  4852, 11703,  2890,\n",
      "         23270, 12672,  1010,  4282,  1999,  2010,  5944,  2008,  2002,  2003,\n",
      "          2028,  1997,  1996,  6735, 10458,  2273,  4142,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3794,  1037, 20754, 23182,  2836,  2013,  1996,  2307,  3817,\n",
      "          8740,  2618, 19231,  1010,  1036,  1036,  6517,  2063,  1005,  1005,\n",
      "          4472,  1996,  2168,  2558,  2004, 23699,  2078,  1005,  1055,  1036,\n",
      "          1036, 21864, 12718,  1005,  1005,  2007,  2062,  4895, 21678,  2989,\n",
      "          2135, 12689,  3463,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  3957,  2017,  1996,  6706,  8187,  1997,  2166,  1999,  1037,\n",
      "          3376,  2103,  7021,  2083,  1996,  2159,  1997,  1037,  2839,  2040,\n",
      "          1010,  1999,  8741,  1997, 13800,  3279,  1998,  4852, 11703,  2890,\n",
      "         23270, 12672,  1010,  4282,  1999,  2010,  5944,  2008,  2002,  2003,\n",
      "          2028,  1997,  1996,  6735, 10458,  2273,  4142,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2566, 0.7434],\n",
      "        [0.2553, 0.7447]]), 'input_ids': tensor([[  101,  3794,  1037, 20754, 23182,  2836,  2013,  1996,  2307,  3817,\n",
      "          8740,  2618, 19231,  1010,  1036,  1036,  6517,  2063,  1005,  1005,\n",
      "          4472,  1996,  2168,  2558,  2004, 23699,  2078,  1005,  1055,  1036,\n",
      "          1036, 21864, 12718,  1005,  1005,  2007,  2062,  4895, 21678,  2989,\n",
      "          2135, 12689,  3463,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  3957,  2017,  1996,  6706,  8187,  1997,  2166,  1999,  1037,\n",
      "          3376,  2103,  7021,  2083,  1996,  2159,  1997,  1037,  2839,  2040,\n",
      "          1010,  1999,  8741,  1997, 13800,  3279,  1998,  4852, 11703,  2890,\n",
      "         23270, 12672,  1010,  4282,  1999,  2010,  5944,  2008,  2002,  2003,\n",
      "          2028,  1997,  1996,  6735, 10458,  2273,  4142,  1012,   102]]), 'ntok': tensor([45, 49]), 'cls_emb': tensor([[-0.1499,  0.0974, -0.3029,  ..., -0.1525,  0.2315,  0.4551],\n",
      "        [-0.1058, -0.0597, -0.3008,  ..., -0.5789,  0.0529, -0.1461]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2065,  2017,  2024,  2019,  3364,  2040,  2064, 14396,  2000,\n",
      "          1996,  3945,  2005,  5110,  3521,  2011, 12099, 10775,  1996,  3268,\n",
      "          1997,  2500, 23542,  1010,  2059, 14631,  1005,  1055,  2466,  2003,\n",
      "          1037, 17075,  8795,  2005,  3606,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2205,  2919,  2008,  1996,  5094,  2192,\n",
      "          2002,  3594,  2000, 16130,  2010, 12760,  2003,  2036,  1037,  3082,\n",
      "          2028,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2065,  2017,  2024,  2019,  3364,  2040,  2064, 14396,  2000,\n",
      "          1996,  3945,  2005,  5110,  3521,  2011, 12099, 10775,  1996,  3268,\n",
      "          1997,  2500, 23542,  1010,  2059, 14631,  1005,  1055,  2466,  2003,\n",
      "          1037, 17075,  8795,  2005,  3606,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2205,  2919,  2008,  1996,  5094,  2192,\n",
      "          2002,  3594,  2000, 16130,  2010, 12760,  2003,  2036,  1037,  3082,\n",
      "          2028,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2363, 0.7637],\n",
      "        [0.2308, 0.7692]]), 'input_ids': tensor([[  101,  2065,  2017,  2024,  2019,  3364,  2040,  2064, 14396,  2000,\n",
      "          1996,  3945,  2005,  5110,  3521,  2011, 12099, 10775,  1996,  3268,\n",
      "          1997,  2500, 23542,  1010,  2059, 14631,  1005,  1055,  2466,  2003,\n",
      "          1037, 17075,  8795,  2005,  3606,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2205,  2919,  2008,  1996,  5094,  2192,\n",
      "          2002,  3594,  2000, 16130,  2010, 12760,  2003,  2036,  1037,  3082,\n",
      "          2028,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([37, 23]), 'cls_emb': tensor([[-0.1507, -0.2035, -0.6160,  ..., -0.4493,  0.2213,  0.3979],\n",
      "        [ 0.1122,  0.4489, -0.2798,  ...,  0.0359,  0.3296,  0.4681]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2748,  1010, 10634,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2070,  1997,  2037, 13198,  2147,  1010,  2021,  2087,  8246,\n",
      "         28616,  6906,  6321,  1998,  1999,  1996,  2203,  1010, 25730,  2003,\n",
      "          2521,  2062,  5805,  2084,  2009,  2003,  6057,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2748,  1010, 10634,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2070,  1997,  2037, 13198,  2147,  1010,  2021,  2087,  8246,\n",
      "         28616,  6906,  6321,  1998,  1999,  1996,  2203,  1010, 25730,  2003,\n",
      "          2521,  2062,  5805,  2084,  2009,  2003,  6057,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2834, 0.7166],\n",
      "        [0.2330, 0.7670]]), 'input_ids': tensor([[  101,  2748,  1010, 10634,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2070,  1997,  2037, 13198,  2147,  1010,  2021,  2087,  8246,\n",
      "         28616,  6906,  6321,  1998,  1999,  1996,  2203,  1010, 25730,  2003,\n",
      "          2521,  2062,  5805,  2084,  2009,  2003,  6057,  1012,   102]]), 'ntok': tensor([ 6, 29]), 'cls_emb': tensor([[-0.3705, -0.0308, -0.3181,  ..., -0.0745,  0.3942,  0.3153],\n",
      "        [-0.3524, -0.1281, -0.5092,  ...,  0.2045,  0.6731,  0.4489]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 23824,  4516,  2029,  2003, 14868, 29454, 12926,  2011,  7995,\n",
      "          2006,  1996,  2466,  1005,  1055,  2560,  5875,  3395,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15311,  2485,  1011, 11139,  1997,  4977,  1011,  2006,  1011,\n",
      "          9372,  1010, 24646, 24200,  5413,  2015,  1010, 11290,  7516,  1010,\n",
      "          2417, 27518,  1998,  1996, 16587,  2047, 29579,  2079,  4009,  3733,\n",
      "         26088,  2021,  2599,  7880,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 23824,  4516,  2029,  2003, 14868, 29454, 12926,  2011,  7995,\n",
      "          2006,  1996,  2466,  1005,  1055,  2560,  5875,  3395,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15311,  2485,  1011, 11139,  1997,  4977,  1011,  2006,  1011,\n",
      "          9372,  1010, 24646, 24200,  5413,  2015,  1010, 11290,  7516,  1010,\n",
      "          2417, 27518,  1998,  1996, 16587,  2047, 29579,  2079,  4009,  3733,\n",
      "         26088,  2021,  2599,  7880,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2526, 0.7474],\n",
      "        [0.2361, 0.7639]]), 'input_ids': tensor([[  101, 23824,  4516,  2029,  2003, 14868, 29454, 12926,  2011,  7995,\n",
      "          2006,  1996,  2466,  1005,  1055,  2560,  5875,  3395,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101, 15311,  2485,  1011, 11139,  1997,  4977,  1011,  2006,  1011,\n",
      "          9372,  1010, 24646, 24200,  5413,  2015,  1010, 11290,  7516,  1010,\n",
      "          2417, 27518,  1998,  1996, 16587,  2047, 29579,  2079,  4009,  3733,\n",
      "         26088,  2021,  2599,  7880,  1012,   102]]), 'ntok': tensor([20, 36]), 'cls_emb': tensor([[-0.5520, -0.4135, -0.2675,  ..., -0.2559,  0.3954,  0.2265],\n",
      "        [ 0.0465,  0.2837,  0.0364,  ..., -0.0896,  0.7261,  0.3139]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996, 28676,  9000,  2011,  3505,  4138,  4472,  1037,  2843,\n",
      "          1997,  2598,  1010,  3383,  2205,  2172,  1010,  2021,  7208,  2477,\n",
      "          2362,  1010, 15981,  1010,  2011,  1996,  2203,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 19460,  1010,  2004,  1999,  9350, 11266,  7474,  1010,  3464,\n",
      "          1037, 12127,  2007,  2019,  5648, 21386,  1998,  1037,  2613,  5592,\n",
      "          2005, 12216, 24222,  4623,  2041,  1997,  3268,  1998, 10906,  2008,\n",
      "          2453,  4728,  4025,  2852,  7875,  1998,  2061, 17080,  2094,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996, 28676,  9000,  2011,  3505,  4138,  4472,  1037,  2843,\n",
      "          1997,  2598,  1010,  3383,  2205,  2172,  1010,  2021,  7208,  2477,\n",
      "          2362,  1010, 15981,  1010,  2011,  1996,  2203,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 19460,  1010,  2004,  1999,  9350, 11266,  7474,  1010,  3464,\n",
      "          1037, 12127,  2007,  2019,  5648, 21386,  1998,  1037,  2613,  5592,\n",
      "          2005, 12216, 24222,  4623,  2041,  1997,  3268,  1998, 10906,  2008,\n",
      "          2453,  4728,  4025,  2852,  7875,  1998,  2061, 17080,  2094,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2672, 0.7328],\n",
      "        [0.2499, 0.7501]]), 'input_ids': tensor([[  101,  1996, 28676,  9000,  2011,  3505,  4138,  4472,  1037,  2843,\n",
      "          1997,  2598,  1010,  3383,  2205,  2172,  1010,  2021,  7208,  2477,\n",
      "          2362,  1010, 15981,  1010,  2011,  1996,  2203,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 19460,  1010,  2004,  1999,  9350, 11266,  7474,  1010,  3464,\n",
      "          1037, 12127,  2007,  2019,  5648, 21386,  1998,  1037,  2613,  5592,\n",
      "          2005, 12216, 24222,  4623,  2041,  1997,  3268,  1998, 10906,  2008,\n",
      "          2453,  4728,  4025,  2852,  7875,  1998,  2061, 17080,  2094,  1012,\n",
      "           102]]), 'ntok': tensor([29, 41]), 'cls_emb': tensor([[ 0.0407, -0.0997, -0.0900,  ..., -0.2266,  0.7278,  0.5421],\n",
      "        [-0.2254, -0.1216, -0.6893,  ..., -0.0864,  0.5616,  0.3136]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3494,  2024,  5875,  1998,  2411,  2200,  5541,  2135,\n",
      "          3833,  2013,  3275,  2000, 10457,  7062,  1012,   102,     0,     0],\n",
      "        [  101,  2061,  4895, 28578, 12474, 15787,  9643,  2008, 28847,  2009,\n",
      "          1037,  3899,  2763, 17367, 18186,  2000, 28735,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3494,  2024,  5875,  1998,  2411,  2200,  5541,  2135,\n",
      "          3833,  2013,  3275,  2000, 10457,  7062,  1012,   102,     0,     0],\n",
      "        [  101,  2061,  4895, 28578, 12474, 15787,  9643,  2008, 28847,  2009,\n",
      "          1037,  3899,  2763, 17367, 18186,  2000, 28735,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2740, 0.7260],\n",
      "        [0.3137, 0.6863]]), 'input_ids': tensor([[  101,  1996,  3494,  2024,  5875,  1998,  2411,  2200,  5541,  2135,\n",
      "          3833,  2013,  3275,  2000, 10457,  7062,  1012,   102,     0,     0],\n",
      "        [  101,  2061,  4895, 28578, 12474, 15787,  9643,  2008, 28847,  2009,\n",
      "          1037,  3899,  2763, 17367, 18186,  2000, 28735,  2015,  1012,   102]]), 'ntok': tensor([18, 20]), 'cls_emb': tensor([[-0.2599,  0.0546, -0.2918,  ..., -0.2321,  0.5122,  0.4316],\n",
      "        [-0.2712, -0.0706, -0.4614,  ...,  0.0035,  0.5010,  0.8304]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 19723, 11411,  1005,  1055, 27222,  5107, 19359,  2003, 20998,\n",
      "          2004,  2092,  2004,  2245,  1011,  4013, 22776,  1012,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  6001,  2097,  4299,  1996,  3185,  2020,  2625, 21934, 24759,\n",
      "          6553,  1010,  5793,  1010, 18856, 18163,  6588, 27347,  1998,  8467,\n",
      "          2135,  7356,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 19723, 11411,  1005,  1055, 27222,  5107, 19359,  2003, 20998,\n",
      "          2004,  2092,  2004,  2245,  1011,  4013, 22776,  1012,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  6001,  2097,  4299,  1996,  3185,  2020,  2625, 21934, 24759,\n",
      "          6553,  1010,  5793,  1010, 18856, 18163,  6588, 27347,  1998,  8467,\n",
      "          2135,  7356,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2278, 0.7722],\n",
      "        [0.2433, 0.7567]]), 'input_ids': tensor([[  101, 19723, 11411,  1005,  1055, 27222,  5107, 19359,  2003, 20998,\n",
      "          2004,  2092,  2004,  2245,  1011,  4013, 22776,  1012,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  6001,  2097,  4299,  1996,  3185,  2020,  2625, 21934, 24759,\n",
      "          6553,  1010,  5793,  1010, 18856, 18163,  6588, 27347,  1998,  8467,\n",
      "          2135,  7356,  1012,   102]]), 'ntok': tensor([19, 24]), 'cls_emb': tensor([[-0.1450,  0.2650,  0.0981,  ..., -0.2270,  0.3606,  0.3158],\n",
      "        [ 0.2333, -0.2103,  0.2479,  ..., -0.5074,  0.4614,  0.5520]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2017,  2097, 12636,  2007,  1037, 24509,  3193,  1997,  2129,\n",
      "          1996, 19456,  1997,  3425, 23088,  2006,  1998,  1996,  2331,  3189,\n",
      "          3310,  2000,  3745,  2250,  7292,  4077,  1996,  3888,  3189,  1012,\n",
      "           102,     0,     0,     0,     0,     0],\n",
      "        [  101,  4283,  2000, 21805,  1005,  7619,  2491,  1997,  1996,  2143,\n",
      "          1005,  1055,  6888,  1010,  1998, 20934,  6977,  2098,  2011,  2093,\n",
      "         27547,  4616,  1010,  2521,  2013,  6014,  2941,  8005,  2125,  2023,\n",
      "         24828, 26536, 18483,  2552,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2017,  2097, 12636,  2007,  1037, 24509,  3193,  1997,  2129,\n",
      "          1996, 19456,  1997,  3425, 23088,  2006,  1998,  1996,  2331,  3189,\n",
      "          3310,  2000,  3745,  2250,  7292,  4077,  1996,  3888,  3189,  1012,\n",
      "           102,     0,     0,     0,     0,     0],\n",
      "        [  101,  4283,  2000, 21805,  1005,  7619,  2491,  1997,  1996,  2143,\n",
      "          1005,  1055,  6888,  1010,  1998, 20934,  6977,  2098,  2011,  2093,\n",
      "         27547,  4616,  1010,  2521,  2013,  6014,  2941,  8005,  2125,  2023,\n",
      "         24828, 26536, 18483,  2552,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2321, 0.7679],\n",
      "        [0.2458, 0.7542]]), 'input_ids': tensor([[  101,  2017,  2097, 12636,  2007,  1037, 24509,  3193,  1997,  2129,\n",
      "          1996, 19456,  1997,  3425, 23088,  2006,  1998,  1996,  2331,  3189,\n",
      "          3310,  2000,  3745,  2250,  7292,  4077,  1996,  3888,  3189,  1012,\n",
      "           102,     0,     0,     0,     0,     0],\n",
      "        [  101,  4283,  2000, 21805,  1005,  7619,  2491,  1997,  1996,  2143,\n",
      "          1005,  1055,  6888,  1010,  1998, 20934,  6977,  2098,  2011,  2093,\n",
      "         27547,  4616,  1010,  2521,  2013,  6014,  2941,  8005,  2125,  2023,\n",
      "         24828, 26536, 18483,  2552,  1012,   102]]), 'ntok': tensor([31, 36]), 'cls_emb': tensor([[ 0.1431, -0.1394,  0.2047,  ..., -0.3191,  0.6323,  0.1872],\n",
      "        [-0.0796, -0.2932, -0.1961,  ..., -0.1808,  0.2476,  0.4776]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3291,  2007,  2023,  2143,  2003,  2008,  2009, 14087,\n",
      "          3579,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7460,  2000,  3817,  2154,  1011,  4572,  2004,  2172,  2004,\n",
      "          2009,  7460,  2000,  3235,  8040,  5668,  6810,  1025,  2009,  1005,\n",
      "          1055,  1037, 13432,  2836,  1999,  1037,  2502,  1010,  8782,  2100,\n",
      "          1010, 14888,  1010,  5866,  1998,  3811,  3144,  2143,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3291,  2007,  2023,  2143,  2003,  2008,  2009, 14087,\n",
      "          3579,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7460,  2000,  3817,  2154,  1011,  4572,  2004,  2172,  2004,\n",
      "          2009,  7460,  2000,  3235,  8040,  5668,  6810,  1025,  2009,  1005,\n",
      "          1055,  1037, 13432,  2836,  1999,  1037,  2502,  1010,  8782,  2100,\n",
      "          1010, 14888,  1010,  5866,  1998,  3811,  3144,  2143,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2506, 0.7494],\n",
      "        [0.2398, 0.7602]]), 'input_ids': tensor([[  101,  1996,  3291,  2007,  2023,  2143,  2003,  2008,  2009, 14087,\n",
      "          3579,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7460,  2000,  3817,  2154,  1011,  4572,  2004,  2172,  2004,\n",
      "          2009,  7460,  2000,  3235,  8040,  5668,  6810,  1025,  2009,  1005,\n",
      "          1055,  1037, 13432,  2836,  1999,  1037,  2502,  1010,  8782,  2100,\n",
      "          1010, 14888,  1010,  5866,  1998,  3811,  3144,  2143,  1012,   102]]), 'ntok': tensor([13, 40]), 'cls_emb': tensor([[-0.2778, -0.1584, -0.2013,  ..., -0.4582,  0.5650,  0.2782],\n",
      "        [ 0.0844,  0.0602, -0.2063,  ..., -0.1992,  0.3487,  0.3582]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  7336,  2048, 15572,  1011,  1011,  2028,  2009,  3957,  2185,\n",
      "          1998,  1996,  2060,  3794,  2107,  6649,  4567,  3494,  2008,  2049,\n",
      "          9560,  6684,  5609,  1012,   102,     0,     0,     0],\n",
      "        [  101,  1037,  2694,  2806,  4028,  6547,  2007,  1037,  2261,  2502,\n",
      "          3898,  5312,  1006,  2164,  2028,  2008,  3849,  2000,  2022,  2081,\n",
      "          2005,  1037,  2367,  2143, 10462,  1007,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  7336,  2048, 15572,  1011,  1011,  2028,  2009,  3957,  2185,\n",
      "          1998,  1996,  2060,  3794,  2107,  6649,  4567,  3494,  2008,  2049,\n",
      "          9560,  6684,  5609,  1012,   102,     0,     0,     0],\n",
      "        [  101,  1037,  2694,  2806,  4028,  6547,  2007,  1037,  2261,  2502,\n",
      "          3898,  5312,  1006,  2164,  2028,  2008,  3849,  2000,  2022,  2081,\n",
      "          2005,  1037,  2367,  2143, 10462,  1007,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2787, 0.7213],\n",
      "        [0.2842, 0.7158]]), 'input_ids': tensor([[  101,  7336,  2048, 15572,  1011,  1011,  2028,  2009,  3957,  2185,\n",
      "          1998,  1996,  2060,  3794,  2107,  6649,  4567,  3494,  2008,  2049,\n",
      "          9560,  6684,  5609,  1012,   102,     0,     0,     0],\n",
      "        [  101,  1037,  2694,  2806,  4028,  6547,  2007,  1037,  2261,  2502,\n",
      "          3898,  5312,  1006,  2164,  2028,  2008,  3849,  2000,  2022,  2081,\n",
      "          2005,  1037,  2367,  2143, 10462,  1007,  1012,   102]]), 'ntok': tensor([25, 28]), 'cls_emb': tensor([[-0.2629, -0.2767, -0.0967,  ..., -0.0496,  0.3008,  0.4521],\n",
      "        [-0.3896, -0.6020, -0.1447,  ..., -0.2526,  0.8201,  0.2103]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2011,  1011,  1996,  1011,  3616,  5776,  1013,  3460,\n",
      "         27263,  2008,  4472,  2035,  1996,  5156,  2598,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037, 14726, 16376,  2147,  1997,  6196,\n",
      "          2486,  1998,  3606,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2011,  1011,  1996,  1011,  3616,  5776,  1013,  3460,\n",
      "         27263,  2008,  4472,  2035,  1996,  5156,  2598,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037, 14726, 16376,  2147,  1997,  6196,\n",
      "          2486,  1998,  3606,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2808, 0.7192],\n",
      "        [0.2576, 0.7424]]), 'input_ids': tensor([[  101,  1037,  2011,  1011,  1996,  1011,  3616,  5776,  1013,  3460,\n",
      "         27263,  2008,  4472,  2035,  1996,  5156,  2598,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037, 14726, 16376,  2147,  1997,  6196,\n",
      "          2486,  1998,  3606,  1012,   102,     0,     0,     0]]), 'ntok': tensor([18, 15]), 'cls_emb': tensor([[-0.5370, -0.3763, -0.0762,  ..., -0.0576,  0.3434,  0.7526],\n",
      "        [ 0.0862, -0.1393, -0.2367,  ..., -0.3638,  0.0667,  0.5069]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2096,  6151,  2483, 29462,  2003,  1050,  1005,  1056,  3599,\n",
      "          1037,  2152,  1010,  2009,  2003,  1037, 13940,  1010, 29369,  2210,\n",
      "          3185,  2008,  3138,  2720,  1012,  2940,  3020,  2084,  2002,  1005,\n",
      "          1055,  2042,  1999,  1037,  2096,  1012,   102],\n",
      "        [  101,  6057,  2021,  2566, 22360, 27191,  7263,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2096,  6151,  2483, 29462,  2003,  1050,  1005,  1056,  3599,\n",
      "          1037,  2152,  1010,  2009,  2003,  1037, 13940,  1010, 29369,  2210,\n",
      "          3185,  2008,  3138,  2720,  1012,  2940,  3020,  2084,  2002,  1005,\n",
      "          1055,  2042,  1999,  1037,  2096,  1012,   102],\n",
      "        [  101,  6057,  2021,  2566, 22360, 27191,  7263,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2696, 0.7304],\n",
      "        [0.2881, 0.7119]]), 'input_ids': tensor([[  101,  2096,  6151,  2483, 29462,  2003,  1050,  1005,  1056,  3599,\n",
      "          1037,  2152,  1010,  2009,  2003,  1037, 13940,  1010, 29369,  2210,\n",
      "          3185,  2008,  3138,  2720,  1012,  2940,  3020,  2084,  2002,  1005,\n",
      "          1055,  2042,  1999,  1037,  2096,  1012,   102],\n",
      "        [  101,  6057,  2021,  2566, 22360, 27191,  7263,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([37,  9]), 'cls_emb': tensor([[ 0.0270, -0.2297,  0.1827,  ..., -0.0515,  0.4965,  0.2250],\n",
      "        [-0.5010, -0.1172, -0.4788,  ..., -0.2848,  0.1563,  0.5202]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1039,  4160,  1005,  1055,  9185,  1997,  3324,  1998,  1996,\n",
      "          2293,  1997,  5988,  1011,  1998,  1011,  2969,  6083,  2498,  2625,\n",
      "          2084,  1037,  2047,  2376,  2008, 17210,  2000,  2022,  2641,  2004,\n",
      "          1037,  2825,  6332,  2000,  1996,  2190,  2647,  5501,  1012,   102,\n",
      "             0],\n",
      "        [  101,  2130,  2065,  2017,  2079,  1050,  1005,  1056,  2228,  1006,\n",
      "          7618,  2121,  1005,  1055,  1007,  2151,  2062,  5905,  1997,  4735,\n",
      "          4023,  2084,  2087,  3824,  2163,  3549,  1010,  2002,  1005,  1040,\n",
      "          2469,  2191,  1037, 20747,  3979,  2307,  4569,  2000,  3422,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1039,  4160,  1005,  1055,  9185,  1997,  3324,  1998,  1996,\n",
      "          2293,  1997,  5988,  1011,  1998,  1011,  2969,  6083,  2498,  2625,\n",
      "          2084,  1037,  2047,  2376,  2008, 17210,  2000,  2022,  2641,  2004,\n",
      "          1037,  2825,  6332,  2000,  1996,  2190,  2647,  5501,  1012,   102,\n",
      "             0],\n",
      "        [  101,  2130,  2065,  2017,  2079,  1050,  1005,  1056,  2228,  1006,\n",
      "          7618,  2121,  1005,  1055,  1007,  2151,  2062,  5905,  1997,  4735,\n",
      "          4023,  2084,  2087,  3824,  2163,  3549,  1010,  2002,  1005,  1040,\n",
      "          2469,  2191,  1037, 20747,  3979,  2307,  4569,  2000,  3422,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2435, 0.7565],\n",
      "        [0.2426, 0.7574]]), 'input_ids': tensor([[  101,  1039,  4160,  1005,  1055,  9185,  1997,  3324,  1998,  1996,\n",
      "          2293,  1997,  5988,  1011,  1998,  1011,  2969,  6083,  2498,  2625,\n",
      "          2084,  1037,  2047,  2376,  2008, 17210,  2000,  2022,  2641,  2004,\n",
      "          1037,  2825,  6332,  2000,  1996,  2190,  2647,  5501,  1012,   102,\n",
      "             0],\n",
      "        [  101,  2130,  2065,  2017,  2079,  1050,  1005,  1056,  2228,  1006,\n",
      "          7618,  2121,  1005,  1055,  1007,  2151,  2062,  5905,  1997,  4735,\n",
      "          4023,  2084,  2087,  3824,  2163,  3549,  1010,  2002,  1005,  1040,\n",
      "          2469,  2191,  1037, 20747,  3979,  2307,  4569,  2000,  3422,  1012,\n",
      "           102]]), 'ntok': tensor([40, 41]), 'cls_emb': tensor([[-0.3420,  0.3227, -0.0539,  ..., -0.4518,  0.2169,  0.2473],\n",
      "        [ 0.1516, -0.0266, -0.1683,  ..., -0.3887,  0.5485,  0.5335]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 28190,  1999,  2049, 11619,  1010, 14888,  2005,  2049,  9313,\n",
      "          6991,  1010,  1996,  3682,  3836,  2003,  1037,  2143,  2008, 13366,\n",
      "          3111,  4937, 20265,  6935,  3370,  1012,   102],\n",
      "        [  101,  1037, 23675,  3686,  8312,  2008,  6919,  2135, 25308,  2015,\n",
      "          1037, 25303,  2724,  1999,  7612,  2007, 25303,  7385,  1999,  2526,\n",
      "          1012,   102,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 28190,  1999,  2049, 11619,  1010, 14888,  2005,  2049,  9313,\n",
      "          6991,  1010,  1996,  3682,  3836,  2003,  1037,  2143,  2008, 13366,\n",
      "          3111,  4937, 20265,  6935,  3370,  1012,   102],\n",
      "        [  101,  1037, 23675,  3686,  8312,  2008,  6919,  2135, 25308,  2015,\n",
      "          1037, 25303,  2724,  1999,  7612,  2007, 25303,  7385,  1999,  2526,\n",
      "          1012,   102,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2505, 0.7495],\n",
      "        [0.3174, 0.6826]]), 'input_ids': tensor([[  101, 28190,  1999,  2049, 11619,  1010, 14888,  2005,  2049,  9313,\n",
      "          6991,  1010,  1996,  3682,  3836,  2003,  1037,  2143,  2008, 13366,\n",
      "          3111,  4937, 20265,  6935,  3370,  1012,   102],\n",
      "        [  101,  1037, 23675,  3686,  8312,  2008,  6919,  2135, 25308,  2015,\n",
      "          1037, 25303,  2724,  1999,  7612,  2007, 25303,  7385,  1999,  2526,\n",
      "          1012,   102,     0,     0,     0,     0,     0]]), 'ntok': tensor([27, 22]), 'cls_emb': tensor([[-0.2239,  0.0405, -0.3629,  ..., -0.2378,  0.3078,  0.5567],\n",
      "        [-0.5348, -0.5971, -0.1431,  ..., -0.4612,  0.5574,  0.6851]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  5896,  2003,  1050,  1005,  1056,  2200,  2204,  1025,\n",
      "          2025,  2130,  2619,  2004, 12785,  2004, 15107,  1006,  1996,  3364,\n",
      "          1007,  2064,  2191,  2009,  2147,  1012,   102],\n",
      "        [  101,  1006,  1041,  1007, 18834, 28488,  1010,  2296,  2801,  1999,\n",
      "          2023,  2143,  2003, 12953,  2091,  1996,  2474, 18886,  2638,  1997,\n",
      "         27117,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  5896,  2003,  1050,  1005,  1056,  2200,  2204,  1025,\n",
      "          2025,  2130,  2619,  2004, 12785,  2004, 15107,  1006,  1996,  3364,\n",
      "          1007,  2064,  2191,  2009,  2147,  1012,   102],\n",
      "        [  101,  1006,  1041,  1007, 18834, 28488,  1010,  2296,  2801,  1999,\n",
      "          2023,  2143,  2003, 12953,  2091,  1996,  2474, 18886,  2638,  1997,\n",
      "         27117,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2632, 0.7368],\n",
      "        [0.2828, 0.7172]]), 'input_ids': tensor([[  101,  1996,  5896,  2003,  1050,  1005,  1056,  2200,  2204,  1025,\n",
      "          2025,  2130,  2619,  2004, 12785,  2004, 15107,  1006,  1996,  3364,\n",
      "          1007,  2064,  2191,  2009,  2147,  1012,   102],\n",
      "        [  101,  1006,  1041,  1007, 18834, 28488,  1010,  2296,  2801,  1999,\n",
      "          2023,  2143,  2003, 12953,  2091,  1996,  2474, 18886,  2638,  1997,\n",
      "         27117,  1012,   102,     0,     0,     0,     0]]), 'ntok': tensor([27, 23]), 'cls_emb': tensor([[ 0.1832,  0.0985, -0.0237,  ..., -0.1693,  0.4540,  0.6478],\n",
      "        [-0.2136,  0.0789, -0.1441,  ..., -0.3327,  0.3372,  0.6028]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  9476,  2008,  1005,  1055,  5621, 21014,  1999,  9531,\n",
      "          1010,  1998,  1037,  2466,  2008,  1005,  1055, 17075,  1998,  2540,\n",
      "         26675,  1011,  1011,  2130,  2065,  1996,  2540,  7460,  2000,  1037,\n",
      "          2502,  1010,  2176,  1011, 15817, 12810, 20984,  2890,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055, 12873,  1010,  2021,  2062, 14780,  1010,\n",
      "          2009,  1005,  1055,  2074,  2025, 12459,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  9476,  2008,  1005,  1055,  5621, 21014,  1999,  9531,\n",
      "          1010,  1998,  1037,  2466,  2008,  1005,  1055, 17075,  1998,  2540,\n",
      "         26675,  1011,  1011,  2130,  2065,  1996,  2540,  7460,  2000,  1037,\n",
      "          2502,  1010,  2176,  1011, 15817, 12810, 20984,  2890,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055, 12873,  1010,  2021,  2062, 14780,  1010,\n",
      "          2009,  1005,  1055,  2074,  2025, 12459,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2566, 0.7434],\n",
      "        [0.2601, 0.7399]]), 'input_ids': tensor([[  101,  1037,  9476,  2008,  1005,  1055,  5621, 21014,  1999,  9531,\n",
      "          1010,  1998,  1037,  2466,  2008,  1005,  1055, 17075,  1998,  2540,\n",
      "         26675,  1011,  1011,  2130,  2065,  1996,  2540,  7460,  2000,  1037,\n",
      "          2502,  1010,  2176,  1011, 15817, 12810, 20984,  2890,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055, 12873,  1010,  2021,  2062, 14780,  1010,\n",
      "          2009,  1005,  1055,  2074,  2025, 12459,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([40, 18]), 'cls_emb': tensor([[-0.2039, -0.3573, -0.2188,  ..., -0.1845,  0.4764,  0.4628],\n",
      "        [ 0.2878,  0.0639, -0.3046,  ...,  0.0468,  0.0366,  0.6233]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 20010, 11636,  2003,  4821,  1037, 23100, 23855,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2004,  1037, 19075,  1997,  7048,  7657,  2993,  2000,  2022,\n",
      "          1037, 19219,  6508, 14366,  1997, 11189,  7570,  5283,  2213,  1010,\n",
      "          2025,  2130,  5796,  1012,  2417, 12830,  1005,  1055, 13969,  2102,\n",
      "          4073,  2064,  2417, 21564,  2009,  2013, 20625, 23069,  3012,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 20010, 11636,  2003,  4821,  1037, 23100, 23855,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2004,  1037, 19075,  1997,  7048,  7657,  2993,  2000,  2022,\n",
      "          1037, 19219,  6508, 14366,  1997, 11189,  7570,  5283,  2213,  1010,\n",
      "          2025,  2130,  5796,  1012,  2417, 12830,  1005,  1055, 13969,  2102,\n",
      "          4073,  2064,  2417, 21564,  2009,  2013, 20625, 23069,  3012,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2463, 0.7537],\n",
      "        [0.2410, 0.7590]]), 'input_ids': tensor([[  101, 20010, 11636,  2003,  4821,  1037, 23100, 23855,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2004,  1037, 19075,  1997,  7048,  7657,  2993,  2000,  2022,\n",
      "          1037, 19219,  6508, 14366,  1997, 11189,  7570,  5283,  2213,  1010,\n",
      "          2025,  2130,  5796,  1012,  2417, 12830,  1005,  1055, 13969,  2102,\n",
      "          4073,  2064,  2417, 21564,  2009,  2013, 20625, 23069,  3012,  1012,\n",
      "           102]]), 'ntok': tensor([10, 41]), 'cls_emb': tensor([[ 0.1416,  0.2914, -0.1103,  ..., -0.1947,  0.2758,  0.5327],\n",
      "        [ 0.0535,  0.0385, -0.1587,  ..., -0.1299,  0.2290,  0.7228]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019, 19401,  2135, 19275,  1998,  6051,  6925,  1012,   102],\n",
      "        [  101,  2023,  2003,  2061,  2919,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019, 19401,  2135, 19275,  1998,  6051,  6925,  1012,   102],\n",
      "        [  101,  2023,  2003,  2061,  2919,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2807, 0.7193],\n",
      "        [0.2570, 0.7430]]), 'input_ids': tensor([[  101,  2019, 19401,  2135, 19275,  1998,  6051,  6925,  1012,   102],\n",
      "        [  101,  2023,  2003,  2061,  2919,  1012,   102,     0,     0,     0]]), 'ntok': tensor([10,  7]), 'cls_emb': tensor([[-0.3809, -0.4126, -0.1968,  ..., -0.4837,  0.1086,  0.4782],\n",
      "        [-0.0893,  0.5692, -0.1263,  ..., -0.3038,  0.1976,  0.6326]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009, 27397,  2482, 12417,  1005,  1055,  5848,  2005,  5755,\n",
      "          1010,  2021,  2025,  3053,  2438,  1998,  2025,  2302, 10095,  3070,\n",
      "          2296,  4530,  1997,  2028,  1005,  1055, 11752,  2000,  2131,  2000,\n",
      "          1996,  2204,  4933,  1012,   102],\n",
      "        [  101,  2422,  2086,  1013,  2195, 24136, 10898,  1013,  3798,  1998,\n",
      "          3798,  1997, 29454,  8939,  5007, 14438,  2488,  2084,  1996,  6770,\n",
      "         18424, 27860,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009, 27397,  2482, 12417,  1005,  1055,  5848,  2005,  5755,\n",
      "          1010,  2021,  2025,  3053,  2438,  1998,  2025,  2302, 10095,  3070,\n",
      "          2296,  4530,  1997,  2028,  1005,  1055, 11752,  2000,  2131,  2000,\n",
      "          1996,  2204,  4933,  1012,   102],\n",
      "        [  101,  2422,  2086,  1013,  2195, 24136, 10898,  1013,  3798,  1998,\n",
      "          3798,  1997, 29454,  8939,  5007, 14438,  2488,  2084,  1996,  6770,\n",
      "         18424, 27860,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2628, 0.7372],\n",
      "        [0.2591, 0.7409]]), 'input_ids': tensor([[  101,  2009, 27397,  2482, 12417,  1005,  1055,  5848,  2005,  5755,\n",
      "          1010,  2021,  2025,  3053,  2438,  1998,  2025,  2302, 10095,  3070,\n",
      "          2296,  4530,  1997,  2028,  1005,  1055, 11752,  2000,  2131,  2000,\n",
      "          1996,  2204,  4933,  1012,   102],\n",
      "        [  101,  2422,  2086,  1013,  2195, 24136, 10898,  1013,  3798,  1998,\n",
      "          3798,  1997, 29454,  8939,  5007, 14438,  2488,  2084,  1996,  6770,\n",
      "         18424, 27860,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 24]), 'cls_emb': tensor([[ 0.1943,  0.1134, -0.1570,  ...,  0.1341,  0.3731,  0.5424],\n",
      "        [-0.5701, -0.2623,  0.0145,  ..., -0.2999,  0.1309,  0.1238]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2055,  2206,  2115,  5544,  1010,  2053,\n",
      "          3043,  2054,  2115,  3008,  2228,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1996,  3452,  3466,  2003,  2625,  2066,  1037,  2336,  1005,\n",
      "          1055,  3185,  2084,  1037, 15680,  2143,  2005,  2925,  5365,  5271,\n",
      "         12166,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2055,  2206,  2115,  5544,  1010,  2053,\n",
      "          3043,  2054,  2115,  3008,  2228,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1996,  3452,  3466,  2003,  2625,  2066,  1037,  2336,  1005,\n",
      "          1055,  3185,  2084,  1037, 15680,  2143,  2005,  2925,  5365,  5271,\n",
      "         12166,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2415, 0.7585],\n",
      "        [0.2591, 0.7409]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2055,  2206,  2115,  5544,  1010,  2053,\n",
      "          3043,  2054,  2115,  3008,  2228,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1996,  3452,  3466,  2003,  2625,  2066,  1037,  2336,  1005,\n",
      "          1055,  3185,  2084,  1037, 15680,  2143,  2005,  2925,  5365,  5271,\n",
      "         12166,  1012,   102]]), 'ntok': tensor([17, 23]), 'cls_emb': tensor([[ 0.2178,  0.0885, -0.4201,  ..., -0.2737,  0.0215,  0.5523],\n",
      "        [ 0.2433,  0.0717,  0.2347,  ..., -0.2846,  0.4753,  0.8723]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 14453,  2011, 10424,  9257,  1998,  3766,  1005,  1055, 11813,\n",
      "          4616,  1010,  1996,  2143,  1005,  1055,  2373,  3658,  1999,  2049,\n",
      "         11619,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4406,  1996, 26203,  1059,  3511,  1011, 25307,  3466,  1997,\n",
      "          2087,  5365, 14927,  1010,  2839,  2458,  1011,  1011,  1998,  2062,\n",
      "         14780,  1010,  2839, 26452,  1011,  1011,  2003,  2012,  1996,  2540,\n",
      "          1997,  3059,  2005,  4088, 16912,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 14453,  2011, 10424,  9257,  1998,  3766,  1005,  1055, 11813,\n",
      "          4616,  1010,  1996,  2143,  1005,  1055,  2373,  3658,  1999,  2049,\n",
      "         11619,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4406,  1996, 26203,  1059,  3511,  1011, 25307,  3466,  1997,\n",
      "          2087,  5365, 14927,  1010,  2839,  2458,  1011,  1011,  1998,  2062,\n",
      "         14780,  1010,  2839, 26452,  1011,  1011,  2003,  2012,  1996,  2540,\n",
      "          1997,  3059,  2005,  4088, 16912,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2451, 0.7549],\n",
      "        [0.2538, 0.7462]]), 'input_ids': tensor([[  101, 14453,  2011, 10424,  9257,  1998,  3766,  1005,  1055, 11813,\n",
      "          4616,  1010,  1996,  2143,  1005,  1055,  2373,  3658,  1999,  2049,\n",
      "         11619,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4406,  1996, 26203,  1059,  3511,  1011, 25307,  3466,  1997,\n",
      "          2087,  5365, 14927,  1010,  2839,  2458,  1011,  1011,  1998,  2062,\n",
      "         14780,  1010,  2839, 26452,  1011,  1011,  2003,  2012,  1996,  2540,\n",
      "          1997,  3059,  2005,  4088, 16912,  1012,   102]]), 'ntok': tensor([23, 37]), 'cls_emb': tensor([[-0.2540,  0.0248, -0.5290,  ..., -0.2497,  0.2265,  0.5482],\n",
      "        [-0.1023, -0.2999, -0.2485,  ..., -0.1051,  0.2376,  0.5576]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  8297,  2008,  1005,  1055,  2172,  2205,  2502,  2005,\n",
      "          2049, 28101,  8376,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  6676,  1005,  1055,  4870,  8509,  2049,  2540,  1999,  1996,\n",
      "          2157,  2173,  1010,  2021,  2049, 14332,  2024,  1999,  2053,  3327,\n",
      "          2173,  2012,  2035,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  8297,  2008,  1005,  1055,  2172,  2205,  2502,  2005,\n",
      "          2049, 28101,  8376,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  6676,  1005,  1055,  4870,  8509,  2049,  2540,  1999,  1996,\n",
      "          2157,  2173,  1010,  2021,  2049, 14332,  2024,  1999,  2053,  3327,\n",
      "          2173,  2012,  2035,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2977, 0.7023],\n",
      "        [0.2612, 0.7388]]), 'input_ids': tensor([[  101,  1037,  8297,  2008,  1005,  1055,  2172,  2205,  2502,  2005,\n",
      "          2049, 28101,  8376,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  6676,  1005,  1055,  4870,  8509,  2049,  2540,  1999,  1996,\n",
      "          2157,  2173,  1010,  2021,  2049, 14332,  2024,  1999,  2053,  3327,\n",
      "          2173,  2012,  2035,  1012,   102]]), 'ntok': tensor([15, 25]), 'cls_emb': tensor([[-0.1649, -0.0961,  0.1679,  ..., -0.3159,  0.5216,  0.6402],\n",
      "        [-0.0313,  0.0368, -0.1009,  ..., -0.0988,  0.2458,  0.7174]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2757,  7406,  2135, 10634,  1010, 14719,  2098,  1999,  9530,\n",
      "          6767,  7630,  3064, 11463,  7716, 14672,  1010,  2512,  5054, 19570,\n",
      "          2389, 15723,  7446,  1998, 10551,  1011,  3356,  1011,  5423,  4450,\n",
      "          6313,  2791,  1012,   102],\n",
      "        [  101,  5202, 14151,  2038,  2053,  7224,  1010,  2053,  6980,  1011,\n",
      "          1011,  2498,  2021,  3465,  3678,  1010, 13109, 29544,  2185,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2757,  7406,  2135, 10634,  1010, 14719,  2098,  1999,  9530,\n",
      "          6767,  7630,  3064, 11463,  7716, 14672,  1010,  2512,  5054, 19570,\n",
      "          2389, 15723,  7446,  1998, 10551,  1011,  3356,  1011,  5423,  4450,\n",
      "          6313,  2791,  1012,   102],\n",
      "        [  101,  5202, 14151,  2038,  2053,  7224,  1010,  2053,  6980,  1011,\n",
      "          1011,  2498,  2021,  3465,  3678,  1010, 13109, 29544,  2185,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2830, 0.7170],\n",
      "        [0.2738, 0.7262]]), 'input_ids': tensor([[  101,  2757,  7406,  2135, 10634,  1010, 14719,  2098,  1999,  9530,\n",
      "          6767,  7630,  3064, 11463,  7716, 14672,  1010,  2512,  5054, 19570,\n",
      "          2389, 15723,  7446,  1998, 10551,  1011,  3356,  1011,  5423,  4450,\n",
      "          6313,  2791,  1012,   102],\n",
      "        [  101,  5202, 14151,  2038,  2053,  7224,  1010,  2053,  6980,  1011,\n",
      "          1011,  2498,  2021,  3465,  3678,  1010, 13109, 29544,  2185,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 21]), 'cls_emb': tensor([[-0.2783,  0.0609, -0.1039,  ..., -0.2449,  0.4479,  0.3384],\n",
      "        [-0.4498,  0.1198, -0.0113,  ..., -0.1720,  0.4625,  0.7543]])}\n",
      "encoded input is: {'input_ids': tensor([[ 101, 1996, 2143, 2003, 3928, 1010, 7801, 1998, 6057, 1012,  102,    0,\n",
      "            0,    0,    0,    0,    0],\n",
      "        [ 101, 1998, 2008, 1005, 1055, 1037, 2502, 2112, 1997, 2339, 2057, 2175,\n",
      "         2000, 1996, 5691, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[ 101, 1996, 2143, 2003, 3928, 1010, 7801, 1998, 6057, 1012,  102,    0,\n",
      "            0,    0,    0,    0,    0],\n",
      "        [ 101, 1998, 2008, 1005, 1055, 1037, 2502, 2112, 1997, 2339, 2057, 2175,\n",
      "         2000, 1996, 5691, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2486, 0.7514],\n",
      "        [0.2677, 0.7323]]), 'input_ids': tensor([[ 101, 1996, 2143, 2003, 3928, 1010, 7801, 1998, 6057, 1012,  102,    0,\n",
      "            0,    0,    0,    0,    0],\n",
      "        [ 101, 1998, 2008, 1005, 1055, 1037, 2502, 2112, 1997, 2339, 2057, 2175,\n",
      "         2000, 1996, 5691, 1012,  102]]), 'ntok': tensor([11, 17]), 'cls_emb': tensor([[-0.1683, -0.0403, -0.1391,  ..., -0.5386,  0.4218,  0.1375],\n",
      "        [ 0.3064,  0.1373, -0.3014,  ..., -0.1686,  0.2967,  0.4947]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  8579,  2121, 17364,  4024,  1011,  1011, 25493,  7472,  1010,\n",
      "          2189,  1010, 23873,  1998,  2895,  1012,   102,     0,     0],\n",
      "        [  101,  1996,  3576,  4481,  4193,  1006,  6173,  1007,  1012,  1012,\n",
      "          1012,  2433,  1037, 24842,  3723,  3923, 16061,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  8579,  2121, 17364,  4024,  1011,  1011, 25493,  7472,  1010,\n",
      "          2189,  1010, 23873,  1998,  2895,  1012,   102,     0,     0],\n",
      "        [  101,  1996,  3576,  4481,  4193,  1006,  6173,  1007,  1012,  1012,\n",
      "          1012,  2433,  1037, 24842,  3723,  3923, 16061,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2522, 0.7478],\n",
      "        [0.2651, 0.7349]]), 'input_ids': tensor([[  101,  8579,  2121, 17364,  4024,  1011,  1011, 25493,  7472,  1010,\n",
      "          2189,  1010, 23873,  1998,  2895,  1012,   102,     0,     0],\n",
      "        [  101,  1996,  3576,  4481,  4193,  1006,  6173,  1007,  1012,  1012,\n",
      "          1012,  2433,  1037, 24842,  3723,  3923, 16061,  1012,   102]]), 'ntok': tensor([17, 19]), 'cls_emb': tensor([[ 0.0286, -0.2699,  0.2013,  ..., -0.2051,  0.3342, -0.0294],\n",
      "        [-0.2022,  0.2127, -0.1594,  ..., -0.2411,  0.3717,  0.4284]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 13433, 25593,  1998, 17075,  2466,  2055,  6550,  1010,\n",
      "          2833,  1997,  2293,  3138,  2149,  2006,  1037, 16906,  2100,  2021,\n",
      "         17087,  4990,  1997,  1996,  2540,  1012,   102],\n",
      "        [  101,  1037,  3185,  2008,  5147, 10188,  2229,  1037,  2190,  4855,\n",
      "          3117,  2046,  1037,  2051, 15643,  2008, 25979,  2008,  2017,  4468,\n",
      "          1996, 26631,  7451, 14904,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 13433, 25593,  1998, 17075,  2466,  2055,  6550,  1010,\n",
      "          2833,  1997,  2293,  3138,  2149,  2006,  1037, 16906,  2100,  2021,\n",
      "         17087,  4990,  1997,  1996,  2540,  1012,   102],\n",
      "        [  101,  1037,  3185,  2008,  5147, 10188,  2229,  1037,  2190,  4855,\n",
      "          3117,  2046,  1037,  2051, 15643,  2008, 25979,  2008,  2017,  4468,\n",
      "          1996, 26631,  7451, 14904,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2466, 0.7534],\n",
      "        [0.2743, 0.7257]]), 'input_ids': tensor([[  101,  1037, 13433, 25593,  1998, 17075,  2466,  2055,  6550,  1010,\n",
      "          2833,  1997,  2293,  3138,  2149,  2006,  1037, 16906,  2100,  2021,\n",
      "         17087,  4990,  1997,  1996,  2540,  1012,   102],\n",
      "        [  101,  1037,  3185,  2008,  5147, 10188,  2229,  1037,  2190,  4855,\n",
      "          3117,  2046,  1037,  2051, 15643,  2008, 25979,  2008,  2017,  4468,\n",
      "          1996, 26631,  7451, 14904,  1012,   102,     0]]), 'ntok': tensor([27, 26]), 'cls_emb': tensor([[-0.0171, -0.0770, -0.3186,  ..., -0.1650,  0.4451,  0.1010],\n",
      "        [-0.2873, -0.4396, -0.5081,  ..., -0.2190,  0.5689,  0.3356]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996, 14954,  2599,  4616, 15770,  3037,  1998, 26452,  1010,\n",
      "          2021,  1996,  4990,  2003,  2521,  2062,  5875,  2084,  1996,  2345,\n",
      "          7688,  1012,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5001,  8490,  6632,  1005,  1055,  3754,  2000, 16636,  9940,\n",
      "          1998,  3246,  2573,  2007, 14077,  1005,  1055,  7591,  9597,  2000,\n",
      "          2191,  2023,  1037,  2048,  1011,  3364,  3040,  2465,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996, 14954,  2599,  4616, 15770,  3037,  1998, 26452,  1010,\n",
      "          2021,  1996,  4990,  2003,  2521,  2062,  5875,  2084,  1996,  2345,\n",
      "          7688,  1012,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5001,  8490,  6632,  1005,  1055,  3754,  2000, 16636,  9940,\n",
      "          1998,  3246,  2573,  2007, 14077,  1005,  1055,  7591,  9597,  2000,\n",
      "          2191,  2023,  1037,  2048,  1011,  3364,  3040,  2465,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2469, 0.7531],\n",
      "        [0.2576, 0.7424]]), 'input_ids': tensor([[  101,  1996, 14954,  2599,  4616, 15770,  3037,  1998, 26452,  1010,\n",
      "          2021,  1996,  4990,  2003,  2521,  2062,  5875,  2084,  1996,  2345,\n",
      "          7688,  1012,   102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5001,  8490,  6632,  1005,  1055,  3754,  2000, 16636,  9940,\n",
      "          1998,  3246,  2573,  2007, 14077,  1005,  1055,  7591,  9597,  2000,\n",
      "          2191,  2023,  1037,  2048,  1011,  3364,  3040,  2465,  1012,   102]]), 'ntok': tensor([23, 30]), 'cls_emb': tensor([[-0.1982,  0.1422, -0.2355,  ..., -0.2512,  0.2866,  0.3607],\n",
      "        [-0.3140, -0.2647, -0.2577,  ..., -0.3362,  0.6598,  0.6282]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 20184, 28104, 15970,  2205,  2172,  2051,  2813, 14138,  1999,\n",
      "         12170,  5638,  1005,  1055, 12391, 17076,  3367,  1006,  2045,  2024,\n",
      "          1037,  2843,  1997,  7171,  1997,  2014, 16448,  2041,  3645,  1007,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2729, 13366, 14626, 19566,  1996,  4687,  1998, 19854,  1997,\n",
      "          3652,  2039,  1010,  2021,  2002,  2196,  2428,  9979,  2015,  1996,\n",
      "          6569,  1997, 11865,  8093,  2386,  1005,  1055, 15615,  9686, 17695,\n",
      "          2964,  2030,  1996,  4519,  1011,  1999,  1011,  7417,  2179,  2011,\n",
      "          2010,  3494,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 20184, 28104, 15970,  2205,  2172,  2051,  2813, 14138,  1999,\n",
      "         12170,  5638,  1005,  1055, 12391, 17076,  3367,  1006,  2045,  2024,\n",
      "          1037,  2843,  1997,  7171,  1997,  2014, 16448,  2041,  3645,  1007,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2729, 13366, 14626, 19566,  1996,  4687,  1998, 19854,  1997,\n",
      "          3652,  2039,  1010,  2021,  2002,  2196,  2428,  9979,  2015,  1996,\n",
      "          6569,  1997, 11865,  8093,  2386,  1005,  1055, 15615,  9686, 17695,\n",
      "          2964,  2030,  1996,  4519,  1011,  1999,  1011,  7417,  2179,  2011,\n",
      "          2010,  3494,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2394, 0.7606],\n",
      "        [0.2504, 0.7496]]), 'input_ids': tensor([[  101, 20184, 28104, 15970,  2205,  2172,  2051,  2813, 14138,  1999,\n",
      "         12170,  5638,  1005,  1055, 12391, 17076,  3367,  1006,  2045,  2024,\n",
      "          1037,  2843,  1997,  7171,  1997,  2014, 16448,  2041,  3645,  1007,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2729, 13366, 14626, 19566,  1996,  4687,  1998, 19854,  1997,\n",
      "          3652,  2039,  1010,  2021,  2002,  2196,  2428,  9979,  2015,  1996,\n",
      "          6569,  1997, 11865,  8093,  2386,  1005,  1055, 15615,  9686, 17695,\n",
      "          2964,  2030,  1996,  4519,  1011,  1999,  1011,  7417,  2179,  2011,\n",
      "          2010,  3494,  1012,   102]]), 'ntok': tensor([32, 44]), 'cls_emb': tensor([[-0.1263,  0.1090, -0.4705,  ..., -0.3506,  1.0288,  0.6842],\n",
      "        [-0.3317,  0.1308, -0.7680,  ..., -0.2924,  0.7282,  0.4454]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  2019, 13059, 16774,  7476, 23855,  2013,  1996,\n",
      "          2684,  1997,  5469,  2472, 26800, 23157,  2080,  1006,  1037,  3135,\n",
      "          2182,  1007,  1010,  2021,  2014,  6315,  2836,  1998, 14395, 22518,\n",
      "          2791,  2191,  2009, 13939,  8060,  1012,   102],\n",
      "        [  101,  2065,  2559,  2005,  1037, 26162, 16596,  1011, 10882, 21014,\n",
      "          4536,  1010,  2079,  1050,  1005,  1056,  7392,  2005,  2023, 17727,\n",
      "         14122,  2121,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  2019, 13059, 16774,  7476, 23855,  2013,  1996,\n",
      "          2684,  1997,  5469,  2472, 26800, 23157,  2080,  1006,  1037,  3135,\n",
      "          2182,  1007,  1010,  2021,  2014,  6315,  2836,  1998, 14395, 22518,\n",
      "          2791,  2191,  2009, 13939,  8060,  1012,   102],\n",
      "        [  101,  2065,  2559,  2005,  1037, 26162, 16596,  1011, 10882, 21014,\n",
      "          4536,  1010,  2079,  1050,  1005,  1056,  7392,  2005,  2023, 17727,\n",
      "         14122,  2121,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2474, 0.7526],\n",
      "        [0.2818, 0.7182]]), 'input_ids': tensor([[  101,  2023,  2003,  2019, 13059, 16774,  7476, 23855,  2013,  1996,\n",
      "          2684,  1997,  5469,  2472, 26800, 23157,  2080,  1006,  1037,  3135,\n",
      "          2182,  1007,  1010,  2021,  2014,  6315,  2836,  1998, 14395, 22518,\n",
      "          2791,  2191,  2009, 13939,  8060,  1012,   102],\n",
      "        [  101,  2065,  2559,  2005,  1037, 26162, 16596,  1011, 10882, 21014,\n",
      "          4536,  1010,  2079,  1050,  1005,  1056,  7392,  2005,  2023, 17727,\n",
      "         14122,  2121,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([37, 24]), 'cls_emb': tensor([[ 0.2624, -0.5895, -0.2511,  ..., -0.1105,  0.2219,  0.6243],\n",
      "        [ 0.1305, -0.0524, -0.1507,  ..., -0.3028,  0.4066,  0.4831]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3248,  2066,  1037, 20606,  1998,  2058, 10052,  1059,  2932,\n",
      "          4827,  3659,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2521,  4218,  1996,  3302,  1010,  2023, 28667,  2239,\n",
      "          8873, 27390,  2098,  6925,  5176, 14888,  3980,  2055,  2216,  2477,\n",
      "          2057,  5987,  2013,  2510,  8680,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3248,  2066,  1037, 20606,  1998,  2058, 10052,  1059,  2932,\n",
      "          4827,  3659,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2521,  4218,  1996,  3302,  1010,  2023, 28667,  2239,\n",
      "          8873, 27390,  2098,  6925,  5176, 14888,  3980,  2055,  2216,  2477,\n",
      "          2057,  5987,  2013,  2510,  8680,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2732, 0.7268],\n",
      "        [0.2511, 0.7489]]), 'input_ids': tensor([[  101,  3248,  2066,  1037, 20606,  1998,  2058, 10052,  1059,  2932,\n",
      "          4827,  3659,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2521,  4218,  1996,  3302,  1010,  2023, 28667,  2239,\n",
      "          8873, 27390,  2098,  6925,  5176, 14888,  3980,  2055,  2216,  2477,\n",
      "          2057,  5987,  2013,  2510,  8680,  2015,  1012,   102]]), 'ntok': tensor([14, 28]), 'cls_emb': tensor([[-0.1034, -0.1435,  0.1231,  ..., -0.7422,  0.2630,  0.1650],\n",
      "        [-0.0186,  0.0356, -0.2984,  ..., -0.1178,  0.1386,  0.5513]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2745, 16216, 15185, 20049,  1005,  1055,  5896,  2003, 15318,\n",
      "          8966,  2007,  4129,  5019,  1012,   102,     0,     0,     0],\n",
      "        [  101,  2062,  6916,  1005,  1055, 17075, 13336,  1997,  9940,  1998,\n",
      "          1996,  3697,  2832,  1997, 25357,  2000,  3279,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2745, 16216, 15185, 20049,  1005,  1055,  5896,  2003, 15318,\n",
      "          8966,  2007,  4129,  5019,  1012,   102,     0,     0,     0],\n",
      "        [  101,  2062,  6916,  1005,  1055, 17075, 13336,  1997,  9940,  1998,\n",
      "          1996,  3697,  2832,  1997, 25357,  2000,  3279,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2647, 0.7353],\n",
      "        [0.2570, 0.7430]]), 'input_ids': tensor([[  101,  2745, 16216, 15185, 20049,  1005,  1055,  5896,  2003, 15318,\n",
      "          8966,  2007,  4129,  5019,  1012,   102,     0,     0,     0],\n",
      "        [  101,  2062,  6916,  1005,  1055, 17075, 13336,  1997,  9940,  1998,\n",
      "          1996,  3697,  2832,  1997, 25357,  2000,  3279,  1012,   102]]), 'ntok': tensor([16, 19]), 'cls_emb': tensor([[-0.4144, -0.1137, -0.3921,  ..., -0.5065,  0.4907,  0.5046],\n",
      "        [-0.5064, -0.0605, -0.7070,  ...,  0.0962,  0.5609, -0.1934]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2061, 27150,  2135,  4297, 17417,  3726,  2003,  3946,  2008,\n",
      "          2005,  1996,  2034,  2051,  2002,  1005,  2222,  2763,  5574,  2062,\n",
      "          2000,  4364,  2084,  2000,  2037, 27408,  2040,  8011,  2068,  2000,\n",
      "          2023,  3185,  2005,  1996,  6621,  5387,  1012,   102],\n",
      "        [  101,  3310,  2125,  2066,  1037,  5837,  5925,  2044, 11624, 13669,\n",
      "          2569,  1010,  4840,  6675,  2039,  2011,  1996, 24654,  3401,  1997,\n",
      "          1037,  3898, 18560,  7886,  2465,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2061, 27150,  2135,  4297, 17417,  3726,  2003,  3946,  2008,\n",
      "          2005,  1996,  2034,  2051,  2002,  1005,  2222,  2763,  5574,  2062,\n",
      "          2000,  4364,  2084,  2000,  2037, 27408,  2040,  8011,  2068,  2000,\n",
      "          2023,  3185,  2005,  1996,  6621,  5387,  1012,   102],\n",
      "        [  101,  3310,  2125,  2066,  1037,  5837,  5925,  2044, 11624, 13669,\n",
      "          2569,  1010,  4840,  6675,  2039,  2011,  1996, 24654,  3401,  1997,\n",
      "          1037,  3898, 18560,  7886,  2465,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2377, 0.7623],\n",
      "        [0.2672, 0.7328]]), 'input_ids': tensor([[  101,  2061, 27150,  2135,  4297, 17417,  3726,  2003,  3946,  2008,\n",
      "          2005,  1996,  2034,  2051,  2002,  1005,  2222,  2763,  5574,  2062,\n",
      "          2000,  4364,  2084,  2000,  2037, 27408,  2040,  8011,  2068,  2000,\n",
      "          2023,  3185,  2005,  1996,  6621,  5387,  1012,   102],\n",
      "        [  101,  3310,  2125,  2066,  1037,  5837,  5925,  2044, 11624, 13669,\n",
      "          2569,  1010,  4840,  6675,  2039,  2011,  1996, 24654,  3401,  1997,\n",
      "          1037,  3898, 18560,  7886,  2465,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([38, 27]), 'cls_emb': tensor([[ 0.1569,  0.0995, -0.0124,  ..., -0.1089,  0.5050,  0.3753],\n",
      "        [-0.1091, -0.3382,  0.0533,  ..., -0.3046,  0.4822,  0.1313]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2038,  2049,  5312,  1997, 25430, 27609,  2075, 11503,\n",
      "          5400,  4063,  2666,  1010,  2021,  2062,  2411,  2074,  5683, 12391,\n",
      "          1010, 13819,  1998,  2589,  2000,  2331,  1012,   102],\n",
      "        [  101,  1037,  6298,  4038, 25202,  2011,  1037,  4629,  3239,  2005,\n",
      "         14632,  1998,  2062,  2015,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2038,  2049,  5312,  1997, 25430, 27609,  2075, 11503,\n",
      "          5400,  4063,  2666,  1010,  2021,  2062,  2411,  2074,  5683, 12391,\n",
      "          1010, 13819,  1998,  2589,  2000,  2331,  1012,   102],\n",
      "        [  101,  1037,  6298,  4038, 25202,  2011,  1037,  4629,  3239,  2005,\n",
      "         14632,  1998,  2062,  2015,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2581, 0.7419],\n",
      "        [0.2868, 0.7132]]), 'input_ids': tensor([[  101,  2009,  2038,  2049,  5312,  1997, 25430, 27609,  2075, 11503,\n",
      "          5400,  4063,  2666,  1010,  2021,  2062,  2411,  2074,  5683, 12391,\n",
      "          1010, 13819,  1998,  2589,  2000,  2331,  1012,   102],\n",
      "        [  101,  1037,  6298,  4038, 25202,  2011,  1037,  4629,  3239,  2005,\n",
      "         14632,  1998,  2062,  2015,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([28, 16]), 'cls_emb': tensor([[ 0.1589, -0.0509, -0.2746,  ..., -0.0829,  0.3794,  0.3872],\n",
      "        [-0.6156, -0.3764, -0.3483,  ..., -0.4440,  0.5275,  0.5645]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  4875,  1011,  2006,  1011,  1996,  1011,  2813,  4118,\n",
      "          2109,  2000,  6254,  3541,  2413,  2082,  2166,  2003,  1037, 27150,\n",
      "          6712,  2013,  1996,  2085,  2062, 15157,  6028,  1997,  1996,  9986,\n",
      "          2226,  1011, 11153,  2108,  1037,  5710,  2112,  1997,  2037,  2147,\n",
      "          1012,   102],\n",
      "        [  101,  4678,  5055,  2038,  2062,  2084,  2438, 11084,  2000,  2191,\n",
      "          2009, 13432,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  4875,  1011,  2006,  1011,  1996,  1011,  2813,  4118,\n",
      "          2109,  2000,  6254,  3541,  2413,  2082,  2166,  2003,  1037, 27150,\n",
      "          6712,  2013,  1996,  2085,  2062, 15157,  6028,  1997,  1996,  9986,\n",
      "          2226,  1011, 11153,  2108,  1037,  5710,  2112,  1997,  2037,  2147,\n",
      "          1012,   102],\n",
      "        [  101,  4678,  5055,  2038,  2062,  2084,  2438, 11084,  2000,  2191,\n",
      "          2009, 13432,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2544, 0.7456],\n",
      "        [0.2643, 0.7357]]), 'input_ids': tensor([[  101,  1996,  4875,  1011,  2006,  1011,  1996,  1011,  2813,  4118,\n",
      "          2109,  2000,  6254,  3541,  2413,  2082,  2166,  2003,  1037, 27150,\n",
      "          6712,  2013,  1996,  2085,  2062, 15157,  6028,  1997,  1996,  9986,\n",
      "          2226,  1011, 11153,  2108,  1037,  5710,  2112,  1997,  2037,  2147,\n",
      "          1012,   102],\n",
      "        [  101,  4678,  5055,  2038,  2062,  2084,  2438, 11084,  2000,  2191,\n",
      "          2009, 13432,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([42, 14]), 'cls_emb': tensor([[-0.2463,  0.3222, -0.4696,  ..., -0.1572,  0.3577,  0.3804],\n",
      "        [ 0.1180,  0.0073, -0.1259,  ..., -0.2222,  0.0622,  0.5295]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  2978, 15640,  2008,  2009,  2069,\n",
      "          9020,  2000,  2022, 11519,  2612,  1997,  2757,  8235,  1012,   102],\n",
      "        [  101,  2009,  2038,  2035,  1996,  8277,  1997,  5983,  1051,  4017,\n",
      "          4168,  2389,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  2978, 15640,  2008,  2009,  2069,\n",
      "          9020,  2000,  2022, 11519,  2612,  1997,  2757,  8235,  1012,   102],\n",
      "        [  101,  2009,  2038,  2035,  1996,  8277,  1997,  5983,  1051,  4017,\n",
      "          4168,  2389,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2644, 0.7356],\n",
      "        [0.2641, 0.7359]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  2978, 15640,  2008,  2009,  2069,\n",
      "          9020,  2000,  2022, 11519,  2612,  1997,  2757,  8235,  1012,   102],\n",
      "        [  101,  2009,  2038,  2035,  1996,  8277,  1997,  5983,  1051,  4017,\n",
      "          4168,  2389,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([20, 14]), 'cls_emb': tensor([[ 0.1662,  0.2088, -0.1519,  ...,  0.0967,  0.1427,  0.6288],\n",
      "        [-0.0638,  0.0792,  0.0418,  ..., -0.2473,  0.4288,  0.6271]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009, 24542,  2015,  1010,  7570, 18752, 14213,  1010,  2707,\n",
      "          4244,  1998,  6904, 11020, 28184,  1025,  2009,  2003,  5263,  2000,\n",
      "          2298,  2185,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2005,  2485,  2000,  2048,  2847,  1996,  4378,  2003,  3140,\n",
      "          2000, 18094,  2093,  5536,  2135, 14777,  1010,  3262, 27118, 28228,\n",
      "         19879,  2618,  1010, 23760, 28466,  2389,  2945,  2005,  1996,  3976,\n",
      "          1997,  2028,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009, 24542,  2015,  1010,  7570, 18752, 14213,  1010,  2707,\n",
      "          4244,  1998,  6904, 11020, 28184,  1025,  2009,  2003,  5263,  2000,\n",
      "          2298,  2185,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2005,  2485,  2000,  2048,  2847,  1996,  4378,  2003,  3140,\n",
      "          2000, 18094,  2093,  5536,  2135, 14777,  1010,  3262, 27118, 28228,\n",
      "         19879,  2618,  1010, 23760, 28466,  2389,  2945,  2005,  1996,  3976,\n",
      "          1997,  2028,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2715, 0.7285],\n",
      "        [0.2542, 0.7458]]), 'input_ids': tensor([[  101,  2009, 24542,  2015,  1010,  7570, 18752, 14213,  1010,  2707,\n",
      "          4244,  1998,  6904, 11020, 28184,  1025,  2009,  2003,  5263,  2000,\n",
      "          2298,  2185,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2005,  2485,  2000,  2048,  2847,  1996,  4378,  2003,  3140,\n",
      "          2000, 18094,  2093,  5536,  2135, 14777,  1010,  3262, 27118, 28228,\n",
      "         19879,  2618,  1010, 23760, 28466,  2389,  2945,  2005,  1996,  3976,\n",
      "          1997,  2028,  1012,   102]]), 'ntok': tensor([24, 34]), 'cls_emb': tensor([[ 0.0151,  0.1569, -0.1728,  ..., -0.3058,  0.2143,  0.6748],\n",
      "        [ 0.1410,  0.3458,  0.0252,  ..., -0.1941,  0.7580,  0.3761]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 21688,  2135,  6051,  1998,  6057,  1013, 24842,  3723,\n",
      "         28458,  1997,  1996,  2529,  6026,  1997,  2028,  2450,  2012,  1996,\n",
      "          2398,  1997,  1996, 16100,  2749,  1997,  6580,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  1056,  1007,  2182,  1005,  1055,  2069,  2061,  2172,\n",
      "          3087,  2064,  2079,  2007,  1037, 13109, 10050,  2094,  1010,  2058,\n",
      "         24759, 26174,  1010,  4776,  5785,  2600,  1005,  1050,  1005,  4897,\n",
      "          4393,  3117,  2077,  1996,  2328,  1011,  1999,  9033, 21202,  7971,\n",
      "          1997,  1996,  2878,  6771, 14222,  2068,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 21688,  2135,  6051,  1998,  6057,  1013, 24842,  3723,\n",
      "         28458,  1997,  1996,  2529,  6026,  1997,  2028,  2450,  2012,  1996,\n",
      "          2398,  1997,  1996, 16100,  2749,  1997,  6580,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  1056,  1007,  2182,  1005,  1055,  2069,  2061,  2172,\n",
      "          3087,  2064,  2079,  2007,  1037, 13109, 10050,  2094,  1010,  2058,\n",
      "         24759, 26174,  1010,  4776,  5785,  2600,  1005,  1050,  1005,  4897,\n",
      "          4393,  3117,  2077,  1996,  2328,  1011,  1999,  9033, 21202,  7971,\n",
      "          1997,  1996,  2878,  6771, 14222,  2068,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2753, 0.7247],\n",
      "        [0.2658, 0.7342]]), 'input_ids': tensor([[  101,  1037, 21688,  2135,  6051,  1998,  6057,  1013, 24842,  3723,\n",
      "         28458,  1997,  1996,  2529,  6026,  1997,  2028,  2450,  2012,  1996,\n",
      "          2398,  1997,  1996, 16100,  2749,  1997,  6580,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  1056,  1007,  2182,  1005,  1055,  2069,  2061,  2172,\n",
      "          3087,  2064,  2079,  2007,  1037, 13109, 10050,  2094,  1010,  2058,\n",
      "         24759, 26174,  1010,  4776,  5785,  2600,  1005,  1050,  1005,  4897,\n",
      "          4393,  3117,  2077,  1996,  2328,  1011,  1999,  9033, 21202,  7971,\n",
      "          1997,  1996,  2878,  6771, 14222,  2068,  1012,   102]]), 'ntok': tensor([29, 48]), 'cls_emb': tensor([[-0.3110, -0.3220, -0.2486,  ..., -0.3569,  0.3192,  0.3330],\n",
      "        [ 0.2125,  0.1895, -0.1327,  ..., -0.5230,  0.4189,  0.3946]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2005,  3087, 16261,  2007,  7279,  2696, 13186,  9080,  6078,\n",
      "          1999,  2236,  1998,  8900,  9575,  1997,  3109,  3506,  1999,  3327,\n",
      "          1010,  2009,  1005,  1055,  2019,  3239,  1011, 16181,  1012,   102],\n",
      "        [  101,  1036,  1036,  3262,  9246,  1005,  1005,  2003,  1037,  4408,\n",
      "          1010,  2422,  2715,  2154,  2155, 11498,  3468,  2008, 11651,  2049,\n",
      "          2540,  2006,  2049, 10353,  2005,  2035,  2000,  2156,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2005,  3087, 16261,  2007,  7279,  2696, 13186,  9080,  6078,\n",
      "          1999,  2236,  1998,  8900,  9575,  1997,  3109,  3506,  1999,  3327,\n",
      "          1010,  2009,  1005,  1055,  2019,  3239,  1011, 16181,  1012,   102],\n",
      "        [  101,  1036,  1036,  3262,  9246,  1005,  1005,  2003,  1037,  4408,\n",
      "          1010,  2422,  2715,  2154,  2155, 11498,  3468,  2008, 11651,  2049,\n",
      "          2540,  2006,  2049, 10353,  2005,  2035,  2000,  2156,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2502, 0.7498],\n",
      "        [0.3345, 0.6655]]), 'input_ids': tensor([[  101,  2005,  3087, 16261,  2007,  7279,  2696, 13186,  9080,  6078,\n",
      "          1999,  2236,  1998,  8900,  9575,  1997,  3109,  3506,  1999,  3327,\n",
      "          1010,  2009,  1005,  1055,  2019,  3239,  1011, 16181,  1012,   102],\n",
      "        [  101,  1036,  1036,  3262,  9246,  1005,  1005,  2003,  1037,  4408,\n",
      "          1010,  2422,  2715,  2154,  2155, 11498,  3468,  2008, 11651,  2049,\n",
      "          2540,  2006,  2049, 10353,  2005,  2035,  2000,  2156,  1012,   102]]), 'ntok': tensor([30, 30]), 'cls_emb': tensor([[ 0.1527,  0.1958, -0.2595,  ...,  0.0022,  0.3409,  0.5114],\n",
      "        [ 0.0016,  0.1675,  0.2029,  ..., -0.0910,  0.7374,  0.6310]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1045,  2074,  3866,  2296,  3371,  1997,  2023,  2143,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  4251,  1010,  5760,  1010, 27213,  2143,   102,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1045,  2074,  3866,  2296,  3371,  1997,  2023,  2143,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  4251,  1010,  5760,  1010, 27213,  2143,   102,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2500, 0.7500],\n",
      "        [0.2990, 0.7010]]), 'input_ids': tensor([[  101,  1045,  2074,  3866,  2296,  3371,  1997,  2023,  2143,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  4251,  1010,  5760,  1010, 27213,  2143,   102,     0,\n",
      "             0]]), 'ntok': tensor([11,  9]), 'cls_emb': tensor([[ 0.1451, -0.0836,  0.0423,  ..., -0.3118,  0.3325,  0.2679],\n",
      "        [-0.2837, -0.2301, -0.1796,  ..., -0.3357,  0.4379,  0.2636]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 10520,  2005,  2216,  2040,  2293,  6585,  4617,  1997,\n",
      "          1996, 22759,  1010,  3391,  3924,  2008,  9125,  2784, 14744,  2545,\n",
      "          1998, 24575,  2015,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3722,  1010,  2021, 24842,  3723,  1998,  2092,  1011,\n",
      "          6051,  7241,  3689,  2008, 13974,  1037, 16834, 19240,  2005,  1037,\n",
      "          2406,  2145,  7149,  2007,  2049, 14870,  2627,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 10520,  2005,  2216,  2040,  2293,  6585,  4617,  1997,\n",
      "          1996, 22759,  1010,  3391,  3924,  2008,  9125,  2784, 14744,  2545,\n",
      "          1998, 24575,  2015,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3722,  1010,  2021, 24842,  3723,  1998,  2092,  1011,\n",
      "          6051,  7241,  3689,  2008, 13974,  1037, 16834, 19240,  2005,  1037,\n",
      "          2406,  2145,  7149,  2007,  2049, 14870,  2627,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2523, 0.7477],\n",
      "        [0.2607, 0.7393]]), 'input_ids': tensor([[  101,  1037, 10520,  2005,  2216,  2040,  2293,  6585,  4617,  1997,\n",
      "          1996, 22759,  1010,  3391,  3924,  2008,  9125,  2784, 14744,  2545,\n",
      "          1998, 24575,  2015,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3722,  1010,  2021, 24842,  3723,  1998,  2092,  1011,\n",
      "          6051,  7241,  3689,  2008, 13974,  1037, 16834, 19240,  2005,  1037,\n",
      "          2406,  2145,  7149,  2007,  2049, 14870,  2627,  1012,   102]]), 'ntok': tensor([25, 29]), 'cls_emb': tensor([[-0.5217, -0.2310, -0.3178,  ..., -0.2639,  0.5933,  0.5929],\n",
      "        [-0.3119, -0.1949, -0.0806,  ..., -0.2664,  0.6185,  0.3149]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2061, 19960,  3695, 16748,  1010,  2750,\n",
      "          1996,  8790,  6829,  2006,  1996,  9388,  4226,  2063,  1010,  2008,\n",
      "          2057,  2074,  6187,  1050,  1005,  1056,  2131,  2053,  9967,  1012,\n",
      "           102],\n",
      "        [  101,  2079,  2025,  2156,  2023,  2143,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2061, 19960,  3695, 16748,  1010,  2750,\n",
      "          1996,  8790,  6829,  2006,  1996,  9388,  4226,  2063,  1010,  2008,\n",
      "          2057,  2074,  6187,  1050,  1005,  1056,  2131,  2053,  9967,  1012,\n",
      "           102],\n",
      "        [  101,  2079,  2025,  2156,  2023,  2143,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2494, 0.7506],\n",
      "        [0.2736, 0.7264]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2061, 19960,  3695, 16748,  1010,  2750,\n",
      "          1996,  8790,  6829,  2006,  1996,  9388,  4226,  2063,  1010,  2008,\n",
      "          2057,  2074,  6187,  1050,  1005,  1056,  2131,  2053,  9967,  1012,\n",
      "           102],\n",
      "        [  101,  2079,  2025,  2156,  2023,  2143,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([31,  8]), 'cls_emb': tensor([[ 0.3489,  0.2086,  0.1873,  ..., -0.3729,  0.3817,  0.4587],\n",
      "        [-0.3537,  0.1157,  0.7447,  ..., -0.4326,  0.3242,  0.2046]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  8026, 23555,  3084,  2009,  5875,  2667,  2000,  2424,  2041,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2087, 17075,  7968,  2386,  8680,  1997,  3522,  2086,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  8026, 23555,  3084,  2009,  5875,  2667,  2000,  2424,  2041,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2087, 17075,  7968,  2386,  8680,  1997,  3522,  2086,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2459, 0.7541],\n",
      "        [0.2851, 0.7149]]), 'input_ids': tensor([[  101,  8026, 23555,  3084,  2009,  5875,  2667,  2000,  2424,  2041,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2087, 17075,  7968,  2386,  8680,  1997,  3522,  2086,\n",
      "          1012,   102]]), 'ntok': tensor([12, 12]), 'cls_emb': tensor([[-0.1265,  0.3515, -0.0968,  ..., -0.3510,  0.7212,  0.5838],\n",
      "        [-0.4345, -0.1198, -0.0586,  ..., -0.3955,  0.6387,  0.2746]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  1005,  1055,  2053,  6832,  8187,  2000,  5943,  2483,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2005,  2169, 15375,  2045,  2024,  2012,  2560,  2184,  3143,\n",
      "         22182,  1010,  2116,  2746,  2013,  1996, 29350,  2166, 10359, 10225,\n",
      "          9027,  1010,  3005,  3772,  4813,  2024, 12435,  2000,  1037, 19747,\n",
      "          3013,  5833,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  1005,  1055,  2053,  6832,  8187,  2000,  5943,  2483,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2005,  2169, 15375,  2045,  2024,  2012,  2560,  2184,  3143,\n",
      "         22182,  1010,  2116,  2746,  2013,  1996, 29350,  2166, 10359, 10225,\n",
      "          9027,  1010,  3005,  3772,  4813,  2024, 12435,  2000,  1037, 19747,\n",
      "          3013,  5833,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2786, 0.7214],\n",
      "        [0.2551, 0.7449]]), 'input_ids': tensor([[  101,  2045,  1005,  1055,  2053,  6832,  8187,  2000,  5943,  2483,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2005,  2169, 15375,  2045,  2024,  2012,  2560,  2184,  3143,\n",
      "         22182,  1010,  2116,  2746,  2013,  1996, 29350,  2166, 10359, 10225,\n",
      "          9027,  1010,  3005,  3772,  4813,  2024, 12435,  2000,  1037, 19747,\n",
      "          3013,  5833,  1012,   102]]), 'ntok': tensor([12, 34]), 'cls_emb': tensor([[ 0.0449, -0.1222, -0.3039,  ..., -0.1598,  0.3405,  0.7369],\n",
      "        [ 0.0531,  0.2511, -0.0991,  ...,  0.1800,  0.5224,  0.6019]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2348, 15876, 18620,  2102,  1005,  1055,  8015,  1998,  3579,\n",
      "          2038,  1037,  6315,  4654, 26415,  8156,  2055,  2009,  1010,  1996,\n",
      "          3682,  3836,  2003,  2505,  2021,  4569,  1012,   102],\n",
      "        [  101,  2013,  1996,  3098,  5019,  1010,  2009,  1005,  1055,  3154,\n",
      "          2008,  2035,  2055,  1996,  6425,  2015,  2003,  1037,  6135,  5675,\n",
      "          2594,  3185,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2348, 15876, 18620,  2102,  1005,  1055,  8015,  1998,  3579,\n",
      "          2038,  1037,  6315,  4654, 26415,  8156,  2055,  2009,  1010,  1996,\n",
      "          3682,  3836,  2003,  2505,  2021,  4569,  1012,   102],\n",
      "        [  101,  2013,  1996,  3098,  5019,  1010,  2009,  1005,  1055,  3154,\n",
      "          2008,  2035,  2055,  1996,  6425,  2015,  2003,  1037,  6135,  5675,\n",
      "          2594,  3185,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2414, 0.7586],\n",
      "        [0.2649, 0.7351]]), 'input_ids': tensor([[  101,  2348, 15876, 18620,  2102,  1005,  1055,  8015,  1998,  3579,\n",
      "          2038,  1037,  6315,  4654, 26415,  8156,  2055,  2009,  1010,  1996,\n",
      "          3682,  3836,  2003,  2505,  2021,  4569,  1012,   102],\n",
      "        [  101,  2013,  1996,  3098,  5019,  1010,  2009,  1005,  1055,  3154,\n",
      "          2008,  2035,  2055,  1996,  6425,  2015,  2003,  1037,  6135,  5675,\n",
      "          2594,  3185,  1012,   102,     0,     0,     0,     0]]), 'ntok': tensor([28, 24]), 'cls_emb': tensor([[-0.3538, -0.0041, -0.7261,  ..., -0.2838,  0.4583,  0.6498],\n",
      "        [ 0.1598, -0.0090, -0.2407,  ..., -0.1919,  0.5199,  0.4602]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2006,  1996,  8265,  1997,  1996,  3614,  3310,  1037,  6660,\n",
      "         22822,  9232,  1998,  8562,  3238,  5469,  3185,  2008,  1010,  2348,\n",
      "         25077,  1010,  2003,  2000,  2022, 22429,  2005,  2049,  3442,  1011,\n",
      "          3805,  3921,  2000, 19815,  9961,  1012,   102],\n",
      "        [  101,  1996,  2143,  2003,  2241,  2006,  3606,  1998,  2664,  2045,\n",
      "          2003,  2242,  2055,  2009,  2008,  5683, 12958,  1010,  2004,  2065,\n",
      "          1996,  2613,  2466,  4627,  2074,  2105,  1996,  3420,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2006,  1996,  8265,  1997,  1996,  3614,  3310,  1037,  6660,\n",
      "         22822,  9232,  1998,  8562,  3238,  5469,  3185,  2008,  1010,  2348,\n",
      "         25077,  1010,  2003,  2000,  2022, 22429,  2005,  2049,  3442,  1011,\n",
      "          3805,  3921,  2000, 19815,  9961,  1012,   102],\n",
      "        [  101,  1996,  2143,  2003,  2241,  2006,  3606,  1998,  2664,  2045,\n",
      "          2003,  2242,  2055,  2009,  2008,  5683, 12958,  1010,  2004,  2065,\n",
      "          1996,  2613,  2466,  4627,  2074,  2105,  1996,  3420,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2471, 0.7529],\n",
      "        [0.2472, 0.7528]]), 'input_ids': tensor([[  101,  2006,  1996,  8265,  1997,  1996,  3614,  3310,  1037,  6660,\n",
      "         22822,  9232,  1998,  8562,  3238,  5469,  3185,  2008,  1010,  2348,\n",
      "         25077,  1010,  2003,  2000,  2022, 22429,  2005,  2049,  3442,  1011,\n",
      "          3805,  3921,  2000, 19815,  9961,  1012,   102],\n",
      "        [  101,  1996,  2143,  2003,  2241,  2006,  3606,  1998,  2664,  2045,\n",
      "          2003,  2242,  2055,  2009,  2008,  5683, 12958,  1010,  2004,  2065,\n",
      "          1996,  2613,  2466,  4627,  2074,  2105,  1996,  3420,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([37, 30]), 'cls_emb': tensor([[ 0.1370,  0.0375, -0.1926,  ...,  0.0031,  0.4529,  0.3497],\n",
      "        [ 0.0797, -0.1310, -0.0592,  ..., -0.3281,  0.3793,  0.4648]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1045,  1005,  2310,  2467, 13830,  1997,  7052, 14775,  1010,\n",
      "          2021,  2044,  3773,  2023,  2143,  1010,  2009,  1005,  1055,  2025,\n",
      "          2008,  2502,  1037,  3066,  1012,   102],\n",
      "        [  101,  1037, 20392,  1998,  5236,  7977,  1011,  2041,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1045,  1005,  2310,  2467, 13830,  1997,  7052, 14775,  1010,\n",
      "          2021,  2044,  3773,  2023,  2143,  1010,  2009,  1005,  1055,  2025,\n",
      "          2008,  2502,  1037,  3066,  1012,   102],\n",
      "        [  101,  1037, 20392,  1998,  5236,  7977,  1011,  2041,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2267, 0.7733],\n",
      "        [0.3059, 0.6941]]), 'input_ids': tensor([[  101,  1045,  1005,  2310,  2467, 13830,  1997,  7052, 14775,  1010,\n",
      "          2021,  2044,  3773,  2023,  2143,  1010,  2009,  1005,  1055,  2025,\n",
      "          2008,  2502,  1037,  3066,  1012,   102],\n",
      "        [  101,  1037, 20392,  1998,  5236,  7977,  1011,  2041,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([26, 10]), 'cls_emb': tensor([[ 0.1676, -0.1679,  0.0942,  ..., -0.1544,  0.2578,  0.3679],\n",
      "        [-0.4687, -0.0364, -0.5192,  ..., -0.3268,  0.5632,  0.3063]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1012,  1012,  1012,  2498, 12459,  2182,  3272,  2005,  2070,\n",
      "          9643,  3772,  1998, 20342,  2569,  3896,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2498,  1999, 12447,  2039,  1999, 17738,  2412,  4427,  2033,\n",
      "          2000,  2228,  1997,  2049,  4864,  2004,  2505,  2062,  2084, 16387,\n",
      "          1999,  1037,  9000,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1012,  1012,  1012,  2498, 12459,  2182,  3272,  2005,  2070,\n",
      "          9643,  3772,  1998, 20342,  2569,  3896,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2498,  1999, 12447,  2039,  1999, 17738,  2412,  4427,  2033,\n",
      "          2000,  2228,  1997,  2049,  4864,  2004,  2505,  2062,  2084, 16387,\n",
      "          1999,  1037,  9000,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2419, 0.7581],\n",
      "        [0.2563, 0.7437]]), 'input_ids': tensor([[  101,  1012,  1012,  1012,  2498, 12459,  2182,  3272,  2005,  2070,\n",
      "          9643,  3772,  1998, 20342,  2569,  3896,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2498,  1999, 12447,  2039,  1999, 17738,  2412,  4427,  2033,\n",
      "          2000,  2228,  1997,  2049,  4864,  2004,  2505,  2062,  2084, 16387,\n",
      "          1999,  1037,  9000,  1012,   102]]), 'ntok': tensor([18, 25]), 'cls_emb': tensor([[ 0.3298, -0.0039, -0.0129,  ..., -0.2613,  0.6908,  0.2295],\n",
      "        [ 0.0918,  0.1003, -0.2203,  ..., -0.1132,  0.2808,  0.5736]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2182,  1005,  1055,  2664,  2178,  2996,  5469,  6329, 14163,\n",
      "         23177,  2039,  2049,  9994,  2007,  1043, 15909,  8376, 10017,  4599,\n",
      "          2071,  6149,  1999,  2037,  3637,  1012,   102,     0],\n",
      "        [  101,  2061, 14477,  4757, 24270,  1998,  5760,  1997,  2540,  1010,\n",
      "          2017,  6187,  1050,  1005,  1056,  2393,  2021, 22775,  7949,  2115,\n",
      "          2608,  1998, 14315,  1036,  3647,   999,  1005,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2182,  1005,  1055,  2664,  2178,  2996,  5469,  6329, 14163,\n",
      "         23177,  2039,  2049,  9994,  2007,  1043, 15909,  8376, 10017,  4599,\n",
      "          2071,  6149,  1999,  2037,  3637,  1012,   102,     0],\n",
      "        [  101,  2061, 14477,  4757, 24270,  1998,  5760,  1997,  2540,  1010,\n",
      "          2017,  6187,  1050,  1005,  1056,  2393,  2021, 22775,  7949,  2115,\n",
      "          2608,  1998, 14315,  1036,  3647,   999,  1005,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2603, 0.7397],\n",
      "        [0.3019, 0.6981]]), 'input_ids': tensor([[  101,  2182,  1005,  1055,  2664,  2178,  2996,  5469,  6329, 14163,\n",
      "         23177,  2039,  2049,  9994,  2007,  1043, 15909,  8376, 10017,  4599,\n",
      "          2071,  6149,  1999,  2037,  3637,  1012,   102,     0],\n",
      "        [  101,  2061, 14477,  4757, 24270,  1998,  5760,  1997,  2540,  1010,\n",
      "          2017,  6187,  1050,  1005,  1056,  2393,  2021, 22775,  7949,  2115,\n",
      "          2608,  1998, 14315,  1036,  3647,   999,  1005,   102]]), 'ntok': tensor([27, 28]), 'cls_emb': tensor([[ 0.2626,  0.0058,  0.0445,  ..., -0.2225,  0.5920,  0.4829],\n",
      "        [ 0.4246, -0.1699,  0.0268,  ..., -0.0119,  0.4014,  0.9196]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009, 18452,  2308,  2066, 28781,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  5436,  8198,  2061,  2312,  1998,  5793,\n",
      "          1037, 10998,  2316,  2453,  2004,  2092,  2022,  2358, 25377,  2075,\n",
      "          2083,  2068,  1999, 15912,  4253,  1010,  2652,  1037,  2267,  2374,\n",
      "          2954,  2299,  2006,  4895,  8525,  7228,  5693,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009, 18452,  2308,  2066, 28781,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  5436,  8198,  2061,  2312,  1998,  5793,\n",
      "          1037, 10998,  2316,  2453,  2004,  2092,  2022,  2358, 25377,  2075,\n",
      "          2083,  2068,  1999, 15912,  4253,  1010,  2652,  1037,  2267,  2374,\n",
      "          2954,  2299,  2006,  4895,  8525,  7228,  5693,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2757, 0.7243],\n",
      "        [0.2576, 0.7424]]), 'input_ids': tensor([[  101,  2009, 18452,  2308,  2066, 28781,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  5436,  8198,  2061,  2312,  1998,  5793,\n",
      "          1037, 10998,  2316,  2453,  2004,  2092,  2022,  2358, 25377,  2075,\n",
      "          2083,  2068,  1999, 15912,  4253,  1010,  2652,  1037,  2267,  2374,\n",
      "          2954,  2299,  2006,  4895,  8525,  7228,  5693,  1012,   102]]), 'ntok': tensor([ 8, 39]), 'cls_emb': tensor([[ 0.0634,  0.4261, -0.1733,  ..., -0.3941,  0.3073,  0.4935],\n",
      "        [ 0.2749,  0.3556, -0.2356,  ..., -0.1510,  0.5923,  0.5721]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2021,  2009,  1005,  1055,  2205,  2146,  1998,  2205,  9530,\n",
      "          6767,  7630,  3064,  1998,  2009,  4515,  1999,  1037,  8494, 10362,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1997,  1996,  2190,  3152,  1997,  1996,  2095,  2007,\n",
      "          2049,  8993,  1997,  1996, 15314,  2000,  8404,  4320,  2011,  2274,\n",
      "          3824,  3633,  1012,  1012,  1012,  1037,  8317, 17743,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2021,  2009,  1005,  1055,  2205,  2146,  1998,  2205,  9530,\n",
      "          6767,  7630,  3064,  1998,  2009,  4515,  1999,  1037,  8494, 10362,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1997,  1996,  2190,  3152,  1997,  1996,  2095,  2007,\n",
      "          2049,  8993,  1997,  1996, 15314,  2000,  8404,  4320,  2011,  2274,\n",
      "          3824,  3633,  1012,  1012,  1012,  1037,  8317, 17743,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2548, 0.7452],\n",
      "        [0.2558, 0.7442]]), 'input_ids': tensor([[  101,  2021,  2009,  1005,  1055,  2205,  2146,  1998,  2205,  9530,\n",
      "          6767,  7630,  3064,  1998,  2009,  4515,  1999,  1037,  8494, 10362,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1997,  1996,  2190,  3152,  1997,  1996,  2095,  2007,\n",
      "          2049,  8993,  1997,  1996, 15314,  2000,  8404,  4320,  2011,  2274,\n",
      "          3824,  3633,  1012,  1012,  1012,  1037,  8317, 17743,  1012,   102]]), 'ntok': tensor([22, 30]), 'cls_emb': tensor([[ 0.1146,  0.0292,  0.1973,  ..., -0.3620,  0.1207,  0.7461],\n",
      "        [-0.3930, -0.0784, -0.3199,  ..., -0.4090,  0.5292,  0.1008]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2348,  2446,  8434,  2515,  2025,  2272, 12192,  2000,  2568,\n",
      "          2043,  6195,  1996,  2088,  1005,  1055,  2190, 12846,  1010,  3262,\n",
      "          9246,  2071,  2191,  2139,  4904,  2818,  3122,  1037,  2759,  7688,\n",
      "          2005,  7501,  9045,  1012,   102],\n",
      "        [  101,  2065,  1996,  2034,  2273,  1999,  2304,  2001,  2769,  1010,\n",
      "          1996,  2117,  2003,  2235,  2689,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2348,  2446,  8434,  2515,  2025,  2272, 12192,  2000,  2568,\n",
      "          2043,  6195,  1996,  2088,  1005,  1055,  2190, 12846,  1010,  3262,\n",
      "          9246,  2071,  2191,  2139,  4904,  2818,  3122,  1037,  2759,  7688,\n",
      "          2005,  7501,  9045,  1012,   102],\n",
      "        [  101,  2065,  1996,  2034,  2273,  1999,  2304,  2001,  2769,  1010,\n",
      "          1996,  2117,  2003,  2235,  2689,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2451, 0.7549],\n",
      "        [0.2595, 0.7405]]), 'input_ids': tensor([[  101,  2348,  2446,  8434,  2515,  2025,  2272, 12192,  2000,  2568,\n",
      "          2043,  6195,  1996,  2088,  1005,  1055,  2190, 12846,  1010,  3262,\n",
      "          9246,  2071,  2191,  2139,  4904,  2818,  3122,  1037,  2759,  7688,\n",
      "          2005,  7501,  9045,  1012,   102],\n",
      "        [  101,  2065,  1996,  2034,  2273,  1999,  2304,  2001,  2769,  1010,\n",
      "          1996,  2117,  2003,  2235,  2689,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 17]), 'cls_emb': tensor([[-0.1441,  0.2966, -0.1119,  ..., -0.3890,  0.5273,  0.3811],\n",
      "        [-0.2271,  0.1472, -0.2735,  ..., -0.2383,  0.4975,  0.5419]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2079,  1050,  1005,  1056,  2022, 25857,  2011,  1996,  8052,\n",
      "          3459,  2862,  1011,  3239,  2156,  2017,  2003,  5760, 18015,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2178,  2028,  1997,  2216,  9765, 22991, 26641,  5691,  2066,\n",
      "          1036,  1036,  7746,  7800,  1997,  1996,  8038,  8038,  2905,  9021,\n",
      "          1010,  1005,  1005,  3272,  2008,  1996,  3015,  1010,  3772,  1998,\n",
      "          2839,  2458,  2024,  1037,  2843,  2488,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2079,  1050,  1005,  1056,  2022, 25857,  2011,  1996,  8052,\n",
      "          3459,  2862,  1011,  3239,  2156,  2017,  2003,  5760, 18015,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2178,  2028,  1997,  2216,  9765, 22991, 26641,  5691,  2066,\n",
      "          1036,  1036,  7746,  7800,  1997,  1996,  8038,  8038,  2905,  9021,\n",
      "          1010,  1005,  1005,  3272,  2008,  1996,  3015,  1010,  3772,  1998,\n",
      "          2839,  2458,  2024,  1037,  2843,  2488,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2708, 0.7292],\n",
      "        [0.2767, 0.7233]]), 'input_ids': tensor([[  101,  2079,  1050,  1005,  1056,  2022, 25857,  2011,  1996,  8052,\n",
      "          3459,  2862,  1011,  3239,  2156,  2017,  2003,  5760, 18015,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2178,  2028,  1997,  2216,  9765, 22991, 26641,  5691,  2066,\n",
      "          1036,  1036,  7746,  7800,  1997,  1996,  8038,  8038,  2905,  9021,\n",
      "          1010,  1005,  1005,  3272,  2008,  1996,  3015,  1010,  3772,  1998,\n",
      "          2839,  2458,  2024,  1037,  2843,  2488,  1012,   102]]), 'ntok': tensor([21, 38]), 'cls_emb': tensor([[ 0.2662, -0.0460,  0.1309,  ..., -0.2355,  0.1698,  0.3670],\n",
      "        [-0.1038, -0.0496, -0.0319,  ..., -0.3585,  0.8547,  0.4791]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  8040,  5668,  6810,  2515,  1050,  1005,  1056,  2507,  2149,\n",
      "          1037,  2839,  4276,  3228,  1037,  4365,  2055,  1012,   102,     0,\n",
      "             0,     0],\n",
      "        [  101,  2007, 10442,  1011,  6947,  8638,  1010,  2053, 29297,  2038,\n",
      "         21727,  2019,  8680,  6925,  2046,  1037,  8155,  1010, 21791,  3185,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  8040,  5668,  6810,  2515,  1050,  1005,  1056,  2507,  2149,\n",
      "          1037,  2839,  4276,  3228,  1037,  4365,  2055,  1012,   102,     0,\n",
      "             0,     0],\n",
      "        [  101,  2007, 10442,  1011,  6947,  8638,  1010,  2053, 29297,  2038,\n",
      "         21727,  2019,  8680,  6925,  2046,  1037,  8155,  1010, 21791,  3185,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2514, 0.7486],\n",
      "        [0.2623, 0.7377]]), 'input_ids': tensor([[  101,  8040,  5668,  6810,  2515,  1050,  1005,  1056,  2507,  2149,\n",
      "          1037,  2839,  4276,  3228,  1037,  4365,  2055,  1012,   102,     0,\n",
      "             0,     0],\n",
      "        [  101,  2007, 10442,  1011,  6947,  8638,  1010,  2053, 29297,  2038,\n",
      "         21727,  2019,  8680,  6925,  2046,  1037,  8155,  1010, 21791,  3185,\n",
      "          1012,   102]]), 'ntok': tensor([19, 22]), 'cls_emb': tensor([[ 0.0708,  0.2420, -0.6527,  ..., -0.5078,  0.7116,  0.6075],\n",
      "        [ 0.0069, -0.1481, -0.3697,  ..., -0.4214,  0.5086,  0.4073]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  5436,  9530,  6767,  7630,  9285,  4821,  5587,  2039,\n",
      "          2000,  2498,  2062,  2084, 22387,  1996,  4378,  1005,  1055,  4677,\n",
      "          1012,   102],\n",
      "        [  101,  2045,  2024,  2070,  6919,  2135,  4840,  5312,  2008,  5744,\n",
      "          1996,  7191, 10551,  2791,  2007,  2529, 16056,  1998, 17772,  2791,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  5436,  9530,  6767,  7630,  9285,  4821,  5587,  2039,\n",
      "          2000,  2498,  2062,  2084, 22387,  1996,  4378,  1005,  1055,  4677,\n",
      "          1012,   102],\n",
      "        [  101,  2045,  2024,  2070,  6919,  2135,  4840,  5312,  2008,  5744,\n",
      "          1996,  7191, 10551,  2791,  2007,  2529, 16056,  1998, 17772,  2791,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2523, 0.7477],\n",
      "        [0.2456, 0.7544]]), 'input_ids': tensor([[  101,  1996,  5436,  9530,  6767,  7630,  9285,  4821,  5587,  2039,\n",
      "          2000,  2498,  2062,  2084, 22387,  1996,  4378,  1005,  1055,  4677,\n",
      "          1012,   102],\n",
      "        [  101,  2045,  2024,  2070,  6919,  2135,  4840,  5312,  2008,  5744,\n",
      "          1996,  7191, 10551,  2791,  2007,  2529, 16056,  1998, 17772,  2791,\n",
      "          1012,   102]]), 'ntok': tensor([22, 22]), 'cls_emb': tensor([[-0.1581,  0.1689,  0.0935,  ..., -0.1676,  0.6575,  0.5608],\n",
      "        [ 0.0656,  0.1934, -0.2757,  ..., -0.4487,  0.2263,  0.6062]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2515,  2210,  2062,  2084,  2377,  2019,  7601, 10085,  8918,\n",
      "          2208,  1997,  6039,  1011,  1999,  1011,  1996,  1011,  8744,  2015,\n",
      "          2007,  1037, 13800,  2627,  1012,   102,     0,     0,     0],\n",
      "        [  101,  3444,  2834,  2121,  1040,  1012,  1046,  1012,  2482, 26658,\n",
      "         23303,  1037,  8579,  7241,  3459,  1010,  5026, 11167,  4116,  5637,\n",
      "          2669,  1005,  1055, 27290, 15587,  2000,  2166,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2515,  2210,  2062,  2084,  2377,  2019,  7601, 10085,  8918,\n",
      "          2208,  1997,  6039,  1011,  1999,  1011,  1996,  1011,  8744,  2015,\n",
      "          2007,  1037, 13800,  2627,  1012,   102,     0,     0,     0],\n",
      "        [  101,  3444,  2834,  2121,  1040,  1012,  1046,  1012,  2482, 26658,\n",
      "         23303,  1037,  8579,  7241,  3459,  1010,  5026, 11167,  4116,  5637,\n",
      "          2669,  1005,  1055, 27290, 15587,  2000,  2166,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2723, 0.7277],\n",
      "        [0.2777, 0.7223]]), 'input_ids': tensor([[  101,  2515,  2210,  2062,  2084,  2377,  2019,  7601, 10085,  8918,\n",
      "          2208,  1997,  6039,  1011,  1999,  1011,  1996,  1011,  8744,  2015,\n",
      "          2007,  1037, 13800,  2627,  1012,   102,     0,     0,     0],\n",
      "        [  101,  3444,  2834,  2121,  1040,  1012,  1046,  1012,  2482, 26658,\n",
      "         23303,  1037,  8579,  7241,  3459,  1010,  5026, 11167,  4116,  5637,\n",
      "          2669,  1005,  1055, 27290, 15587,  2000,  2166,  1012,   102]]), 'ntok': tensor([26, 29]), 'cls_emb': tensor([[-0.1446,  0.0341, -0.1689,  ..., -0.3140,  0.5898,  0.1408],\n",
      "        [-0.2380,  0.0966, -0.3695,  ..., -0.4082,  0.4916, -0.1776]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2515,  2498,  2047,  2007,  1996,  2214,  2466,  1010,\n",
      "          3272,  2000,  2265,  7345,  2594, 16093, 10343,  1999,  2023,  4066,\n",
      "          1997,  2644,  1011,  2175,  4030,  4367,  2008,  3084,  1996,  6080,\n",
      "         15658,  2015,  2298,  2066,  2027,  1005,  2128,  2108, 18498,  2058,\n",
      "          1037,  2654,  2243,  5549,  2213,  1012,   102],\n",
      "        [  101,  2028,  1997,  2216, 18114, 20096,  1010,  2019,  2434,  2008,\n",
      "          3531,  2015,  2471,  3071,  2040,  5927,  2009,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2515,  2498,  2047,  2007,  1996,  2214,  2466,  1010,\n",
      "          3272,  2000,  2265,  7345,  2594, 16093, 10343,  1999,  2023,  4066,\n",
      "          1997,  2644,  1011,  2175,  4030,  4367,  2008,  3084,  1996,  6080,\n",
      "         15658,  2015,  2298,  2066,  2027,  1005,  2128,  2108, 18498,  2058,\n",
      "          1037,  2654,  2243,  5549,  2213,  1012,   102],\n",
      "        [  101,  2028,  1997,  2216, 18114, 20096,  1010,  2019,  2434,  2008,\n",
      "          3531,  2015,  2471,  3071,  2040,  5927,  2009,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2744, 0.7256],\n",
      "        [0.2696, 0.7304]]), 'input_ids': tensor([[  101,  2009,  2515,  2498,  2047,  2007,  1996,  2214,  2466,  1010,\n",
      "          3272,  2000,  2265,  7345,  2594, 16093, 10343,  1999,  2023,  4066,\n",
      "          1997,  2644,  1011,  2175,  4030,  4367,  2008,  3084,  1996,  6080,\n",
      "         15658,  2015,  2298,  2066,  2027,  1005,  2128,  2108, 18498,  2058,\n",
      "          1037,  2654,  2243,  5549,  2213,  1012,   102],\n",
      "        [  101,  2028,  1997,  2216, 18114, 20096,  1010,  2019,  2434,  2008,\n",
      "          3531,  2015,  2471,  3071,  2040,  5927,  2009,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([47, 19]), 'cls_emb': tensor([[ 0.1304, -0.0339,  0.2264,  ..., -0.1580,  0.7856,  0.7040],\n",
      "        [-0.1819, -0.4784, -0.3342,  ..., -0.0265,  0.3366,  0.3266]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  7367, 15150,  7317,  1005,  1055,  6437,  2003,  1037, 10480,\n",
      "          1998,  3048,  6533,  1997,  2619,  3005,  2088,  2003,  2357, 14961,\n",
      "          2091,  1010,  2034,  2011,  6896,  1998,  2059,  2011,  7355,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3413,  3085,  4024,  1010,  2021,  2009,  1005,  1055,  1996,\n",
      "          2785,  1997,  4367,  3861,  2008, 24185,  1050,  1005,  1056,  2191,\n",
      "          2172,  1997,  1037, 17624,  2043,  2009,  1005,  1055,  2207,  1010,\n",
      "          1998,  2097,  2025,  2022,  4622,  2146,  5728,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  7367, 15150,  7317,  1005,  1055,  6437,  2003,  1037, 10480,\n",
      "          1998,  3048,  6533,  1997,  2619,  3005,  2088,  2003,  2357, 14961,\n",
      "          2091,  1010,  2034,  2011,  6896,  1998,  2059,  2011,  7355,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3413,  3085,  4024,  1010,  2021,  2009,  1005,  1055,  1996,\n",
      "          2785,  1997,  4367,  3861,  2008, 24185,  1050,  1005,  1056,  2191,\n",
      "          2172,  1997,  1037, 17624,  2043,  2009,  1005,  1055,  2207,  1010,\n",
      "          1998,  2097,  2025,  2022,  4622,  2146,  5728,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2641, 0.7359],\n",
      "        [0.2427, 0.7573]]), 'input_ids': tensor([[  101,  7367, 15150,  7317,  1005,  1055,  6437,  2003,  1037, 10480,\n",
      "          1998,  3048,  6533,  1997,  2619,  3005,  2088,  2003,  2357, 14961,\n",
      "          2091,  1010,  2034,  2011,  6896,  1998,  2059,  2011,  7355,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3413,  3085,  4024,  1010,  2021,  2009,  1005,  1055,  1996,\n",
      "          2785,  1997,  4367,  3861,  2008, 24185,  1050,  1005,  1056,  2191,\n",
      "          2172,  1997,  1037, 17624,  2043,  2009,  1005,  1055,  2207,  1010,\n",
      "          1998,  2097,  2025,  2022,  4622,  2146,  5728,  1012,   102]]), 'ntok': tensor([31, 39]), 'cls_emb': tensor([[-0.3616, -0.1923, -0.4834,  ...,  0.0275,  0.2854,  0.5619],\n",
      "        [ 0.0859,  0.0172, -0.0347,  ..., -0.2395,  0.5553,  0.7799]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2143,  1005,  1055,  4309,  1998, 15732,  2024,  2125,\n",
      "          2471,  2013,  1996,  2131,  1011,  2175,  1012,   102],\n",
      "        [  101,  8403,  1998, 13433, 25593,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2143,  1005,  1055,  4309,  1998, 15732,  2024,  2125,\n",
      "          2471,  2013,  1996,  2131,  1011,  2175,  1012,   102],\n",
      "        [  101,  8403,  1998, 13433, 25593,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2722, 0.7278],\n",
      "        [0.2726, 0.7274]]), 'input_ids': tensor([[  101,  1996,  2143,  1005,  1055,  4309,  1998, 15732,  2024,  2125,\n",
      "          2471,  2013,  1996,  2131,  1011,  2175,  1012,   102],\n",
      "        [  101,  8403,  1998, 13433, 25593,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([18,  7]), 'cls_emb': tensor([[ 0.1972,  0.0445, -0.2136,  ..., -0.3368,  0.5559,  0.4481],\n",
      "        [-0.4667,  0.1678, -0.3661,  ..., -0.3394,  0.2326,  0.5499]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  5041,  1010, 11463,  7716, 14672,  4588,  9765, 22991,\n",
      "          3850,  2008,  1005,  1055,  3492, 11704,  1999,  2049,  2219,  2157,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  2472,  1007,  1051,  1005, 16443,  9020,  2000,  2404,\n",
      "          2070,  8403,  4620,  2039,  2006,  1996,  2502,  3898,  1010,  2021,\n",
      "          2010,  8066,  2012,  4129,  1037,  2466,  1011,  1011,  2002,  2036,\n",
      "          5201,  2000,  1996,  9000,  1011,  1011,  4212,  2460,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  5041,  1010, 11463,  7716, 14672,  4588,  9765, 22991,\n",
      "          3850,  2008,  1005,  1055,  3492, 11704,  1999,  2049,  2219,  2157,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  2472,  1007,  1051,  1005, 16443,  9020,  2000,  2404,\n",
      "          2070,  8403,  4620,  2039,  2006,  1996,  2502,  3898,  1010,  2021,\n",
      "          2010,  8066,  2012,  4129,  1037,  2466,  1011,  1011,  2002,  2036,\n",
      "          5201,  2000,  1996,  9000,  1011,  1011,  4212,  2460,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2733, 0.7267],\n",
      "        [0.2581, 0.7419]]), 'input_ids': tensor([[  101,  1037,  5041,  1010, 11463,  7716, 14672,  4588,  9765, 22991,\n",
      "          3850,  2008,  1005,  1055,  3492, 11704,  1999,  2049,  2219,  2157,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  2472,  1007,  1051,  1005, 16443,  9020,  2000,  2404,\n",
      "          2070,  8403,  4620,  2039,  2006,  1996,  2502,  3898,  1010,  2021,\n",
      "          2010,  8066,  2012,  4129,  1037,  2466,  1011,  1011,  2002,  2036,\n",
      "          5201,  2000,  1996,  9000,  1011,  1011,  4212,  2460,  1012,   102]]), 'ntok': tensor([22, 40]), 'cls_emb': tensor([[-0.1184, -0.2348, -0.2461,  ..., -0.2854,  0.4849,  0.6376],\n",
      "        [-0.3316, -0.0207, -0.5496,  ..., -0.4714,  0.6871,  0.8537]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4107,  2200,  2210, 10218,  7472,  1998,  2130,  8491, 11680,\n",
      "          1012,  1012,  1012,  1037,  6517, 13130,  1997,  1037,  3185,  1010,\n",
      "          4321, 22808,  1997, 11084,  1012,   102],\n",
      "        [  101,  2295,  2069,  3438,  2781,  2146,  1010,  1996,  2143,  2003,\n",
      "          8966,  2007,  2592,  1998, 19221,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4107,  2200,  2210, 10218,  7472,  1998,  2130,  8491, 11680,\n",
      "          1012,  1012,  1012,  1037,  6517, 13130,  1997,  1037,  3185,  1010,\n",
      "          4321, 22808,  1997, 11084,  1012,   102],\n",
      "        [  101,  2295,  2069,  3438,  2781,  2146,  1010,  1996,  2143,  2003,\n",
      "          8966,  2007,  2592,  1998, 19221,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2653, 0.7347],\n",
      "        [0.2711, 0.7289]]), 'input_ids': tensor([[  101,  4107,  2200,  2210, 10218,  7472,  1998,  2130,  8491, 11680,\n",
      "          1012,  1012,  1012,  1037,  6517, 13130,  1997,  1037,  3185,  1010,\n",
      "          4321, 22808,  1997, 11084,  1012,   102],\n",
      "        [  101,  2295,  2069,  3438,  2781,  2146,  1010,  1996,  2143,  2003,\n",
      "          8966,  2007,  2592,  1998, 19221,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([26, 17]), 'cls_emb': tensor([[-0.0832,  0.0876, -0.4763,  ..., -0.2356,  0.7303,  0.3050],\n",
      "        [-0.0809,  0.2184, -0.1185,  ..., -0.0768,  0.4445,  0.4952]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2074,  2025,  3409,  2100,  2438,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2296,  3153,  4150,  2055, 26962,  1010,  2073, 10457,  2696,\n",
      "         23200,  1998, 14583,  2015,  2024,  6334,  1010,  1998,  3348,  2003,\n",
      "          9598,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2074,  2025,  3409,  2100,  2438,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2296,  3153,  4150,  2055, 26962,  1010,  2073, 10457,  2696,\n",
      "         23200,  1998, 14583,  2015,  2024,  6334,  1010,  1998,  3348,  2003,\n",
      "          9598,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2874, 0.7126],\n",
      "        [0.2560, 0.7440]]), 'input_ids': tensor([[  101,  2074,  2025,  3409,  2100,  2438,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2296,  3153,  4150,  2055, 26962,  1010,  2073, 10457,  2696,\n",
      "         23200,  1998, 14583,  2015,  2024,  6334,  1010,  1998,  3348,  2003,\n",
      "          9598,  1012,   102]]), 'ntok': tensor([ 7, 23]), 'cls_emb': tensor([[-0.1339,  0.1403, -0.2195,  ..., -0.1098,  0.1141,  0.2722],\n",
      "        [-0.0955,  0.1624,  0.1027,  ..., -0.6237,  0.2657,  0.6427]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  3138,  1037,  3056,  2785,  1997,  5469,  3185,  2000,\n",
      "          7515,  2004,  1036,  4788,  2084,  3517,  1010,  1005,  2021,  5745,\n",
      "          2911,  5064,  9020,  2000,  2079,  3599,  2008,  1012,   102],\n",
      "        [  101,  2009,  2064,  2025,  2022,  5632,  1010,  2130,  2006,  1996,\n",
      "          2504,  2008,  2028, 15646,  1037,  2919, 18296,  2121, 17312,  1010,\n",
      "          3952,  2138,  2009,  2003, 10634,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  3138,  1037,  3056,  2785,  1997,  5469,  3185,  2000,\n",
      "          7515,  2004,  1036,  4788,  2084,  3517,  1010,  1005,  2021,  5745,\n",
      "          2911,  5064,  9020,  2000,  2079,  3599,  2008,  1012,   102],\n",
      "        [  101,  2009,  2064,  2025,  2022,  5632,  1010,  2130,  2006,  1996,\n",
      "          2504,  2008,  2028, 15646,  1037,  2919, 18296,  2121, 17312,  1010,\n",
      "          3952,  2138,  2009,  2003, 10634,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2306, 0.7694],\n",
      "        [0.2577, 0.7423]]), 'input_ids': tensor([[  101,  2009,  3138,  1037,  3056,  2785,  1997,  5469,  3185,  2000,\n",
      "          7515,  2004,  1036,  4788,  2084,  3517,  1010,  1005,  2021,  5745,\n",
      "          2911,  5064,  9020,  2000,  2079,  3599,  2008,  1012,   102],\n",
      "        [  101,  2009,  2064,  2025,  2022,  5632,  1010,  2130,  2006,  1996,\n",
      "          2504,  2008,  2028, 15646,  1037,  2919, 18296,  2121, 17312,  1010,\n",
      "          3952,  2138,  2009,  2003, 10634,  1012,   102,     0,     0]]), 'ntok': tensor([29, 27]), 'cls_emb': tensor([[ 0.3601,  0.1079, -0.3857,  ..., -0.1589,  0.4621,  0.5432],\n",
      "        [ 0.1084, -0.3380, -0.1978,  ..., -0.1073,  0.5586,  0.5800]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2750,  2035,  3350,  2000,  1996, 10043,  1010,  2023, 18856,\n",
      "         16814,  2121,  2038,  5064,  3266,  2000, 13382,  2004,  2019,  5025,\n",
      "          3444,  3185,  1010,  1996,  2785,  2008,  5571,  2440,  9634,  1998,\n",
      "          4152,  1044, 18863,  2094,  2006,  2694,  1998, 16405, 14536, 11589,\n",
      "          2015,  2000,  2572,  8557,  2235,  2336,  1998,  9808, 25808,  7028,\n",
      "          6001,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2074,  6039,  2121,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2750,  2035,  3350,  2000,  1996, 10043,  1010,  2023, 18856,\n",
      "         16814,  2121,  2038,  5064,  3266,  2000, 13382,  2004,  2019,  5025,\n",
      "          3444,  3185,  1010,  1996,  2785,  2008,  5571,  2440,  9634,  1998,\n",
      "          4152,  1044, 18863,  2094,  2006,  2694,  1998, 16405, 14536, 11589,\n",
      "          2015,  2000,  2572,  8557,  2235,  2336,  1998,  9808, 25808,  7028,\n",
      "          6001,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2074,  6039,  2121,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2404, 0.7596],\n",
      "        [0.2772, 0.7228]]), 'input_ids': tensor([[  101,  2750,  2035,  3350,  2000,  1996, 10043,  1010,  2023, 18856,\n",
      "         16814,  2121,  2038,  5064,  3266,  2000, 13382,  2004,  2019,  5025,\n",
      "          3444,  3185,  1010,  1996,  2785,  2008,  5571,  2440,  9634,  1998,\n",
      "          4152,  1044, 18863,  2094,  2006,  2694,  1998, 16405, 14536, 11589,\n",
      "          2015,  2000,  2572,  8557,  2235,  2336,  1998,  9808, 25808,  7028,\n",
      "          6001,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2074,  6039,  2121,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([53,  9]), 'cls_emb': tensor([[-0.0051,  0.1411, -0.0214,  ...,  0.0716,  0.3912,  0.6455],\n",
      "        [ 0.2259,  0.2430, -0.0550,  ..., -0.0809,  0.1385,  0.5273]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 10654,  8873, 14701,  6298,  4038,  2008,  3084,  2256,\n",
      "          2611,  1996,  5292, 21112,  2015,  6904,  6895, 27606,  4263,  1997,\n",
      "          2019,  3668, 10036,  2915,  2408,  1996,  6701,  1011, 11357,  2240,\n",
      "          1012,   102],\n",
      "        [  101,  2028,  1997,  2216,  4620,  3005, 10015,  1010,  2065,  2738,\n",
      "          9062,  1010, 18458,  2003,  2104, 12690,  2011,  5515,  4509,  7781,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 10654,  8873, 14701,  6298,  4038,  2008,  3084,  2256,\n",
      "          2611,  1996,  5292, 21112,  2015,  6904,  6895, 27606,  4263,  1997,\n",
      "          2019,  3668, 10036,  2915,  2408,  1996,  6701,  1011, 11357,  2240,\n",
      "          1012,   102],\n",
      "        [  101,  2028,  1997,  2216,  4620,  3005, 10015,  1010,  2065,  2738,\n",
      "          9062,  1010, 18458,  2003,  2104, 12690,  2011,  5515,  4509,  7781,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2828, 0.7172],\n",
      "        [0.2757, 0.7243]]), 'input_ids': tensor([[  101,  1037, 10654,  8873, 14701,  6298,  4038,  2008,  3084,  2256,\n",
      "          2611,  1996,  5292, 21112,  2015,  6904,  6895, 27606,  4263,  1997,\n",
      "          2019,  3668, 10036,  2915,  2408,  1996,  6701,  1011, 11357,  2240,\n",
      "          1012,   102],\n",
      "        [  101,  2028,  1997,  2216,  4620,  3005, 10015,  1010,  2065,  2738,\n",
      "          9062,  1010, 18458,  2003,  2104, 12690,  2011,  5515,  4509,  7781,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 22]), 'cls_emb': tensor([[-0.2363, -0.1443, -0.0934,  ..., -0.3989,  0.6405,  0.3431],\n",
      "        [-0.1401, -0.3801, -0.3282,  ..., -0.0584,  0.4234,  0.4678]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  8562,  2003,  1050,  1005,  1056,  2004,  4629,  1010,\n",
      "          1996,  3896,  2025,  2004,  9525,  1010,  4496,  1996,  2466,  2004,\n",
      "         28575,  2004,  1999,  1996,  2434,  1012,   102],\n",
      "        [  101,  2472,  1057,  8545,  8945,  3363,  1998,  1996,  5889,  3073,\n",
      "         13594,  2102,  3114,  2000,  2729,  1999,  2023, 13587,  1005, 17549,\n",
      "          5466,  5963,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  8562,  2003,  1050,  1005,  1056,  2004,  4629,  1010,\n",
      "          1996,  3896,  2025,  2004,  9525,  1010,  4496,  1996,  2466,  2004,\n",
      "         28575,  2004,  1999,  1996,  2434,  1012,   102],\n",
      "        [  101,  2472,  1057,  8545,  8945,  3363,  1998,  1996,  5889,  3073,\n",
      "         13594,  2102,  3114,  2000,  2729,  1999,  2023, 13587,  1005, 17549,\n",
      "          5466,  5963,  1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2558, 0.7442],\n",
      "        [0.2568, 0.7432]]), 'input_ids': tensor([[  101,  1996,  8562,  2003,  1050,  1005,  1056,  2004,  4629,  1010,\n",
      "          1996,  3896,  2025,  2004,  9525,  1010,  4496,  1996,  2466,  2004,\n",
      "         28575,  2004,  1999,  1996,  2434,  1012,   102],\n",
      "        [  101,  2472,  1057,  8545,  8945,  3363,  1998,  1996,  5889,  3073,\n",
      "         13594,  2102,  3114,  2000,  2729,  1999,  2023, 13587,  1005, 17549,\n",
      "          5466,  5963,  1012,   102,     0,     0,     0]]), 'ntok': tensor([27, 24]), 'cls_emb': tensor([[-0.4053, -0.4350, -0.4534,  ..., -0.4928,  0.7238,  0.7637],\n",
      "        [ 0.0394,  0.3468, -0.1293,  ..., -0.3098,  0.5877,  0.1627]])}\n",
      "encoded input is: {'input_ids': tensor([[ 101, 1012, 1012, 1012, 1037, 2466, 2057, 2031, 1050, 1005, 1056, 2464,\n",
      "         2006, 1996, 2502, 3898, 2077, 1010, 1998, 2009, 1005, 1055, 1037, 2466,\n",
      "         2008, 2057, 2004, 4841, 1010, 1998, 2529, 9552, 1010, 2323, 2113, 1012,\n",
      "          102],\n",
      "        [ 101, 2065, 2115, 5510, 3216, 2000, 1036, 3697, 1005, 3152, 2017, 7078,\n",
      "         6187, 1050, 1005, 1056, 3335, 2009, 1012,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[ 101, 1012, 1012, 1012, 1037, 2466, 2057, 2031, 1050, 1005, 1056, 2464,\n",
      "         2006, 1996, 2502, 3898, 2077, 1010, 1998, 2009, 1005, 1055, 1037, 2466,\n",
      "         2008, 2057, 2004, 4841, 1010, 1998, 2529, 9552, 1010, 2323, 2113, 1012,\n",
      "          102],\n",
      "        [ 101, 2065, 2115, 5510, 3216, 2000, 1036, 3697, 1005, 3152, 2017, 7078,\n",
      "         6187, 1050, 1005, 1056, 3335, 2009, 1012,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2361, 0.7639],\n",
      "        [0.2625, 0.7375]]), 'input_ids': tensor([[ 101, 1012, 1012, 1012, 1037, 2466, 2057, 2031, 1050, 1005, 1056, 2464,\n",
      "         2006, 1996, 2502, 3898, 2077, 1010, 1998, 2009, 1005, 1055, 1037, 2466,\n",
      "         2008, 2057, 2004, 4841, 1010, 1998, 2529, 9552, 1010, 2323, 2113, 1012,\n",
      "          102],\n",
      "        [ 101, 2065, 2115, 5510, 3216, 2000, 1036, 3697, 1005, 3152, 2017, 7078,\n",
      "         6187, 1050, 1005, 1056, 3335, 2009, 1012,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0]]), 'ntok': tensor([37, 20]), 'cls_emb': tensor([[-0.0233,  0.2240, -0.2525,  ..., -0.2831,  0.2823,  0.4013],\n",
      "        [ 0.1737, -0.0153, -0.4103,  ..., -0.2703,  0.5545,  0.6430]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  3185,  2003,  2242,  1997,  2019, 17727, 14122,  2953,\n",
      "          2993,  1010, 10917,  1998, 11687,  4667,  2049,  3430,  1999,  1037,\n",
      "         14819,  1997,  2757,  4515,  1998, 25012,  4950,  2147,  1012,   102],\n",
      "        [  101,  1045,  2288,  1037, 14978,  3666,  2023, 25120,  2091,  2121,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  3185,  2003,  2242,  1997,  2019, 17727, 14122,  2953,\n",
      "          2993,  1010, 10917,  1998, 11687,  4667,  2049,  3430,  1999,  1037,\n",
      "         14819,  1997,  2757,  4515,  1998, 25012,  4950,  2147,  1012,   102],\n",
      "        [  101,  1045,  2288,  1037, 14978,  3666,  2023, 25120,  2091,  2121,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2377, 0.7623],\n",
      "        [0.2782, 0.7218]]), 'input_ids': tensor([[  101,  2023,  3185,  2003,  2242,  1997,  2019, 17727, 14122,  2953,\n",
      "          2993,  1010, 10917,  1998, 11687,  4667,  2049,  3430,  1999,  1037,\n",
      "         14819,  1997,  2757,  4515,  1998, 25012,  4950,  2147,  1012,   102],\n",
      "        [  101,  1045,  2288,  1037, 14978,  3666,  2023, 25120,  2091,  2121,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([30, 12]), 'cls_emb': tensor([[ 0.3218,  0.2046,  0.0747,  ..., -0.0628,  0.5324,  0.6630],\n",
      "        [ 0.2924,  0.1709,  0.0609,  ..., -0.1197,  0.5592,  0.2293]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 23564,  8524,  2078,  1005,  1055,  5896,  2038,  4510,  2438,\n",
      "          5436,  2000,  5164,  1996, 28465,  2362,  1998,  2025,  3243,  2438,\n",
      "         23191,  2000,  2562,  1996,  5344,  3442,  1012,   102],\n",
      "        [  101,  1996, 27547,  1998,  2022, 29602,  4063, 15787,  2104,  9250,\n",
      "          6063,  3660,  3957,  1037,  2732,  2836,  2008,  2003,  2498,  2460,\n",
      "          1997,  2033,  6491, 11124,  6774,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 23564,  8524,  2078,  1005,  1055,  5896,  2038,  4510,  2438,\n",
      "          5436,  2000,  5164,  1996, 28465,  2362,  1998,  2025,  3243,  2438,\n",
      "         23191,  2000,  2562,  1996,  5344,  3442,  1012,   102],\n",
      "        [  101,  1996, 27547,  1998,  2022, 29602,  4063, 15787,  2104,  9250,\n",
      "          6063,  3660,  3957,  1037,  2732,  2836,  2008,  2003,  2498,  2460,\n",
      "          1997,  2033,  6491, 11124,  6774,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2599, 0.7401],\n",
      "        [0.2428, 0.7572]]), 'input_ids': tensor([[  101, 23564,  8524,  2078,  1005,  1055,  5896,  2038,  4510,  2438,\n",
      "          5436,  2000,  5164,  1996, 28465,  2362,  1998,  2025,  3243,  2438,\n",
      "         23191,  2000,  2562,  1996,  5344,  3442,  1012,   102],\n",
      "        [  101,  1996, 27547,  1998,  2022, 29602,  4063, 15787,  2104,  9250,\n",
      "          6063,  3660,  3957,  1037,  2732,  2836,  2008,  2003,  2498,  2460,\n",
      "          1997,  2033,  6491, 11124,  6774,  1012,   102,     0]]), 'ntok': tensor([28, 27]), 'cls_emb': tensor([[-0.3208,  0.0215, -0.5216,  ..., -0.4388,  0.8184,  0.4431],\n",
      "        [-0.1050, -0.0609, -0.2310,  ..., -0.5458,  0.4510,  0.3382]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2311,  3254,  1998, 28797,  1010,  1996,  2143,  1010,  7419,\n",
      "          1037, 21986,  9096, 11867, 12162,  7231,  3012,  1998, 12689,  3973,\n",
      "          4567, 23191,  2015,  1010, 11791,  2046,  1037,  3278,  2839,  2817,\n",
      "          2008,  2003,  2119,  3048,  1998,  7968,  1012,   102,     0],\n",
      "        [  101,  2035,  1996, 23713,  2098,  1011,  2039,  4116,  9881,  1011,\n",
      "          2806, 28465,  1998, 27042,  2075,  9680,  1011,  3384,  6187,  1050,\n",
      "          1005,  1056, 14249,  1996,  2755,  2008,  1010,  2428,  1010,  2057,\n",
      "          1005,  2310,  2042,  2182,  1010,  2589,  2008,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2311,  3254,  1998, 28797,  1010,  1996,  2143,  1010,  7419,\n",
      "          1037, 21986,  9096, 11867, 12162,  7231,  3012,  1998, 12689,  3973,\n",
      "          4567, 23191,  2015,  1010, 11791,  2046,  1037,  3278,  2839,  2817,\n",
      "          2008,  2003,  2119,  3048,  1998,  7968,  1012,   102,     0],\n",
      "        [  101,  2035,  1996, 23713,  2098,  1011,  2039,  4116,  9881,  1011,\n",
      "          2806, 28465,  1998, 27042,  2075,  9680,  1011,  3384,  6187,  1050,\n",
      "          1005,  1056, 14249,  1996,  2755,  2008,  1010,  2428,  1010,  2057,\n",
      "          1005,  2310,  2042,  2182,  1010,  2589,  2008,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2608, 0.7392],\n",
      "        [0.2571, 0.7429]]), 'input_ids': tensor([[  101,  2311,  3254,  1998, 28797,  1010,  1996,  2143,  1010,  7419,\n",
      "          1037, 21986,  9096, 11867, 12162,  7231,  3012,  1998, 12689,  3973,\n",
      "          4567, 23191,  2015,  1010, 11791,  2046,  1037,  3278,  2839,  2817,\n",
      "          2008,  2003,  2119,  3048,  1998,  7968,  1012,   102,     0],\n",
      "        [  101,  2035,  1996, 23713,  2098,  1011,  2039,  4116,  9881,  1011,\n",
      "          2806, 28465,  1998, 27042,  2075,  9680,  1011,  3384,  6187,  1050,\n",
      "          1005,  1056, 14249,  1996,  2755,  2008,  1010,  2428,  1010,  2057,\n",
      "          1005,  2310,  2042,  2182,  1010,  2589,  2008,  1012,   102]]), 'ntok': tensor([38, 39]), 'cls_emb': tensor([[-0.2459,  0.0409, -0.3944,  ..., -0.4211,  0.3115,  0.5744],\n",
      "        [ 0.2423,  0.2564, -0.1299,  ..., -0.1427,  0.6307,  0.2740]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2472,  4282,  2129,  2000,  6611,  3793, 11137, 27068,\n",
      "          1010,  2021,  2010,  6533,  1997,  3348,  1011,  2004,  1011,  2162,\n",
      "          2003,  9975, 13130,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 17453,  2738, 14726,  1010,  2021,  4821,  1037,  8502,  1011,\n",
      "          2559,  8501,  1010,  1996,  2995, 14842,  2052,  2031,  2042,  2000,\n",
      "          5342,  8813,  4774,  4498,  1998,  3294, 24964,  2863, 11528,  2063,\n",
      "          2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2472,  4282,  2129,  2000,  6611,  3793, 11137, 27068,\n",
      "          1010,  2021,  2010,  6533,  1997,  3348,  1011,  2004,  1011,  2162,\n",
      "          2003,  9975, 13130,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 17453,  2738, 14726,  1010,  2021,  4821,  1037,  8502,  1011,\n",
      "          2559,  8501,  1010,  1996,  2995, 14842,  2052,  2031,  2042,  2000,\n",
      "          5342,  8813,  4774,  4498,  1998,  3294, 24964,  2863, 11528,  2063,\n",
      "          2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2559, 0.7441],\n",
      "        [0.2578, 0.7422]]), 'input_ids': tensor([[  101,  1996,  2472,  4282,  2129,  2000,  6611,  3793, 11137, 27068,\n",
      "          1010,  2021,  2010,  6533,  1997,  3348,  1011,  2004,  1011,  2162,\n",
      "          2003,  9975, 13130,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 17453,  2738, 14726,  1010,  2021,  4821,  1037,  8502,  1011,\n",
      "          2559,  8501,  1010,  1996,  2995, 14842,  2052,  2031,  2042,  2000,\n",
      "          5342,  8813,  4774,  4498,  1998,  3294, 24964,  2863, 11528,  2063,\n",
      "          2009,  1012,   102]]), 'ntok': tensor([25, 33]), 'cls_emb': tensor([[-0.1047,  0.1540, -0.3570,  ..., -0.2937,  0.7645,  0.7265],\n",
      "        [-0.3771, -0.2822, -0.3041,  ..., -0.2001,  0.1199,  0.6725]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2512,  5054, 19570,  2389,  1010, 10634,  1036,  1036, 16941,\n",
      "          1011,  5469,  1005,  1005, 17312,  2003,  1037, 11844,  1010,  8892,\n",
      "          6912,  1999,  4257, 29421,  1998,  2919,  3772,  1012,   102],\n",
      "        [  101,  2502,  6638,  5949,  1997,  2051,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2512,  5054, 19570,  2389,  1010, 10634,  1036,  1036, 16941,\n",
      "          1011,  5469,  1005,  1005, 17312,  2003,  1037, 11844,  1010,  8892,\n",
      "          6912,  1999,  4257, 29421,  1998,  2919,  3772,  1012,   102],\n",
      "        [  101,  2502,  6638,  5949,  1997,  2051,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2503, 0.7497],\n",
      "        [0.2787, 0.7213]]), 'input_ids': tensor([[  101,  2512,  5054, 19570,  2389,  1010, 10634,  1036,  1036, 16941,\n",
      "          1011,  5469,  1005,  1005, 17312,  2003,  1037, 11844,  1010,  8892,\n",
      "          6912,  1999,  4257, 29421,  1998,  2919,  3772,  1012,   102],\n",
      "        [  101,  2502,  6638,  5949,  1997,  2051,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([29,  8]), 'cls_emb': tensor([[ 0.0984,  0.2101,  0.1430,  ..., -0.6158,  0.8423,  0.3948],\n",
      "        [-0.3967,  0.3086, -0.0652,  ..., -0.4555,  0.2548,  0.1626]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 12145,  4092,  1010,  2009,  1005,  1055, 23421,  2000,  5376,\n",
      "          2911,  1999,  2254,  2000,  4468,  9951,  8040,  7317,  7432,  2066,\n",
      "          2023, 26822, 14968, 23873, 10874,  1012,   102],\n",
      "        [  101, 11281,  1037,  2613,  2091,  2121,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 12145,  4092,  1010,  2009,  1005,  1055, 23421,  2000,  5376,\n",
      "          2911,  1999,  2254,  2000,  4468,  9951,  8040,  7317,  7432,  2066,\n",
      "          2023, 26822, 14968, 23873, 10874,  1012,   102],\n",
      "        [  101, 11281,  1037,  2613,  2091,  2121,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2486, 0.7514],\n",
      "        [0.2913, 0.7087]]), 'input_ids': tensor([[  101, 12145,  4092,  1010,  2009,  1005,  1055, 23421,  2000,  5376,\n",
      "          2911,  1999,  2254,  2000,  4468,  9951,  8040,  7317,  7432,  2066,\n",
      "          2023, 26822, 14968, 23873, 10874,  1012,   102],\n",
      "        [  101, 11281,  1037,  2613,  2091,  2121,  1029,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([27,  8]), 'cls_emb': tensor([[ 0.0979, -0.0892,  0.0805,  ..., -0.2521,  0.4674,  0.5212],\n",
      "        [ 0.0765, -0.0109, -0.1059,  ..., -0.3206,  0.2317,  0.4382]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2612,  1010,  2002,  3065,  2068,  1996,  4847,  2027,  2024,\n",
      "          2349,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2034,  1011,  2051,  3213,  1011,  2472, 14262,  2854,  3065,\n",
      "          1037,  9487,  5592,  2005, 20957,  2007,  2023,  3048,  1010,  4621,\n",
      "          2210,  2143,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2612,  1010,  2002,  3065,  2068,  1996,  4847,  2027,  2024,\n",
      "          2349,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2034,  1011,  2051,  3213,  1011,  2472, 14262,  2854,  3065,\n",
      "          1037,  9487,  5592,  2005, 20957,  2007,  2023,  3048,  1010,  4621,\n",
      "          2210,  2143,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2214, 0.7786],\n",
      "        [0.2507, 0.7493]]), 'input_ids': tensor([[  101,  2612,  1010,  2002,  3065,  2068,  1996,  4847,  2027,  2024,\n",
      "          2349,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2034,  1011,  2051,  3213,  1011,  2472, 14262,  2854,  3065,\n",
      "          1037,  9487,  5592,  2005, 20957,  2007,  2023,  3048,  1010,  4621,\n",
      "          2210,  2143,  1012,   102]]), 'ntok': tensor([13, 24]), 'cls_emb': tensor([[-0.3858,  0.2762,  0.0629,  ...,  0.0888,  0.3119,  0.6173],\n",
      "        [-0.2463, -0.1689, -0.3928,  ..., -0.2836,  0.5621,  0.3122]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 12297,  1005,  1055,  4087, 26120,  4515,  2039,  4855,  2010,\n",
      "          2143,  2460,  1025,  2002,  5744,  2229,  2058,  2524, 23019,  2130,\n",
      "          2004,  2002, 26944,  2015,  2068,  1012,   102],\n",
      "        [  101,  8509,  1037,  2529,  2227,  2006,  1037,  2455,  2087,  2530,\n",
      "          2545,  2024, 16261,  2007,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 12297,  1005,  1055,  4087, 26120,  4515,  2039,  4855,  2010,\n",
      "          2143,  2460,  1025,  2002,  5744,  2229,  2058,  2524, 23019,  2130,\n",
      "          2004,  2002, 26944,  2015,  2068,  1012,   102],\n",
      "        [  101,  8509,  1037,  2529,  2227,  2006,  1037,  2455,  2087,  2530,\n",
      "          2545,  2024, 16261,  2007,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2521, 0.7479],\n",
      "        [0.2534, 0.7466]]), 'input_ids': tensor([[  101, 12297,  1005,  1055,  4087, 26120,  4515,  2039,  4855,  2010,\n",
      "          2143,  2460,  1025,  2002,  5744,  2229,  2058,  2524, 23019,  2130,\n",
      "          2004,  2002, 26944,  2015,  2068,  1012,   102],\n",
      "        [  101,  8509,  1037,  2529,  2227,  2006,  1037,  2455,  2087,  2530,\n",
      "          2545,  2024, 16261,  2007,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([27, 16]), 'cls_emb': tensor([[-0.5705, -0.0865, -0.5300,  ..., -0.1407,  0.4159,  0.4491],\n",
      "        [-0.3320,  0.1206, -0.4710,  ..., -0.7870,  0.2963,  0.0600]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3084,  2005,  1037,  3492, 16010, 10523,  3325,  1012,   102,\n",
      "             0,     0],\n",
      "        [  101,  6289, 23644,  2232,  1012,  1012,  1012,  7195,  2003,  4086,\n",
      "           999,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3084,  2005,  1037,  3492, 16010, 10523,  3325,  1012,   102,\n",
      "             0,     0],\n",
      "        [  101,  6289, 23644,  2232,  1012,  1012,  1012,  7195,  2003,  4086,\n",
      "           999,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2669, 0.7331],\n",
      "        [0.2630, 0.7370]]), 'input_ids': tensor([[  101,  3084,  2005,  1037,  3492, 16010, 10523,  3325,  1012,   102,\n",
      "             0,     0],\n",
      "        [  101,  6289, 23644,  2232,  1012,  1012,  1012,  7195,  2003,  4086,\n",
      "           999,   102]]), 'ntok': tensor([10, 12]), 'cls_emb': tensor([[ 0.1275,  0.1129, -0.0783,  ..., -0.2988,  0.3203,  0.3443],\n",
      "        [ 0.2129,  0.3005,  0.2075,  ..., -0.3051,  0.1585,  0.3950]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2152, 12618,  2860,  2969,  1011,  2805, 14240,  1997,  3226,\n",
      "          2342,  2025,  6611,  1010,  2021,  2216,  2040,  3866,  4658,  2004,\n",
      "          3256,  2031,  2012,  2197,  2179,  1037, 11007,  3582,  1011,  2039,\n",
      "          1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  3157,  8603,  2003,  2025,  2069,  2084,  1037, 17115,  2135,\n",
      "          5214,  2834,  1998,  6907,  3538,  1010,  2021,  2036,  1037, 20057,\n",
      "         12326,  1997,  1037,  4795,  2576,  3663,  2006,  1996, 16079,  1997,\n",
      "          2746,  2000,  1037,  2132,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2152, 12618,  2860,  2969,  1011,  2805, 14240,  1997,  3226,\n",
      "          2342,  2025,  6611,  1010,  2021,  2216,  2040,  3866,  4658,  2004,\n",
      "          3256,  2031,  2012,  2197,  2179,  1037, 11007,  3582,  1011,  2039,\n",
      "          1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  3157,  8603,  2003,  2025,  2069,  2084,  1037, 17115,  2135,\n",
      "          5214,  2834,  1998,  6907,  3538,  1010,  2021,  2036,  1037, 20057,\n",
      "         12326,  1997,  1037,  4795,  2576,  3663,  2006,  1996, 16079,  1997,\n",
      "          2746,  2000,  1037,  2132,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2439, 0.7561],\n",
      "        [0.2607, 0.7393]]), 'input_ids': tensor([[  101,  2152, 12618,  2860,  2969,  1011,  2805, 14240,  1997,  3226,\n",
      "          2342,  2025,  6611,  1010,  2021,  2216,  2040,  3866,  4658,  2004,\n",
      "          3256,  2031,  2012,  2197,  2179,  1037, 11007,  3582,  1011,  2039,\n",
      "          1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  3157,  8603,  2003,  2025,  2069,  2084,  1037, 17115,  2135,\n",
      "          5214,  2834,  1998,  6907,  3538,  1010,  2021,  2036,  1037, 20057,\n",
      "         12326,  1997,  1037,  4795,  2576,  3663,  2006,  1996, 16079,  1997,\n",
      "          2746,  2000,  1037,  2132,  1012,   102]]), 'ntok': tensor([32, 36]), 'cls_emb': tensor([[ 0.0929,  0.0463, -0.0479,  ..., -0.3089,  0.3809,  0.3490],\n",
      "        [-0.1825, -0.0265, -0.3122,  ..., -0.2257,  0.4104,  0.4963]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2066,  2017,  2071,  1050,  1005,  1056,  5437,  2023,  4977,\n",
      "         22005,  2013,  2661,  2185,  1012,   102],\n",
      "        [  101,  1996,  4616,  2202,  1996,  3185,  2000,  1037,  3020,  2504,\n",
      "          1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2066,  2017,  2071,  1050,  1005,  1056,  5437,  2023,  4977,\n",
      "         22005,  2013,  2661,  2185,  1012,   102],\n",
      "        [  101,  1996,  4616,  2202,  1996,  3185,  2000,  1037,  3020,  2504,\n",
      "          1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2787, 0.7213],\n",
      "        [0.2634, 0.7366]]), 'input_ids': tensor([[  101,  2066,  2017,  2071,  1050,  1005,  1056,  5437,  2023,  4977,\n",
      "         22005,  2013,  2661,  2185,  1012,   102],\n",
      "        [  101,  1996,  4616,  2202,  1996,  3185,  2000,  1037,  3020,  2504,\n",
      "          1012,   102,     0,     0,     0,     0]]), 'ntok': tensor([16, 12]), 'cls_emb': tensor([[ 0.1282,  0.1456, -0.3958,  ...,  0.0571,  0.4209,  0.1746],\n",
      "        [-0.0603, -0.1631,  0.2571,  ..., -0.4902,  0.3921,  0.1090]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4482,  1012,  1012,  1012,  2003,  2061,  4372, 22591,  5596,\n",
      "          1997,  2014,  2219,  4325,  2008,  2016,  6187,  1050,  1005,  1056,\n",
      "          2156,  2129, 16021, 16093, 27709,  3468,  1996,  2839,  2003,  1012,\n",
      "           102],\n",
      "        [  101,  1012,  1012,  1012,  3138,  1996,  5053,  1997,  3598,  1998,\n",
      "         11463,  5104,  2009,  2007,  1037,  2466,  2008,  2071,  3543,  3087,\n",
      "          7539,  1997,  2037, 24666,  2007,  1996,  4368,   102,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4482,  1012,  1012,  1012,  2003,  2061,  4372, 22591,  5596,\n",
      "          1997,  2014,  2219,  4325,  2008,  2016,  6187,  1050,  1005,  1056,\n",
      "          2156,  2129, 16021, 16093, 27709,  3468,  1996,  2839,  2003,  1012,\n",
      "           102],\n",
      "        [  101,  1012,  1012,  1012,  3138,  1996,  5053,  1997,  3598,  1998,\n",
      "         11463,  5104,  2009,  2007,  1037,  2466,  2008,  2071,  3543,  3087,\n",
      "          7539,  1997,  2037, 24666,  2007,  1996,  4368,   102,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2769, 0.7231],\n",
      "        [0.2484, 0.7516]]), 'input_ids': tensor([[  101,  4482,  1012,  1012,  1012,  2003,  2061,  4372, 22591,  5596,\n",
      "          1997,  2014,  2219,  4325,  2008,  2016,  6187,  1050,  1005,  1056,\n",
      "          2156,  2129, 16021, 16093, 27709,  3468,  1996,  2839,  2003,  1012,\n",
      "           102],\n",
      "        [  101,  1012,  1012,  1012,  3138,  1996,  5053,  1997,  3598,  1998,\n",
      "         11463,  5104,  2009,  2007,  1037,  2466,  2008,  2071,  3543,  3087,\n",
      "          7539,  1997,  2037, 24666,  2007,  1996,  4368,   102,     0,     0,\n",
      "             0]]), 'ntok': tensor([31, 28]), 'cls_emb': tensor([[ 0.1330, -0.1137, -0.3625,  ..., -0.1675,  0.4586,  0.5992],\n",
      "        [-0.0788,  0.0863, -0.7457,  ..., -0.3848,  0.5592,  0.2298]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2114,  2035, 10238,  1999,  6014,  1998,  3109,  1010,  2009,\n",
      "         19815,  2098,  2033,  2041,  2074,  2986,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2004,  1996,  6745,  7226,  1999,  1996,  2694,  1011,  2000,\n",
      "          1011,  3185,  6329,  2208,  1010,  1045,  8645,  3084,  2049,  2502,\n",
      "          1011,  3898,  4443,  2007,  2210,  1997,  1996, 11265,  2099, 10736,\n",
      "          2434,  3012,  1997,  2049, 23222,  2235,  1011,  3898,  4013,  6914,\n",
      "         15660,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2114,  2035, 10238,  1999,  6014,  1998,  3109,  1010,  2009,\n",
      "         19815,  2098,  2033,  2041,  2074,  2986,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2004,  1996,  6745,  7226,  1999,  1996,  2694,  1011,  2000,\n",
      "          1011,  3185,  6329,  2208,  1010,  1045,  8645,  3084,  2049,  2502,\n",
      "          1011,  3898,  4443,  2007,  2210,  1997,  1996, 11265,  2099, 10736,\n",
      "          2434,  3012,  1997,  2049, 23222,  2235,  1011,  3898,  4013,  6914,\n",
      "         15660,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2594, 0.7406],\n",
      "        [0.2526, 0.7474]]), 'input_ids': tensor([[  101,  2114,  2035, 10238,  1999,  6014,  1998,  3109,  1010,  2009,\n",
      "         19815,  2098,  2033,  2041,  2074,  2986,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2004,  1996,  6745,  7226,  1999,  1996,  2694,  1011,  2000,\n",
      "          1011,  3185,  6329,  2208,  1010,  1045,  8645,  3084,  2049,  2502,\n",
      "          1011,  3898,  4443,  2007,  2210,  1997,  1996, 11265,  2099, 10736,\n",
      "          2434,  3012,  1997,  2049, 23222,  2235,  1011,  3898,  4013,  6914,\n",
      "         15660,  1012,   102]]), 'ntok': tensor([18, 43]), 'cls_emb': tensor([[ 0.1569, -0.0831, -0.2938,  ..., -0.1078,  0.2854,  0.1986],\n",
      "        [-0.3199, -0.1849, -0.1324,  ..., -0.2243,  0.6338,  0.6992]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  1005,  1055,  2428,  2069,  2028,  2204,  2801,  1999,\n",
      "          2023,  3185,  1010,  2021,  1996,  2472,  3216,  2007,  2009,  1998,\n",
      "          7534,  2009,  2007,  2019,  4895, 29278, 18150, 10880,  5107,  6090,\n",
      "         15395,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  2061,  1011,  1999, 23606,  1011,  2009,  1005,  1055,\n",
      "          1011, 16524, 12931, 10472,  1006,  3794,  1996,  5755,  1997,  9465,\n",
      "          2485,  1010, 20588,  6316,  8428,  1998,  7987, 11012,  2378, 11527,\n",
      "          1007,  7545,  2067,  5758,  1997, 18178,  2229,  2100,  2214, 26631,\n",
      "         17312,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  1005,  1055,  2428,  2069,  2028,  2204,  2801,  1999,\n",
      "          2023,  3185,  1010,  2021,  1996,  2472,  3216,  2007,  2009,  1998,\n",
      "          7534,  2009,  2007,  2019,  4895, 29278, 18150, 10880,  5107,  6090,\n",
      "         15395,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  2061,  1011,  1999, 23606,  1011,  2009,  1005,  1055,\n",
      "          1011, 16524, 12931, 10472,  1006,  3794,  1996,  5755,  1997,  9465,\n",
      "          2485,  1010, 20588,  6316,  8428,  1998,  7987, 11012,  2378, 11527,\n",
      "          1007,  7545,  2067,  5758,  1997, 18178,  2229,  2100,  2214, 26631,\n",
      "         17312,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2326, 0.7674],\n",
      "        [0.2547, 0.7453]]), 'input_ids': tensor([[  101,  2045,  1005,  1055,  2428,  2069,  2028,  2204,  2801,  1999,\n",
      "          2023,  3185,  1010,  2021,  1996,  2472,  3216,  2007,  2009,  1998,\n",
      "          7534,  2009,  2007,  2019,  4895, 29278, 18150, 10880,  5107,  6090,\n",
      "         15395,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  2061,  1011,  1999, 23606,  1011,  2009,  1005,  1055,\n",
      "          1011, 16524, 12931, 10472,  1006,  3794,  1996,  5755,  1997,  9465,\n",
      "          2485,  1010, 20588,  6316,  8428,  1998,  7987, 11012,  2378, 11527,\n",
      "          1007,  7545,  2067,  5758,  1997, 18178,  2229,  2100,  2214, 26631,\n",
      "         17312,  2015,  1012,   102]]), 'ntok': tensor([33, 44]), 'cls_emb': tensor([[ 0.0628,  0.0040, -0.1389,  ..., -0.3506,  0.5491,  0.5522],\n",
      "        [-0.4095, -0.1027, -0.2125,  ..., -0.0105,  0.8917,  0.3855]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2302,  2512,  1011,  2644, 21416,  2030,  1996, 25953,  4818,\n",
      "          2058, 11115,  1997,  1037, 11382,  2229,  8261,  5488, 16561,  6925,\n",
      "          1010, 11530,  4877, 13887,  2003,  2074,  2178,  3467, 24372,  2015,\n",
      "          1012,   102],\n",
      "        [  101,  2019,  4895, 26266, 10128,  2401,  6321,  9643,  2817,  1999,\n",
      "          2969,  1011,  1998,  4378,  1011,  6905,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2302,  2512,  1011,  2644, 21416,  2030,  1996, 25953,  4818,\n",
      "          2058, 11115,  1997,  1037, 11382,  2229,  8261,  5488, 16561,  6925,\n",
      "          1010, 11530,  4877, 13887,  2003,  2074,  2178,  3467, 24372,  2015,\n",
      "          1012,   102],\n",
      "        [  101,  2019,  4895, 26266, 10128,  2401,  6321,  9643,  2817,  1999,\n",
      "          2969,  1011,  1998,  4378,  1011,  6905,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2658, 0.7342],\n",
      "        [0.2796, 0.7204]]), 'input_ids': tensor([[  101,  2302,  2512,  1011,  2644, 21416,  2030,  1996, 25953,  4818,\n",
      "          2058, 11115,  1997,  1037, 11382,  2229,  8261,  5488, 16561,  6925,\n",
      "          1010, 11530,  4877, 13887,  2003,  2074,  2178,  3467, 24372,  2015,\n",
      "          1012,   102],\n",
      "        [  101,  2019,  4895, 26266, 10128,  2401,  6321,  9643,  2817,  1999,\n",
      "          2969,  1011,  1998,  4378,  1011,  6905,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 18]), 'cls_emb': tensor([[ 0.1321,  0.0433, -0.0889,  ..., -0.2919,  0.3941,  0.3209],\n",
      "        [-0.4446, -0.0936, -0.4905,  ..., -0.1835,  0.4590,  0.5246]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185, 26966,  5662,  1997,  2183,  2000,  1037,  4596,\n",
      "          2283,  1998,  2108,  3140,  2000,  3422,  1996,  3677,  1998, 22566,\n",
      "          1005,  1055,  2188,  2678,  1997,  2037,  3336,  1005,  1055,  4182,\n",
      "          1012,   102],\n",
      "        [  101, 12631, 22084,  2099,  2515,  1050,  1005,  1056,  6614,  2005,\n",
      "          2256, 11883,  1010,  2021,  2738, 18058,  1037,  2836,  1997,  8478,\n",
      "          8066,  1998,  5995,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185, 26966,  5662,  1997,  2183,  2000,  1037,  4596,\n",
      "          2283,  1998,  2108,  3140,  2000,  3422,  1996,  3677,  1998, 22566,\n",
      "          1005,  1055,  2188,  2678,  1997,  2037,  3336,  1005,  1055,  4182,\n",
      "          1012,   102],\n",
      "        [  101, 12631, 22084,  2099,  2515,  1050,  1005,  1056,  6614,  2005,\n",
      "          2256, 11883,  1010,  2021,  2738, 18058,  1037,  2836,  1997,  8478,\n",
      "          8066,  1998,  5995,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2706, 0.7294],\n",
      "        [0.2408, 0.7592]]), 'input_ids': tensor([[  101,  1996,  3185, 26966,  5662,  1997,  2183,  2000,  1037,  4596,\n",
      "          2283,  1998,  2108,  3140,  2000,  3422,  1996,  3677,  1998, 22566,\n",
      "          1005,  1055,  2188,  2678,  1997,  2037,  3336,  1005,  1055,  4182,\n",
      "          1012,   102],\n",
      "        [  101, 12631, 22084,  2099,  2515,  1050,  1005,  1056,  6614,  2005,\n",
      "          2256, 11883,  1010,  2021,  2738, 18058,  1037,  2836,  1997,  8478,\n",
      "          8066,  1998,  5995,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 25]), 'cls_emb': tensor([[-0.4494, -0.4544, -0.0734,  ..., -0.1638,  0.5569,  0.1923],\n",
      "        [-0.1489,  0.1714, -0.5862,  ..., -0.3934,  0.5321,  0.6770]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2261,  3152,  5425,  2061,  6669,  1996,  8069,  1998,  5544,\n",
      "          1997,  2210,  3337,  2006,  3598,  4249,  2004,  2092,  2004,  1996,\n",
      "          4961,  2273,  2040,  4133,  1999,  1996,  4832,  1012,   102],\n",
      "        [  101,  2009,  2003, 19142,  1010,  1998,  2008,  1005,  1055,  2035,\n",
      "          2009,  3791,  2000,  2022,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2261,  3152,  5425,  2061,  6669,  1996,  8069,  1998,  5544,\n",
      "          1997,  2210,  3337,  2006,  3598,  4249,  2004,  2092,  2004,  1996,\n",
      "          4961,  2273,  2040,  4133,  1999,  1996,  4832,  1012,   102],\n",
      "        [  101,  2009,  2003, 19142,  1010,  1998,  2008,  1005,  1055,  2035,\n",
      "          2009,  3791,  2000,  2022,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2279, 0.7721],\n",
      "        [0.2466, 0.7534]]), 'input_ids': tensor([[  101,  2261,  3152,  5425,  2061,  6669,  1996,  8069,  1998,  5544,\n",
      "          1997,  2210,  3337,  2006,  3598,  4249,  2004,  2092,  2004,  1996,\n",
      "          4961,  2273,  2040,  4133,  1999,  1996,  4832,  1012,   102],\n",
      "        [  101,  2009,  2003, 19142,  1010,  1998,  2008,  1005,  1055,  2035,\n",
      "          2009,  3791,  2000,  2022,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([29, 16]), 'cls_emb': tensor([[-0.0084,  0.1536, -0.2414,  ..., -0.2823,  0.3318,  0.4621],\n",
      "        [ 0.1839,  0.2422,  0.0871,  ...,  0.0284, -0.0377,  0.6600]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 10368,  1010, 23852,  2135, 25540, 25725,  2075,  1998,  4895,\n",
      "         10258,  8490, 28392,  5541,  1012,   102,     0,     0],\n",
      "        [  101,  2005,  1996,  2087,  2112,  8799, 21096,  2015,  2083,  2006,\n",
      "          2070,  5024,  4616,  1998, 25591,  7982,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 10368,  1010, 23852,  2135, 25540, 25725,  2075,  1998,  4895,\n",
      "         10258,  8490, 28392,  5541,  1012,   102,     0,     0],\n",
      "        [  101,  2005,  1996,  2087,  2112,  8799, 21096,  2015,  2083,  2006,\n",
      "          2070,  5024,  4616,  1998, 25591,  7982,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2650, 0.7350],\n",
      "        [0.2452, 0.7548]]), 'input_ids': tensor([[  101, 10368,  1010, 23852,  2135, 25540, 25725,  2075,  1998,  4895,\n",
      "         10258,  8490, 28392,  5541,  1012,   102,     0,     0],\n",
      "        [  101,  2005,  1996,  2087,  2112,  8799, 21096,  2015,  2083,  2006,\n",
      "          2070,  5024,  4616,  1998, 25591,  7982,  1012,   102]]), 'ntok': tensor([16, 18]), 'cls_emb': tensor([[-0.5148,  0.1758, -0.2839,  ..., -0.5168,  0.3171,  0.3022],\n",
      "        [-0.2915, -0.0472, -0.7998,  ..., -0.2638,  0.7186,  0.3662]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023, 17312,  2003,  2055,  2004,  4658,  1998,  4306,  1011,\n",
      "         24820,  2004,  1037,  4516,  2064,  2131,  1012,   102],\n",
      "        [  101,  6091, 12554,  2015,  2024,  2025, 14036,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023, 17312,  2003,  2055,  2004,  4658,  1998,  4306,  1011,\n",
      "         24820,  2004,  1037,  4516,  2064,  2131,  1012,   102],\n",
      "        [  101,  6091, 12554,  2015,  2024,  2025, 14036,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2619, 0.7381],\n",
      "        [0.2563, 0.7437]]), 'input_ids': tensor([[  101,  2023, 17312,  2003,  2055,  2004,  4658,  1998,  4306,  1011,\n",
      "         24820,  2004,  1037,  4516,  2064,  2131,  1012,   102],\n",
      "        [  101,  6091, 12554,  2015,  2024,  2025, 14036,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([18,  9]), 'cls_emb': tensor([[ 0.2188, -0.0771, -0.0010,  ..., -0.3375,  0.5787,  0.3355],\n",
      "        [ 0.1633,  0.2898, -0.1964,  ..., -0.3785,  0.1693,  0.4254]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3213,  1011,  2472,  1005,  1055,  2033, 22893,  1005,  1055,\n",
      "          3947,  2038,  6197,  1997, 11084,  1998,  1996,  1059, 14341,  6508,\n",
      "          2003,  1999,  1996,  8150,  1010,  1996,  2046,  9048, 18252, 16137,\n",
      "          7911,  1010,  1997,  8578,  1998,  2143, 11541,  1012,   102],\n",
      "        [  101, 11664,  1010, 11268,  7231,  1010,  8966,  2007,  9476,  4509,\n",
      "          4808,  1998,  5021,  1011,  6167,  3494,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3213,  1011,  2472,  1005,  1055,  2033, 22893,  1005,  1055,\n",
      "          3947,  2038,  6197,  1997, 11084,  1998,  1996,  1059, 14341,  6508,\n",
      "          2003,  1999,  1996,  8150,  1010,  1996,  2046,  9048, 18252, 16137,\n",
      "          7911,  1010,  1997,  8578,  1998,  2143, 11541,  1012,   102],\n",
      "        [  101, 11664,  1010, 11268,  7231,  1010,  8966,  2007,  9476,  4509,\n",
      "          4808,  1998,  5021,  1011,  6167,  3494,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2492, 0.7508],\n",
      "        [0.2500, 0.7500]]), 'input_ids': tensor([[  101,  3213,  1011,  2472,  1005,  1055,  2033, 22893,  1005,  1055,\n",
      "          3947,  2038,  6197,  1997, 11084,  1998,  1996,  1059, 14341,  6508,\n",
      "          2003,  1999,  1996,  8150,  1010,  1996,  2046,  9048, 18252, 16137,\n",
      "          7911,  1010,  1997,  8578,  1998,  2143, 11541,  1012,   102],\n",
      "        [  101, 11664,  1010, 11268,  7231,  1010,  8966,  2007,  9476,  4509,\n",
      "          4808,  1998,  5021,  1011,  6167,  3494,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([39, 18]), 'cls_emb': tensor([[-0.6004, -0.1624, -0.2783,  ..., -0.5815,  0.6303,  0.0909],\n",
      "        [-0.4663,  0.0194, -0.5939,  ..., -0.3539,  0.3162,  0.3139]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 21642,  8317, 10874,  2008,  2515,  1050,  1005,  1056,\n",
      "          5949,  1037,  2617,  1997,  2049,  2048,  1011,  3178,  2770,  2051,\n",
      "          1012,   102],\n",
      "        [  101,  7641,  2196,  2428, 17445,  2229,  2000,  2440,  3466,  1996,\n",
      "         18114,  3459,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 21642,  8317, 10874,  2008,  2515,  1050,  1005,  1056,\n",
      "          5949,  1037,  2617,  1997,  2049,  2048,  1011,  3178,  2770,  2051,\n",
      "          1012,   102],\n",
      "        [  101,  7641,  2196,  2428, 17445,  2229,  2000,  2440,  3466,  1996,\n",
      "         18114,  3459,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2757, 0.7243],\n",
      "        [0.2682, 0.7318]]), 'input_ids': tensor([[  101,  1037, 21642,  8317, 10874,  2008,  2515,  1050,  1005,  1056,\n",
      "          5949,  1037,  2617,  1997,  2049,  2048,  1011,  3178,  2770,  2051,\n",
      "          1012,   102],\n",
      "        [  101,  7641,  2196,  2428, 17445,  2229,  2000,  2440,  3466,  1996,\n",
      "         18114,  3459,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([22, 14]), 'cls_emb': tensor([[-0.4254, -0.3328, -0.0951,  ..., -0.5485,  0.8831,  0.0346],\n",
      "        [-0.1507,  0.2015, -0.2624,  ..., -0.3533,  0.6631,  0.6575]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2074, 14325,  1998,  1037, 13727,  3168,  1997,  9467,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2145,  1010,  2004,  1037,  5107,  7438,  1010,  1996,  2143,\n",
      "          2003,  2471,  4895, 26210, 15194,  2098,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2074, 14325,  1998,  1037, 13727,  3168,  1997,  9467,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2145,  1010,  2004,  1037,  5107,  7438,  1010,  1996,  2143,\n",
      "          2003,  2471,  4895, 26210, 15194,  2098,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2694, 0.7306],\n",
      "        [0.2545, 0.7455]]), 'input_ids': tensor([[  101,  2074, 14325,  1998,  1037, 13727,  3168,  1997,  9467,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2145,  1010,  2004,  1037,  5107,  7438,  1010,  1996,  2143,\n",
      "          2003,  2471,  4895, 26210, 15194,  2098,  1012,   102]]), 'ntok': tensor([11, 18]), 'cls_emb': tensor([[-0.2575, -0.0660, -0.1634,  ..., -0.1982,  0.3656,  0.5649],\n",
      "        [-0.1015,  0.1621, -0.3447,  ..., -0.2636,  0.2386,  0.4336]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  5671, 10954,  1996,  3898,  1010,  2478,  2010, 25737,  3723,\n",
      "          2000,  6592,  1996, 10958,  3567,  8449,  1997,  1037,  2166,  1997,\n",
      "          7897,  1998, 18101,  2791,  1012,   102],\n",
      "        [  101,  2030,  4064,  2075,  9350, 16735,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  5671, 10954,  1996,  3898,  1010,  2478,  2010, 25737,  3723,\n",
      "          2000,  6592,  1996, 10958,  3567,  8449,  1997,  1037,  2166,  1997,\n",
      "          7897,  1998, 18101,  2791,  1012,   102],\n",
      "        [  101,  2030,  4064,  2075,  9350, 16735,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2569, 0.7431],\n",
      "        [0.2954, 0.7046]]), 'input_ids': tensor([[  101,  5671, 10954,  1996,  3898,  1010,  2478,  2010, 25737,  3723,\n",
      "          2000,  6592,  1996, 10958,  3567,  8449,  1997,  1037,  2166,  1997,\n",
      "          7897,  1998, 18101,  2791,  1012,   102],\n",
      "        [  101,  2030,  4064,  2075,  9350, 16735,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([26,  8]), 'cls_emb': tensor([[-0.1590,  0.2233, -0.1562,  ..., -0.3668,  0.4872,  0.2725],\n",
      "        [-0.0745, -0.2004, -0.5509,  ..., -0.2278,  0.3116,  0.3296]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4107,  2172,  2000,  5959,  1012,  1012,  1012,  1998,  1037,\n",
      "          2843,  2000, 14163,  3363,  2058,  1999,  3408,  1997,  2293,  1010,\n",
      "          9721,  1998,  1996,  3267,  1997,  6595,  2814,  1012,   102],\n",
      "        [  101,  1996, 14255, 16211,  3372,  2466,  3791,  2062,  6918,  6240,\n",
      "          2006,  2049,  5944,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4107,  2172,  2000,  5959,  1012,  1012,  1012,  1998,  1037,\n",
      "          2843,  2000, 14163,  3363,  2058,  1999,  3408,  1997,  2293,  1010,\n",
      "          9721,  1998,  1996,  3267,  1997,  6595,  2814,  1012,   102],\n",
      "        [  101,  1996, 14255, 16211,  3372,  2466,  3791,  2062,  6918,  6240,\n",
      "          2006,  2049,  5944,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2546, 0.7454],\n",
      "        [0.2783, 0.7217]]), 'input_ids': tensor([[  101,  4107,  2172,  2000,  5959,  1012,  1012,  1012,  1998,  1037,\n",
      "          2843,  2000, 14163,  3363,  2058,  1999,  3408,  1997,  2293,  1010,\n",
      "          9721,  1998,  1996,  3267,  1997,  6595,  2814,  1012,   102],\n",
      "        [  101,  1996, 14255, 16211,  3372,  2466,  3791,  2062,  6918,  6240,\n",
      "          2006,  2049,  5944,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([29, 15]), 'cls_emb': tensor([[-0.0022,  0.1929,  0.0775,  ..., -0.2757,  0.4136,  0.1642],\n",
      "        [-0.0183,  0.0598,  0.0770,  ..., -0.3630,  0.4341,  0.6606]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2026,  2564,  2003,  2019,  3883,  2003,  2019, 12580, 11951,\n",
      "          2413,  4038,  2008,  5683,  2061,  2137,  1999, 12411, 28255,  1998,\n",
      "          2806,  2009,  1005,  1055,  8990,  2049,  2219,  5365, 12661,  1012,\n",
      "           102],\n",
      "        [  101, 24436,  2135, 17727, 28128,  7028, 24593, 20273,  1997,  1037,\n",
      "          3185,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2026,  2564,  2003,  2019,  3883,  2003,  2019, 12580, 11951,\n",
      "          2413,  4038,  2008,  5683,  2061,  2137,  1999, 12411, 28255,  1998,\n",
      "          2806,  2009,  1005,  1055,  8990,  2049,  2219,  5365, 12661,  1012,\n",
      "           102],\n",
      "        [  101, 24436,  2135, 17727, 28128,  7028, 24593, 20273,  1997,  1037,\n",
      "          3185,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2622, 0.7378],\n",
      "        [0.2385, 0.7615]]), 'input_ids': tensor([[  101,  2026,  2564,  2003,  2019,  3883,  2003,  2019, 12580, 11951,\n",
      "          2413,  4038,  2008,  5683,  2061,  2137,  1999, 12411, 28255,  1998,\n",
      "          2806,  2009,  1005,  1055,  8990,  2049,  2219,  5365, 12661,  1012,\n",
      "           102],\n",
      "        [  101, 24436,  2135, 17727, 28128,  7028, 24593, 20273,  1997,  1037,\n",
      "          3185,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([31, 13]), 'cls_emb': tensor([[ 0.0681, -0.0861, -0.0363,  ..., -0.1568,  0.4856,  0.6146],\n",
      "        [-0.5750,  0.0880, -0.4723,  ..., -0.2712,  0.6997,  0.1620]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019,  2590,  3185,  1010,  1037, 14764,  1997,  1996,  2373,\n",
      "          1997,  2143,  2000,  2693,  2149,  1998,  2000,  2191,  2149, 11628,\n",
      "          2256,  5300,  1012,   102],\n",
      "        [  101,  1996,  3894,  1997,  1996,  2143,  3658,  2025,  1999,  1996,\n",
      "          8075,  3500,  2021,  1999,  1996,  4138,  2791,  1997,  2049,  4616,\n",
      "          1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019,  2590,  3185,  1010,  1037, 14764,  1997,  1996,  2373,\n",
      "          1997,  2143,  2000,  2693,  2149,  1998,  2000,  2191,  2149, 11628,\n",
      "          2256,  5300,  1012,   102],\n",
      "        [  101,  1996,  3894,  1997,  1996,  2143,  3658,  2025,  1999,  1996,\n",
      "          8075,  3500,  2021,  1999,  1996,  4138,  2791,  1997,  2049,  4616,\n",
      "          1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2617, 0.7383],\n",
      "        [0.2421, 0.7579]]), 'input_ids': tensor([[  101,  2019,  2590,  3185,  1010,  1037, 14764,  1997,  1996,  2373,\n",
      "          1997,  2143,  2000,  2693,  2149,  1998,  2000,  2191,  2149, 11628,\n",
      "          2256,  5300,  1012,   102],\n",
      "        [  101,  1996,  3894,  1997,  1996,  2143,  3658,  2025,  1999,  1996,\n",
      "          8075,  3500,  2021,  1999,  1996,  4138,  2791,  1997,  2049,  4616,\n",
      "          1012,   102,     0,     0]]), 'ntok': tensor([24, 22]), 'cls_emb': tensor([[-0.1860, -0.1107, -0.2082,  ..., -0.3333,  0.3288,  0.2135],\n",
      "        [-0.0518,  0.0514, -0.2755,  ..., -0.2162,  0.1967,  0.3826]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2128,  1011,  2079,  2003,  2061, 12873,  1998,  2061,\n",
      "         18077,  8082,  1999,  2049,  4808,  2008,  1010, 18527,  1010,  2009,\n",
      "          4150,  2673,  2008,  1996,  2738, 22902,  2434,  2001, 15747,  2114,\n",
      "          1012,   102],\n",
      "        [  101,  1996, 14855,  5910,  2009, 13495,  2024,  2460,  1010,  5362,\n",
      "          2872,  1998,  2757,  1011,  2415,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2128,  1011,  2079,  2003,  2061, 12873,  1998,  2061,\n",
      "         18077,  8082,  1999,  2049,  4808,  2008,  1010, 18527,  1010,  2009,\n",
      "          4150,  2673,  2008,  1996,  2738, 22902,  2434,  2001, 15747,  2114,\n",
      "          1012,   102],\n",
      "        [  101,  1996, 14855,  5910,  2009, 13495,  2024,  2460,  1010,  5362,\n",
      "          2872,  1998,  2757,  1011,  2415,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2523, 0.7477],\n",
      "        [0.2690, 0.7310]]), 'input_ids': tensor([[  101,  2023,  2128,  1011,  2079,  2003,  2061, 12873,  1998,  2061,\n",
      "         18077,  8082,  1999,  2049,  4808,  2008,  1010, 18527,  1010,  2009,\n",
      "          4150,  2673,  2008,  1996,  2738, 22902,  2434,  2001, 15747,  2114,\n",
      "          1012,   102],\n",
      "        [  101,  1996, 14855,  5910,  2009, 13495,  2024,  2460,  1010,  5362,\n",
      "          2872,  1998,  2757,  1011,  2415,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 17]), 'cls_emb': tensor([[-0.0017, -0.0782, -0.1892,  ..., -0.1171,  0.2198,  0.7734],\n",
      "        [-0.1028,  0.1118, -0.1990,  ...,  0.1140,  0.1954,  0.3834]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2096, 10575,  2097,  2131,  1037,  5926,  2041,  1997, 27963,\n",
      "          6044,  4573,  1010,  1996,  2717,  1997,  1996,  2088,  2097,  5959,\n",
      "          1037,  3435,  1011, 13823,  4038,  2007, 21864, 19987,  2008,  2453,\n",
      "          2191,  1996,  2400,  1011,  3045, 24873,  2078,  3428,  4372, 24918,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2616,  1010,  1036, 19597,  1010,  2026,  6203,  1010,\n",
      "          1045,  2079,  1050,  1005,  1056,  2507,  1037,  4365,  1010,  1005,\n",
      "          2031,  2196,  2042,  2062,  6413,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2096, 10575,  2097,  2131,  1037,  5926,  2041,  1997, 27963,\n",
      "          6044,  4573,  1010,  1996,  2717,  1997,  1996,  2088,  2097,  5959,\n",
      "          1037,  3435,  1011, 13823,  4038,  2007, 21864, 19987,  2008,  2453,\n",
      "          2191,  1996,  2400,  1011,  3045, 24873,  2078,  3428,  4372, 24918,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2616,  1010,  1036, 19597,  1010,  2026,  6203,  1010,\n",
      "          1045,  2079,  1050,  1005,  1056,  2507,  1037,  4365,  1010,  1005,\n",
      "          2031,  2196,  2042,  2062,  6413,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2855, 0.7145],\n",
      "        [0.2556, 0.7444]]), 'input_ids': tensor([[  101,  2096, 10575,  2097,  2131,  1037,  5926,  2041,  1997, 27963,\n",
      "          6044,  4573,  1010,  1996,  2717,  1997,  1996,  2088,  2097,  5959,\n",
      "          1037,  3435,  1011, 13823,  4038,  2007, 21864, 19987,  2008,  2453,\n",
      "          2191,  1996,  2400,  1011,  3045, 24873,  2078,  3428,  4372, 24918,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2616,  1010,  1036, 19597,  1010,  2026,  6203,  1010,\n",
      "          1045,  2079,  1050,  1005,  1056,  2507,  1037,  4365,  1010,  1005,\n",
      "          2031,  2196,  2042,  2062,  6413,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([42, 27]), 'cls_emb': tensor([[ 0.2376,  0.0275,  0.4333,  ..., -0.3973,  0.4481,  0.4065],\n",
      "        [-0.1456,  0.4253, -0.3456,  ...,  0.1127,  0.3743,  0.6398]])}\n",
      "encoded input is: {'input_ids': tensor([[ 101, 1996, 2936, 1996, 3185, 3632, 1010, 1996, 4788, 2009, 4152, 1010,\n",
      "         2021, 2009, 1005, 1055, 2941, 3492, 2204, 1999, 1996, 2034, 2261, 2781,\n",
      "         1012,  102],\n",
      "        [ 101, 2205, 2172, 1997, 1996, 8562, 4212, 4257, 1012,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[ 101, 1996, 2936, 1996, 3185, 3632, 1010, 1996, 4788, 2009, 4152, 1010,\n",
      "         2021, 2009, 1005, 1055, 2941, 3492, 2204, 1999, 1996, 2034, 2261, 2781,\n",
      "         1012,  102],\n",
      "        [ 101, 2205, 2172, 1997, 1996, 8562, 4212, 4257, 1012,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2369, 0.7631],\n",
      "        [0.2550, 0.7450]]), 'input_ids': tensor([[ 101, 1996, 2936, 1996, 3185, 3632, 1010, 1996, 4788, 2009, 4152, 1010,\n",
      "         2021, 2009, 1005, 1055, 2941, 3492, 2204, 1999, 1996, 2034, 2261, 2781,\n",
      "         1012,  102],\n",
      "        [ 101, 2205, 2172, 1997, 1996, 8562, 4212, 4257, 1012,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0]]), 'ntok': tensor([26, 10]), 'cls_emb': tensor([[ 0.6331, -0.0876,  0.0744,  ...,  0.0332,  0.2391,  0.4949],\n",
      "        [ 0.1207,  0.2258, -0.0768,  ..., -0.4701,  0.3665,  0.2518]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2582,  6947,  2008,  1996,  8680, 29110,  1997,  4658,  1010,\n",
      "          3376,  1010,  2245,  1011,  4013, 22776,  3097,  5988,  2003, 21526,\n",
      "          1011,  4830,  2497,  1999,  1996,  2690,  1997, 12931,  3148,  1005,\n",
      "          1055,  8123,  1997,  4763,  1012,   102],\n",
      "        [  101,  1996,  2143,  1005,  1055,  2261,  4784,  2024,  7121,  2000,\n",
      "          1996,  2391,  1997,  9345, 17822,  3370,  1025,  1996,  2878,  2430,\n",
      "          2930,  2003,  2028,  2502,  5252,  2008,  3849,  2000,  2031,  2053,\n",
      "          3125,  1998,  2053, 19353,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2582,  6947,  2008,  1996,  8680, 29110,  1997,  4658,  1010,\n",
      "          3376,  1010,  2245,  1011,  4013, 22776,  3097,  5988,  2003, 21526,\n",
      "          1011,  4830,  2497,  1999,  1996,  2690,  1997, 12931,  3148,  1005,\n",
      "          1055,  8123,  1997,  4763,  1012,   102],\n",
      "        [  101,  1996,  2143,  1005,  1055,  2261,  4784,  2024,  7121,  2000,\n",
      "          1996,  2391,  1997,  9345, 17822,  3370,  1025,  1996,  2878,  2430,\n",
      "          2930,  2003,  2028,  2502,  5252,  2008,  3849,  2000,  2031,  2053,\n",
      "          3125,  1998,  2053, 19353,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2568, 0.7432],\n",
      "        [0.2476, 0.7524]]), 'input_ids': tensor([[  101,  2582,  6947,  2008,  1996,  8680, 29110,  1997,  4658,  1010,\n",
      "          3376,  1010,  2245,  1011,  4013, 22776,  3097,  5988,  2003, 21526,\n",
      "          1011,  4830,  2497,  1999,  1996,  2690,  1997, 12931,  3148,  1005,\n",
      "          1055,  8123,  1997,  4763,  1012,   102],\n",
      "        [  101,  1996,  2143,  1005,  1055,  2261,  4784,  2024,  7121,  2000,\n",
      "          1996,  2391,  1997,  9345, 17822,  3370,  1025,  1996,  2878,  2430,\n",
      "          2930,  2003,  2028,  2502,  5252,  2008,  3849,  2000,  2031,  2053,\n",
      "          3125,  1998,  2053, 19353,  1012,   102]]), 'ntok': tensor([36, 36]), 'cls_emb': tensor([[ 0.0244, -0.1263,  0.0144,  ..., -0.2902,  0.4621,  0.5561],\n",
      "        [ 0.1243,  0.1311, -0.1100,  ..., -0.3345,  0.4797,  0.7136]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2205,  4030,  1010,  2205,  2146,  1998,  2205,  2210,  6433,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2349,  2000,  2070,  5896, 21775,  1998,  1996,  9179,  1997,\n",
      "          1996,  2472,  1005,  1055,  2567,  1010,  1996,  2143,  9612,  2125,\n",
      "          2046,  4297,  5644,  2063, 15417,  4818,  3012,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2205,  4030,  1010,  2205,  2146,  1998,  2205,  2210,  6433,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2349,  2000,  2070,  5896, 21775,  1998,  1996,  9179,  1997,\n",
      "          1996,  2472,  1005,  1055,  2567,  1010,  1996,  2143,  9612,  2125,\n",
      "          2046,  4297,  5644,  2063, 15417,  4818,  3012,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2337, 0.7663],\n",
      "        [0.2377, 0.7623]]), 'input_ids': tensor([[  101,  2205,  4030,  1010,  2205,  2146,  1998,  2205,  2210,  6433,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2349,  2000,  2070,  5896, 21775,  1998,  1996,  9179,  1997,\n",
      "          1996,  2472,  1005,  1055,  2567,  1010,  1996,  2143,  9612,  2125,\n",
      "          2046,  4297,  5644,  2063, 15417,  4818,  3012,  1012,   102]]), 'ntok': tensor([12, 29]), 'cls_emb': tensor([[ 0.1576,  0.2457,  0.4395,  ..., -0.3719, -0.0379,  0.4769],\n",
      "        [-0.0256,  0.1846, -0.0991,  ..., -0.5930,  0.4778,  0.4018]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2200,  2919,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3768,  7393,  3334,  1010, 16655, 14416, 20925,  8297,\n",
      "          2000,  1996,  4438,  6373,  6789,  1997,  1046,  1012,  1049,  1012,\n",
      "         24953,  1005,  1055,  2848,  6090,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2200,  2919,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3768,  7393,  3334,  1010, 16655, 14416, 20925,  8297,\n",
      "          2000,  1996,  4438,  6373,  6789,  1997,  1046,  1012,  1049,  1012,\n",
      "         24953,  1005,  1055,  2848,  6090,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2892, 0.7108],\n",
      "        [0.2713, 0.7287]]), 'input_ids': tensor([[  101,  2200,  2919,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3768,  7393,  3334,  1010, 16655, 14416, 20925,  8297,\n",
      "          2000,  1996,  4438,  6373,  6789,  1997,  1046,  1012,  1049,  1012,\n",
      "         24953,  1005,  1055,  2848,  6090,  1012,   102]]), 'ntok': tensor([ 5, 27]), 'cls_emb': tensor([[-0.4477,  0.2063, -0.2226,  ..., -0.1436,  0.2697,  0.3043],\n",
      "        [-0.6655, -0.3083, -0.5720,  ..., -0.2233,  0.7855,  0.4858]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2671,  1011,  4349,  2627, 17322,  2061, 11158,  1999,\n",
      "          2434,  3012,  2008,  2065,  2017, 10040,  2185,  2049,  7780,  2015,\n",
      "          2045,  2052,  2022,  9062,  2210,  2187,  1012,   102],\n",
      "        [  101,  5798,  2611,  2003,  2019, 19142,  6569,  4536,  1010,  2007,\n",
      "          2070, 10889,  6355,  5312,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2671,  1011,  4349,  2627, 17322,  2061, 11158,  1999,\n",
      "          2434,  3012,  2008,  2065,  2017, 10040,  2185,  2049,  7780,  2015,\n",
      "          2045,  2052,  2022,  9062,  2210,  2187,  1012,   102],\n",
      "        [  101,  5798,  2611,  2003,  2019, 19142,  6569,  4536,  1010,  2007,\n",
      "          2070, 10889,  6355,  5312,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2724, 0.7276],\n",
      "        [0.2511, 0.7489]]), 'input_ids': tensor([[  101,  1037,  2671,  1011,  4349,  2627, 17322,  2061, 11158,  1999,\n",
      "          2434,  3012,  2008,  2065,  2017, 10040,  2185,  2049,  7780,  2015,\n",
      "          2045,  2052,  2022,  9062,  2210,  2187,  1012,   102],\n",
      "        [  101,  5798,  2611,  2003,  2019, 19142,  6569,  4536,  1010,  2007,\n",
      "          2070, 10889,  6355,  5312,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([28, 16]), 'cls_emb': tensor([[-0.1236, -0.1072, -0.3967,  ..., -0.2008,  0.5553,  0.2873],\n",
      "        [-0.0200, -0.1428, -0.2320,  ..., -0.5410,  0.3841,  0.3705]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2061,  2172,  6904,  6895,  2571,  6028,  1010,  2107, 10140,\n",
      "          4784,  1010,  2061,  2210,  3185,  1012,   102,     0,     0,     0],\n",
      "        [  101,  5987,  1996,  2168,  1011,  2214,  1010, 20342,  1011,  2214,\n",
      "         18296,  2121, 14652,  1010,  2074,  2007,  2367, 17363,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2061,  2172,  6904,  6895,  2571,  6028,  1010,  2107, 10140,\n",
      "          4784,  1010,  2061,  2210,  3185,  1012,   102,     0,     0,     0],\n",
      "        [  101,  5987,  1996,  2168,  1011,  2214,  1010, 20342,  1011,  2214,\n",
      "         18296,  2121, 14652,  1010,  2074,  2007,  2367, 17363,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2701, 0.7299],\n",
      "        [0.2903, 0.7097]]), 'input_ids': tensor([[  101,  2061,  2172,  6904,  6895,  2571,  6028,  1010,  2107, 10140,\n",
      "          4784,  1010,  2061,  2210,  3185,  1012,   102,     0,     0,     0],\n",
      "        [  101,  5987,  1996,  2168,  1011,  2214,  1010, 20342,  1011,  2214,\n",
      "         18296,  2121, 14652,  1010,  2074,  2007,  2367, 17363,  1012,   102]]), 'ntok': tensor([17, 20]), 'cls_emb': tensor([[-0.0938,  0.4387, -0.1257,  ..., -0.2468,  0.5663,  0.6836],\n",
      "        [ 0.3723, -0.0106, -0.1887,  ..., -0.3423,  0.4992,  0.4668]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  6047,  1010, 25591,  3582,  1011,  2039,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 15775, 12618,  2140,  2038,  2579, 10015,  3430,  2005,  1037,\n",
      "          2304,  4038,  1998,  2357,  2009,  2612,  2046,  1037, 28587,  4574,\n",
      "          3689,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  6047,  1010, 25591,  3582,  1011,  2039,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 15775, 12618,  2140,  2038,  2579, 10015,  3430,  2005,  1037,\n",
      "          2304,  4038,  1998,  2357,  2009,  2612,  2046,  1037, 28587,  4574,\n",
      "          3689,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.3010, 0.6990],\n",
      "        [0.2679, 0.7321]]), 'input_ids': tensor([[  101,  1037,  6047,  1010, 25591,  3582,  1011,  2039,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101, 15775, 12618,  2140,  2038,  2579, 10015,  3430,  2005,  1037,\n",
      "          2304,  4038,  1998,  2357,  2009,  2612,  2046,  1037, 28587,  4574,\n",
      "          3689,  1012,   102]]), 'ntok': tensor([10, 23]), 'cls_emb': tensor([[-0.3352, -0.2360, -0.2981,  ..., -0.4655,  0.3377,  0.4925],\n",
      "        [-0.4651, -0.0348, -0.4594,  ..., -0.2704,  0.7132,  0.6027]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2066,  3505,  2003,  1037,  3453,  2005,  4268,  1010,  1998,\n",
      "          2053,  4797,  1037,  3453,  2005, 13451,  6812, 10166,  1010,  2040,\n",
      "          2064,  2085,  5587,  5691,  2000,  1996,  2862,  1997,  2477,  2002,\n",
      "          2515,  2092,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2178,  2678,  3185, 16164,  2066,  1037,\n",
      "          2143,  1010,  2007,  1996,  2919,  7497,  2008,  1005,  1055,  2411,\n",
      "          2517,  2125,  2004, 10271,  2143,  3019,  2964,  1012,   102,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2066,  3505,  2003,  1037,  3453,  2005,  4268,  1010,  1998,\n",
      "          2053,  4797,  1037,  3453,  2005, 13451,  6812, 10166,  1010,  2040,\n",
      "          2064,  2085,  5587,  5691,  2000,  1996,  2862,  1997,  2477,  2002,\n",
      "          2515,  2092,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2178,  2678,  3185, 16164,  2066,  1037,\n",
      "          2143,  1010,  2007,  1996,  2919,  7497,  2008,  1005,  1055,  2411,\n",
      "          2517,  2125,  2004, 10271,  2143,  3019,  2964,  1012,   102,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2663, 0.7337],\n",
      "        [0.2711, 0.7289]]), 'input_ids': tensor([[  101,  2066,  3505,  2003,  1037,  3453,  2005,  4268,  1010,  1998,\n",
      "          2053,  4797,  1037,  3453,  2005, 13451,  6812, 10166,  1010,  2040,\n",
      "          2064,  2085,  5587,  5691,  2000,  1996,  2862,  1997,  2477,  2002,\n",
      "          2515,  2092,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2178,  2678,  3185, 16164,  2066,  1037,\n",
      "          2143,  1010,  2007,  1996,  2919,  7497,  2008,  1005,  1055,  2411,\n",
      "          2517,  2125,  2004, 10271,  2143,  3019,  2964,  1012,   102,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 29]), 'cls_emb': tensor([[-0.0981,  0.1771, -0.0211,  ..., -0.1290,  0.6837,  0.3149],\n",
      "        [ 0.2464, -0.1537, -0.0841,  ..., -0.1068,  0.6058,  0.6218]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  1005,  1055,  2025,  2438,  2182,  2000, 16114,  1996,\n",
      "          2471,  2048,  2847,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2009,  2097,  6218,  2130,  7193,  2040,  2024,  1050,  1005,\n",
      "          1056,  4699,  1999,  9680,  1010,  2004,  2009,  7659,  2000,  1996,\n",
      "          2540,  1997,  2137,  2554,  1999,  2019,  4895,  3678,  6455,  2126,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  1005,  1055,  2025,  2438,  2182,  2000, 16114,  1996,\n",
      "          2471,  2048,  2847,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2009,  2097,  6218,  2130,  7193,  2040,  2024,  1050,  1005,\n",
      "          1056,  4699,  1999,  9680,  1010,  2004,  2009,  7659,  2000,  1996,\n",
      "          2540,  1997,  2137,  2554,  1999,  2019,  4895,  3678,  6455,  2126,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2444, 0.7556],\n",
      "        [0.2600, 0.7400]]), 'input_ids': tensor([[  101,  2045,  1005,  1055,  2025,  2438,  2182,  2000, 16114,  1996,\n",
      "          2471,  2048,  2847,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2009,  2097,  6218,  2130,  7193,  2040,  2024,  1050,  1005,\n",
      "          1056,  4699,  1999,  9680,  1010,  2004,  2009,  7659,  2000,  1996,\n",
      "          2540,  1997,  2137,  2554,  1999,  2019,  4895,  3678,  6455,  2126,\n",
      "          1012,   102]]), 'ntok': tensor([15, 32]), 'cls_emb': tensor([[ 0.0359,  0.3496, -0.0435,  ..., -0.1326,  0.3784,  0.3128],\n",
      "        [ 0.0624, -0.1541, -0.1398,  ..., -0.3402,  0.2796,  0.2432]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2143,  2003, 17950,  5614,  1010,  2021,  1010,  2062,\n",
      "          2000,  1996,  2391,  1010,  1996,  3314,  2024, 28797,  3591,  1010,\n",
      "          6605,  2000,  3328,  1037,  2986,  2240,  2007,  7634,  2000,  1996,\n",
      "          3160,  1997,  7437,  1005,  1055, 12013,  1012,   102],\n",
      "        [  101,  1998,  2065,  2017,  1005,  2128,  2025,  3053,  2333,  2000,\n",
      "          4000,  2011,  1037,  3232,  1997,  5019,  1010,  2017,  1005,  2310,\n",
      "          2288,  3256,  2300,  1999,  2115,  9607,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2143,  2003, 17950,  5614,  1010,  2021,  1010,  2062,\n",
      "          2000,  1996,  2391,  1010,  1996,  3314,  2024, 28797,  3591,  1010,\n",
      "          6605,  2000,  3328,  1037,  2986,  2240,  2007,  7634,  2000,  1996,\n",
      "          3160,  1997,  7437,  1005,  1055, 12013,  1012,   102],\n",
      "        [  101,  1998,  2065,  2017,  1005,  2128,  2025,  3053,  2333,  2000,\n",
      "          4000,  2011,  1037,  3232,  1997,  5019,  1010,  2017,  1005,  2310,\n",
      "          2288,  3256,  2300,  1999,  2115,  9607,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2497, 0.7503],\n",
      "        [0.2774, 0.7226]]), 'input_ids': tensor([[  101,  1996,  2143,  2003, 17950,  5614,  1010,  2021,  1010,  2062,\n",
      "          2000,  1996,  2391,  1010,  1996,  3314,  2024, 28797,  3591,  1010,\n",
      "          6605,  2000,  3328,  1037,  2986,  2240,  2007,  7634,  2000,  1996,\n",
      "          3160,  1997,  7437,  1005,  1055, 12013,  1012,   102],\n",
      "        [  101,  1998,  2065,  2017,  1005,  2128,  2025,  3053,  2333,  2000,\n",
      "          4000,  2011,  1037,  3232,  1997,  5019,  1010,  2017,  1005,  2310,\n",
      "          2288,  3256,  2300,  1999,  2115,  9607,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([38, 28]), 'cls_emb': tensor([[-0.3839,  0.0873, -0.5084,  ..., -0.4069,  0.4388,  0.6895],\n",
      "        [ 0.1023, -0.0895, -0.5220,  ..., -0.4112,  0.0206,  0.4055]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2957, 16216,  2890,  1998, 12082,  4644,  2404,  1999,  2986,\n",
      "          4616,  2004,  2515,  2413,  3364,  6291, 10337,  1012,   102],\n",
      "        [  101,  2204,  2143,  1010,  2021,  2200,  1043, 12942,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2957, 16216,  2890,  1998, 12082,  4644,  2404,  1999,  2986,\n",
      "          4616,  2004,  2515,  2413,  3364,  6291, 10337,  1012,   102],\n",
      "        [  101,  2204,  2143,  1010,  2021,  2200,  1043, 12942,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2489, 0.7511],\n",
      "        [0.2715, 0.7285]]), 'input_ids': tensor([[  101,  2957, 16216,  2890,  1998, 12082,  4644,  2404,  1999,  2986,\n",
      "          4616,  2004,  2515,  2413,  3364,  6291, 10337,  1012,   102],\n",
      "        [  101,  2204,  2143,  1010,  2021,  2200,  1043, 12942,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([19, 10]), 'cls_emb': tensor([[-0.1684,  0.0280, -0.1858,  ..., -0.2150,  0.7254, -0.0626],\n",
      "        [-0.0974,  0.0263, -0.0558,  ..., -0.1681,  0.4972,  0.4091]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2045,  2024,  5436,  8198,  2502,  2438,  2005, 25850,  2226,\n",
      "          1996,  6359, 13156,  2000,  9880,  2083,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101, 25250,  2229,  2000,  2048,  3294,  2367, 24743,  2012,  1996,\n",
      "          2168,  2051,  1010,  2029,  2003,  1037,  3492,  6429, 24718,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2045,  2024,  5436,  8198,  2502,  2438,  2005, 25850,  2226,\n",
      "          1996,  6359, 13156,  2000,  9880,  2083,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101, 25250,  2229,  2000,  2048,  3294,  2367, 24743,  2012,  1996,\n",
      "          2168,  2051,  1010,  2029,  2003,  1037,  3492,  6429, 24718,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2393, 0.7607],\n",
      "        [0.2881, 0.7119]]), 'input_ids': tensor([[  101,  2045,  2024,  5436,  8198,  2502,  2438,  2005, 25850,  2226,\n",
      "          1996,  6359, 13156,  2000,  9880,  2083,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101, 25250,  2229,  2000,  2048,  3294,  2367, 24743,  2012,  1996,\n",
      "          2168,  2051,  1010,  2029,  2003,  1037,  3492,  6429, 24718,  1012,\n",
      "           102]]), 'ntok': tensor([18, 21]), 'cls_emb': tensor([[-0.0618, -0.1024, -0.2403,  ..., -0.2202,  0.2896,  0.4741],\n",
      "        [ 0.0932, -0.0717, -0.2677,  ..., -0.1246,  0.9535, -0.0560]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 12034, 19880, 22164,  2296, 20578,  1011,  3063,  7577,  2000,\n",
      "          2507,  2149,  1996,  1051,  6559,  2100,  1011, 11867, 14659,  3111,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2048,  2847,  4875,  2011,  1011,  1011,  3850,  1005,  1055,\n",
      "          1037,  5165,  2043,  2017,  2079,  1050,  1005,  1056,  2031,  2000,\n",
      "         18094,  6970, 25481,  2015,  1011,  1011,  1998,  2130,  1037, 23131,\n",
      "          2000,  1996,  2433,  3310,  2185,  4654, 26415,  9250,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 12034, 19880, 22164,  2296, 20578,  1011,  3063,  7577,  2000,\n",
      "          2507,  2149,  1996,  1051,  6559,  2100,  1011, 11867, 14659,  3111,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2048,  2847,  4875,  2011,  1011,  1011,  3850,  1005,  1055,\n",
      "          1037,  5165,  2043,  2017,  2079,  1050,  1005,  1056,  2031,  2000,\n",
      "         18094,  6970, 25481,  2015,  1011,  1011,  1998,  2130,  1037, 23131,\n",
      "          2000,  1996,  2433,  3310,  2185,  4654, 26415,  9250,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2569, 0.7431],\n",
      "        [0.2445, 0.7555]]), 'input_ids': tensor([[  101, 12034, 19880, 22164,  2296, 20578,  1011,  3063,  7577,  2000,\n",
      "          2507,  2149,  1996,  1051,  6559,  2100,  1011, 11867, 14659,  3111,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2048,  2847,  4875,  2011,  1011,  1011,  3850,  1005,  1055,\n",
      "          1037,  5165,  2043,  2017,  2079,  1050,  1005,  1056,  2031,  2000,\n",
      "         18094,  6970, 25481,  2015,  1011,  1011,  1998,  2130,  1037, 23131,\n",
      "          2000,  1996,  2433,  3310,  2185,  4654, 26415,  9250,  1012,   102]]), 'ntok': tensor([22, 40]), 'cls_emb': tensor([[ 0.2123,  0.3572,  0.0173,  ..., -0.3613,  0.8125,  0.5346],\n",
      "        [-0.0913,  0.2277, -0.2640,  ...,  0.0967,  0.5181,  0.8492]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1999,  2035,  1010,  2023,  2003,  1037,  3422,  3085,  3185,\n",
      "          2008,  1005,  1055,  2025,  3243,  1996, 13432,  3325,  2009,  2453,\n",
      "          2031,  2042,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9010,  2017,  2046,  1037, 14849,  2075,  1010, 20606,  1010,\n",
      "          3778,  1011, 16546,  2099,  1997,  1037,  3663,  2008,  2855,  4586,\n",
      "         18510,  2041,  1997,  2491,  1010,  2096,  7995,  2006,  1996,  2054,\n",
      "          2172,  2062,  2084,  1996,  2339,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1999,  2035,  1010,  2023,  2003,  1037,  3422,  3085,  3185,\n",
      "          2008,  1005,  1055,  2025,  3243,  1996, 13432,  3325,  2009,  2453,\n",
      "          2031,  2042,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9010,  2017,  2046,  1037, 14849,  2075,  1010, 20606,  1010,\n",
      "          3778,  1011, 16546,  2099,  1997,  1037,  3663,  2008,  2855,  4586,\n",
      "         18510,  2041,  1997,  2491,  1010,  2096,  7995,  2006,  1996,  2054,\n",
      "          2172,  2062,  2084,  1996,  2339,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2374, 0.7626],\n",
      "        [0.2779, 0.7221]]), 'input_ids': tensor([[  101,  1999,  2035,  1010,  2023,  2003,  1037,  3422,  3085,  3185,\n",
      "          2008,  1005,  1055,  2025,  3243,  1996, 13432,  3325,  2009,  2453,\n",
      "          2031,  2042,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  9010,  2017,  2046,  1037, 14849,  2075,  1010, 20606,  1010,\n",
      "          3778,  1011, 16546,  2099,  1997,  1037,  3663,  2008,  2855,  4586,\n",
      "         18510,  2041,  1997,  2491,  1010,  2096,  7995,  2006,  1996,  2054,\n",
      "          2172,  2062,  2084,  1996,  2339,  1012,   102]]), 'ntok': tensor([24, 37]), 'cls_emb': tensor([[ 0.0952, -0.0698, -0.2033,  ...,  0.0037,  0.2300,  0.4107],\n",
      "        [-0.1308,  0.0042, -0.3533,  ..., -0.5723,  0.1277,  0.3923]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 13787, 13059,  7054,  2038,  9530, 26949,  2039,  1037,  4800,\n",
      "         24314,  2098,  2147,  2008, 10455,  2151,  2193,  1997, 17160,  3314,\n",
      "           102],\n",
      "        [  101, 13554,  3538,  1997,  2892,  1011,  4712,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 13787, 13059,  7054,  2038,  9530, 26949,  2039,  1037,  4800,\n",
      "         24314,  2098,  2147,  2008, 10455,  2151,  2193,  1997, 17160,  3314,\n",
      "           102],\n",
      "        [  101, 13554,  3538,  1997,  2892,  1011,  4712,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2682, 0.7318],\n",
      "        [0.2821, 0.7179]]), 'input_ids': tensor([[  101, 13787, 13059,  7054,  2038,  9530, 26949,  2039,  1037,  4800,\n",
      "         24314,  2098,  2147,  2008, 10455,  2151,  2193,  1997, 17160,  3314,\n",
      "           102],\n",
      "        [  101, 13554,  3538,  1997,  2892,  1011,  4712,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([21,  9]), 'cls_emb': tensor([[-0.2723,  0.2235, -0.3464,  ..., -0.1097,  0.5208,  0.5810],\n",
      "        [-0.2678,  0.0310, -0.1092,  ..., -0.4330,  0.3413,  0.1414]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2092,  1011,  9152,  5603, 16655,  4859, 23086,  1012,  1012,\n",
      "          1012,  2295,  1996,  3861, 18859,  2000,  2468, 21014,  4623,  1010,\n",
      "          2009,  3464,  2139, 24128,  2135,  4013, 15816,  2278,  1998, 10634,\n",
      "          1012,   102],\n",
      "        [  101, 16686, 28173,  2003,  2019, 23693,  2466, 23567,  2121,  1010,\n",
      "          5214,  1997,  4531,  5053,  1999,  1996,  2087,  2139, 24128,  3182,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2092,  1011,  9152,  5603, 16655,  4859, 23086,  1012,  1012,\n",
      "          1012,  2295,  1996,  3861, 18859,  2000,  2468, 21014,  4623,  1010,\n",
      "          2009,  3464,  2139, 24128,  2135,  4013, 15816,  2278,  1998, 10634,\n",
      "          1012,   102],\n",
      "        [  101, 16686, 28173,  2003,  2019, 23693,  2466, 23567,  2121,  1010,\n",
      "          5214,  1997,  4531,  5053,  1999,  1996,  2087,  2139, 24128,  3182,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2361, 0.7639],\n",
      "        [0.2424, 0.7576]]), 'input_ids': tensor([[  101,  2092,  1011,  9152,  5603, 16655,  4859, 23086,  1012,  1012,\n",
      "          1012,  2295,  1996,  3861, 18859,  2000,  2468, 21014,  4623,  1010,\n",
      "          2009,  3464,  2139, 24128,  2135,  4013, 15816,  2278,  1998, 10634,\n",
      "          1012,   102],\n",
      "        [  101, 16686, 28173,  2003,  2019, 23693,  2466, 23567,  2121,  1010,\n",
      "          5214,  1997,  4531,  5053,  1999,  1996,  2087,  2139, 24128,  3182,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 22]), 'cls_emb': tensor([[ 0.3053,  0.2927,  0.2061,  ..., -0.3026,  0.4589,  0.5020],\n",
      "        [-0.6463, -0.3158, -0.6377,  ..., -0.1597,  0.6962,  0.4387]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3185,  2003,  1050,  1005,  1056,  2074, 26316,  1024,\n",
      "          2009,  1005,  1055, 25591,  1998,  1999, 15338,  3512,  1010,  2205,\n",
      "          1010,  1998,  1999, 17666, 25807,  1010,  2009,  2003,  1050,  1005,\n",
      "          1056,  2130,  2035,  2008, 12873,  1012,   102],\n",
      "        [  101, 16587,  2040,  2064, 13366, 14626,  2689, 27824,  2024, 17605,\n",
      "          1998,  2130,  8348,  2015,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3185,  2003,  1050,  1005,  1056,  2074, 26316,  1024,\n",
      "          2009,  1005,  1055, 25591,  1998,  1999, 15338,  3512,  1010,  2205,\n",
      "          1010,  1998,  1999, 17666, 25807,  1010,  2009,  2003,  1050,  1005,\n",
      "          1056,  2130,  2035,  2008, 12873,  1012,   102],\n",
      "        [  101, 16587,  2040,  2064, 13366, 14626,  2689, 27824,  2024, 17605,\n",
      "          1998,  2130,  8348,  2015,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2539, 0.7461],\n",
      "        [0.2490, 0.7510]]), 'input_ids': tensor([[  101,  1996,  3185,  2003,  1050,  1005,  1056,  2074, 26316,  1024,\n",
      "          2009,  1005,  1055, 25591,  1998,  1999, 15338,  3512,  1010,  2205,\n",
      "          1010,  1998,  1999, 17666, 25807,  1010,  2009,  2003,  1050,  1005,\n",
      "          1056,  2130,  2035,  2008, 12873,  1012,   102],\n",
      "        [  101, 16587,  2040,  2064, 13366, 14626,  2689, 27824,  2024, 17605,\n",
      "          1998,  2130,  8348,  2015,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([37, 16]), 'cls_emb': tensor([[ 0.2852, -0.0928, -0.2744,  ..., -0.0741,  0.4562,  0.7214],\n",
      "        [ 0.2011,  0.2297, -0.1168,  ..., -0.2166,  0.4672,  0.2547]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  8995,  3012,  1997,  1996,  5889,  7906,  1996,  8015,\n",
      "          1997,  1996,  2143,  2152,  1010,  2130,  2004,  1996,  2358, 27528,\n",
      "          8613, 12586,  2362,  1012,   102],\n",
      "        [  101,  1006,  1037,  1007,  4338,  3238,  1038,  4135,  2497,  1997,\n",
      "          7143,  4024,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  8995,  3012,  1997,  1996,  5889,  7906,  1996,  8015,\n",
      "          1997,  1996,  2143,  2152,  1010,  2130,  2004,  1996,  2358, 27528,\n",
      "          8613, 12586,  2362,  1012,   102],\n",
      "        [  101,  1006,  1037,  1007,  4338,  3238,  1038,  4135,  2497,  1997,\n",
      "          7143,  4024,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2390, 0.7610],\n",
      "        [0.2982, 0.7018]]), 'input_ids': tensor([[  101,  1996,  8995,  3012,  1997,  1996,  5889,  7906,  1996,  8015,\n",
      "          1997,  1996,  2143,  2152,  1010,  2130,  2004,  1996,  2358, 27528,\n",
      "          8613, 12586,  2362,  1012,   102],\n",
      "        [  101,  1006,  1037,  1007,  4338,  3238,  1038,  4135,  2497,  1997,\n",
      "          7143,  4024,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([25, 14]), 'cls_emb': tensor([[ 0.1163,  0.2268, -0.1174,  ..., -0.4478,  0.3078,  0.1593],\n",
      "        [-0.4235,  0.0616, -0.2938,  ..., -0.4521,  0.4667,  0.3550]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1999,  1996,  2203,  1010,  1996,  3185, 25938,  2006,  2049,\n",
      "         15311,  3192,  2750,  1996,  2190,  4073,  1997,  2472,  3533,  2482,\n",
      "         15272,  2319,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2995,  6925,  1997,  8424,  1011,  1011,  1998,  4012, 27293,\n",
      "          1011,  1011,  2012, 24363,  2003,  1037, 24560,  2075,  3689,  2008,\n",
      "          5363,  2000,  2425,  1997,  1996,  4895, 13102, 25508,  3085,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1999,  1996,  2203,  1010,  1996,  3185, 25938,  2006,  2049,\n",
      "         15311,  3192,  2750,  1996,  2190,  4073,  1997,  2472,  3533,  2482,\n",
      "         15272,  2319,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2995,  6925,  1997,  8424,  1011,  1011,  1998,  4012, 27293,\n",
      "          1011,  1011,  2012, 24363,  2003,  1037, 24560,  2075,  3689,  2008,\n",
      "          5363,  2000,  2425,  1997,  1996,  4895, 13102, 25508,  3085,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2458, 0.7542],\n",
      "        [0.2514, 0.7486]]), 'input_ids': tensor([[  101,  1999,  1996,  2203,  1010,  1996,  3185, 25938,  2006,  2049,\n",
      "         15311,  3192,  2750,  1996,  2190,  4073,  1997,  2472,  3533,  2482,\n",
      "         15272,  2319,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2995,  6925,  1997,  8424,  1011,  1011,  1998,  4012, 27293,\n",
      "          1011,  1011,  2012, 24363,  2003,  1037, 24560,  2075,  3689,  2008,\n",
      "          5363,  2000,  2425,  1997,  1996,  4895, 13102, 25508,  3085,  1012,\n",
      "           102]]), 'ntok': tensor([24, 31]), 'cls_emb': tensor([[-0.1840, -0.1321, -0.3599,  ..., -0.3936,  0.2478,  0.5622],\n",
      "        [-0.0657, -0.0769, -0.4843,  ..., -0.0946,  0.7275,  0.2478]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2817,  1999, 13178,  1997,  3897,  1010,  5378,  2993,\n",
      "          2039,  1999, 11259,  5436, 23802,  1012,  1012,  1012,   102,     0,\n",
      "             0],\n",
      "        [  101,  2053,  3898,  5913,  1011,  6172,  1999,  3522,  3638,  2038,\n",
      "          1996,  2265, 21530,  1997, 24418,  1005,  2197,  3429,  2781,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2817,  1999, 13178,  1997,  3897,  1010,  5378,  2993,\n",
      "          2039,  1999, 11259,  5436, 23802,  1012,  1012,  1012,   102,     0,\n",
      "             0],\n",
      "        [  101,  2053,  3898,  5913,  1011,  6172,  1999,  3522,  3638,  2038,\n",
      "          1996,  2265, 21530,  1997, 24418,  1005,  2197,  3429,  2781,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2861, 0.7139],\n",
      "        [0.2538, 0.7462]]), 'input_ids': tensor([[  101,  1037,  2817,  1999, 13178,  1997,  3897,  1010,  5378,  2993,\n",
      "          2039,  1999, 11259,  5436, 23802,  1012,  1012,  1012,   102,     0,\n",
      "             0],\n",
      "        [  101,  2053,  3898,  5913,  1011,  6172,  1999,  3522,  3638,  2038,\n",
      "          1996,  2265, 21530,  1997, 24418,  1005,  2197,  3429,  2781,  1012,\n",
      "           102]]), 'ntok': tensor([19, 21]), 'cls_emb': tensor([[-0.0449, -0.0101, -0.4867,  ..., -0.0487,  0.4899,  0.5433],\n",
      "        [-0.3457,  0.0352,  0.1084,  ..., -0.4523,  0.6974,  0.3227]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2062,  6298,  1010,  2062,  6832,  1998,  4821,  2062, 17087,\n",
      "          2084,  1996,  7697,  2100,  1011,  7168,  2434,  1012,   102,     0],\n",
      "        [  101,  2023,  2003,  1037,  9467,  3238, 25850,  1010, 10174,  2000,\n",
      "          5356,  1999,  2006,  1996,  6217,  1997,  2049,  3340,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2062,  6298,  1010,  2062,  6832,  1998,  4821,  2062, 17087,\n",
      "          2084,  1996,  7697,  2100,  1011,  7168,  2434,  1012,   102,     0],\n",
      "        [  101,  2023,  2003,  1037,  9467,  3238, 25850,  1010, 10174,  2000,\n",
      "          5356,  1999,  2006,  1996,  6217,  1997,  2049,  3340,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2740, 0.7260],\n",
      "        [0.2599, 0.7401]]), 'input_ids': tensor([[  101,  2062,  6298,  1010,  2062,  6832,  1998,  4821,  2062, 17087,\n",
      "          2084,  1996,  7697,  2100,  1011,  7168,  2434,  1012,   102,     0],\n",
      "        [  101,  2023,  2003,  1037,  9467,  3238, 25850,  1010, 10174,  2000,\n",
      "          5356,  1999,  2006,  1996,  6217,  1997,  2049,  3340,  1012,   102]]), 'ntok': tensor([19, 20]), 'cls_emb': tensor([[-0.4751, -0.2937, -0.3154,  ..., -0.2849,  0.3649,  0.4757],\n",
      "        [ 0.1408,  0.3150,  0.0761,  ..., -0.5602,  0.4512,  0.4427]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2065,  2017,  1005,  2310,  2412, 21474,  1996,  9366,  1997,\n",
      "          2725,  2054,  1996,  2516,  1997,  2023,  2143, 12748,  1010,  2054,\n",
      "          3348,  2007, 12358,  2941,  3065,  2089,  2404,  2017,  2125,  1996,\n",
      "          2801,  5091,  1012,   102],\n",
      "        [  101,  2320,  1996,  2753,  2095,  2214, 28378,  2072,  3544,  2004,\n",
      "          1996,  2516,  2839,  1010,  2057,  2424,  9731, 15752,  2005,  1996,\n",
      "          3796,  1997,  3536,  2000,  2272,  2067,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2065,  2017,  1005,  2310,  2412, 21474,  1996,  9366,  1997,\n",
      "          2725,  2054,  1996,  2516,  1997,  2023,  2143, 12748,  1010,  2054,\n",
      "          3348,  2007, 12358,  2941,  3065,  2089,  2404,  2017,  2125,  1996,\n",
      "          2801,  5091,  1012,   102],\n",
      "        [  101,  2320,  1996,  2753,  2095,  2214, 28378,  2072,  3544,  2004,\n",
      "          1996,  2516,  2839,  1010,  2057,  2424,  9731, 15752,  2005,  1996,\n",
      "          3796,  1997,  3536,  2000,  2272,  2067,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2398, 0.7602],\n",
      "        [0.2598, 0.7402]]), 'input_ids': tensor([[  101,  2065,  2017,  1005,  2310,  2412, 21474,  1996,  9366,  1997,\n",
      "          2725,  2054,  1996,  2516,  1997,  2023,  2143, 12748,  1010,  2054,\n",
      "          3348,  2007, 12358,  2941,  3065,  2089,  2404,  2017,  2125,  1996,\n",
      "          2801,  5091,  1012,   102],\n",
      "        [  101,  2320,  1996,  2753,  2095,  2214, 28378,  2072,  3544,  2004,\n",
      "          1996,  2516,  2839,  1010,  2057,  2424,  9731, 15752,  2005,  1996,\n",
      "          3796,  1997,  3536,  2000,  2272,  2067,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 28]), 'cls_emb': tensor([[ 0.2199, -0.2891, -0.2263,  ..., -0.3875,  0.0458,  0.2476],\n",
      "        [-0.0372, -0.0114, -0.0333,  ..., -0.0306,  0.5990,  0.4847]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 24646,  7096, 11787,  2135,  1010, 12873, 14876,  8630, 15787,\n",
      "          1010,  2568,  1011, 15903, 15787,  2919,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019,  6464, 17109,  1010,  3571,  1011, 29290,  1006,  2025,\n",
      "          3571,  1011,  8161,  1007,  2143,  2013,  2887,  2472,  5342,  2080,\n",
      "         17823,  6790,  1010,  2040,  3138,  1996,  3565, 16643, 20771,  8364,\n",
      "          2006,  4677,  4144,  1998,  2941, 12033,  2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 24646,  7096, 11787,  2135,  1010, 12873, 14876,  8630, 15787,\n",
      "          1010,  2568,  1011, 15903, 15787,  2919,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019,  6464, 17109,  1010,  3571,  1011, 29290,  1006,  2025,\n",
      "          3571,  1011,  8161,  1007,  2143,  2013,  2887,  2472,  5342,  2080,\n",
      "         17823,  6790,  1010,  2040,  3138,  1996,  3565, 16643, 20771,  8364,\n",
      "          2006,  4677,  4144,  1998,  2941, 12033,  2009,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2641, 0.7359],\n",
      "        [0.2666, 0.7334]]), 'input_ids': tensor([[  101, 24646,  7096, 11787,  2135,  1010, 12873, 14876,  8630, 15787,\n",
      "          1010,  2568,  1011, 15903, 15787,  2919,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019,  6464, 17109,  1010,  3571,  1011, 29290,  1006,  2025,\n",
      "          3571,  1011,  8161,  1007,  2143,  2013,  2887,  2472,  5342,  2080,\n",
      "         17823,  6790,  1010,  2040,  3138,  1996,  3565, 16643, 20771,  8364,\n",
      "          2006,  4677,  4144,  1998,  2941, 12033,  2009,  1012,   102]]), 'ntok': tensor([18, 39]), 'cls_emb': tensor([[-0.5415,  0.2702, -0.3049,  ..., -0.3894,  0.4403,  0.2852],\n",
      "        [-0.3742, -0.1883, -0.2770,  ..., -0.1705,  0.5748,  0.2615]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 15770,  2015,  2049,  3959, 10359, 21096,  2083,  1037,  8338,\n",
      "          1997, 18178,  2229,  2100, 16507,  2015,  1998,  5285, 29441,  8918,\n",
      "         10036,  3896,  1010,  2025,  1996,  2560,  1997,  2029,  2003,  9423,\n",
      "         17083, 28418,  2078,  1011,  2358, 22591,  2015,  1012,   102],\n",
      "        [  101,  2138,  1997,  2019, 14203,  1998, 22902,  2197,  3496,  1010,\n",
      "          1036,  9880, 15143,  1005,  2187,  2033,  2007,  1037,  2200,  2919,\n",
      "          3110,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 15770,  2015,  2049,  3959, 10359, 21096,  2083,  1037,  8338,\n",
      "          1997, 18178,  2229,  2100, 16507,  2015,  1998,  5285, 29441,  8918,\n",
      "         10036,  3896,  1010,  2025,  1996,  2560,  1997,  2029,  2003,  9423,\n",
      "         17083, 28418,  2078,  1011,  2358, 22591,  2015,  1012,   102],\n",
      "        [  101,  2138,  1997,  2019, 14203,  1998, 22902,  2197,  3496,  1010,\n",
      "          1036,  9880, 15143,  1005,  2187,  2033,  2007,  1037,  2200,  2919,\n",
      "          3110,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2789, 0.7211],\n",
      "        [0.2563, 0.7437]]), 'input_ids': tensor([[  101, 15770,  2015,  2049,  3959, 10359, 21096,  2083,  1037,  8338,\n",
      "          1997, 18178,  2229,  2100, 16507,  2015,  1998,  5285, 29441,  8918,\n",
      "         10036,  3896,  1010,  2025,  1996,  2560,  1997,  2029,  2003,  9423,\n",
      "         17083, 28418,  2078,  1011,  2358, 22591,  2015,  1012,   102],\n",
      "        [  101,  2138,  1997,  2019, 14203,  1998, 22902,  2197,  3496,  1010,\n",
      "          1036,  9880, 15143,  1005,  2187,  2033,  2007,  1037,  2200,  2919,\n",
      "          3110,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([39, 23]), 'cls_emb': tensor([[-0.1727, -0.0085,  0.0560,  ..., -0.4127,  0.4046,  0.3443],\n",
      "        [ 0.1290, -0.0308, -0.2555,  ..., -0.2328,  0.1792,  0.3507]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2053, 22877,  2000,  2591, 12324, 12367,  1996,  3185,  2544,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4133,  2083,  2023,  2028,  1010,  1998,  2017, 24185,  1050,\n",
      "          1005,  1056,  2342,  1037,  3894,  3422,  2000,  2644,  2051,  1025,\n",
      "          2115,  4966,  2447,  2097,  2079,  2009,  2005,  2017,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2053, 22877,  2000,  2591, 12324, 12367,  1996,  3185,  2544,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4133,  2083,  2023,  2028,  1010,  1998,  2017, 24185,  1050,\n",
      "          1005,  1056,  2342,  1037,  3894,  3422,  2000,  2644,  2051,  1025,\n",
      "          2115,  4966,  2447,  2097,  2079,  2009,  2005,  2017,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2672, 0.7328],\n",
      "        [0.2500, 0.7500]]), 'input_ids': tensor([[  101,  2053, 22877,  2000,  2591, 12324, 12367,  1996,  3185,  2544,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4133,  2083,  2023,  2028,  1010,  1998,  2017, 24185,  1050,\n",
      "          1005,  1056,  2342,  1037,  3894,  3422,  2000,  2644,  2051,  1025,\n",
      "          2115,  4966,  2447,  2097,  2079,  2009,  2005,  2017,  1012,   102]]), 'ntok': tensor([12, 30]), 'cls_emb': tensor([[ 0.0903,  0.0230, -0.0815,  ..., -0.7529,  0.3791,  0.3223],\n",
      "        [ 0.0576, -0.3351,  0.1582,  ..., -0.1580,  0.3647,  0.5449]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2005,  1996,  2034,  2051,  1999,  2086,  1010,  2139,  9152,\n",
      "          3217, 10667,  2015,  2784, 14868,  1010,  3383,  2138,  2002,  1005,\n",
      "          1055,  2042, 13551,  2011,  1996,  3928,  2147,  1997,  2010,  2522,\n",
      "          1011,  3340,  1012,   102],\n",
      "        [  101,  2025,  2144,  3419,  8592,  1999, 19188,  2449,  2038,  2019,\n",
      "          3364,  2081,  2107,  1037,  2844,  8605,  1999,  2010, 14236,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2005,  1996,  2034,  2051,  1999,  2086,  1010,  2139,  9152,\n",
      "          3217, 10667,  2015,  2784, 14868,  1010,  3383,  2138,  2002,  1005,\n",
      "          1055,  2042, 13551,  2011,  1996,  3928,  2147,  1997,  2010,  2522,\n",
      "          1011,  3340,  1012,   102],\n",
      "        [  101,  2025,  2144,  3419,  8592,  1999, 19188,  2449,  2038,  2019,\n",
      "          3364,  2081,  2107,  1037,  2844,  8605,  1999,  2010, 14236,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2377, 0.7623],\n",
      "        [0.2413, 0.7587]]), 'input_ids': tensor([[  101,  2005,  1996,  2034,  2051,  1999,  2086,  1010,  2139,  9152,\n",
      "          3217, 10667,  2015,  2784, 14868,  1010,  3383,  2138,  2002,  1005,\n",
      "          1055,  2042, 13551,  2011,  1996,  3928,  2147,  1997,  2010,  2522,\n",
      "          1011,  3340,  1012,   102],\n",
      "        [  101,  2025,  2144,  3419,  8592,  1999, 19188,  2449,  2038,  2019,\n",
      "          3364,  2081,  2107,  1037,  2844,  8605,  1999,  2010, 14236,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 21]), 'cls_emb': tensor([[ 0.0245,  0.0675, -0.4392,  ..., -0.2249,  0.3270,  0.2408],\n",
      "        [ 0.0199, -0.0634, -0.6229,  ..., -0.1981,  0.3481,  0.5301]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019,  5875,  2466,  2007,  1037,  2566, 10196,  3372,  1006,\n",
      "         21014,  3973,  4310,  1007,  4471,  1010,  2409,  7199,  2092,  1998,\n",
      "          3195,  2000, 15401,  1010,  1045,  2179,  2870,  8084,  2000,  2404,\n",
      "          2026,  4344,  2006,  2008, 26475,  1036,  1036,  4394,  2518,  1012,\n",
      "          1005,  1005,   102],\n",
      "        [  101,  1012,  1012,  1012,  9410,  1010, 19741, 20150,  1998,  2210,\n",
      "          2842,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019,  5875,  2466,  2007,  1037,  2566, 10196,  3372,  1006,\n",
      "         21014,  3973,  4310,  1007,  4471,  1010,  2409,  7199,  2092,  1998,\n",
      "          3195,  2000, 15401,  1010,  1045,  2179,  2870,  8084,  2000,  2404,\n",
      "          2026,  4344,  2006,  2008, 26475,  1036,  1036,  4394,  2518,  1012,\n",
      "          1005,  1005,   102],\n",
      "        [  101,  1012,  1012,  1012,  9410,  1010, 19741, 20150,  1998,  2210,\n",
      "          2842,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.3183, 0.6817],\n",
      "        [0.2587, 0.7413]]), 'input_ids': tensor([[  101,  2019,  5875,  2466,  2007,  1037,  2566, 10196,  3372,  1006,\n",
      "         21014,  3973,  4310,  1007,  4471,  1010,  2409,  7199,  2092,  1998,\n",
      "          3195,  2000, 15401,  1010,  1045,  2179,  2870,  8084,  2000,  2404,\n",
      "          2026,  4344,  2006,  2008, 26475,  1036,  1036,  4394,  2518,  1012,\n",
      "          1005,  1005,   102],\n",
      "        [  101,  1012,  1012,  1012,  9410,  1010, 19741, 20150,  1998,  2210,\n",
      "          2842,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([43, 13]), 'cls_emb': tensor([[ 0.4468,  0.0533, -0.1407,  ..., -0.1079,  0.4111,  0.6781],\n",
      "        [ 0.1269,  0.2799,  0.0420,  ..., -0.2351,  0.3159,  0.5917]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2003,  1996,  2051,  2428, 22503,  2005,  1037, 17336,  1011,\n",
      "          2058,  2508,  5416,  6172,  1010,  2007,  1037,  2352, 10041,  2004,\n",
      "          1996,  4002,  2581, 17598,  1029,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2130,  1996, 10418, 10026,  6187,  1050,  1005,  1056,  2191,\n",
      "          1037,  2980, 16168,  2046,  2505,  2062,  2084,  1037,  2980, 16168,\n",
      "          1010,  1998,  2728,  2139,  9152,  3217,  6187,  1050,  1005,  1056,\n",
      "          2191,  2023,  3185,  2505,  2062,  2084,  1037, 11669,  2100,  8872,\n",
      "          8937,  4038,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2003,  1996,  2051,  2428, 22503,  2005,  1037, 17336,  1011,\n",
      "          2058,  2508,  5416,  6172,  1010,  2007,  1037,  2352, 10041,  2004,\n",
      "          1996,  4002,  2581, 17598,  1029,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2130,  1996, 10418, 10026,  6187,  1050,  1005,  1056,  2191,\n",
      "          1037,  2980, 16168,  2046,  2505,  2062,  2084,  1037,  2980, 16168,\n",
      "          1010,  1998,  2728,  2139,  9152,  3217,  6187,  1050,  1005,  1056,\n",
      "          2191,  2023,  3185,  2505,  2062,  2084,  1037, 11669,  2100,  8872,\n",
      "          8937,  4038,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2588, 0.7412],\n",
      "        [0.2639, 0.7361]]), 'input_ids': tensor([[  101,  2003,  1996,  2051,  2428, 22503,  2005,  1037, 17336,  1011,\n",
      "          2058,  2508,  5416,  6172,  1010,  2007,  1037,  2352, 10041,  2004,\n",
      "          1996,  4002,  2581, 17598,  1029,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2130,  1996, 10418, 10026,  6187,  1050,  1005,  1056,  2191,\n",
      "          1037,  2980, 16168,  2046,  2505,  2062,  2084,  1037,  2980, 16168,\n",
      "          1010,  1998,  2728,  2139,  9152,  3217,  6187,  1050,  1005,  1056,\n",
      "          2191,  2023,  3185,  2505,  2062,  2084,  1037, 11669,  2100,  8872,\n",
      "          8937,  4038,  1012,   102]]), 'ntok': tensor([26, 44]), 'cls_emb': tensor([[ 0.0713, -0.2539,  0.0072,  ..., -0.3741,  0.3934,  0.7537],\n",
      "        [-0.1659,  0.2230, -0.1387,  ..., -0.3467,  0.8120,  0.4479]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  4507,  1997,  1996,  2047,  2444,  1011,  2895,  9231,\n",
      "         10085, 23584,  2002,  2856,  1010, 11190, 21709,  2063,  1998,  5652,\n",
      "          1999,  6645,  2006,  1996, 27707,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 17015,  2527,  5003, 10023,  9067,  3676,  2546,  1005,  1055,\n",
      "          2047,  2143,  2304, 15271,  2003,  2172,  2066,  1996,  3802, 15006,\n",
      "          1997,  1037,  5460,  1997,  8298,  1010,  2348,  1010,  2009,  1005,\n",
      "          1055, 15140,  2005,  1996, 13972,  2008,  1996,  4301,  1998, 16055,\n",
      "          2746,  2083,  2024, 17153, 23267,  1998,  7221,  2389,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  4507,  1997,  1996,  2047,  2444,  1011,  2895,  9231,\n",
      "         10085, 23584,  2002,  2856,  1010, 11190, 21709,  2063,  1998,  5652,\n",
      "          1999,  6645,  2006,  1996, 27707,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 17015,  2527,  5003, 10023,  9067,  3676,  2546,  1005,  1055,\n",
      "          2047,  2143,  2304, 15271,  2003,  2172,  2066,  1996,  3802, 15006,\n",
      "          1997,  1037,  5460,  1997,  8298,  1010,  2348,  1010,  2009,  1005,\n",
      "          1055, 15140,  2005,  1996, 13972,  2008,  1996,  4301,  1998, 16055,\n",
      "          2746,  2083,  2024, 17153, 23267,  1998,  7221,  2389,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2937, 0.7063],\n",
      "        [0.3015, 0.6985]]), 'input_ids': tensor([[  101,  1996,  4507,  1997,  1996,  2047,  2444,  1011,  2895,  9231,\n",
      "         10085, 23584,  2002,  2856,  1010, 11190, 21709,  2063,  1998,  5652,\n",
      "          1999,  6645,  2006,  1996, 27707,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 17015,  2527,  5003, 10023,  9067,  3676,  2546,  1005,  1055,\n",
      "          2047,  2143,  2304, 15271,  2003,  2172,  2066,  1996,  3802, 15006,\n",
      "          1997,  1037,  5460,  1997,  8298,  1010,  2348,  1010,  2009,  1005,\n",
      "          1055, 15140,  2005,  1996, 13972,  2008,  1996,  4301,  1998, 16055,\n",
      "          2746,  2083,  2024, 17153, 23267,  1998,  7221,  2389,   102]]), 'ntok': tensor([27, 49]), 'cls_emb': tensor([[-0.3552, -0.0191, -0.1936,  ..., -0.2803,  0.6750,  0.2780],\n",
      "        [ 0.1192,  0.1582, -0.2057,  ..., -0.0785,  0.4403,  0.1607]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  1038,  4135,  4383,  3806, 16078,  9459, 27707,  2135,\n",
      "          7622,  2011,  2049,  2219, 11721, 16998, 26302,  2078, 15240,  1997,\n",
      "          2969,  1011,  5197,  1012,  1012,  1012,   102],\n",
      "        [  101,  2296,  2051,  2017,  2298,  1010,  4086,  2188,  6041,  2003,\n",
      "          2635,  2178, 26352,  5017,  1997,  1037,  3308,  2735,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  1038,  4135,  4383,  3806, 16078,  9459, 27707,  2135,\n",
      "          7622,  2011,  2049,  2219, 11721, 16998, 26302,  2078, 15240,  1997,\n",
      "          2969,  1011,  5197,  1012,  1012,  1012,   102],\n",
      "        [  101,  2296,  2051,  2017,  2298,  1010,  4086,  2188,  6041,  2003,\n",
      "          2635,  2178, 26352,  5017,  1997,  1037,  3308,  2735,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2696, 0.7304],\n",
      "        [0.2632, 0.7368]]), 'input_ids': tensor([[  101,  1037,  1038,  4135,  4383,  3806, 16078,  9459, 27707,  2135,\n",
      "          7622,  2011,  2049,  2219, 11721, 16998, 26302,  2078, 15240,  1997,\n",
      "          2969,  1011,  5197,  1012,  1012,  1012,   102],\n",
      "        [  101,  2296,  2051,  2017,  2298,  1010,  4086,  2188,  6041,  2003,\n",
      "          2635,  2178, 26352,  5017,  1997,  1037,  3308,  2735,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([27, 20]), 'cls_emb': tensor([[ 0.0176,  0.0960, -0.3443,  ..., -0.1378,  0.6475,  0.4429],\n",
      "        [ 0.0586, -0.0276, -0.1808,  ..., -0.4138,  0.1928,  0.2958]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2129,  2079,  2017,  6297, 18856, 17322,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053, 10013,  2075,  2003,  2205,  5793,  2030, 21934, 24759,\n",
      "          6553,  2005,  2023,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2129,  2079,  2017,  6297, 18856, 17322,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053, 10013,  2075,  2003,  2205,  5793,  2030, 21934, 24759,\n",
      "          6553,  2005,  2023,  3185,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2966, 0.7034],\n",
      "        [0.2679, 0.7321]]), 'input_ids': tensor([[  101,  2129,  2079,  2017,  6297, 18856, 17322,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2053, 10013,  2075,  2003,  2205,  5793,  2030, 21934, 24759,\n",
      "          6553,  2005,  2023,  3185,  1012,   102]]), 'ntok': tensor([ 9, 16]), 'cls_emb': tensor([[ 0.1002,  0.2215, -0.2341,  ..., -0.3722,  0.1891,  0.5337],\n",
      "        [ 0.0424, -0.0444,  0.0678,  ..., -0.4347,  0.3353,  0.4614]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2472,  1997,  5855, 21721,  3972, 23393,  4168,  2915,  1996,\n",
      "          3185,  1999, 12090,  6087,  1010,  1998,  1996, 12703,  1998,  4520,\n",
      "          2024,  2882,  1012,   102],\n",
      "        [  101,  1045,  2245,  2026,  2219,  3422,  2018,  3030,  4363,  2051,\n",
      "          2004,  1045, 22889,  8649,  5999,  2026,  2126,  2083, 20940, 14399,\n",
      "          7347,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2472,  1997,  5855, 21721,  3972, 23393,  4168,  2915,  1996,\n",
      "          3185,  1999, 12090,  6087,  1010,  1998,  1996, 12703,  1998,  4520,\n",
      "          2024,  2882,  1012,   102],\n",
      "        [  101,  1045,  2245,  2026,  2219,  3422,  2018,  3030,  4363,  2051,\n",
      "          2004,  1045, 22889,  8649,  5999,  2026,  2126,  2083, 20940, 14399,\n",
      "          7347,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2589, 0.7411],\n",
      "        [0.2616, 0.7384]]), 'input_ids': tensor([[  101,  2472,  1997,  5855, 21721,  3972, 23393,  4168,  2915,  1996,\n",
      "          3185,  1999, 12090,  6087,  1010,  1998,  1996, 12703,  1998,  4520,\n",
      "          2024,  2882,  1012,   102],\n",
      "        [  101,  1045,  2245,  2026,  2219,  3422,  2018,  3030,  4363,  2051,\n",
      "          2004,  1045, 22889,  8649,  5999,  2026,  2126,  2083, 20940, 14399,\n",
      "          7347,  1012,   102,     0]]), 'ntok': tensor([24, 23]), 'cls_emb': tensor([[-0.2235, -0.1591,  0.0825,  ..., -0.6377,  0.4284,  0.2005],\n",
      "        [ 0.0894,  0.1657, -0.3153,  ..., -0.0192,  0.2360,  0.4300]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2625, 14849,  2075,  2084,  2074, 14849,  1010,  1996, 14855,\n",
      "         16671,  2003,  8134,  2058,  2077,  2009,  4269,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3452,  1996,  2143,  5683,  2066,  1037,  2659,  1011,  5166,\n",
      "          2694,  4405,  2008,  2071,  2025,  2424,  1037, 17634,  2000,  2377,\n",
      "          2009,  2006,  1996,  7270,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2625, 14849,  2075,  2084,  2074, 14849,  1010,  1996, 14855,\n",
      "         16671,  2003,  8134,  2058,  2077,  2009,  4269,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3452,  1996,  2143,  5683,  2066,  1037,  2659,  1011,  5166,\n",
      "          2694,  4405,  2008,  2071,  2025,  2424,  1037, 17634,  2000,  2377,\n",
      "          2009,  2006,  1996,  7270,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2390, 0.7610],\n",
      "        [0.2553, 0.7447]]), 'input_ids': tensor([[  101,  2625, 14849,  2075,  2084,  2074, 14849,  1010,  1996, 14855,\n",
      "         16671,  2003,  8134,  2058,  2077,  2009,  4269,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3452,  1996,  2143,  5683,  2066,  1037,  2659,  1011,  5166,\n",
      "          2694,  4405,  2008,  2071,  2025,  2424,  1037, 17634,  2000,  2377,\n",
      "          2009,  2006,  1996,  7270,  1012,   102]]), 'ntok': tensor([19, 26]), 'cls_emb': tensor([[ 0.2115,  0.1783,  0.4653,  ..., -0.1374,  0.2343,  0.5373],\n",
      "        [ 0.0016, -0.2278,  0.0099,  ..., -0.2999,  0.5577,  0.4483]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2027,  2323,  2031,  2170,  2009,  9535,  3334,  7384,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13931,  8902, 10483,  2819,  1011,  1011,  2096,  6151, 19825,\n",
      "          6321,  5875,  1011,  1011,  5078,  2041,  2049,  6160,  2092,  2077,\n",
      "          1996,  2203,  6495,  4565,  2055,  3429,  2781,  1999,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2027,  2323,  2031,  2170,  2009,  9535,  3334,  7384,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13931,  8902, 10483,  2819,  1011,  1011,  2096,  6151, 19825,\n",
      "          6321,  5875,  1011,  1011,  5078,  2041,  2049,  6160,  2092,  2077,\n",
      "          1996,  2203,  6495,  4565,  2055,  3429,  2781,  1999,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2959, 0.7041],\n",
      "        [0.2660, 0.7340]]), 'input_ids': tensor([[  101,  2027,  2323,  2031,  2170,  2009,  9535,  3334,  7384,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13931,  8902, 10483,  2819,  1011,  1011,  2096,  6151, 19825,\n",
      "          6321,  5875,  1011,  1011,  5078,  2041,  2049,  6160,  2092,  2077,\n",
      "          1996,  2203,  6495,  4565,  2055,  3429,  2781,  1999,  1012,   102]]), 'ntok': tensor([11, 30]), 'cls_emb': tensor([[ 0.0321,  0.0841,  0.0393,  ..., -0.1521,  0.1895,  0.4330],\n",
      "        [ 0.3327, -0.0966,  0.0519,  ..., -0.0185,  0.6983,  0.6224]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1006,  1037,  1007,  1050, 12580, 11951,  1998, 26316,  2143,\n",
      "          2008,  6966,  2033,  1997,  1996,  2190,  1997,  1996,  6373, 22092,\n",
      "          2013,  1996, 20341,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  1005,  1055,  2205,  2172,  6270,  2791,  2000,  1996,\n",
      "          2117,  2431,  1010,  1998,  2054,  2211,  2004,  2019, 23824,  2298,\n",
      "          2012,  3360, 10882, 17644,  2015,  2046,  1037, 10634,  1010,  9951,\n",
      "          3535,  2012,  2540,  1011, 17100,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1006,  1037,  1007,  1050, 12580, 11951,  1998, 26316,  2143,\n",
      "          2008,  6966,  2033,  1997,  1996,  2190,  1997,  1996,  6373, 22092,\n",
      "          2013,  1996, 20341,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  1005,  1055,  2205,  2172,  6270,  2791,  2000,  1996,\n",
      "          2117,  2431,  1010,  1998,  2054,  2211,  2004,  2019, 23824,  2298,\n",
      "          2012,  3360, 10882, 17644,  2015,  2046,  1037, 10634,  1010,  9951,\n",
      "          3535,  2012,  2540,  1011, 17100,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2694, 0.7306],\n",
      "        [0.2391, 0.7609]]), 'input_ids': tensor([[  101,  1006,  1037,  1007,  1050, 12580, 11951,  1998, 26316,  2143,\n",
      "          2008,  6966,  2033,  1997,  1996,  2190,  1997,  1996,  6373, 22092,\n",
      "          2013,  1996, 20341,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  1005,  1055,  2205,  2172,  6270,  2791,  2000,  1996,\n",
      "          2117,  2431,  1010,  1998,  2054,  2211,  2004,  2019, 23824,  2298,\n",
      "          2012,  3360, 10882, 17644,  2015,  2046,  1037, 10634,  1010,  9951,\n",
      "          3535,  2012,  2540,  1011, 17100,  1012,   102]]), 'ntok': tensor([25, 37]), 'cls_emb': tensor([[-0.2466, -0.1762, -0.0976,  ..., -0.3943,  0.5442,  0.5368],\n",
      "        [ 0.2080,  0.2145, -0.3174,  ..., -0.3360,  0.5329,  0.6756]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 29585,  1011, 29290,  7982,  1010, 16215, 16338,  1011,  4497,\n",
      "         12703,  1010,  4013,  3367, 20086,  5789,  2011, 10021,  2404,  3723,\n",
      "          1998,  2463,  8445,  2630,  1011,  2422,  1011,  2569,  3896,  2035,\n",
      "          9530, 13102,  7442,  2000,  3231, 10313, 11602,  9721,  1012,   102],\n",
      "        [  101,  1037, 20001,  2135, 14336,  1998, 19401,  2135,  6361,  3689,\n",
      "          2055,  1037,  2269,  1998,  2365,  4434,  2008,  2003,  1037,  4766,\n",
      "          5008,  2732,  1997,  2293,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 29585,  1011, 29290,  7982,  1010, 16215, 16338,  1011,  4497,\n",
      "         12703,  1010,  4013,  3367, 20086,  5789,  2011, 10021,  2404,  3723,\n",
      "          1998,  2463,  8445,  2630,  1011,  2422,  1011,  2569,  3896,  2035,\n",
      "          9530, 13102,  7442,  2000,  3231, 10313, 11602,  9721,  1012,   102],\n",
      "        [  101,  1037, 20001,  2135, 14336,  1998, 19401,  2135,  6361,  3689,\n",
      "          2055,  1037,  2269,  1998,  2365,  4434,  2008,  2003,  1037,  4766,\n",
      "          5008,  2732,  1997,  2293,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2403, 0.7597],\n",
      "        [0.2831, 0.7169]]), 'input_ids': tensor([[  101, 29585,  1011, 29290,  7982,  1010, 16215, 16338,  1011,  4497,\n",
      "         12703,  1010,  4013,  3367, 20086,  5789,  2011, 10021,  2404,  3723,\n",
      "          1998,  2463,  8445,  2630,  1011,  2422,  1011,  2569,  3896,  2035,\n",
      "          9530, 13102,  7442,  2000,  3231, 10313, 11602,  9721,  1012,   102],\n",
      "        [  101,  1037, 20001,  2135, 14336,  1998, 19401,  2135,  6361,  3689,\n",
      "          2055,  1037,  2269,  1998,  2365,  4434,  2008,  2003,  1037,  4766,\n",
      "          5008,  2732,  1997,  2293,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([40, 26]), 'cls_emb': tensor([[-0.1610,  0.2068, -0.2569,  ...,  0.0373,  0.3440,  0.8344],\n",
      "        [-0.4526, -0.3561,  0.0586,  ..., -0.3959,  0.5278,  0.1762]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  2529,  4038,  2012,  2049,  2087, 19142,  1010,\n",
      "          5875,  1998, 19195,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101, 13156,  2100,  1005,  1055,  9128,  2000, 10047, 16862,  2063,\n",
      "          2017,  1999, 11591,  1010,  4895, 16570, 26951, 23277, 29574,  2791,\n",
      "          2003, 15095,  2075,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  2529,  4038,  2012,  2049,  2087, 19142,  1010,\n",
      "          5875,  1998, 19195,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101, 13156,  2100,  1005,  1055,  9128,  2000, 10047, 16862,  2063,\n",
      "          2017,  1999, 11591,  1010,  4895, 16570, 26951, 23277, 29574,  2791,\n",
      "          2003, 15095,  2075,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2622, 0.7378],\n",
      "        [0.2382, 0.7618]]), 'input_ids': tensor([[  101,  2023,  2003,  2529,  4038,  2012,  2049,  2087, 19142,  1010,\n",
      "          5875,  1998, 19195,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101, 13156,  2100,  1005,  1055,  9128,  2000, 10047, 16862,  2063,\n",
      "          2017,  1999, 11591,  1010,  4895, 16570, 26951, 23277, 29574,  2791,\n",
      "          2003, 15095,  2075,  1012,   102]]), 'ntok': tensor([15, 25]), 'cls_emb': tensor([[ 0.0443,  0.1240, -0.0550,  ..., -0.1335,  0.3233,  0.5348],\n",
      "        [ 0.0756,  0.1283, -0.4023,  ..., -0.3077,  0.4712,  0.3628]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4276,  3666,  2005, 11947, 10147,  2063,  1005,  1055,  2836,\n",
      "          1011,  1011,  1998,  2005,  1996,  2126,  2009,  5491,  1037,  3226,\n",
      "          1999,  1996, 16215,  3217,  2229,  1997,  5915,  2689,  1012,   102],\n",
      "        [  101,  1037, 13433, 25593,  1010,  2396,  7699, 19275, 13804,  2006,\n",
      "         13356,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4276,  3666,  2005, 11947, 10147,  2063,  1005,  1055,  2836,\n",
      "          1011,  1011,  1998,  2005,  1996,  2126,  2009,  5491,  1037,  3226,\n",
      "          1999,  1996, 16215,  3217,  2229,  1997,  5915,  2689,  1012,   102],\n",
      "        [  101,  1037, 13433, 25593,  1010,  2396,  7699, 19275, 13804,  2006,\n",
      "         13356,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2569, 0.7431],\n",
      "        [0.2708, 0.7292]]), 'input_ids': tensor([[  101,  4276,  3666,  2005, 11947, 10147,  2063,  1005,  1055,  2836,\n",
      "          1011,  1011,  1998,  2005,  1996,  2126,  2009,  5491,  1037,  3226,\n",
      "          1999,  1996, 16215,  3217,  2229,  1997,  5915,  2689,  1012,   102],\n",
      "        [  101,  1037, 13433, 25593,  1010,  2396,  7699, 19275, 13804,  2006,\n",
      "         13356,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([30, 13]), 'cls_emb': tensor([[ 0.1485, -0.2018, -0.4758,  ..., -0.1888,  0.4453,  0.4506],\n",
      "        [-0.5669, -0.3166, -0.5023,  ..., -0.3449,  0.2101,  0.4533]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2205, 19868,  2000,  2022,  1037, 11576,  2265,  1010,  2205,\n",
      "         22146,  1998,  5793,  2000,  2022, 18439,  1010,  2205, 10634,  1998,\n",
      "          3653,  6528, 20771,  2000,  2022, 11973,  1012,  1012,  1012,  1996,\n",
      "          8842, 13366,  3111,  2019,  3733,  4937, 20265, 26910,  1012,   102],\n",
      "        [  101, 12297,  1005,  1055,  2093,  5889,  1011,  1011,  9587,  4571,\n",
      "          1010, 13097,  1998, 22759,  6633,  1011,  1011, 24970,  1999, 12369,\n",
      "          3993,  1010,  7861, 15069, 16530,  4616,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2205, 19868,  2000,  2022,  1037, 11576,  2265,  1010,  2205,\n",
      "         22146,  1998,  5793,  2000,  2022, 18439,  1010,  2205, 10634,  1998,\n",
      "          3653,  6528, 20771,  2000,  2022, 11973,  1012,  1012,  1012,  1996,\n",
      "          8842, 13366,  3111,  2019,  3733,  4937, 20265, 26910,  1012,   102],\n",
      "        [  101, 12297,  1005,  1055,  2093,  5889,  1011,  1011,  9587,  4571,\n",
      "          1010, 13097,  1998, 22759,  6633,  1011,  1011, 24970,  1999, 12369,\n",
      "          3993,  1010,  7861, 15069, 16530,  4616,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2436, 0.7564],\n",
      "        [0.2490, 0.7510]]), 'input_ids': tensor([[  101,  2205, 19868,  2000,  2022,  1037, 11576,  2265,  1010,  2205,\n",
      "         22146,  1998,  5793,  2000,  2022, 18439,  1010,  2205, 10634,  1998,\n",
      "          3653,  6528, 20771,  2000,  2022, 11973,  1012,  1012,  1012,  1996,\n",
      "          8842, 13366,  3111,  2019,  3733,  4937, 20265, 26910,  1012,   102],\n",
      "        [  101, 12297,  1005,  1055,  2093,  5889,  1011,  1011,  9587,  4571,\n",
      "          1010, 13097,  1998, 22759,  6633,  1011,  1011, 24970,  1999, 12369,\n",
      "          3993,  1010,  7861, 15069, 16530,  4616,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([40, 28]), 'cls_emb': tensor([[-2.9719e-04,  8.4832e-02,  2.8818e-02,  ..., -1.4505e-01,\n",
      "          3.7684e-01,  8.0288e-01],\n",
      "        [-3.2810e-01,  1.3870e-01, -4.6413e-01,  ..., -1.3823e-01,\n",
      "          5.3030e-01,  5.2857e-01]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2673,  2017,  2079,  1050,  1005,  1056,\n",
      "          2175,  2000,  1996,  5691,  2005,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  3946,  1005,  1055,  1007, 26352,  9709,  3894,  3138,\n",
      "          2058,  1996,  2143,  1010,  1998,  2009,  4332,  2041,  2000,  2022,\n",
      "          2178,  3045,  2732,  4316,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2673,  2017,  2079,  1050,  1005,  1056,\n",
      "          2175,  2000,  1996,  5691,  2005,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  3946,  1005,  1055,  1007, 26352,  9709,  3894,  3138,\n",
      "          2058,  1996,  2143,  1010,  1998,  2009,  4332,  2041,  2000,  2022,\n",
      "          2178,  3045,  2732,  4316,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2767, 0.7233],\n",
      "        [0.2641, 0.7359]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2673,  2017,  2079,  1050,  1005,  1056,\n",
      "          2175,  2000,  1996,  5691,  2005,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006,  3946,  1005,  1055,  1007, 26352,  9709,  3894,  3138,\n",
      "          2058,  1996,  2143,  1010,  1998,  2009,  4332,  2041,  2000,  2022,\n",
      "          2178,  3045,  2732,  4316,  1012,   102]]), 'ntok': tensor([17, 26]), 'cls_emb': tensor([[ 0.0923, -0.0037, -0.3154,  ..., -0.3033,  0.0114,  0.5230],\n",
      "        [-0.2532, -0.0369, -0.0275,  ..., -0.2465,  0.2566,  0.5180]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  4152,  3031,  1996,  3898,  2074,  2055,  2004,  2172,\n",
      "          1997,  1996, 20674,  2004,  2028,  2071, 16286,  5987,  1010,  1998,\n",
      "          2003, 25540, 25725,  2075,  1998,  3048,  1999,  2049,  2219,  2157,\n",
      "          1012,   102],\n",
      "        [  101, 10146,  5836,  2673,  3308,  2007,  1005,  1005,  2981,  2143,\n",
      "          1005,  1005,  2004,  1037,  4012,  5302,  4305, 10451,  1010,  2853,\n",
      "          1011,  2041,  4145,  2006,  1996,  2137, 24466,  3496,  1012,   102,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  4152,  3031,  1996,  3898,  2074,  2055,  2004,  2172,\n",
      "          1997,  1996, 20674,  2004,  2028,  2071, 16286,  5987,  1010,  1998,\n",
      "          2003, 25540, 25725,  2075,  1998,  3048,  1999,  2049,  2219,  2157,\n",
      "          1012,   102],\n",
      "        [  101, 10146,  5836,  2673,  3308,  2007,  1005,  1005,  2981,  2143,\n",
      "          1005,  1005,  2004,  1037,  4012,  5302,  4305, 10451,  1010,  2853,\n",
      "          1011,  2041,  4145,  2006,  1996,  2137, 24466,  3496,  1012,   102,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2542, 0.7458],\n",
      "        [0.2502, 0.7498]]), 'input_ids': tensor([[  101,  2009,  4152,  3031,  1996,  3898,  2074,  2055,  2004,  2172,\n",
      "          1997,  1996, 20674,  2004,  2028,  2071, 16286,  5987,  1010,  1998,\n",
      "          2003, 25540, 25725,  2075,  1998,  3048,  1999,  2049,  2219,  2157,\n",
      "          1012,   102],\n",
      "        [  101, 10146,  5836,  2673,  3308,  2007,  1005,  1005,  2981,  2143,\n",
      "          1005,  1005,  2004,  1037,  4012,  5302,  4305, 10451,  1010,  2853,\n",
      "          1011,  2041,  4145,  2006,  1996,  2137, 24466,  3496,  1012,   102,\n",
      "             0,     0]]), 'ntok': tensor([32, 30]), 'cls_emb': tensor([[ 0.1330, -0.1312,  0.1204,  ..., -0.1944,  0.4381,  0.7175],\n",
      "        [-0.2465, -0.1769, -0.2717,  ..., -0.4743,  0.4845,  0.5774]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2021,  2579,  2004,  1037,  2358,  8516,  4509,  1998, 18114,\n",
      "          2028,  1011,  2915,  1010,  1996,  3035,  1997,  1996,  9636,  2064,\n",
      "          2025,  2022,  2056,  2000, 11891,  1012,   102],\n",
      "        [  101,  1996,  3538,  3248,  2004,  2092,  2004,  2009,  2515,  4283,\n",
      "          1999,  2312,  5468,  2000,  2019, 13102,  4887,  5603,  1005,  1055,\n",
      "          2093,  2599, 19910,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2021,  2579,  2004,  1037,  2358,  8516,  4509,  1998, 18114,\n",
      "          2028,  1011,  2915,  1010,  1996,  3035,  1997,  1996,  9636,  2064,\n",
      "          2025,  2022,  2056,  2000, 11891,  1012,   102],\n",
      "        [  101,  1996,  3538,  3248,  2004,  2092,  2004,  2009,  2515,  4283,\n",
      "          1999,  2312,  5468,  2000,  2019, 13102,  4887,  5603,  1005,  1055,\n",
      "          2093,  2599, 19910,  1012,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2744, 0.7256],\n",
      "        [0.2554, 0.7446]]), 'input_ids': tensor([[  101,  2021,  2579,  2004,  1037,  2358,  8516,  4509,  1998, 18114,\n",
      "          2028,  1011,  2915,  1010,  1996,  3035,  1997,  1996,  9636,  2064,\n",
      "          2025,  2022,  2056,  2000, 11891,  1012,   102],\n",
      "        [  101,  1996,  3538,  3248,  2004,  2092,  2004,  2009,  2515,  4283,\n",
      "          1999,  2312,  5468,  2000,  2019, 13102,  4887,  5603,  1005,  1055,\n",
      "          2093,  2599, 19910,  1012,   102,     0,     0]]), 'ntok': tensor([27, 25]), 'cls_emb': tensor([[ 0.2030, -0.0454, -0.3002,  ..., -0.1753,  0.3464,  0.4451],\n",
      "        [-0.2269,  0.0034,  0.1658,  ..., -0.1979,  0.3367,  0.9074]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 10514,  4246, 24755,  3064,  2011,  2049, 28554,  2100,  5896,\n",
      "          1998,  2039, 26143,  3494,  1010,  2023,  2442,  2100,  6789,  2003,\n",
      "          2035,  1996,  2062, 15703,  2144,  2009,  1005,  1055,  2042, 21972,\n",
      "          1998,  2853,  2067,  2000,  2149,  2011,  5365,  1012,   102],\n",
      "        [  101,  2021,  2054,  2024,  6001,  2725,  1999,  1996,  4258,  2012,\n",
      "          2035,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 10514,  4246, 24755,  3064,  2011,  2049, 28554,  2100,  5896,\n",
      "          1998,  2039, 26143,  3494,  1010,  2023,  2442,  2100,  6789,  2003,\n",
      "          2035,  1996,  2062, 15703,  2144,  2009,  1005,  1055,  2042, 21972,\n",
      "          1998,  2853,  2067,  2000,  2149,  2011,  5365,  1012,   102],\n",
      "        [  101,  2021,  2054,  2024,  6001,  2725,  1999,  1996,  4258,  2012,\n",
      "          2035,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2518, 0.7482],\n",
      "        [0.2862, 0.7138]]), 'input_ids': tensor([[  101, 10514,  4246, 24755,  3064,  2011,  2049, 28554,  2100,  5896,\n",
      "          1998,  2039, 26143,  3494,  1010,  2023,  2442,  2100,  6789,  2003,\n",
      "          2035,  1996,  2062, 15703,  2144,  2009,  1005,  1055,  2042, 21972,\n",
      "          1998,  2853,  2067,  2000,  2149,  2011,  5365,  1012,   102],\n",
      "        [  101,  2021,  2054,  2024,  6001,  2725,  1999,  1996,  4258,  2012,\n",
      "          2035,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([39, 13]), 'cls_emb': tensor([[ 0.1195,  0.0789,  0.0253,  ..., -0.1057,  0.4294,  0.4431],\n",
      "        [ 0.1921,  0.3115,  0.1022,  ..., -0.3622,  0.5061,  0.4896]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2066,  2108,  7567,  2012,  1037, 18870, 25312,  2102,  2283,\n",
      "          1012,  1012,  1012,  2129,  2064,  2242,  2061,  7977,  2022,  2061,\n",
      "         11771,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2158,  2013, 20779, 17043,  4249,  2003,  1037,  3147,\n",
      "          1010, 13670,  1011,  2625,  2147,  2008, 27778,  2247,  3241,  2993,\n",
      "          2070,  2590,  7615,  2006,  2129,  2166, 11618,  2149,  2070, 11693,\n",
      "         19231,  2075, 10543,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2066,  2108,  7567,  2012,  1037, 18870, 25312,  2102,  2283,\n",
      "          1012,  1012,  1012,  2129,  2064,  2242,  2061,  7977,  2022,  2061,\n",
      "         11771,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2158,  2013, 20779, 17043,  4249,  2003,  1037,  3147,\n",
      "          1010, 13670,  1011,  2625,  2147,  2008, 27778,  2247,  3241,  2993,\n",
      "          2070,  2590,  7615,  2006,  2129,  2166, 11618,  2149,  2070, 11693,\n",
      "         19231,  2075, 10543,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2482, 0.7518],\n",
      "        [0.2450, 0.7550]]), 'input_ids': tensor([[  101,  2066,  2108,  7567,  2012,  1037, 18870, 25312,  2102,  2283,\n",
      "          1012,  1012,  1012,  2129,  2064,  2242,  2061,  7977,  2022,  2061,\n",
      "         11771,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2158,  2013, 20779, 17043,  4249,  2003,  1037,  3147,\n",
      "          1010, 13670,  1011,  2625,  2147,  2008, 27778,  2247,  3241,  2993,\n",
      "          2070,  2590,  7615,  2006,  2129,  2166, 11618,  2149,  2070, 11693,\n",
      "         19231,  2075, 10543,  1012,   102]]), 'ntok': tensor([23, 35]), 'cls_emb': tensor([[ 0.4020,  0.2492,  0.0036,  ..., -0.0078,  0.3732,  0.5828],\n",
      "        [-0.0146,  0.0089, -0.0089,  ..., -0.0631,  0.4325,  0.4261]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  1050,  1005,  1056,  2130, 11284,  1005,  1055,\n",
      "          7260,  2185,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3325,  1997,  2183,  2000,  1037,  2143,  2782,  2003,\n",
      "          1037, 10377,  2075,  2028,  1025,  1996, 13417,  1997, 16227,  2028,\n",
      "          2083,  2023,  3185,  2003,  2025,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  1050,  1005,  1056,  2130, 11284,  1005,  1055,\n",
      "          7260,  2185,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3325,  1997,  2183,  2000,  1037,  2143,  2782,  2003,\n",
      "          1037, 10377,  2075,  2028,  1025,  1996, 13417,  1997, 16227,  2028,\n",
      "          2083,  2023,  3185,  2003,  2025,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2654, 0.7346],\n",
      "        [0.2343, 0.7657]]), 'input_ids': tensor([[  101,  2023,  2003,  1050,  1005,  1056,  2130, 11284,  1005,  1055,\n",
      "          7260,  2185,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3325,  1997,  2183,  2000,  1037,  2143,  2782,  2003,\n",
      "          1037, 10377,  2075,  2028,  1025,  1996, 13417,  1997, 16227,  2028,\n",
      "          2083,  2023,  3185,  2003,  2025,  1012,   102]]), 'ntok': tensor([14, 27]), 'cls_emb': tensor([[-0.1288, -0.1414,  0.1133,  ..., -0.3120,  0.1559,  0.4421],\n",
      "        [ 0.3940, -0.0549, -0.3227,  ..., -0.1132,  0.3493,  0.4026]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2137, 15775,  2072, 16171, 13413,  3993,  7239,  2012, 22807,\n",
      "          2069,  2019,  2796,  1011,  2137,  2052,  6807,  1012,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2026,  2502,  6638,  3306,  5030,  3594, 22807,  1999,  1037,\n",
      "         26380, 12586,  1997,  4086,  7472,  1998,  8295,  2135,  9841,  2098,\n",
      "          2041,  8562,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2137, 15775,  2072, 16171, 13413,  3993,  7239,  2012, 22807,\n",
      "          2069,  2019,  2796,  1011,  2137,  2052,  6807,  1012,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2026,  2502,  6638,  3306,  5030,  3594, 22807,  1999,  1037,\n",
      "         26380, 12586,  1997,  4086,  7472,  1998,  8295,  2135,  9841,  2098,\n",
      "          2041,  8562,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2574, 0.7426],\n",
      "        [0.2534, 0.7466]]), 'input_ids': tensor([[  101,  2137, 15775,  2072, 16171, 13413,  3993,  7239,  2012, 22807,\n",
      "          2069,  2019,  2796,  1011,  2137,  2052,  6807,  1012,   102,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2026,  2502,  6638,  3306,  5030,  3594, 22807,  1999,  1037,\n",
      "         26380, 12586,  1997,  4086,  7472,  1998,  8295,  2135,  9841,  2098,\n",
      "          2041,  8562,  1012,   102]]), 'ntok': tensor([19, 24]), 'cls_emb': tensor([[-0.3031, -0.1402, -0.5766,  ..., -0.1447,  0.5490,  0.4214],\n",
      "        [-0.2736,  0.2093, -0.0570,  ..., -0.6294,  0.6264,  0.3610]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1037, 12047,  3689,  2092,  4276,  9651,\n",
      "          2091,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  7436, 18575,  1005,  1055, 17743,  1010,  1996,  5197,  1997,\n",
      "          2108, 17300,  1010,  2089,  2022,  1996,  2190,  2377,  1997,  1996,\n",
      "          3708,  2301,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1012,  1012,  1012,  1037, 12047,  3689,  2092,  4276,  9651,\n",
      "          2091,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  7436, 18575,  1005,  1055, 17743,  1010,  1996,  5197,  1997,\n",
      "          2108, 17300,  1010,  2089,  2022,  1996,  2190,  2377,  1997,  1996,\n",
      "          3708,  2301,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2583, 0.7417],\n",
      "        [0.2515, 0.7485]]), 'input_ids': tensor([[  101,  1012,  1012,  1012,  1037, 12047,  3689,  2092,  4276,  9651,\n",
      "          2091,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  7436, 18575,  1005,  1055, 17743,  1010,  1996,  5197,  1997,\n",
      "          2108, 17300,  1010,  2089,  2022,  1996,  2190,  2377,  1997,  1996,\n",
      "          3708,  2301,  1012,   102]]), 'ntok': tensor([13, 24]), 'cls_emb': tensor([[-0.1738,  0.0465, -0.1204,  ..., -0.3859,  0.3074,  0.4481],\n",
      "        [-0.5048, -0.0797, -0.5313,  ..., -0.5588,  0.3571,  0.4547]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4560,  3409,  7231,  4571, 18058,  1037, 11853, 18534,  2466,\n",
      "          7765,  2007, 23069,  3012,  2021,  7987,  5714,  6562,  2007,  7132,\n",
      "          8562,  1010,  8618, 26760, 15558,  4130,  2891,  1010,  1998, 13677,\n",
      "          5312,  2008, 26577,  2066, 20057, 12326,  2015,  1997,  3638,  1012,\n",
      "           102],\n",
      "        [  101,  2021,  2009,  2145, 29262,  2015,  1999,  1996,  4979,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4560,  3409,  7231,  4571, 18058,  1037, 11853, 18534,  2466,\n",
      "          7765,  2007, 23069,  3012,  2021,  7987,  5714,  6562,  2007,  7132,\n",
      "          8562,  1010,  8618, 26760, 15558,  4130,  2891,  1010,  1998, 13677,\n",
      "          5312,  2008, 26577,  2066, 20057, 12326,  2015,  1997,  3638,  1012,\n",
      "           102],\n",
      "        [  101,  2021,  2009,  2145, 29262,  2015,  1999,  1996,  4979,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2334, 0.7666],\n",
      "        [0.2350, 0.7650]]), 'input_ids': tensor([[  101,  4560,  3409,  7231,  4571, 18058,  1037, 11853, 18534,  2466,\n",
      "          7765,  2007, 23069,  3012,  2021,  7987,  5714,  6562,  2007,  7132,\n",
      "          8562,  1010,  8618, 26760, 15558,  4130,  2891,  1010,  1998, 13677,\n",
      "          5312,  2008, 26577,  2066, 20057, 12326,  2015,  1997,  3638,  1012,\n",
      "           102],\n",
      "        [  101,  2021,  2009,  2145, 29262,  2015,  1999,  1996,  4979,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([41, 11]), 'cls_emb': tensor([[-0.2515, -0.0030, -0.5126,  ..., -0.5537,  0.6064,  0.1509],\n",
      "        [-0.2139,  0.2457,  0.0670,  ..., -0.1434,  0.1712,  0.6514]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17183, 14088, 18628,  2818,  6752,\n",
      "          1006,  2348,  1996, 15488, 14644,  2100,  3617,  2678,  2515,  2674,\n",
      "          1996,  8494, 20043,  7984,  1007,  1010,  2021,  2009,  1005,  1055,\n",
      "          7842,  2615, 10736,  2055,  8958,  1998,  2038,  2062, 18453,  1998,\n",
      "          2943,  2084,  2172,  1997,  2054,  2097,  2330,  2023,  2095,  1012,\n",
      "           102],\n",
      "        [  101,  2017,  2428,  2031,  2000,  4687,  2129,  2006,  3011,  3087,\n",
      "          1010,  5973,  2071,  2031,  2245,  2027,  1005,  1040,  2191,  9501,\n",
      "         19739, 20961,  2860,  2007,  1037,  5896,  2004, 12580, 22939, 18647,\n",
      "          2389,  2004,  2023,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17183, 14088, 18628,  2818,  6752,\n",
      "          1006,  2348,  1996, 15488, 14644,  2100,  3617,  2678,  2515,  2674,\n",
      "          1996,  8494, 20043,  7984,  1007,  1010,  2021,  2009,  1005,  1055,\n",
      "          7842,  2615, 10736,  2055,  8958,  1998,  2038,  2062, 18453,  1998,\n",
      "          2943,  2084,  2172,  1997,  2054,  2097,  2330,  2023,  2095,  1012,\n",
      "           102],\n",
      "        [  101,  2017,  2428,  2031,  2000,  4687,  2129,  2006,  3011,  3087,\n",
      "          1010,  5973,  2071,  2031,  2245,  2027,  1005,  1040,  2191,  9501,\n",
      "         19739, 20961,  2860,  2007,  1037,  5896,  2004, 12580, 22939, 18647,\n",
      "          2389,  2004,  2023,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2613, 0.7387],\n",
      "        [0.2558, 0.7442]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 17183, 14088, 18628,  2818,  6752,\n",
      "          1006,  2348,  1996, 15488, 14644,  2100,  3617,  2678,  2515,  2674,\n",
      "          1996,  8494, 20043,  7984,  1007,  1010,  2021,  2009,  1005,  1055,\n",
      "          7842,  2615, 10736,  2055,  8958,  1998,  2038,  2062, 18453,  1998,\n",
      "          2943,  2084,  2172,  1997,  2054,  2097,  2330,  2023,  2095,  1012,\n",
      "           102],\n",
      "        [  101,  2017,  2428,  2031,  2000,  4687,  2129,  2006,  3011,  3087,\n",
      "          1010,  5973,  2071,  2031,  2245,  2027,  1005,  1040,  2191,  9501,\n",
      "         19739, 20961,  2860,  2007,  1037,  5896,  2004, 12580, 22939, 18647,\n",
      "          2389,  2004,  2023,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([51, 35]), 'cls_emb': tensor([[ 0.1972, -0.0862,  0.2768,  ..., -0.1245,  0.1996,  0.5026],\n",
      "        [ 0.2307,  0.0935, -0.3428,  ..., -0.4278,  0.4238,  0.5510]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2028,  2013,  1996,  2540,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2081,  2007,  2053,  5860, 11795,  7028,  7477,  1998, 21668,\n",
      "          2135,  2624,  6593, 16339, 27678,  2271,  1999,  7149,  2007,  5593,\n",
      "          3279,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2028,  2013,  1996,  2540,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2081,  2007,  2053,  5860, 11795,  7028,  7477,  1998, 21668,\n",
      "          2135,  2624,  6593, 16339, 27678,  2271,  1999,  7149,  2007,  5593,\n",
      "          3279,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2697, 0.7303],\n",
      "        [0.2770, 0.7230]]), 'input_ids': tensor([[  101,  2028,  2013,  1996,  2540,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2081,  2007,  2053,  5860, 11795,  7028,  7477,  1998, 21668,\n",
      "          2135,  2624,  6593, 16339, 27678,  2271,  1999,  7149,  2007,  5593,\n",
      "          3279,  1012,   102]]), 'ntok': tensor([ 7, 23]), 'cls_emb': tensor([[-0.4009, -0.1572, -0.6033,  ..., -0.0868,  0.3929,  0.5144],\n",
      "        [-0.4631, -0.1671, -0.4475,  ..., -0.0294,  0.1770,  0.5253]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2111,  5988,  2012,  2049, 10418,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1005,  1055, 11341,  2055,  2440, 19124,  2003,  2008,\n",
      "          2750,  2049,  2058,  2102,  2969,  1011,  7073,  1010,  3033,  1997,\n",
      "          1996,  3185,  2145,  6133,  2000,  3338,  2627,  1996,  2396, 23664,\n",
      "          1998, 12246,  8526,  2017,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2111,  5988,  2012,  2049, 10418,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1005,  1055, 11341,  2055,  2440, 19124,  2003,  2008,\n",
      "          2750,  2049,  2058,  2102,  2969,  1011,  7073,  1010,  3033,  1997,\n",
      "          1996,  3185,  2145,  6133,  2000,  3338,  2627,  1996,  2396, 23664,\n",
      "          1998, 12246,  8526,  2017,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2548, 0.7452],\n",
      "        [0.2454, 0.7546]]), 'input_ids': tensor([[  101,  2111,  5988,  2012,  2049, 10418,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  1005,  1055, 11341,  2055,  2440, 19124,  2003,  2008,\n",
      "          2750,  2049,  2058,  2102,  2969,  1011,  7073,  1010,  3033,  1997,\n",
      "          1996,  3185,  2145,  6133,  2000,  3338,  2627,  1996,  2396, 23664,\n",
      "          1998, 12246,  8526,  2017,  1012,   102]]), 'ntok': tensor([ 8, 36]), 'cls_emb': tensor([[-0.2636, -0.3467, -0.0701,  ..., -0.3033,  0.4513,  0.0238],\n",
      "        [ 0.2379, -0.2971, -0.3213,  ..., -0.1010,  0.1473,  0.7332]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1998,  2043,  2017,  1005,  2128,  3331,  2055,  1037, 14308,\n",
      "         21354,  4038,  1010,  2008,  1005,  1055,  1037,  3492,  2502,  3291,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037,  2551,  2465,  1036,  1036,  2149,  5443,  1012,  2068,\n",
      "          1005,  1005,  3850,  2008,  3727,  2053,  8072, 18886,  3070,  4895,\n",
      "          8525, 15567,  1998,  2053,  4314,  3426,  4895, 24759, 20824,  2098,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1998,  2043,  2017,  1005,  2128,  3331,  2055,  1037, 14308,\n",
      "         21354,  4038,  1010,  2008,  1005,  1055,  1037,  3492,  2502,  3291,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037,  2551,  2465,  1036,  1036,  2149,  5443,  1012,  2068,\n",
      "          1005,  1005,  3850,  2008,  3727,  2053,  8072, 18886,  3070,  4895,\n",
      "          8525, 15567,  1998,  2053,  4314,  3426,  4895, 24759, 20824,  2098,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2626, 0.7374],\n",
      "        [0.2791, 0.7209]]), 'input_ids': tensor([[  101,  1998,  2043,  2017,  1005,  2128,  3331,  2055,  1037, 14308,\n",
      "         21354,  4038,  1010,  2008,  1005,  1055,  1037,  3492,  2502,  3291,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037,  2551,  2465,  1036,  1036,  2149,  5443,  1012,  2068,\n",
      "          1005,  1005,  3850,  2008,  3727,  2053,  8072, 18886,  3070,  4895,\n",
      "          8525, 15567,  1998,  2053,  4314,  3426,  4895, 24759, 20824,  2098,\n",
      "          1012,   102]]), 'ntok': tensor([22, 32]), 'cls_emb': tensor([[ 0.1190,  0.0146, -0.4885,  ..., -0.0077,  0.2865,  0.5459],\n",
      "        [-0.1860, -0.0478, -0.1078,  ..., -0.4149,  0.3961,  0.8407]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  5912,  1005,  1055, 23197,  4895,  5054,  7292, 15758,  3921,\n",
      "          1012,  1012,  1012, 19237,  1996,  8438,  2013,  1996,  2143,  1010,\n",
      "          2975,  2369,  2019, 23512,  2021,  6881,  2135, 16655, 18938, 19301,\n",
      "         21177,  1012,   102],\n",
      "        [  101,  2028,  2146,  5164,  1997, 18856, 17322,  2015,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  5912,  1005,  1055, 23197,  4895,  5054,  7292, 15758,  3921,\n",
      "          1012,  1012,  1012, 19237,  1996,  8438,  2013,  1996,  2143,  1010,\n",
      "          2975,  2369,  2019, 23512,  2021,  6881,  2135, 16655, 18938, 19301,\n",
      "         21177,  1012,   102],\n",
      "        [  101,  2028,  2146,  5164,  1997, 18856, 17322,  2015,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2554, 0.7446],\n",
      "        [0.2813, 0.7187]]), 'input_ids': tensor([[  101,  5912,  1005,  1055, 23197,  4895,  5054,  7292, 15758,  3921,\n",
      "          1012,  1012,  1012, 19237,  1996,  8438,  2013,  1996,  2143,  1010,\n",
      "          2975,  2369,  2019, 23512,  2021,  6881,  2135, 16655, 18938, 19301,\n",
      "         21177,  1012,   102],\n",
      "        [  101,  2028,  2146,  5164,  1997, 18856, 17322,  2015,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([33, 10]), 'cls_emb': tensor([[ 0.0977,  0.0818, -0.2724,  ..., -0.3703,  0.7237,  0.4900],\n",
      "        [-0.1109,  0.0154, -0.4626,  ..., -0.3085,  0.5230,  0.4025]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2066,  3666,  1037,  4377, 17887,  1996,  2733,  2077,  1996,\n",
      "          2265,  3632,  2039,  1024,  2673,  1005,  1055,  1999,  2173,  2021,\n",
      "          2242,  1005,  1055,  2074,  1037,  2210,  2125,  1011, 11382, 21928,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2524,  2000,  5674,  5070, 15745,  2378,\n",
      "          2108,  2488,  2084,  2002,  2003,  1999,  2023,  2836,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2066,  3666,  1037,  4377, 17887,  1996,  2733,  2077,  1996,\n",
      "          2265,  3632,  2039,  1024,  2673,  1005,  1055,  1999,  2173,  2021,\n",
      "          2242,  1005,  1055,  2074,  1037,  2210,  2125,  1011, 11382, 21928,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2524,  2000,  5674,  5070, 15745,  2378,\n",
      "          2108,  2488,  2084,  2002,  2003,  1999,  2023,  2836,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2558, 0.7442],\n",
      "        [0.2524, 0.7476]]), 'input_ids': tensor([[  101,  2066,  3666,  1037,  4377, 17887,  1996,  2733,  2077,  1996,\n",
      "          2265,  3632,  2039,  1024,  2673,  1005,  1055,  1999,  2173,  2021,\n",
      "          2242,  1005,  1055,  2074,  1037,  2210,  2125,  1011, 11382, 21928,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2524,  2000,  5674,  5070, 15745,  2378,\n",
      "          2108,  2488,  2084,  2002,  2003,  1999,  2023,  2836,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 20]), 'cls_emb': tensor([[ 0.2601, -0.2844,  0.0527,  ..., -0.2566, -0.0794,  0.6782],\n",
      "        [ 0.1105,  0.1583, -0.4073,  ...,  0.0852,  0.3247,  0.6258]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2143,  2097,  2377,  8053,  2092,  2006,  2119,  1996,\n",
      "          3115,  1998,  5016, 12117,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1012,  1012,  1012,  1037,  4569,  2210,  2051, 17311,  3334,\n",
      "          1010,  3271,  2926,  2011,  1996,  4658,  3739,  1997,  3744, 17738,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2143,  2097,  2377,  8053,  2092,  2006,  2119,  1996,\n",
      "          3115,  1998,  5016, 12117,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1012,  1012,  1012,  1037,  4569,  2210,  2051, 17311,  3334,\n",
      "          1010,  3271,  2926,  2011,  1996,  4658,  3739,  1997,  3744, 17738,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2423, 0.7577],\n",
      "        [0.2491, 0.7509]]), 'input_ids': tensor([[  101,  1996,  2143,  2097,  2377,  8053,  2092,  2006,  2119,  1996,\n",
      "          3115,  1998,  5016, 12117,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1012,  1012,  1012,  1037,  4569,  2210,  2051, 17311,  3334,\n",
      "          1010,  3271,  2926,  2011,  1996,  4658,  3739,  1997,  3744, 17738,\n",
      "          1012,   102]]), 'ntok': tensor([16, 22]), 'cls_emb': tensor([[-0.0249, -0.0766,  0.6686,  ...,  0.0895,  0.5480,  0.0812],\n",
      "        [-0.0626, -0.1477, -0.3528,  ..., -0.5022,  0.4197,  0.4756]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2242,  2066, 18157, 10472,  1996, 11848,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2045,  1005,  1055,  2438, 11463,  7716, 14672,  1999,  2023,\n",
      "         24659, 21111, 26061,  2000,  2191, 13866,  2050,  7098,  2664,  2472,\n",
      "         14163, 14693,  3630,  1005,  1055,  3494,  2024,  2625, 11007,  1997,\n",
      "         16405, 14693,  3490,  2084,  2027,  2024,  1997, 12217,  2547,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2242,  2066, 18157, 10472,  1996, 11848,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2045,  1005,  1055,  2438, 11463,  7716, 14672,  1999,  2023,\n",
      "         24659, 21111, 26061,  2000,  2191, 13866,  2050,  7098,  2664,  2472,\n",
      "         14163, 14693,  3630,  1005,  1055,  3494,  2024,  2625, 11007,  1997,\n",
      "         16405, 14693,  3490,  2084,  2027,  2024,  1997, 12217,  2547,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2782, 0.7218],\n",
      "        [0.2555, 0.7445]]), 'input_ids': tensor([[  101,  2242,  2066, 18157, 10472,  1996, 11848,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2045,  1005,  1055,  2438, 11463,  7716, 14672,  1999,  2023,\n",
      "         24659, 21111, 26061,  2000,  2191, 13866,  2050,  7098,  2664,  2472,\n",
      "         14163, 14693,  3630,  1005,  1055,  3494,  2024,  2625, 11007,  1997,\n",
      "         16405, 14693,  3490,  2084,  2027,  2024,  1997, 12217,  2547,  1012,\n",
      "           102]]), 'ntok': tensor([ 9, 41]), 'cls_emb': tensor([[-0.2153, -0.1879, -0.3532,  ..., -0.2453,  0.1112,  0.4026],\n",
      "        [-0.1261, -0.2428,  0.2233,  ..., -0.4696,  0.6391,  0.5823]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2089,  2022,  2521,  2013,  1996,  2190,  1997,  1996,  2186,\n",
      "          1010,  2021,  2009,  1005,  1055,  8916,  1010,  6919,  2135, 26438,\n",
      "          1997,  2049,  2627,  1998, 26162,  2438,  2000,  2191,  2009, 12990,\n",
      "          2135,  3154,  2008,  2023,  3185,  9575,  2038,  2320,  2153, 27788,\n",
      "         15338,  2098,  2993,  2005,  1037,  2047,  4245,  1012,   102],\n",
      "        [  101,  2065,  2045,  1005,  1055,  2028,  2518,  2023,  2088,  3791,\n",
      "          2625,  1997,  1010,  2009,  1005,  1055,  5691,  2055,  2267,  2008,\n",
      "          2024,  2517,  1998,  2856,  2011,  2111,  2040,  2071,  1050,  1005,\n",
      "          1056,  3413,  2019,  4211, 11360,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2089,  2022,  2521,  2013,  1996,  2190,  1997,  1996,  2186,\n",
      "          1010,  2021,  2009,  1005,  1055,  8916,  1010,  6919,  2135, 26438,\n",
      "          1997,  2049,  2627,  1998, 26162,  2438,  2000,  2191,  2009, 12990,\n",
      "          2135,  3154,  2008,  2023,  3185,  9575,  2038,  2320,  2153, 27788,\n",
      "         15338,  2098,  2993,  2005,  1037,  2047,  4245,  1012,   102],\n",
      "        [  101,  2065,  2045,  1005,  1055,  2028,  2518,  2023,  2088,  3791,\n",
      "          2625,  1997,  1010,  2009,  1005,  1055,  5691,  2055,  2267,  2008,\n",
      "          2024,  2517,  1998,  2856,  2011,  2111,  2040,  2071,  1050,  1005,\n",
      "          1056,  3413,  2019,  4211, 11360,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2412, 0.7588],\n",
      "        [0.2695, 0.7305]]), 'input_ids': tensor([[  101,  2089,  2022,  2521,  2013,  1996,  2190,  1997,  1996,  2186,\n",
      "          1010,  2021,  2009,  1005,  1055,  8916,  1010,  6919,  2135, 26438,\n",
      "          1997,  2049,  2627,  1998, 26162,  2438,  2000,  2191,  2009, 12990,\n",
      "          2135,  3154,  2008,  2023,  3185,  9575,  2038,  2320,  2153, 27788,\n",
      "         15338,  2098,  2993,  2005,  1037,  2047,  4245,  1012,   102],\n",
      "        [  101,  2065,  2045,  1005,  1055,  2028,  2518,  2023,  2088,  3791,\n",
      "          2625,  1997,  1010,  2009,  1005,  1055,  5691,  2055,  2267,  2008,\n",
      "          2024,  2517,  1998,  2856,  2011,  2111,  2040,  2071,  1050,  1005,\n",
      "          1056,  3413,  2019,  4211, 11360,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([49, 37]), 'cls_emb': tensor([[ 0.1836, -0.3369,  0.0285,  ..., -0.2988,  0.4279,  0.1566],\n",
      "        [ 0.3201,  0.2113, -0.3878,  ..., -0.2334,  0.6213,  0.5865]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3213,  1013,  2472,  3533,  2482, 15272,  2319,  1005,  1055,\n",
      "         11844,  2100,  4126,  3689,  2003,  1037,  6410,  1997, 18761, 18856,\n",
      "         17322,  2015,  1010,  2021,  2009,  5829,  3435,  2438,  2000,  3104,\n",
      "          2049, 18856, 16814,  2100,  7982,  1998, 10876,  2229,  1999,  7961,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2765,  2003,  1037, 11721, 20217,  4524,  1997, 26729,\n",
      "          9485,  1010,  2242,  2013,  1037, 14414,  2008,  2351,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3213,  1013,  2472,  3533,  2482, 15272,  2319,  1005,  1055,\n",
      "         11844,  2100,  4126,  3689,  2003,  1037,  6410,  1997, 18761, 18856,\n",
      "         17322,  2015,  1010,  2021,  2009,  5829,  3435,  2438,  2000,  3104,\n",
      "          2049, 18856, 16814,  2100,  7982,  1998, 10876,  2229,  1999,  7961,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2765,  2003,  1037, 11721, 20217,  4524,  1997, 26729,\n",
      "          9485,  1010,  2242,  2013,  1037, 14414,  2008,  2351,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2931, 0.7069],\n",
      "        [0.2398, 0.7602]]), 'input_ids': tensor([[  101,  3213,  1013,  2472,  3533,  2482, 15272,  2319,  1005,  1055,\n",
      "         11844,  2100,  4126,  3689,  2003,  1037,  6410,  1997, 18761, 18856,\n",
      "         17322,  2015,  1010,  2021,  2009,  5829,  3435,  2438,  2000,  3104,\n",
      "          2049, 18856, 16814,  2100,  7982,  1998, 10876,  2229,  1999,  7961,\n",
      "          1012,   102],\n",
      "        [  101,  1996,  2765,  2003,  1037, 11721, 20217,  4524,  1997, 26729,\n",
      "          9485,  1010,  2242,  2013,  1037, 14414,  2008,  2351,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([42, 20]), 'cls_emb': tensor([[-0.1251, -0.2980, -0.1617,  ..., -0.3438,  0.6115,  0.4481],\n",
      "        [ 0.0467,  0.3855, -0.0374,  ...,  0.0213,  0.7084,  0.6029]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  8403,  2143,  2007,  8403,  4616,\n",
      "          2011,  4965,  1998, 16222,  5668,  2072,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  1005,  1055,  2242, 17151, 24330,  6313,  1010,  1998,\n",
      "         15236,  1010,  2205,  1010,  2055,  1996,  6018, 12753,  2008, 13956,\n",
      "          1037,  3484,  1011,  8048,  2472,  2066,  7112, 28740,  2000,  3582,\n",
      "          1037,  1012,  1045,  1012,  2007,  2023, 10368,  3189,  2061, 20090,\n",
      "          2000,  4895,  3678,  3726,  1996,  3484,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  8403,  2143,  2007,  8403,  4616,\n",
      "          2011,  4965,  1998, 16222,  5668,  2072,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  1005,  1055,  2242, 17151, 24330,  6313,  1010,  1998,\n",
      "         15236,  1010,  2205,  1010,  2055,  1996,  6018, 12753,  2008, 13956,\n",
      "          1037,  3484,  1011,  8048,  2472,  2066,  7112, 28740,  2000,  3582,\n",
      "          1037,  1012,  1045,  1012,  2007,  2023, 10368,  3189,  2061, 20090,\n",
      "          2000,  4895,  3678,  3726,  1996,  3484,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2510, 0.7490],\n",
      "        [0.2397, 0.7603]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037,  8403,  2143,  2007,  8403,  4616,\n",
      "          2011,  4965,  1998, 16222,  5668,  2072,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2045,  1005,  1055,  2242, 17151, 24330,  6313,  1010,  1998,\n",
      "         15236,  1010,  2205,  1010,  2055,  1996,  6018, 12753,  2008, 13956,\n",
      "          1037,  3484,  1011,  8048,  2472,  2066,  7112, 28740,  2000,  3582,\n",
      "          1037,  1012,  1045,  1012,  2007,  2023, 10368,  3189,  2061, 20090,\n",
      "          2000,  4895,  3678,  3726,  1996,  3484,  1012,   102]]), 'ntok': tensor([18, 48]), 'cls_emb': tensor([[ 0.2357, -0.1978,  0.0909,  ..., -0.5135,  0.3997,  0.4316],\n",
      "        [ 0.0147, -0.0313, -0.6527,  ..., -0.2990,  0.4554,  0.6182]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  3185,  4599,  1010,  2131,  3201,  2000,  2202,  2125,  1012,\n",
      "          1012,  1012,  1996,  2060,  3257,  1012,   102,     0],\n",
      "        [  101,  2025,  2019, 22224,  3085,  2030, 10634,  2143,  1025,  2009,\n",
      "          6414, 14087,  2673,  3272,  2204, 11174,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  3185,  4599,  1010,  2131,  3201,  2000,  2202,  2125,  1012,\n",
      "          1012,  1012,  1996,  2060,  3257,  1012,   102,     0],\n",
      "        [  101,  2025,  2019, 22224,  3085,  2030, 10634,  2143,  1025,  2009,\n",
      "          6414, 14087,  2673,  3272,  2204, 11174,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2554, 0.7446],\n",
      "        [0.2546, 0.7454]]), 'input_ids': tensor([[  101,  3185,  4599,  1010,  2131,  3201,  2000,  2202,  2125,  1012,\n",
      "          1012,  1012,  1996,  2060,  3257,  1012,   102,     0],\n",
      "        [  101,  2025,  2019, 22224,  3085,  2030, 10634,  2143,  1025,  2009,\n",
      "          6414, 14087,  2673,  3272,  2204, 11174,  1012,   102]]), 'ntok': tensor([17, 18]), 'cls_emb': tensor([[ 0.0483,  0.0566,  0.4326,  ..., -0.3743,  0.2658,  0.4210],\n",
      "        [-0.1141, -0.0691, -0.1940,  ..., -0.1854,  0.3561,  0.4496]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2096,  2049,  6176,  6393,  1998,  9428, 28670,  2466,  2089,\n",
      "          2025, 13225,  2296,  3185,  3995,  2121,  1005,  1055, 18923,  1010,\n",
      "          1996,  2143,  1005,  1055,  2345,  3496,  2003, 23990,  2135,  1010,\n",
      "         13338,  2135,  3048,  1012,   102],\n",
      "        [  101,  1037,  2143,  2055,  1037,  2402,  2158,  4531,  2643,  2008,\n",
      "          2003,  7801,  1998,  7244,  2000,  1996, 24960,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2096,  2049,  6176,  6393,  1998,  9428, 28670,  2466,  2089,\n",
      "          2025, 13225,  2296,  3185,  3995,  2121,  1005,  1055, 18923,  1010,\n",
      "          1996,  2143,  1005,  1055,  2345,  3496,  2003, 23990,  2135,  1010,\n",
      "         13338,  2135,  3048,  1012,   102],\n",
      "        [  101,  1037,  2143,  2055,  1037,  2402,  2158,  4531,  2643,  2008,\n",
      "          2003,  7801,  1998,  7244,  2000,  1996, 24960,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2407, 0.7593],\n",
      "        [0.2813, 0.7187]]), 'input_ids': tensor([[  101,  2096,  2049,  6176,  6393,  1998,  9428, 28670,  2466,  2089,\n",
      "          2025, 13225,  2296,  3185,  3995,  2121,  1005,  1055, 18923,  1010,\n",
      "          1996,  2143,  1005,  1055,  2345,  3496,  2003, 23990,  2135,  1010,\n",
      "         13338,  2135,  3048,  1012,   102],\n",
      "        [  101,  1037,  2143,  2055,  1037,  2402,  2158,  4531,  2643,  2008,\n",
      "          2003,  7801,  1998,  7244,  2000,  1996, 24960,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 19]), 'cls_emb': tensor([[ 0.0539, -0.0816, -0.2672,  ..., -0.3949,  0.2847,  0.5058],\n",
      "        [-0.3108, -0.3934, -0.2515,  ..., -0.0337,  0.5508,  0.0786]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 17075,  3009,  2143,  2055,  1996,  2007,  7999,  3896,\n",
      "          1997, 14225,  1999,  1996,  2166,  1997,  1037,  2402, 11590,  3005,\n",
      "          4424,  6896,  2005,  2014,  3129,  4150,  2019, 17418,  1012,   102],\n",
      "        [  101,  2019, 16514,  3451, 28458,  2007,  1037, 11937, 21756,  5703,\n",
      "          1997,  2155,  3689,  1998, 10424,  8625,  4588,  4038,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 17075,  3009,  2143,  2055,  1996,  2007,  7999,  3896,\n",
      "          1997, 14225,  1999,  1996,  2166,  1997,  1037,  2402, 11590,  3005,\n",
      "          4424,  6896,  2005,  2014,  3129,  4150,  2019, 17418,  1012,   102],\n",
      "        [  101,  2019, 16514,  3451, 28458,  2007,  1037, 11937, 21756,  5703,\n",
      "          1997,  2155,  3689,  1998, 10424,  8625,  4588,  4038,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2752, 0.7248],\n",
      "        [0.2858, 0.7142]]), 'input_ids': tensor([[  101,  1037, 17075,  3009,  2143,  2055,  1996,  2007,  7999,  3896,\n",
      "          1997, 14225,  1999,  1996,  2166,  1997,  1037,  2402, 11590,  3005,\n",
      "          4424,  6896,  2005,  2014,  3129,  4150,  2019, 17418,  1012,   102],\n",
      "        [  101,  2019, 16514,  3451, 28458,  2007,  1037, 11937, 21756,  5703,\n",
      "          1997,  2155,  3689,  1998, 10424,  8625,  4588,  4038,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([30, 20]), 'cls_emb': tensor([[-0.2805, -0.0447, -0.1236,  ..., -0.5320,  0.5958,  0.2953],\n",
      "        [-0.4451, -0.2695, -0.0971,  ..., -0.5402,  0.5933,  0.3324]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1045,  2079,  1050,  1005,  1056,  2228,  1045,  4191,  2041,\n",
      "          5189,  2320,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2200,  2569,  3896,  1010,  8235,  2135,  7782,  6087,  1998,\n",
      "         21106,  4507,  6187,  1050,  1005,  1056,  5342,  1996,  5016, 23167,\n",
      "          1005, 12073,  1999,  1036,  1036,  6990,  2210,  1016,  1036,  1036,\n",
      "          1024,  2045,  1005,  1055,  2074,  2053,  2466,  1010, 12455,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1045,  2079,  1050,  1005,  1056,  2228,  1045,  4191,  2041,\n",
      "          5189,  2320,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2200,  2569,  3896,  1010,  8235,  2135,  7782,  6087,  1998,\n",
      "         21106,  4507,  6187,  1050,  1005,  1056,  5342,  1996,  5016, 23167,\n",
      "          1005, 12073,  1999,  1036,  1036,  6990,  2210,  1016,  1036,  1036,\n",
      "          1024,  2045,  1005,  1055,  2074,  2053,  2466,  1010, 12455,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2850, 0.7150],\n",
      "        [0.2715, 0.7285]]), 'input_ids': tensor([[  101,  1045,  2079,  1050,  1005,  1056,  2228,  1045,  4191,  2041,\n",
      "          5189,  2320,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2200,  2569,  3896,  1010,  8235,  2135,  7782,  6087,  1998,\n",
      "         21106,  4507,  6187,  1050,  1005,  1056,  5342,  1996,  5016, 23167,\n",
      "          1005, 12073,  1999,  1036,  1036,  6990,  2210,  1016,  1036,  1036,\n",
      "          1024,  2045,  1005,  1055,  2074,  2053,  2466,  1010, 12455,  1012,\n",
      "           102]]), 'ntok': tensor([14, 41]), 'cls_emb': tensor([[ 0.1478,  0.0931, -0.1881,  ...,  0.2146,  0.5821,  0.4894],\n",
      "        [ 0.1046, -0.0459,  0.2262,  ..., -0.2110,  0.5154,  0.6984]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2025,  1996,  2785,  1997,  2143,  2008,  2097,  5574,  2000,\n",
      "          1037,  7731,  2137,  4378,  1010,  2021,  2045,  2003,  1037,  3056,\n",
      "         11084,  2055,  1996,  2143,  2008,  3084,  2009,  1037,  7218,  4443,\n",
      "          2046,  1996, 17037,  4984,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  3376, 12013,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2025,  1996,  2785,  1997,  2143,  2008,  2097,  5574,  2000,\n",
      "          1037,  7731,  2137,  4378,  1010,  2021,  2045,  2003,  1037,  3056,\n",
      "         11084,  2055,  1996,  2143,  2008,  3084,  2009,  1037,  7218,  4443,\n",
      "          2046,  1996, 17037,  4984,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  3376, 12013,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2429, 0.7571],\n",
      "        [0.2574, 0.7426]]), 'input_ids': tensor([[  101,  2025,  1996,  2785,  1997,  2143,  2008,  2097,  5574,  2000,\n",
      "          1037,  7731,  2137,  4378,  1010,  2021,  2045,  2003,  1037,  3056,\n",
      "         11084,  2055,  1996,  2143,  2008,  3084,  2009,  1037,  7218,  4443,\n",
      "          2046,  1996, 17037,  4984,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  1037,  3376, 12013,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([36,  9]), 'cls_emb': tensor([[ 0.0351, -0.4935, -0.1341,  ..., -0.1979,  0.4008,  0.3002],\n",
      "        [ 0.1384,  0.2320,  0.1837,  ..., -0.3545,  0.1118,  0.5198]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2043,  1996,  2143,  3092,  1010,  1045,  2371,  5458,  1998,\n",
      "         11055,  1998,  2359,  2000,  4682,  2006,  2026,  2219,  2331,  8270,\n",
      "          2005,  1037,  2096,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2428,  2919,  2061,  2172,  2004,  4487,  9153, 13473,\n",
      "          3993,  1024,  2057,  2342, 15071, 23873, 16547,  2157,  2085,  2066,\n",
      "          2057,  2342, 12677, 16150,  4710, 10874,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2043,  1996,  2143,  3092,  1010,  1045,  2371,  5458,  1998,\n",
      "         11055,  1998,  2359,  2000,  4682,  2006,  2026,  2219,  2331,  8270,\n",
      "          2005,  1037,  2096,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2428,  2919,  2061,  2172,  2004,  4487,  9153, 13473,\n",
      "          3993,  1024,  2057,  2342, 15071, 23873, 16547,  2157,  2085,  2066,\n",
      "          2057,  2342, 12677, 16150,  4710, 10874,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2285, 0.7715],\n",
      "        [0.2648, 0.7352]]), 'input_ids': tensor([[  101,  2043,  1996,  2143,  3092,  1010,  1045,  2371,  5458,  1998,\n",
      "         11055,  1998,  2359,  2000,  4682,  2006,  2026,  2219,  2331,  8270,\n",
      "          2005,  1037,  2096,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  2025,  2428,  2919,  2061,  2172,  2004,  4487,  9153, 13473,\n",
      "          3993,  1024,  2057,  2342, 15071, 23873, 16547,  2157,  2085,  2066,\n",
      "          2057,  2342, 12677, 16150,  4710, 10874,  2015,  1012,   102]]), 'ntok': tensor([25, 29]), 'cls_emb': tensor([[ 0.5319, -0.1695, -0.1149,  ..., -0.0993,  0.2368,  0.3002],\n",
      "        [ 0.3662, -0.4486,  0.2039,  ..., -0.5271,  0.8970,  0.2987]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2004,  1036, 14556, 17312,  2015,  1005,  2175,  1010,  2023,\n",
      "          2028,  2003,  3492, 13736,  1010,  7001,  2075,  2000,  5164,  1011,\n",
      "          4815,  2738,  2084, 11476,  2839,  2458,  1998,  9414, 20699,  1012,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2011, 27467, 18718, 17555,  1996,  4331,  2920,  1999,  1996,\n",
      "          4325,  1997,  2019,  9313,  3538,  1997,  2189,  1010,  1006,  3557,\n",
      "          1007,  4455,  2256,  3086,  2000,  1996, 16112,  4736,  2090,  6236,\n",
      "          1998, 14842,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2004,  1036, 14556, 17312,  2015,  1005,  2175,  1010,  2023,\n",
      "          2028,  2003,  3492, 13736,  1010,  7001,  2075,  2000,  5164,  1011,\n",
      "          4815,  2738,  2084, 11476,  2839,  2458,  1998,  9414, 20699,  1012,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2011, 27467, 18718, 17555,  1996,  4331,  2920,  1999,  1996,\n",
      "          4325,  1997,  2019,  9313,  3538,  1997,  2189,  1010,  1006,  3557,\n",
      "          1007,  4455,  2256,  3086,  2000,  1996, 16112,  4736,  2090,  6236,\n",
      "          1998, 14842,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2556, 0.7444],\n",
      "        [0.2393, 0.7607]]), 'input_ids': tensor([[  101,  2004,  1036, 14556, 17312,  2015,  1005,  2175,  1010,  2023,\n",
      "          2028,  2003,  3492, 13736,  1010,  7001,  2075,  2000,  5164,  1011,\n",
      "          4815,  2738,  2084, 11476,  2839,  2458,  1998,  9414, 20699,  1012,\n",
      "           102,     0,     0,     0],\n",
      "        [  101,  2011, 27467, 18718, 17555,  1996,  4331,  2920,  1999,  1996,\n",
      "          4325,  1997,  2019,  9313,  3538,  1997,  2189,  1010,  1006,  3557,\n",
      "          1007,  4455,  2256,  3086,  2000,  1996, 16112,  4736,  2090,  6236,\n",
      "          1998, 14842,  1012,   102]]), 'ntok': tensor([31, 34]), 'cls_emb': tensor([[ 0.3351, -0.2016, -0.1941,  ..., -0.2844,  0.6504,  0.6429],\n",
      "        [-0.4672,  0.3183, -0.9500,  ..., -0.1006,  0.3590,  0.5298]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2028,  1997,  1996,  2087,  3278,  3185, 26966, 26552,  1997,\n",
      "          1996,  2095,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 10975,  9496,  4765,  2377, 20744,  2015,  4998,  1010,  2045,\n",
      "          1005,  1055,  2210,  2000,  2293,  2055,  2023,  2394, 13012, 21031,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2028,  1997,  1996,  2087,  3278,  3185, 26966, 26552,  1997,\n",
      "          1996,  2095,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 10975,  9496,  4765,  2377, 20744,  2015,  4998,  1010,  2045,\n",
      "          1005,  1055,  2210,  2000,  2293,  2055,  2023,  2394, 13012, 21031,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2839, 0.7161],\n",
      "        [0.2552, 0.7448]]), 'input_ids': tensor([[  101,  2028,  1997,  1996,  2087,  3278,  3185, 26966, 26552,  1997,\n",
      "          1996,  2095,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 10975,  9496,  4765,  2377, 20744,  2015,  4998,  1010,  2045,\n",
      "          1005,  1055,  2210,  2000,  2293,  2055,  2023,  2394, 13012, 21031,\n",
      "          1012,   102]]), 'ntok': tensor([14, 22]), 'cls_emb': tensor([[-0.4540, -0.1665, -0.0648,  ..., -0.5524,  0.4488,  0.0081],\n",
      "        [ 0.0855,  0.1399, -0.0435,  ..., -0.2344,  0.2820,  0.5501]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037, 22561, 17824,  1998,  2358, 10893,  2094,  1998, 17300,\n",
      "          2510, 20747,  3689,  1012,   102],\n",
      "        [  101,  2012,  2320,  2431,  1011, 17776,  1998,  2058, 20192,  3064,\n",
      "          1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037, 22561, 17824,  1998,  2358, 10893,  2094,  1998, 17300,\n",
      "          2510, 20747,  3689,  1012,   102],\n",
      "        [  101,  2012,  2320,  2431,  1011, 17776,  1998,  2058, 20192,  3064,\n",
      "          1012,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2761, 0.7239],\n",
      "        [0.2656, 0.7344]]), 'input_ids': tensor([[  101,  1037, 22561, 17824,  1998,  2358, 10893,  2094,  1998, 17300,\n",
      "          2510, 20747,  3689,  1012,   102],\n",
      "        [  101,  2012,  2320,  2431,  1011, 17776,  1998,  2058, 20192,  3064,\n",
      "          1012,   102,     0,     0,     0]]), 'ntok': tensor([15, 12]), 'cls_emb': tensor([[-0.8294, -0.2923, -0.4404,  ..., -0.6265,  0.4300,  0.6711],\n",
      "        [-0.4159,  0.2060, -0.5009,  ..., -0.2826,  0.7016,  0.5076]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  3252,  1996,  2143,  3138,  2089,  2424,  4717, 11317,\n",
      "          1998,  3841, 21358, 21031,  3600,  2320,  2153,  2559,  2005, 21961,\n",
      "          2015,  2004,  2023,  3985, 28123,  1037,  2204,  2097,  5933, 11544,\n",
      "          2008,  2001,  2196,  3740,  1012,   102],\n",
      "        [  101,  1996,  3185,  2515,  1037,  2204,  3105,  1997, 10201,  2041,\n",
      "          2070,  1997,  1996,  2350,  3314,  2008,  2057,  8087,  2004,  2057,\n",
      "          4990,  2083,  2166,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  3252,  1996,  2143,  3138,  2089,  2424,  4717, 11317,\n",
      "          1998,  3841, 21358, 21031,  3600,  2320,  2153,  2559,  2005, 21961,\n",
      "          2015,  2004,  2023,  3985, 28123,  1037,  2204,  2097,  5933, 11544,\n",
      "          2008,  2001,  2196,  3740,  1012,   102],\n",
      "        [  101,  1996,  3185,  2515,  1037,  2204,  3105,  1997, 10201,  2041,\n",
      "          2070,  1997,  1996,  2350,  3314,  2008,  2057,  8087,  2004,  2057,\n",
      "          4990,  2083,  2166,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2612, 0.7388],\n",
      "        [0.2476, 0.7524]]), 'input_ids': tensor([[  101,  1996,  3252,  1996,  2143,  3138,  2089,  2424,  4717, 11317,\n",
      "          1998,  3841, 21358, 21031,  3600,  2320,  2153,  2559,  2005, 21961,\n",
      "          2015,  2004,  2023,  3985, 28123,  1037,  2204,  2097,  5933, 11544,\n",
      "          2008,  2001,  2196,  3740,  1012,   102],\n",
      "        [  101,  1996,  3185,  2515,  1037,  2204,  3105,  1997, 10201,  2041,\n",
      "          2070,  1997,  1996,  2350,  3314,  2008,  2057,  8087,  2004,  2057,\n",
      "          4990,  2083,  2166,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([36, 25]), 'cls_emb': tensor([[ 0.0361, -0.2000,  0.2247,  ..., -0.2523,  0.5356,  0.0045],\n",
      "        [-0.1541, -0.0112, -0.1759,  ..., -0.4283,  0.4289,  0.3282]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2200, 18224, 27953, 21252,  2389,  1011,  1011, 26422,  2135,\n",
      "          2061,  1011,  1011,  1998,  2036, 27150,  2135,  4706,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4998,  2013,  3576,  9543,  5484,  2075,  1010,  2023,  2003,\n",
      "          1996,  2168,  3185,  2017,  2763,  3866,  1999,  2807,  1010,  3272,\n",
      "          2008,  2009,  3504,  2130,  2488,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2200, 18224, 27953, 21252,  2389,  1011,  1011, 26422,  2135,\n",
      "          2061,  1011,  1011,  1998,  2036, 27150,  2135,  4706,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4998,  2013,  3576,  9543,  5484,  2075,  1010,  2023,  2003,\n",
      "          1996,  2168,  3185,  2017,  2763,  3866,  1999,  2807,  1010,  3272,\n",
      "          2008,  2009,  3504,  2130,  2488,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2465, 0.7535],\n",
      "        [0.2504, 0.7496]]), 'input_ids': tensor([[  101,  2200, 18224, 27953, 21252,  2389,  1011,  1011, 26422,  2135,\n",
      "          2061,  1011,  1011,  1998,  2036, 27150,  2135,  4706,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4998,  2013,  3576,  9543,  5484,  2075,  1010,  2023,  2003,\n",
      "          1996,  2168,  3185,  2017,  2763,  3866,  1999,  2807,  1010,  3272,\n",
      "          2008,  2009,  3504,  2130,  2488,  1012,   102]]), 'ntok': tensor([20, 27]), 'cls_emb': tensor([[-0.4139,  0.2169, -0.5407,  ..., -0.3691,  0.2791,  0.7325],\n",
      "        [ 0.1691, -0.0984,  0.1028,  ..., -0.2819,  0.2664,  0.3488]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2143,  3084,  1037, 10611,  6707,  1024,  2009,  5176,\n",
      "          2149,  2000,  2729,  2055,  1037,  2402,  2158,  3005,  2069,  6835,\n",
      "         11870,  2003,  2008,  2002,  2003,  2025,  3243,  2004, 16010,  2004,\n",
      "          2070,  1997,  1996,  2111,  1999,  2010,  2166,  1012,   102],\n",
      "        [  101,  1037,  3643,  3238, 25358,  2666,  6643, 11219,  2000,  4013,\n",
      "          3455,  2104, 15773,  2011,  1996,  6452,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2143,  3084,  1037, 10611,  6707,  1024,  2009,  5176,\n",
      "          2149,  2000,  2729,  2055,  1037,  2402,  2158,  3005,  2069,  6835,\n",
      "         11870,  2003,  2008,  2002,  2003,  2025,  3243,  2004, 16010,  2004,\n",
      "          2070,  1997,  1996,  2111,  1999,  2010,  2166,  1012,   102],\n",
      "        [  101,  1037,  3643,  3238, 25358,  2666,  6643, 11219,  2000,  4013,\n",
      "          3455,  2104, 15773,  2011,  1996,  6452,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2341, 0.7659],\n",
      "        [0.2850, 0.7150]]), 'input_ids': tensor([[  101,  1996,  2143,  3084,  1037, 10611,  6707,  1024,  2009,  5176,\n",
      "          2149,  2000,  2729,  2055,  1037,  2402,  2158,  3005,  2069,  6835,\n",
      "         11870,  2003,  2008,  2002,  2003,  2025,  3243,  2004, 16010,  2004,\n",
      "          2070,  1997,  1996,  2111,  1999,  2010,  2166,  1012,   102],\n",
      "        [  101,  1037,  3643,  3238, 25358,  2666,  6643, 11219,  2000,  4013,\n",
      "          3455,  2104, 15773,  2011,  1996,  6452,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([39, 18]), 'cls_emb': tensor([[-0.2358,  0.2329, -0.5108,  ..., -0.1758,  0.3962,  0.7044],\n",
      "        [-0.7710, -0.1331, -0.4048,  ..., -0.2069,  0.6439,  0.5130]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2241,  2006,  1037,  6548, 19983, 25591,  5896,  2011,  9533,\n",
      "         11338,  3995,  7447,  1998,  9152,  9050, 26774,  1010,  1996,  2143,\n",
      "          4152,  2307, 11680,  1010,  2021,  2196,  2012,  1996, 10961,  1997,\n",
      "          2049,  3494,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2004,  2065,  2017,  1005,  2128,  3666,\n",
      "          1037,  3185,  2008,  2001,  2081,  1999,  3301,  2021,  2025,  2207,\n",
      "          2059,  2138,  2009,  2001,  2061,  5410,  1010,  1998,  2009,  2038,\n",
      "          2042, 27422,  1998,  2207,  2085,  1010,  2043,  2009,  2038,  2468,\n",
      "          2130, 15863,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2241,  2006,  1037,  6548, 19983, 25591,  5896,  2011,  9533,\n",
      "         11338,  3995,  7447,  1998,  9152,  9050, 26774,  1010,  1996,  2143,\n",
      "          4152,  2307, 11680,  1010,  2021,  2196,  2012,  1996, 10961,  1997,\n",
      "          2049,  3494,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2004,  2065,  2017,  1005,  2128,  3666,\n",
      "          1037,  3185,  2008,  2001,  2081,  1999,  3301,  2021,  2025,  2207,\n",
      "          2059,  2138,  2009,  2001,  2061,  5410,  1010,  1998,  2009,  2038,\n",
      "          2042, 27422,  1998,  2207,  2085,  1010,  2043,  2009,  2038,  2468,\n",
      "          2130, 15863,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2650, 0.7350],\n",
      "        [0.2455, 0.7545]]), 'input_ids': tensor([[  101,  2241,  2006,  1037,  6548, 19983, 25591,  5896,  2011,  9533,\n",
      "         11338,  3995,  7447,  1998,  9152,  9050, 26774,  1010,  1996,  2143,\n",
      "          4152,  2307, 11680,  1010,  2021,  2196,  2012,  1996, 10961,  1997,\n",
      "          2049,  3494,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2004,  2065,  2017,  1005,  2128,  3666,\n",
      "          1037,  3185,  2008,  2001,  2081,  1999,  3301,  2021,  2025,  2207,\n",
      "          2059,  2138,  2009,  2001,  2061,  5410,  1010,  1998,  2009,  2038,\n",
      "          2042, 27422,  1998,  2207,  2085,  1010,  2043,  2009,  2038,  2468,\n",
      "          2130, 15863,  1012,   102]]), 'ntok': tensor([33, 44]), 'cls_emb': tensor([[-0.1151, -0.0117,  0.2744,  ..., -0.3506,  0.3628,  0.2351],\n",
      "        [ 0.1266,  0.2152, -0.5193,  ..., -0.0538,  0.5418,  0.6589]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2008,  1005,  1055,  1037, 21910,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  5399, 22902,  1998,  2205,  2292,  8167,\n",
      "         26715,  2135, 13823,  1011,  1011,  2021,  2049,  2466,  2055,  1037,\n",
      "          8075,  6492,  2007, 12663,  7590,  4107,  1037,  5024,  3857,  1011,\n",
      "          2039,  1010,  1037, 27547, 14463,  1010,  1998,  2070,  3835, 10720,\n",
      "          2015,  2247,  1996,  2126,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2008,  1005,  1055,  1037, 21910,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  5399, 22902,  1998,  2205,  2292,  8167,\n",
      "         26715,  2135, 13823,  1011,  1011,  2021,  2049,  2466,  2055,  1037,\n",
      "          8075,  6492,  2007, 12663,  7590,  4107,  1037,  5024,  3857,  1011,\n",
      "          2039,  1010,  1037, 27547, 14463,  1010,  1998,  2070,  3835, 10720,\n",
      "          2015,  2247,  1996,  2126,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2861, 0.7139],\n",
      "        [0.2525, 0.7475]]), 'input_ids': tensor([[  101,  2008,  1005,  1055,  1037, 21910,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  1005,  1055,  5399, 22902,  1998,  2205,  2292,  8167,\n",
      "         26715,  2135, 13823,  1011,  1011,  2021,  2049,  2466,  2055,  1037,\n",
      "          8075,  6492,  2007, 12663,  7590,  4107,  1037,  5024,  3857,  1011,\n",
      "          2039,  1010,  1037, 27547, 14463,  1010,  1998,  2070,  3835, 10720,\n",
      "          2015,  2247,  1996,  2126,  1012,   102]]), 'ntok': tensor([ 8, 46]), 'cls_emb': tensor([[ 0.2647,  0.2506, -0.1936,  ..., -0.1726,  0.3199,  0.7749],\n",
      "        [ 0.0981, -0.3026, -0.0727,  ...,  0.1621,  0.3336,  0.3255]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  4569,  5507,  2063,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  2019,  4728,  6387,  1010,  9792,  1011,\n",
      "          1998,  1011,  2735, 10874,  2008,  5121,  2323,  1050,  1005,  1056,\n",
      "          3480, 10904,  2402, 18201,  4819,  1005,  1055, 13746,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  4569,  5507,  2063,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  2019,  4728,  6387,  1010,  9792,  1011,\n",
      "          1998,  1011,  2735, 10874,  2008,  5121,  2323,  1050,  1005,  1056,\n",
      "          3480, 10904,  2402, 18201,  4819,  1005,  1055, 13746,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2607, 0.7393],\n",
      "        [0.2644, 0.7356]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  4569,  5507,  2063,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012,  2019,  4728,  6387,  1010,  9792,  1011,\n",
      "          1998,  1011,  2735, 10874,  2008,  5121,  2323,  1050,  1005,  1056,\n",
      "          3480, 10904,  2402, 18201,  4819,  1005,  1055, 13746,  1012,   102]]), 'ntok': tensor([ 9, 30]), 'cls_emb': tensor([[-0.0215,  0.0897,  0.3248,  ..., -0.2699,  0.3267,  0.2570],\n",
      "        [-0.1584, -0.1069, -0.2650,  ..., -0.4497,  0.6302,  0.3502]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009, 23283, 16133,  2121,  1005,  1055,  3570,  2004,  1037,\n",
      "          2143,  9338,  2040,  2396,  7699, 23394,  4087,  2113,  1011,  2129,\n",
      "          2000,  1996,  2326,  1997,  8317, 12369,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2143,  3397,  2053,  2204, 13198,  1010,  2053,  2204,\n",
      "          5019,  1010,  4510,  1037,  2617,  2043,  2482, 12417,  1005,  1055,\n",
      "          5095,  2305,  2444,  1011, 10189,  2098, 23150,  2854,  9466,  2682,\n",
      "          1996,  2504,  1997, 14325,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009, 23283, 16133,  2121,  1005,  1055,  3570,  2004,  1037,\n",
      "          2143,  9338,  2040,  2396,  7699, 23394,  4087,  2113,  1011,  2129,\n",
      "          2000,  1996,  2326,  1997,  8317, 12369,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2143,  3397,  2053,  2204, 13198,  1010,  2053,  2204,\n",
      "          5019,  1010,  4510,  1037,  2617,  2043,  2482, 12417,  1005,  1055,\n",
      "          5095,  2305,  2444,  1011, 10189,  2098, 23150,  2854,  9466,  2682,\n",
      "          1996,  2504,  1997, 14325,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2587, 0.7413],\n",
      "        [0.2759, 0.7241]]), 'input_ids': tensor([[  101,  2009, 23283, 16133,  2121,  1005,  1055,  3570,  2004,  1037,\n",
      "          2143,  9338,  2040,  2396,  7699, 23394,  4087,  2113,  1011,  2129,\n",
      "          2000,  1996,  2326,  1997,  8317, 12369,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2143,  3397,  2053,  2204, 13198,  1010,  2053,  2204,\n",
      "          5019,  1010,  4510,  1037,  2617,  2043,  2482, 12417,  1005,  1055,\n",
      "          5095,  2305,  2444,  1011, 10189,  2098, 23150,  2854,  9466,  2682,\n",
      "          1996,  2504,  1997, 14325,  1012,   102]]), 'ntok': tensor([28, 36]), 'cls_emb': tensor([[-0.0800,  0.1900, -0.3552,  ..., -0.3118,  0.5378,  0.6294],\n",
      "        [-0.0492, -0.0437, -0.2110,  ..., -0.3276,  0.6033,  0.8217]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  4906,  7699, 19142, 17083,  2361,  2008,  1010,  2065,\n",
      "          2498,  2842,  1010,  2097,  5574,  2000,  4599,  1997,  8861,  1999,\n",
      "          1996,  2690,  1998,  2049,  9047,  2229, 13013,  2732,  1010, 12784,\n",
      "         14163,  3490,  2480,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2025,  2434,  1010,  1998,  1010, 20114,\n",
      "          1997,  1996,  5783,  1997,  4474,  1010,  2009,  2515,  1050,  1005,\n",
      "          1056,  2031,  2151,  4121, 11680,  1999,  2049,  2466,  1997, 20868,\n",
      "          6072, 26029, 19307, 10558,  2040,  2293,  2000,  2377, 26418,  2015,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  4906,  7699, 19142, 17083,  2361,  2008,  1010,  2065,\n",
      "          2498,  2842,  1010,  2097,  5574,  2000,  4599,  1997,  8861,  1999,\n",
      "          1996,  2690,  1998,  2049,  9047,  2229, 13013,  2732,  1010, 12784,\n",
      "         14163,  3490,  2480,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2025,  2434,  1010,  1998,  1010, 20114,\n",
      "          1997,  1996,  5783,  1997,  4474,  1010,  2009,  2515,  1050,  1005,\n",
      "          1056,  2031,  2151,  4121, 11680,  1999,  2049,  2466,  1997, 20868,\n",
      "          6072, 26029, 19307, 10558,  2040,  2293,  2000,  2377, 26418,  2015,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2573, 0.7427],\n",
      "        [0.2642, 0.7358]]), 'input_ids': tensor([[  101,  1037,  4906,  7699, 19142, 17083,  2361,  2008,  1010,  2065,\n",
      "          2498,  2842,  1010,  2097,  5574,  2000,  4599,  1997,  8861,  1999,\n",
      "          1996,  2690,  1998,  2049,  9047,  2229, 13013,  2732,  1010, 12784,\n",
      "         14163,  3490,  2480,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2009,  1005,  1055,  2025,  2434,  1010,  1998,  1010, 20114,\n",
      "          1997,  1996,  5783,  1997,  4474,  1010,  2009,  2515,  1050,  1005,\n",
      "          1056,  2031,  2151,  4121, 11680,  1999,  2049,  2466,  1997, 20868,\n",
      "          6072, 26029, 19307, 10558,  2040,  2293,  2000,  2377, 26418,  2015,\n",
      "          1012,   102]]), 'ntok': tensor([35, 42]), 'cls_emb': tensor([[-0.0624, -0.2816,  0.4127,  ..., -0.4093,  0.4267,  0.2558],\n",
      "        [ 0.1318, -0.0902, -0.1882,  ..., -0.0447,  0.5393,  0.6625]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2295, 11986,  3542,  2003, 16360, 25890,  2007, 10251,  5889,\n",
      "          1998, 19910,  1998, 10455,  1037,  3395,  2008,  1005,  1055,  9280,\n",
      "          3048,  1010,  1996,  3185,  2003,  2205, 21425,  1998,  2205,  2969,\n",
      "          1011,  9715,  2000,  3362,  1037,  2504,  1997,  2152,  3689,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  8616,  1010, 25591,  1010, 14408, 17441,  2143,  2055,\n",
      "          6860,  1010,  2293,  1010,  3638,  1010,  3404,  1998,  9721,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2295, 11986,  3542,  2003, 16360, 25890,  2007, 10251,  5889,\n",
      "          1998, 19910,  1998, 10455,  1037,  3395,  2008,  1005,  1055,  9280,\n",
      "          3048,  1010,  1996,  3185,  2003,  2205, 21425,  1998,  2205,  2969,\n",
      "          1011,  9715,  2000,  3362,  1037,  2504,  1997,  2152,  3689,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  8616,  1010, 25591,  1010, 14408, 17441,  2143,  2055,\n",
      "          6860,  1010,  2293,  1010,  3638,  1010,  3404,  1998,  9721,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2510, 0.7490],\n",
      "        [0.2783, 0.7217]]), 'input_ids': tensor([[  101,  2295, 11986,  3542,  2003, 16360, 25890,  2007, 10251,  5889,\n",
      "          1998, 19910,  1998, 10455,  1037,  3395,  2008,  1005,  1055,  9280,\n",
      "          3048,  1010,  1996,  3185,  2003,  2205, 21425,  1998,  2205,  2969,\n",
      "          1011,  9715,  2000,  3362,  1037,  2504,  1997,  2152,  3689,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  8616,  1010, 25591,  1010, 14408, 17441,  2143,  2055,\n",
      "          6860,  1010,  2293,  1010,  3638,  1010,  3404,  1998,  9721,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([41, 21]), 'cls_emb': tensor([[ 0.0421, -0.2161, -0.1738,  ..., -0.2257,  0.3412,  0.3649],\n",
      "        [-0.4928, -0.2940, -0.1322,  ..., -0.4069,  0.4741,  0.4277]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2005,  2035,  2049,  4087,  6819,  5339, 19098, 17759,  1010,\n",
      "          1996,  2143,  2003,  2061, 14719,  2098,  1999, 11799,  1998,  2379,\n",
      "          1011,  1060, 16515, 20200, 21877,  2850,  3995,  6292,  2008,  2009,\n",
      "          1005,  1055,  2438,  2000,  2191,  2028,  7222,  2005,  1996,  2154,\n",
      "          2043,  2643,  4232,  2064,  2053,  2936,  5047,  1996, 19838,  5668,\n",
      "          1997, 24466,  1012,   102],\n",
      "        [  101,  2023,  2143,  3849, 24907,  2005,  9185,  1010,  2993,  2635,\n",
      "          2006, 20274, 11647,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2005,  2035,  2049,  4087,  6819,  5339, 19098, 17759,  1010,\n",
      "          1996,  2143,  2003,  2061, 14719,  2098,  1999, 11799,  1998,  2379,\n",
      "          1011,  1060, 16515, 20200, 21877,  2850,  3995,  6292,  2008,  2009,\n",
      "          1005,  1055,  2438,  2000,  2191,  2028,  7222,  2005,  1996,  2154,\n",
      "          2043,  2643,  4232,  2064,  2053,  2936,  5047,  1996, 19838,  5668,\n",
      "          1997, 24466,  1012,   102],\n",
      "        [  101,  2023,  2143,  3849, 24907,  2005,  9185,  1010,  2993,  2635,\n",
      "          2006, 20274, 11647,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2505, 0.7495],\n",
      "        [0.2618, 0.7382]]), 'input_ids': tensor([[  101,  2005,  2035,  2049,  4087,  6819,  5339, 19098, 17759,  1010,\n",
      "          1996,  2143,  2003,  2061, 14719,  2098,  1999, 11799,  1998,  2379,\n",
      "          1011,  1060, 16515, 20200, 21877,  2850,  3995,  6292,  2008,  2009,\n",
      "          1005,  1055,  2438,  2000,  2191,  2028,  7222,  2005,  1996,  2154,\n",
      "          2043,  2643,  4232,  2064,  2053,  2936,  5047,  1996, 19838,  5668,\n",
      "          1997, 24466,  1012,   102],\n",
      "        [  101,  2023,  2143,  3849, 24907,  2005,  9185,  1010,  2993,  2635,\n",
      "          2006, 20274, 11647,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([54, 15]), 'cls_emb': tensor([[ 0.2198,  0.0729, -0.3637,  ..., -0.0275,  0.2536,  0.7217],\n",
      "        [-0.1289, -0.0305, -0.3103,  ..., -0.5642,  0.4263,  0.2002]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  4172,  2571,  3762,  2518,  2453,  2031,  2062, 15667,\n",
      "          2104, 11115,  2084,  2019,  5752,  7104,  2143,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22132,  7847, 12303,  9092,  9080, 10057,  2011,  5378,  1037,\n",
      "         21392,  2361,  2265,  2046,  1996,  3268,  1997,  1996,  3690,  1005,\n",
      "          1055, 13675, 21382,  2139,  2474,  3526, 18845,  3593,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  4172,  2571,  3762,  2518,  2453,  2031,  2062, 15667,\n",
      "          2104, 11115,  2084,  2019,  5752,  7104,  2143,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22132,  7847, 12303,  9092,  9080, 10057,  2011,  5378,  1037,\n",
      "         21392,  2361,  2265,  2046,  1996,  3268,  1997,  1996,  3690,  1005,\n",
      "          1055, 13675, 21382,  2139,  2474,  3526, 18845,  3593,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2715, 0.7285],\n",
      "        [0.2510, 0.7490]]), 'input_ids': tensor([[  101,  2023,  4172,  2571,  3762,  2518,  2453,  2031,  2062, 15667,\n",
      "          2104, 11115,  2084,  2019,  5752,  7104,  2143,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22132,  7847, 12303,  9092,  9080, 10057,  2011,  5378,  1037,\n",
      "         21392,  2361,  2265,  2046,  1996,  3268,  1997,  1996,  3690,  1005,\n",
      "          1055, 13675, 21382,  2139,  2474,  3526, 18845,  3593,  1012,   102]]), 'ntok': tensor([19, 30]), 'cls_emb': tensor([[ 0.2724, -0.0188, -0.1325,  ..., -0.1514,  0.2940,  0.5692],\n",
      "        [-0.2500,  0.3189, -0.7547,  ..., -0.1904,  0.6855,  0.6151]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2021,  1996,  2373,  1997,  2122,  1006,  5739,  1007,  2003,\n",
      "         23649,  2011,  1996,  3484,  1997,  1996,  2143,  2008,  3065,  1037,\n",
      "         17337,  4950,  2006,  1037,  3395,  2008,  2071,  2022, 13534,  2005,\n",
      "          3228,  1037,  2270,  2030,  3370,  1010,  2738,  2084,  8020,  2000,\n",
      "          1037,  2143,  1005,  1055,  7984,  1012,   102],\n",
      "        [  101, 17514,  2003,  1037,  2158,  2007,  2438, 25869,  2964,  2050,\n",
      "          1998,  8740,  2850, 12972,  2000,  4287,  1037,  6474,  3152,  1010,\n",
      "          2021,  2023,  3327,  2765,  2003,  4821,  2218,  2067,  2013,  2108,\n",
      "          2242,  3618,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2021,  1996,  2373,  1997,  2122,  1006,  5739,  1007,  2003,\n",
      "         23649,  2011,  1996,  3484,  1997,  1996,  2143,  2008,  3065,  1037,\n",
      "         17337,  4950,  2006,  1037,  3395,  2008,  2071,  2022, 13534,  2005,\n",
      "          3228,  1037,  2270,  2030,  3370,  1010,  2738,  2084,  8020,  2000,\n",
      "          1037,  2143,  1005,  1055,  7984,  1012,   102],\n",
      "        [  101, 17514,  2003,  1037,  2158,  2007,  2438, 25869,  2964,  2050,\n",
      "          1998,  8740,  2850, 12972,  2000,  4287,  1037,  6474,  3152,  1010,\n",
      "          2021,  2023,  3327,  2765,  2003,  4821,  2218,  2067,  2013,  2108,\n",
      "          2242,  3618,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2652, 0.7348],\n",
      "        [0.2443, 0.7557]]), 'input_ids': tensor([[  101,  2021,  1996,  2373,  1997,  2122,  1006,  5739,  1007,  2003,\n",
      "         23649,  2011,  1996,  3484,  1997,  1996,  2143,  2008,  3065,  1037,\n",
      "         17337,  4950,  2006,  1037,  3395,  2008,  2071,  2022, 13534,  2005,\n",
      "          3228,  1037,  2270,  2030,  3370,  1010,  2738,  2084,  8020,  2000,\n",
      "          1037,  2143,  1005,  1055,  7984,  1012,   102],\n",
      "        [  101, 17514,  2003,  1037,  2158,  2007,  2438, 25869,  2964,  2050,\n",
      "          1998,  8740,  2850, 12972,  2000,  4287,  1037,  6474,  3152,  1010,\n",
      "          2021,  2023,  3327,  2765,  2003,  4821,  2218,  2067,  2013,  2108,\n",
      "          2242,  3618,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([47, 34]), 'cls_emb': tensor([[-0.1472,  0.1995, -0.3141,  ..., -0.1591,  0.2486,  0.7347],\n",
      "        [-0.3392,  0.0430, -0.4040,  ..., -0.2128,  0.5734,  0.5873]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 21960, 16481,  2016,  1005,  1055,  2008,  4678, 11320, 22311,\n",
      "          2854,  2040, 14678, 13275,  1996,  3115,  1997,  2014,  9518,  1012,\n",
      "           102],\n",
      "        [  101,  2074,  2004,  3048,  1010,  2039, 26644,  1998,  6057,  2004,\n",
      "          2412,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 21960, 16481,  2016,  1005,  1055,  2008,  4678, 11320, 22311,\n",
      "          2854,  2040, 14678, 13275,  1996,  3115,  1997,  2014,  9518,  1012,\n",
      "           102],\n",
      "        [  101,  2074,  2004,  3048,  1010,  2039, 26644,  1998,  6057,  2004,\n",
      "          2412,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2537, 0.7463],\n",
      "        [0.2679, 0.7321]]), 'input_ids': tensor([[  101, 21960, 16481,  2016,  1005,  1055,  2008,  4678, 11320, 22311,\n",
      "          2854,  2040, 14678, 13275,  1996,  3115,  1997,  2014,  9518,  1012,\n",
      "           102],\n",
      "        [  101,  2074,  2004,  3048,  1010,  2039, 26644,  1998,  6057,  2004,\n",
      "          2412,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([21, 13]), 'cls_emb': tensor([[ 0.0152,  0.1618, -0.1520,  ..., -0.4969,  0.5228,  0.5418],\n",
      "        [-0.6449, -0.2016, -0.0330,  ..., -0.3611,  0.2907,  0.1606]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  8216,  2135, 14036,  2005,  3185,  3995,  2545,  1997,  2151,\n",
      "          2287,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1037,  8155,  1010, 13366, 14626,  2915,  1010,  2092,  1011,\n",
      "          6051,  1010,  6881,  2135, 22307, 10874,  2008, 17722,  1037, 21298,\n",
      "          1997,  1005, 20341,  1998,  1005, 17549,  2647,  1011,  2275,  8645,\n",
      "          4620,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  8216,  2135, 14036,  2005,  3185,  3995,  2545,  1997,  2151,\n",
      "          2287,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1037,  8155,  1010, 13366, 14626,  2915,  1010,  2092,  1011,\n",
      "          6051,  1010,  6881,  2135, 22307, 10874,  2008, 17722,  1037, 21298,\n",
      "          1997,  1005, 20341,  1998,  1005, 17549,  2647,  1011,  2275,  8645,\n",
      "          4620,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2490, 0.7510],\n",
      "        [0.2528, 0.7472]]), 'input_ids': tensor([[  101,  8216,  2135, 14036,  2005,  3185,  3995,  2545,  1997,  2151,\n",
      "          2287,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1037,  8155,  1010, 13366, 14626,  2915,  1010,  2092,  1011,\n",
      "          6051,  1010,  6881,  2135, 22307, 10874,  2008, 17722,  1037, 21298,\n",
      "          1997,  1005, 20341,  1998,  1005, 17549,  2647,  1011,  2275,  8645,\n",
      "          4620,  1012,   102]]), 'ntok': tensor([13, 33]), 'cls_emb': tensor([[-0.5269,  0.1841,  0.0699,  ..., -0.2950,  0.2876,  0.1883],\n",
      "        [-0.4161, -0.4262, -0.1546,  ..., -0.5670,  0.6159,  0.2933]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  1037,  2204,  5896,  1010,  2204,  7982,  1010,\n",
      "          6057,  2130,  2005,  6001,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996, 12242,  3686,  7077,  9961,  2008,  2320,  2790, 27480,\n",
      "          2000, 17183,  4168,  1005,  1055,  7339,  2038,  1037,  7823,  2051,\n",
      "          8361,  2013,  2090,  1996,  6649,  6052, 10140,  6508,  1011, 11345,\n",
      "          6547, 11967,  1998,  1996,  2047, 15143, 11533,  5365,  2695,  1011,\n",
      "          2537,  3896,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  1037,  2204,  5896,  1010,  2204,  7982,  1010,\n",
      "          6057,  2130,  2005,  6001,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996, 12242,  3686,  7077,  9961,  2008,  2320,  2790, 27480,\n",
      "          2000, 17183,  4168,  1005,  1055,  7339,  2038,  1037,  7823,  2051,\n",
      "          8361,  2013,  2090,  1996,  6649,  6052, 10140,  6508,  1011, 11345,\n",
      "          6547, 11967,  1998,  1996,  2047, 15143, 11533,  5365,  2695,  1011,\n",
      "          2537,  3896,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2518, 0.7482],\n",
      "        [0.2611, 0.7389]]), 'input_ids': tensor([[  101,  2023,  2003,  1037,  2204,  5896,  1010,  2204,  7982,  1010,\n",
      "          6057,  2130,  2005,  6001,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996, 12242,  3686,  7077,  9961,  2008,  2320,  2790, 27480,\n",
      "          2000, 17183,  4168,  1005,  1055,  7339,  2038,  1037,  7823,  2051,\n",
      "          8361,  2013,  2090,  1996,  6649,  6052, 10140,  6508,  1011, 11345,\n",
      "          6547, 11967,  1998,  1996,  2047, 15143, 11533,  5365,  2695,  1011,\n",
      "          2537,  3896,  1012,   102]]), 'ntok': tensor([16, 44]), 'cls_emb': tensor([[-0.1140, -0.2220, -0.0288,  ..., -0.3919,  0.6217,  0.5413],\n",
      "        [ 0.0593, -0.0619,  0.0133,  ..., -0.2647,  0.4537,  0.4675]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023, 16524, 12267, 25107,  1011, 25325,  5657,  2143,  2003,\n",
      "          2036,  1037, 19817,  7140,  9709,  7613,  1997, 14925, 18954,  7951,\n",
      "          4570,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1045,  2064,  2202, 10527,  9463,  8562,  1012,  1012,  1012,\n",
      "          2021,  2023,  2003,  1996,  4066,  1997, 10527,  9463,  2008,  3084,\n",
      "          2017,  4687,  2055,  5278,  1996,  2472,  1998,  3213,  1005,  1055,\n",
      "         22939,  7347,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023, 16524, 12267, 25107,  1011, 25325,  5657,  2143,  2003,\n",
      "          2036,  1037, 19817,  7140,  9709,  7613,  1997, 14925, 18954,  7951,\n",
      "          4570,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1045,  2064,  2202, 10527,  9463,  8562,  1012,  1012,  1012,\n",
      "          2021,  2023,  2003,  1996,  4066,  1997, 10527,  9463,  2008,  3084,\n",
      "          2017,  4687,  2055,  5278,  1996,  2472,  1998,  3213,  1005,  1055,\n",
      "         22939,  7347,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2530, 0.7470],\n",
      "        [0.2571, 0.7429]]), 'input_ids': tensor([[  101,  2023, 16524, 12267, 25107,  1011, 25325,  5657,  2143,  2003,\n",
      "          2036,  1037, 19817,  7140,  9709,  7613,  1997, 14925, 18954,  7951,\n",
      "          4570,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1045,  2064,  2202, 10527,  9463,  8562,  1012,  1012,  1012,\n",
      "          2021,  2023,  2003,  1996,  4066,  1997, 10527,  9463,  2008,  3084,\n",
      "          2017,  4687,  2055,  5278,  1996,  2472,  1998,  3213,  1005,  1055,\n",
      "         22939,  7347,  1012,   102]]), 'ntok': tensor([23, 34]), 'cls_emb': tensor([[-0.1070,  0.3395, -0.4481,  ..., -0.2612,  0.6866,  0.6769],\n",
      "        [ 0.2156,  0.0036, -0.2626,  ..., -0.4236,  0.4909,  0.7789]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  3538,  1997,  3149,  1019,  3694, 11669,  2003,  1010,\n",
      "          3243, 19597,  1010,  2019, 15301,  2000,  1996,  4454,  1997,  1996,\n",
      "          2995,  6907, 29550,  1012,   102],\n",
      "        [  101,  1037, 26380,  2746,  1011,  1997,  1011,  2287,  2466,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  3538,  1997,  3149,  1019,  3694, 11669,  2003,  1010,\n",
      "          3243, 19597,  1010,  2019, 15301,  2000,  1996,  4454,  1997,  1996,\n",
      "          2995,  6907, 29550,  1012,   102],\n",
      "        [  101,  1037, 26380,  2746,  1011,  1997,  1011,  2287,  2466,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2478, 0.7522],\n",
      "        [0.2879, 0.7121]]), 'input_ids': tensor([[  101,  2023,  3538,  1997,  3149,  1019,  3694, 11669,  2003,  1010,\n",
      "          3243, 19597,  1010,  2019, 15301,  2000,  1996,  4454,  1997,  1996,\n",
      "          2995,  6907, 29550,  1012,   102],\n",
      "        [  101,  1037, 26380,  2746,  1011,  1997,  1011,  2287,  2466,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([25, 11]), 'cls_emb': tensor([[ 0.0676,  0.2129, -0.1090,  ..., -0.2307,  0.5585,  0.5725],\n",
      "        [-0.3157, -0.2910, -0.2680,  ..., -0.4097,  0.3345,  0.3325]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  6297,  8428,  4667,  3060,  2143,  2055,  1996,  2715,\n",
      "          4650,  1997,  7117, 24913,  1010,  1037,  2110,  5281,  2011,  8817,\n",
      "          2105,  1996,  7595,  1012,   102],\n",
      "        [  101,  1037, 13939, 17075,  1998,  8235,  2135,  6051,  8317,  3689,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  6297,  8428,  4667,  3060,  2143,  2055,  1996,  2715,\n",
      "          4650,  1997,  7117, 24913,  1010,  1037,  2110,  5281,  2011,  8817,\n",
      "          2105,  1996,  7595,  1012,   102],\n",
      "        [  101,  1037, 13939, 17075,  1998,  8235,  2135,  6051,  8317,  3689,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2746, 0.7254],\n",
      "        [0.2696, 0.7304]]), 'input_ids': tensor([[  101,  1037,  6297,  8428,  4667,  3060,  2143,  2055,  1996,  2715,\n",
      "          4650,  1997,  7117, 24913,  1010,  1037,  2110,  5281,  2011,  8817,\n",
      "          2105,  1996,  7595,  1012,   102],\n",
      "        [  101,  1037, 13939, 17075,  1998,  8235,  2135,  6051,  8317,  3689,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([25, 12]), 'cls_emb': tensor([[-0.0751, -0.0299, -0.2163,  ..., -0.1536,  0.4802,  0.0544],\n",
      "        [-0.3370, -0.1467, -0.1594,  ..., -0.3974,  0.3758,  0.4693]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2069,  8277,  3310,  2043,  1996,  6495,  2633,  4897,\n",
      "          1998,  2017,  2131,  2000,  2681,  1996,  4258,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3185,  2003,  6440,  1997,  1996,  2757,  4625,  2007,\n",
      "          2198, 10533,  1005,  1055, 11277,  1997,  7733,  1010,  2007, 14106,\n",
      "          2025,  2004,  1043,  6806, 15859,  4095,  2004,  1996,  2034,  1998,\n",
      "          4499,  2025,  2004,  2502,  2004,  1996,  2117,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2069,  8277,  3310,  2043,  1996,  6495,  2633,  4897,\n",
      "          1998,  2017,  2131,  2000,  2681,  1996,  4258,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3185,  2003,  6440,  1997,  1996,  2757,  4625,  2007,\n",
      "          2198, 10533,  1005,  1055, 11277,  1997,  7733,  1010,  2007, 14106,\n",
      "          2025,  2004,  1043,  6806, 15859,  4095,  2004,  1996,  2034,  1998,\n",
      "          4499,  2025,  2004,  2502,  2004,  1996,  2117,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2474, 0.7526],\n",
      "        [0.2621, 0.7379]]), 'input_ids': tensor([[  101,  1996,  2069,  8277,  3310,  2043,  1996,  6495,  2633,  4897,\n",
      "          1998,  2017,  2131,  2000,  2681,  1996,  4258,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  3185,  2003,  6440,  1997,  1996,  2757,  4625,  2007,\n",
      "          2198, 10533,  1005,  1055, 11277,  1997,  7733,  1010,  2007, 14106,\n",
      "          2025,  2004,  1043,  6806, 15859,  4095,  2004,  1996,  2034,  1998,\n",
      "          4499,  2025,  2004,  2502,  2004,  1996,  2117,  1012,   102]]), 'ntok': tensor([19, 39]), 'cls_emb': tensor([[ 0.3267, -0.1535,  0.5025,  ..., -0.3999,  0.3589,  0.6088],\n",
      "        [-0.1235, -0.3026, -0.1037,  ..., -0.0512,  0.8686,  0.2396]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  2038,  1996, 11084,  1997,  1996,  2434,  2137,  2346,\n",
      "          5691,  1010,  9831,  2075,  2006,  1996,  9882,  1010, 13456,  3270,\n",
      "         19250,  5957,  1997,  1996, 12127,  1005,  1055,  2388,  3122,  1012,\n",
      "           102],\n",
      "        [  101, 10990,  1998,  3622,  1010,  2007,  5745, 13425,  2008,  3065,\n",
      "          2074,  2438,  2000,  2562,  2149,  2006,  2256, 10393,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  2038,  1996, 11084,  1997,  1996,  2434,  2137,  2346,\n",
      "          5691,  1010,  9831,  2075,  2006,  1996,  9882,  1010, 13456,  3270,\n",
      "         19250,  5957,  1997,  1996, 12127,  1005,  1055,  2388,  3122,  1012,\n",
      "           102],\n",
      "        [  101, 10990,  1998,  3622,  1010,  2007,  5745, 13425,  2008,  3065,\n",
      "          2074,  2438,  2000,  2562,  2149,  2006,  2256, 10393,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2482, 0.7518],\n",
      "        [0.2715, 0.7285]]), 'input_ids': tensor([[  101,  2009,  2038,  1996, 11084,  1997,  1996,  2434,  2137,  2346,\n",
      "          5691,  1010,  9831,  2075,  2006,  1996,  9882,  1010, 13456,  3270,\n",
      "         19250,  5957,  1997,  1996, 12127,  1005,  1055,  2388,  3122,  1012,\n",
      "           102],\n",
      "        [  101, 10990,  1998,  3622,  1010,  2007,  5745, 13425,  2008,  3065,\n",
      "          2074,  2438,  2000,  2562,  2149,  2006,  2256, 10393,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'ntok': tensor([31, 20]), 'cls_emb': tensor([[ 0.0884,  0.0061, -0.2709,  ..., -0.3250,  0.4197,  0.4182],\n",
      "        [ 0.0854, -0.1900, -0.0686,  ..., -0.4771,  0.3258,  0.2610]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 11829,  6292,  8011,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  4122,  2000,  1056,  8545,  4817,  2068,  2007,  1037,\n",
      "          5510,  1997,  9745,  2100,  2047,  8562,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 11829,  6292,  8011,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  4122,  2000,  1056,  8545,  4817,  2068,  2007,  1037,\n",
      "          5510,  1997,  9745,  2100,  2047,  8562,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2638, 0.7362],\n",
      "        [0.2557, 0.7443]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1037, 11829,  6292,  8011,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2009,  4122,  2000,  1056,  8545,  4817,  2068,  2007,  1037,\n",
      "          5510,  1997,  9745,  2100,  2047,  8562,  1012,   102]]), 'ntok': tensor([10, 18]), 'cls_emb': tensor([[ 0.1585,  0.2543, -0.0760,  ..., -0.2800,  0.2121,  0.5892],\n",
      "        [-0.0516,  0.1642,  0.1418,  ..., -0.3243,  0.2583,  0.6022]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2397,  3510,  1005,  1055, 10551,  2791,  2003,  9832,  2000,\n",
      "         10580,  1996,  6832, 18856,  5833,  2000, 11740,  1057,  1012,  1055,\n",
      "          1012,  7193,  2125,  2037,  2519,  1012,   102,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 27467,  2094,  1998,  6625,  1025,  1037,  2143,  2008, 13366,\n",
      "         14626,  5703,  2015,  2895,  1998,  9185,  2004,  2009, 11082,  2017,\n",
      "         10616,  1998,  2514,  1996,  6896,  2500,  2031,  2005,  2037,  2147,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2397,  3510,  1005,  1055, 10551,  2791,  2003,  9832,  2000,\n",
      "         10580,  1996,  6832, 18856,  5833,  2000, 11740,  1057,  1012,  1055,\n",
      "          1012,  7193,  2125,  2037,  2519,  1012,   102,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 27467,  2094,  1998,  6625,  1025,  1037,  2143,  2008, 13366,\n",
      "         14626,  5703,  2015,  2895,  1998,  9185,  2004,  2009, 11082,  2017,\n",
      "         10616,  1998,  2514,  1996,  6896,  2500,  2031,  2005,  2037,  2147,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2687, 0.7313],\n",
      "        [0.2583, 0.7417]]), 'input_ids': tensor([[  101,  2397,  3510,  1005,  1055, 10551,  2791,  2003,  9832,  2000,\n",
      "         10580,  1996,  6832, 18856,  5833,  2000, 11740,  1057,  1012,  1055,\n",
      "          1012,  7193,  2125,  2037,  2519,  1012,   102,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 27467,  2094,  1998,  6625,  1025,  1037,  2143,  2008, 13366,\n",
      "         14626,  5703,  2015,  2895,  1998,  9185,  2004,  2009, 11082,  2017,\n",
      "         10616,  1998,  2514,  1996,  6896,  2500,  2031,  2005,  2037,  2147,\n",
      "          1012,   102]]), 'ntok': tensor([27, 32]), 'cls_emb': tensor([[-0.0846, -0.1851, -0.1075,  ..., -0.5328,  0.6270,  0.5649],\n",
      "        [-0.1844, -0.3417, -0.2559,  ..., -0.2687,  0.3547,  0.2507]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  4251,  8813,  1011,  1011,  1037,  2143,  2000,  2022,\n",
      "          7842, 14550,  2098,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  1996,  3185,  1010,  2856,  2011, 10872,  4027,  1010,  3727,\n",
      "          2053, 18856, 17322,  4895, 22299,  2098,  1010,  2013,  1996, 21425,\n",
      "          5436,  2000,  1996,  3494,  3442,  2041,  1997,  2430,  9179,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  4251,  8813,  1011,  1011,  1037,  2143,  2000,  2022,\n",
      "          7842, 14550,  2098,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  1996,  3185,  1010,  2856,  2011, 10872,  4027,  1010,  3727,\n",
      "          2053, 18856, 17322,  4895, 22299,  2098,  1010,  2013,  1996, 21425,\n",
      "          5436,  2000,  1996,  3494,  3442,  2041,  1997,  2430,  9179,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2498, 0.7502],\n",
      "        [0.2729, 0.7271]]), 'input_ids': tensor([[  101,  1037,  4251,  8813,  1011,  1011,  1037,  2143,  2000,  2022,\n",
      "          7842, 14550,  2098,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  1996,  3185,  1010,  2856,  2011, 10872,  4027,  1010,  3727,\n",
      "          2053, 18856, 17322,  4895, 22299,  2098,  1010,  2013,  1996, 21425,\n",
      "          5436,  2000,  1996,  3494,  3442,  2041,  1997,  2430,  9179,  1012,\n",
      "           102]]), 'ntok': tensor([15, 31]), 'cls_emb': tensor([[-0.3917, -0.2266, -0.2479,  ..., -0.3024,  0.1865,  0.3118],\n",
      "        [-0.0102,  0.0674,  0.0133,  ..., -0.4046,  0.5391,  0.3515]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2023,  2003,  1996,  4066,  1997, 20934, 21194,  2895, 17312,\n",
      "          2073,  2028, 16507, 16405, 29033,  2015,  2178,  1010,  7984, 13185,\n",
      "          2003,  1037, 15967,  2461,  4580,  1010,  1998,  3649,  5235,  2005,\n",
      "          7961,  2003,  1037,  5387,  1997,  1996,  2197,  5436,  5080,  2187,\n",
      "          3061,  1012,   102],\n",
      "        [  101,  9458,  5691,  2031,  2428,  2718,  1996,  8301,  5104,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2023,  2003,  1996,  4066,  1997, 20934, 21194,  2895, 17312,\n",
      "          2073,  2028, 16507, 16405, 29033,  2015,  2178,  1010,  7984, 13185,\n",
      "          2003,  1037, 15967,  2461,  4580,  1010,  1998,  3649,  5235,  2005,\n",
      "          7961,  2003,  1037,  5387,  1997,  1996,  2197,  5436,  5080,  2187,\n",
      "          3061,  1012,   102],\n",
      "        [  101,  9458,  5691,  2031,  2428,  2718,  1996,  8301,  5104,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2631, 0.7369],\n",
      "        [0.2888, 0.7112]]), 'input_ids': tensor([[  101,  2023,  2003,  1996,  4066,  1997, 20934, 21194,  2895, 17312,\n",
      "          2073,  2028, 16507, 16405, 29033,  2015,  2178,  1010,  7984, 13185,\n",
      "          2003,  1037, 15967,  2461,  4580,  1010,  1998,  3649,  5235,  2005,\n",
      "          7961,  2003,  1037,  5387,  1997,  1996,  2197,  5436,  5080,  2187,\n",
      "          3061,  1012,   102],\n",
      "        [  101,  9458,  5691,  2031,  2428,  2718,  1996,  8301,  5104,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0]]), 'ntok': tensor([43, 11]), 'cls_emb': tensor([[ 0.0501, -0.1009, -0.1476,  ..., -0.0631,  0.4964,  0.5126],\n",
      "        [ 0.3863, -0.3322, -0.1634,  ..., -0.3539,  0.5720,  0.3284]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 13703,  5297,  1005,  1055,  6745,  2003,  2019,  2572,  9709,\n",
      "          1010,  5041,  4038,  2055,  2035,  2045,  2003,  2000,  2293,  1011,\n",
      "          1011,  1998,  5223,  1011,  1011,  2055,  1996,  3185, 12170,  2480,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2081,  2007, 13366, 14626,  4895, 21678,\n",
      "          2989,  6907, 22012,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 13703,  5297,  1005,  1055,  6745,  2003,  2019,  2572,  9709,\n",
      "          1010,  5041,  4038,  2055,  2035,  2045,  2003,  2000,  2293,  1011,\n",
      "          1011,  1998,  5223,  1011,  1011,  2055,  1996,  3185, 12170,  2480,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2081,  2007, 13366, 14626,  4895, 21678,\n",
      "          2989,  6907, 22012,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.3085, 0.6915],\n",
      "        [0.2680, 0.7320]]), 'input_ids': tensor([[  101, 13703,  5297,  1005,  1055,  6745,  2003,  2019,  2572,  9709,\n",
      "          1010,  5041,  4038,  2055,  2035,  2045,  2003,  2000,  2293,  1011,\n",
      "          1011,  1998,  5223,  1011,  1011,  2055,  1996,  3185, 12170,  2480,\n",
      "          1012,   102],\n",
      "        [  101,  2009,  1005,  1055,  2081,  2007, 13366, 14626,  4895, 21678,\n",
      "          2989,  6907, 22012,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([32, 15]), 'cls_emb': tensor([[-0.1553, -0.1528, -0.2814,  ..., -0.0135,  1.0107,  0.3360],\n",
      "        [ 0.2067,  0.1228, -0.3189,  ..., -0.1502,  0.4128,  0.3282]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  9020,  2000,  2265,  2166,  1999,  2035,  1997,  2049,  7221,\n",
      "         23732,  2043,  1996,  6808,  2003,  3243,  1996,  4500,  1012,   102,\n",
      "             0],\n",
      "        [  101,  4821,  5683,  4064,  1998,  4895, 16846,  2483, 14116,  1010,\n",
      "          2066, 18468,  1037, 15661, 11333,  7512,  2302,  1996,  4511,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  9020,  2000,  2265,  2166,  1999,  2035,  1997,  2049,  7221,\n",
      "         23732,  2043,  1996,  6808,  2003,  3243,  1996,  4500,  1012,   102,\n",
      "             0],\n",
      "        [  101,  4821,  5683,  4064,  1998,  4895, 16846,  2483, 14116,  1010,\n",
      "          2066, 18468,  1037, 15661, 11333,  7512,  2302,  1996,  4511,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2515, 0.7485],\n",
      "        [0.2460, 0.7540]]), 'input_ids': tensor([[  101,  9020,  2000,  2265,  2166,  1999,  2035,  1997,  2049,  7221,\n",
      "         23732,  2043,  1996,  6808,  2003,  3243,  1996,  4500,  1012,   102,\n",
      "             0],\n",
      "        [  101,  4821,  5683,  4064,  1998,  4895, 16846,  2483, 14116,  1010,\n",
      "          2066, 18468,  1037, 15661, 11333,  7512,  2302,  1996,  4511,  1012,\n",
      "           102]]), 'ntok': tensor([20, 21]), 'cls_emb': tensor([[ 0.0024,  0.0825, -0.3919,  ..., -0.2770, -0.0083,  0.4424],\n",
      "        [-0.2445, -0.0715,  0.0660,  ..., -0.4731,  0.2727,  0.7166]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 24172,  4053,  2633, 18058,  1996,  5350,  2005, 29058,  8625,\n",
      "         13327,  4599,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037, 17565,  1011, 29290,  4038,  2007, 10245,  7685,  7982,\n",
      "          1998,  3045,  4616,  2011,  2019,  9832,  2136,  1997,  7436,  1011,\n",
      "          4791,  1024,  6294,  7354, 19333,  1998,  2751,  2666,  5292,  7962,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 24172,  4053,  2633, 18058,  1996,  5350,  2005, 29058,  8625,\n",
      "         13327,  4599,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037, 17565,  1011, 29290,  4038,  2007, 10245,  7685,  7982,\n",
      "          1998,  3045,  4616,  2011,  2019,  9832,  2136,  1997,  7436,  1011,\n",
      "          4791,  1024,  6294,  7354, 19333,  1998,  2751,  2666,  5292,  7962,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2785, 0.7215],\n",
      "        [0.2741, 0.7259]]), 'input_ids': tensor([[  101, 24172,  4053,  2633, 18058,  1996,  5350,  2005, 29058,  8625,\n",
      "         13327,  4599,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1037, 17565,  1011, 29290,  4038,  2007, 10245,  7685,  7982,\n",
      "          1998,  3045,  4616,  2011,  2019,  9832,  2136,  1997,  7436,  1011,\n",
      "          4791,  1024,  6294,  7354, 19333,  1998,  2751,  2666,  5292,  7962,\n",
      "          1012,   102]]), 'ntok': tensor([14, 32]), 'cls_emb': tensor([[-2.6091e-04, -4.2232e-02, -1.2573e-01,  ..., -3.7628e-01,\n",
      "          4.5238e-01,  2.5443e-01],\n",
      "        [-2.2594e-01, -2.7753e-01, -1.5078e-01,  ..., -3.2088e-01,\n",
      "          7.0070e-01,  3.0808e-01]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2205,  2969,  1011,  2590,  1998, 20228,\n",
      "          7716,  4667,  2000,  2022,  6057,  1010,  1998,  2205, 20144,  1998,\n",
      "         12066,  2000,  2022,  2019,  8680,  1012,   102],\n",
      "        [  101,  2097,  2572,  8557,  1998, 27895, 29118,  6001,  1999, 12233,\n",
      "          9356,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  2205,  2969,  1011,  2590,  1998, 20228,\n",
      "          7716,  4667,  2000,  2022,  6057,  1010,  1998,  2205, 20144,  1998,\n",
      "         12066,  2000,  2022,  2019,  8680,  1012,   102],\n",
      "        [  101,  2097,  2572,  8557,  1998, 27895, 29118,  6001,  1999, 12233,\n",
      "          9356,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2757, 0.7243],\n",
      "        [0.2404, 0.7596]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  2205,  2969,  1011,  2590,  1998, 20228,\n",
      "          7716,  4667,  2000,  2022,  6057,  1010,  1998,  2205, 20144,  1998,\n",
      "         12066,  2000,  2022,  2019,  8680,  1012,   102],\n",
      "        [  101,  2097,  2572,  8557,  1998, 27895, 29118,  6001,  1999, 12233,\n",
      "          9356,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([27, 13]), 'cls_emb': tensor([[ 0.2102, -0.0518, -0.3189,  ..., -0.1628,  0.3072,  0.9090],\n",
      "        [-0.6636, -0.3439, -0.0120,  ..., -0.5086,  0.3660, -0.3210]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2823,  3849,  2625,  2066, 20957,  2084,  2242,  1996,  4728,\n",
      "         17075,  2472,  2734,  2000,  2131,  2125,  2010,  3108,  1012,   102],\n",
      "        [  101,  2021,  2023,  3152, 14087,  1996,  6896,  3223,  2000,  5271,\n",
      "          1996,  3430,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2823,  3849,  2625,  2066, 20957,  2084,  2242,  1996,  4728,\n",
      "         17075,  2472,  2734,  2000,  2131,  2125,  2010,  3108,  1012,   102],\n",
      "        [  101,  2021,  2023,  3152, 14087,  1996,  6896,  3223,  2000,  5271,\n",
      "          1996,  3430,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2776, 0.7224],\n",
      "        [0.2604, 0.7396]]), 'input_ids': tensor([[  101,  2823,  3849,  2625,  2066, 20957,  2084,  2242,  1996,  4728,\n",
      "         17075,  2472,  2734,  2000,  2131,  2125,  2010,  3108,  1012,   102],\n",
      "        [  101,  2021,  2023,  3152, 14087,  1996,  6896,  3223,  2000,  5271,\n",
      "          1996,  3430,  1012,   102,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([20, 14]), 'cls_emb': tensor([[-0.0031,  0.0282, -0.3283,  ..., -0.0846,  0.2628,  0.2075],\n",
      "        [-0.4262,  0.0681, -0.1634,  ..., -0.5795,  0.6813,  0.0031]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2054,  2003,  2531,  1003,  4394,  2182,  2003,  1037,  5896,\n",
      "          1997,  2130,  1996,  2087, 19529,  8433,  1010,  2019, 10710,  2989,\n",
      "          1997, 10218, 15966,  1010,  1998,  2505, 15525,  3772,  1012,   102],\n",
      "        [  101,  2045,  1005,  1055,  1037, 10433,  2135,  4942, 14028,  3512,\n",
      "          6260,  2000,  1996,  2190,  3033,  1997,  5798,  2611,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2054,  2003,  2531,  1003,  4394,  2182,  2003,  1037,  5896,\n",
      "          1997,  2130,  1996,  2087, 19529,  8433,  1010,  2019, 10710,  2989,\n",
      "          1997, 10218, 15966,  1010,  1998,  2505, 15525,  3772,  1012,   102],\n",
      "        [  101,  2045,  1005,  1055,  1037, 10433,  2135,  4942, 14028,  3512,\n",
      "          6260,  2000,  1996,  2190,  3033,  1997,  5798,  2611,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2528, 0.7472],\n",
      "        [0.2667, 0.7333]]), 'input_ids': tensor([[  101,  2054,  2003,  2531,  1003,  4394,  2182,  2003,  1037,  5896,\n",
      "          1997,  2130,  1996,  2087, 19529,  8433,  1010,  2019, 10710,  2989,\n",
      "          1997, 10218, 15966,  1010,  1998,  2505, 15525,  3772,  1012,   102],\n",
      "        [  101,  2045,  1005,  1055,  1037, 10433,  2135,  4942, 14028,  3512,\n",
      "          6260,  2000,  1996,  2190,  3033,  1997,  5798,  2611,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([30, 20]), 'cls_emb': tensor([[-0.1186,  0.0283, -0.2651,  ..., -0.2302,  0.3765,  0.7452],\n",
      "        [ 0.0847, -0.1528, -0.3306,  ..., -0.1129,  0.1595,  0.5869]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  2488,  2516,  1010,  2005,  2035,  4986,  1010,  2453,\n",
      "          2022,  7260,  2104,  1996, 20452,  1012,   102],\n",
      "        [  101,  1037, 13544, 20316,  6832,  3325,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  2488,  2516,  1010,  2005,  2035,  4986,  1010,  2453,\n",
      "          2022,  7260,  2104,  1996, 20452,  1012,   102],\n",
      "        [  101,  1037, 13544, 20316,  6832,  3325,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2787, 0.7213],\n",
      "        [0.2737, 0.7263]]), 'input_ids': tensor([[  101,  1037,  2488,  2516,  1010,  2005,  2035,  4986,  1010,  2453,\n",
      "          2022,  7260,  2104,  1996, 20452,  1012,   102],\n",
      "        [  101,  1037, 13544, 20316,  6832,  3325,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([17,  8]), 'cls_emb': tensor([[-0.1003, -0.1102, -0.0827,  ..., -0.4025,  0.1163,  0.5787],\n",
      "        [-0.6259,  0.0284, -0.8078,  ..., -0.2705,  0.3881,  0.2222]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2445,  2129,  3082,  1011,  4375,  1998, 25927,  3372,  1011,\n",
      "          3082,  2009,  2003,  1010,  2023,  2071,  2022,  1996,  5409,  2518,\n",
      "          2061,  4063,  4059,  2232,  2038,  2412,  2589,  1012,   102,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2750,  1996, 23408, 24755,  6024, 20749, 23408,  2378,  6129,\n",
      "          1996,  8892,  2110,  1997,  2715,  2293,  2166,  1010,  1996,  2143,\n",
      "          2196,  2566, 26289,  4570,  3458,  1037, 18847,  2669,  3560,  1059,\n",
      "         14014,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2445,  2129,  3082,  1011,  4375,  1998, 25927,  3372,  1011,\n",
      "          3082,  2009,  2003,  1010,  2023,  2071,  2022,  1996,  5409,  2518,\n",
      "          2061,  4063,  4059,  2232,  2038,  2412,  2589,  1012,   102,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2750,  1996, 23408, 24755,  6024, 20749, 23408,  2378,  6129,\n",
      "          1996,  8892,  2110,  1997,  2715,  2293,  2166,  1010,  1996,  2143,\n",
      "          2196,  2566, 26289,  4570,  3458,  1037, 18847,  2669,  3560,  1059,\n",
      "         14014,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2589, 0.7411],\n",
      "        [0.2544, 0.7456]]), 'input_ids': tensor([[  101,  2445,  2129,  3082,  1011,  4375,  1998, 25927,  3372,  1011,\n",
      "          3082,  2009,  2003,  1010,  2023,  2071,  2022,  1996,  5409,  2518,\n",
      "          2061,  4063,  4059,  2232,  2038,  2412,  2589,  1012,   102,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2750,  1996, 23408, 24755,  6024, 20749, 23408,  2378,  6129,\n",
      "          1996,  8892,  2110,  1997,  2715,  2293,  2166,  1010,  1996,  2143,\n",
      "          2196,  2566, 26289,  4570,  3458,  1037, 18847,  2669,  3560,  1059,\n",
      "         14014,  1012,   102]]), 'ntok': tensor([29, 33]), 'cls_emb': tensor([[-0.0492,  0.1519, -0.2914,  ..., -0.0021,  0.1019,  0.6089],\n",
      "        [ 0.1092,  0.1268, -0.1449,  ..., -0.2419,  0.3917,  0.4821]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2019, 18691,  2923,  4038,  2055,  7344,  3370,  1010,  8745,\n",
      "          1998,  3279,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012, 13897,  1010,  9680,  3340,  1998,  7415,\n",
      "         11432, 10007,  2037,  9200,  4641,  1999,  1037, 19723, 12514, 18557,\n",
      "          1997, 21014,  4808,  2008,  3957, 12077,  4182,  2000,  2019,  9832,\n",
      "          1010,  2021,  5622,  2912,  3468,  1010,  5394,  1012,  1005,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2019, 18691,  2923,  4038,  2055,  7344,  3370,  1010,  8745,\n",
      "          1998,  3279,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012, 13897,  1010,  9680,  3340,  1998,  7415,\n",
      "         11432, 10007,  2037,  9200,  4641,  1999,  1037, 19723, 12514, 18557,\n",
      "          1997, 21014,  4808,  2008,  3957, 12077,  4182,  2000,  2019,  9832,\n",
      "          1010,  2021,  5622,  2912,  3468,  1010,  5394,  1012,  1005,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2813, 0.7187],\n",
      "        [0.2696, 0.7304]]), 'input_ids': tensor([[  101,  2019, 18691,  2923,  4038,  2055,  7344,  3370,  1010,  8745,\n",
      "          1998,  3279,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1012,  1012,  1012, 13897,  1010,  9680,  3340,  1998,  7415,\n",
      "         11432, 10007,  2037,  9200,  4641,  1999,  1037, 19723, 12514, 18557,\n",
      "          1997, 21014,  4808,  2008,  3957, 12077,  4182,  2000,  2019,  9832,\n",
      "          1010,  2021,  5622,  2912,  3468,  1010,  5394,  1012,  1005,   102]]), 'ntok': tensor([14, 40]), 'cls_emb': tensor([[-0.3637, -0.1272, -0.3814,  ..., -0.1979,  0.5052,  0.4680],\n",
      "        [ 0.7663,  0.1768,  0.0741,  ..., -0.6332,  0.9000,  0.2253]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2010,  7965,  3168,  1997, 18312,  2003,  2422,  1998,  4569,\n",
      "          1012,  1012,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 11749,  2137, 13012,  6528,  7971,  1998, 17839,  2024,  7463,\n",
      "          2041,  1996,  3332,  2007,  1996,  9414,  2413,  3689,  2008, 13366,\n",
      "         14626, 15102,  1996,  3697,  3276,  2090,  1037,  2269,  1998,  2365,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2010,  7965,  3168,  1997, 18312,  2003,  2422,  1998,  4569,\n",
      "          1012,  1012,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 11749,  2137, 13012,  6528,  7971,  1998, 17839,  2024,  7463,\n",
      "          2041,  1996,  3332,  2007,  1996,  9414,  2413,  3689,  2008, 13366,\n",
      "         14626, 15102,  1996,  3697,  3276,  2090,  1037,  2269,  1998,  2365,\n",
      "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2617, 0.7383],\n",
      "        [0.2698, 0.7302]]), 'input_ids': tensor([[  101,  2010,  7965,  3168,  1997, 18312,  2003,  2422,  1998,  4569,\n",
      "          1012,  1012,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 11749,  2137, 13012,  6528,  7971,  1998, 17839,  2024,  7463,\n",
      "          2041,  1996,  3332,  2007,  1996,  9414,  2413,  3689,  2008, 13366,\n",
      "         14626, 15102,  1996,  3697,  3276,  2090,  1037,  2269,  1998,  2365,\n",
      "          1012,   102]]), 'ntok': tensor([14, 32]), 'cls_emb': tensor([[-0.1490,  0.4002, -0.5270,  ..., -0.2224,  0.7293,  0.2474],\n",
      "        [-0.4134,  0.2214, -0.5686,  ..., -0.6947,  0.6610,  0.2366]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4679,  2003,  2652,  2061,  2489,  2007,  6699,  1010,  1998,\n",
      "          1996,  2755,  2008,  2336,  2024, 19323,  2000,  7280,  1010,  2008,\n",
      "          2002,  3084,  1996,  4378, 13446,  2000,  2010, 25430, 27609,  2075,\n",
      "          7461,  3370,  1997, 27994,  1012,   102],\n",
      "        [  101, 17727, 14122,  2953,  2038,  1037,  9210,  1997, 26162,  5312,\n",
      "          1998,  1037,  3232,  1997,  2204,  4616,  1010,  2021,  1996,  3185,\n",
      "          2515,  1050,  1005,  1056,  3243,  4875,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4679,  2003,  2652,  2061,  2489,  2007,  6699,  1010,  1998,\n",
      "          1996,  2755,  2008,  2336,  2024, 19323,  2000,  7280,  1010,  2008,\n",
      "          2002,  3084,  1996,  4378, 13446,  2000,  2010, 25430, 27609,  2075,\n",
      "          7461,  3370,  1997, 27994,  1012,   102],\n",
      "        [  101, 17727, 14122,  2953,  2038,  1037,  9210,  1997, 26162,  5312,\n",
      "          1998,  1037,  3232,  1997,  2204,  4616,  1010,  2021,  1996,  3185,\n",
      "          2515,  1050,  1005,  1056,  3243,  4875,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2401, 0.7599],\n",
      "        [0.2483, 0.7517]]), 'input_ids': tensor([[  101,  4679,  2003,  2652,  2061,  2489,  2007,  6699,  1010,  1998,\n",
      "          1996,  2755,  2008,  2336,  2024, 19323,  2000,  7280,  1010,  2008,\n",
      "          2002,  3084,  1996,  4378, 13446,  2000,  2010, 25430, 27609,  2075,\n",
      "          7461,  3370,  1997, 27994,  1012,   102],\n",
      "        [  101, 17727, 14122,  2953,  2038,  1037,  9210,  1997, 26162,  5312,\n",
      "          1998,  1037,  3232,  1997,  2204,  4616,  1010,  2021,  1996,  3185,\n",
      "          2515,  1050,  1005,  1056,  3243,  4875,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'ntok': tensor([36, 28]), 'cls_emb': tensor([[-0.3213, -0.0186, -0.3247,  ..., -0.2731,  0.5392,  0.6651],\n",
      "        [ 0.2927, -0.2710,  0.0281,  ..., -0.2288,  0.5729,  0.4970]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2112,  2659,  9278, 23834,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006, 14262,  2854,  1007,  4122,  2000, 12586,  4331,  1998,\n",
      "          3689,  1010,  2019,  4748, 14503,  3085, 16290,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2112,  2659,  9278, 23834,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006, 14262,  2854,  1007,  4122,  2000, 12586,  4331,  1998,\n",
      "          3689,  1010,  2019,  4748, 14503,  3085, 16290,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2800, 0.7200],\n",
      "        [0.2701, 0.7299]]), 'input_ids': tensor([[  101,  2112,  2659,  9278, 23834,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1006, 14262,  2854,  1007,  4122,  2000, 12586,  4331,  1998,\n",
      "          3689,  1010,  2019,  4748, 14503,  3085, 16290,  1012,   102]]), 'ntok': tensor([ 7, 19]), 'cls_emb': tensor([[-0.2505, -0.0738, -0.0133,  ..., -0.3250,  0.4196,  0.3306],\n",
      "        [-0.1980,  0.0817, -0.3958,  ..., -0.6106,  0.3980,  0.3358]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2005,  2035,  1996, 26185,  1998, 23701,  2989,  1010,  4000,\n",
      "          1010,  7385,  1998, 21075, 26641,  2015,  1010,  2045,  1005,  1055,\n",
      "          2053,  3168,  1997,  5025,  6896,  2108,  8871,  2185,  1999,  2293,\n",
      "          1005,  1055, 12275,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055, 17160,  2000,  2156,  2129,  6655,  5794,\n",
      "          2100,  1998, 25005,  2377,  2125,  2169,  2060,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2005,  2035,  1996, 26185,  1998, 23701,  2989,  1010,  4000,\n",
      "          1010,  7385,  1998, 21075, 26641,  2015,  1010,  2045,  1005,  1055,\n",
      "          2053,  3168,  1997,  5025,  6896,  2108,  8871,  2185,  1999,  2293,\n",
      "          1005,  1055, 12275,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055, 17160,  2000,  2156,  2129,  6655,  5794,\n",
      "          2100,  1998, 25005,  2377,  2125,  2169,  2060,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2535, 0.7465],\n",
      "        [0.2609, 0.7391]]), 'input_ids': tensor([[  101,  2005,  2035,  1996, 26185,  1998, 23701,  2989,  1010,  4000,\n",
      "          1010,  7385,  1998, 21075, 26641,  2015,  1010,  2045,  1005,  1055,\n",
      "          2053,  3168,  1997,  5025,  6896,  2108,  8871,  2185,  1999,  2293,\n",
      "          1005,  1055, 12275,  1012,   102],\n",
      "        [  101,  2009,  1005,  1055, 17160,  2000,  2156,  2129,  6655,  5794,\n",
      "          2100,  1998, 25005,  2377,  2125,  2169,  2060,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'ntok': tensor([35, 19]), 'cls_emb': tensor([[ 0.0974,  0.0858, -0.3547,  ..., -0.3618,  0.3847,  0.6978],\n",
      "        [ 0.3245,  0.0834, -0.2746,  ..., -0.1482,  0.3493,  0.6345]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1999,  1037,  2126,  1010,  1996,  2143,  5683,  2066,  1037,\n",
      "          3052,  1997,  4840,  2250,  1010,  2021,  2069,  2000,  2216,  2008,\n",
      "          3499,  2009,  1999,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 17453, 28575,  1010, 23539,  3973, 16021, 18300,  3512,  1998,\n",
      "         12246, 26380,  1010,  2009,  3138,  2149,  2006,  1037, 11220,  1011,\n",
      "         16817,  4536,  2013, 12660,  2000,  3325,  2302,  2130,  1037,  9374,\n",
      "          1997,  2008,  5171, 25358,  2666,  1011, 17312, 23069,  3012,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1999,  1037,  2126,  1010,  1996,  2143,  5683,  2066,  1037,\n",
      "          3052,  1997,  4840,  2250,  1010,  2021,  2069,  2000,  2216,  2008,\n",
      "          3499,  2009,  1999,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 17453, 28575,  1010, 23539,  3973, 16021, 18300,  3512,  1998,\n",
      "         12246, 26380,  1010,  2009,  3138,  2149,  2006,  1037, 11220,  1011,\n",
      "         16817,  4536,  2013, 12660,  2000,  3325,  2302,  2130,  1037,  9374,\n",
      "          1997,  2008,  5171, 25358,  2666,  1011, 17312, 23069,  3012,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2349, 0.7651],\n",
      "        [0.2389, 0.7611]]), 'input_ids': tensor([[  101,  1999,  1037,  2126,  1010,  1996,  2143,  5683,  2066,  1037,\n",
      "          3052,  1997,  4840,  2250,  1010,  2021,  2069,  2000,  2216,  2008,\n",
      "          3499,  2009,  1999,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 17453, 28575,  1010, 23539,  3973, 16021, 18300,  3512,  1998,\n",
      "         12246, 26380,  1010,  2009,  3138,  2149,  2006,  1037, 11220,  1011,\n",
      "         16817,  4536,  2013, 12660,  2000,  3325,  2302,  2130,  1037,  9374,\n",
      "          1997,  2008,  5171, 25358,  2666,  1011, 17312, 23069,  3012,  1012,\n",
      "           102]]), 'ntok': tensor([25, 41]), 'cls_emb': tensor([[ 0.1191,  0.0920,  0.0116,  ..., -0.2658,  0.2696,  0.7030],\n",
      "        [-0.0267, -0.1990, -0.0280,  ..., -0.3198,  0.4051,  0.3669]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2143,  1005,  1055,  6160, 21986, 21254,  4757,  1998,\n",
      "          2070,  4895,  8671,  2666,  3567,  6321, 26316,  5312,  1011,  1011,\n",
      "          2087, 17274,  1996,  8909,  3695,  5666,  1997,  1996,  2143,  3068,\n",
      "          1011,  1011,  2191,  2009,  3262,  4276,  1996,  4440,  1012,   102],\n",
      "        [  101,  5587,  2664,  2178,  6045,  2000,  1037, 10904,  2132,  1010,\n",
      "         18856,  7828,  3240,  1005,  1055,  1037,  2204,  2472,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2143,  1005,  1055,  6160, 21986, 21254,  4757,  1998,\n",
      "          2070,  4895,  8671,  2666,  3567,  6321, 26316,  5312,  1011,  1011,\n",
      "          2087, 17274,  1996,  8909,  3695,  5666,  1997,  1996,  2143,  3068,\n",
      "          1011,  1011,  2191,  2009,  3262,  4276,  1996,  4440,  1012,   102],\n",
      "        [  101,  5587,  2664,  2178,  6045,  2000,  1037, 10904,  2132,  1010,\n",
      "         18856,  7828,  3240,  1005,  1055,  1037,  2204,  2472,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2384, 0.7616],\n",
      "        [0.2647, 0.7353]]), 'input_ids': tensor([[  101,  1996,  2143,  1005,  1055,  6160, 21986, 21254,  4757,  1998,\n",
      "          2070,  4895,  8671,  2666,  3567,  6321, 26316,  5312,  1011,  1011,\n",
      "          2087, 17274,  1996,  8909,  3695,  5666,  1997,  1996,  2143,  3068,\n",
      "          1011,  1011,  2191,  2009,  3262,  4276,  1996,  4440,  1012,   102],\n",
      "        [  101,  5587,  2664,  2178,  6045,  2000,  1037, 10904,  2132,  1010,\n",
      "         18856,  7828,  3240,  1005,  1055,  1037,  2204,  2472,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([40, 20]), 'cls_emb': tensor([[ 0.3038,  0.1725, -0.0514,  ..., -0.1044,  0.4192,  0.3935],\n",
      "        [-0.0337,  0.1638, -0.1845,  ..., -0.5233,  0.6509,  0.4390]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  4459,  2128,  2050,  1010, 12643,  8804,  1010,  1998,  5070,\n",
      "         11205,  2377, 16192,  1005,  1055,  3423,  8125,  1010,  1998,  2043,\n",
      "          2587,  2011, 10243,  7229,  1010,  1996,  4356,  1997,  2023,  2882,\n",
      "         22360, 15417,  8530,  8840, 13112,  1999,  3492,  3493, 10906,  2003,\n",
      "          1037,  8242,  2438,  2518,  1010,  1036, 22320,  1012,   102],\n",
      "        [  101,  8076,  1005,  1055, 19176,  2594,  2836,  8847,  6702,  2062,\n",
      "          3606,  2084,  2151,  1036,  4507,  1005,  2265,  1010,  1998, 10334,\n",
      "         25247,  2037,  2219, 23956,  2166,  3431,  2323,  3422,  2070,  2303,\n",
      "          2034,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  4459,  2128,  2050,  1010, 12643,  8804,  1010,  1998,  5070,\n",
      "         11205,  2377, 16192,  1005,  1055,  3423,  8125,  1010,  1998,  2043,\n",
      "          2587,  2011, 10243,  7229,  1010,  1996,  4356,  1997,  2023,  2882,\n",
      "         22360, 15417,  8530,  8840, 13112,  1999,  3492,  3493, 10906,  2003,\n",
      "          1037,  8242,  2438,  2518,  1010,  1036, 22320,  1012,   102],\n",
      "        [  101,  8076,  1005,  1055, 19176,  2594,  2836,  8847,  6702,  2062,\n",
      "          3606,  2084,  2151,  1036,  4507,  1005,  2265,  1010,  1998, 10334,\n",
      "         25247,  2037,  2219, 23956,  2166,  3431,  2323,  3422,  2070,  2303,\n",
      "          2034,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2600, 0.7400],\n",
      "        [0.2529, 0.7471]]), 'input_ids': tensor([[  101,  4459,  2128,  2050,  1010, 12643,  8804,  1010,  1998,  5070,\n",
      "         11205,  2377, 16192,  1005,  1055,  3423,  8125,  1010,  1998,  2043,\n",
      "          2587,  2011, 10243,  7229,  1010,  1996,  4356,  1997,  2023,  2882,\n",
      "         22360, 15417,  8530,  8840, 13112,  1999,  3492,  3493, 10906,  2003,\n",
      "          1037,  8242,  2438,  2518,  1010,  1036, 22320,  1012,   102],\n",
      "        [  101,  8076,  1005,  1055, 19176,  2594,  2836,  8847,  6702,  2062,\n",
      "          3606,  2084,  2151,  1036,  4507,  1005,  2265,  1010,  1998, 10334,\n",
      "         25247,  2037,  2219, 23956,  2166,  3431,  2323,  3422,  2070,  2303,\n",
      "          2034,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'ntok': tensor([49, 33]), 'cls_emb': tensor([[ 0.2435,  0.4049,  0.1915,  ..., -0.0260,  0.6576,  0.1630],\n",
      "        [ 0.1389, -0.0930, -0.2234,  ..., -0.2572,  0.3852,  0.6752]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1999,  7245,  6132,  3512,  1010, 18350,\n",
      "          1010,  2328,  2000, 18708,  1996,  2402,  2111,  1010,  2275,  2000,\n",
      "          2019, 16655, 15683,  6050,  1997,  3509,  2283,  3769,  3616,  1998,\n",
      "          4998,  2013,  2049,  9487,  4950,  6198,  1998, 12476, 17363,  1010,\n",
      "          2009,  1005,  1055,  2055,  2004, 10990,  2004,  1037,  3103,  8022,\n",
      "          1012,   102],\n",
      "        [  101,  2096,  2009,  1005,  1055, 15958,  4658,  2000,  2963,  3494,\n",
      "          2831,  2055,  2220,  9680,  2636,  1006,  5699,  2940,  6080,  1010,\n",
      "          4385,  1012,  1007,  1010,  1996,  5377, 28789,  1997,  5099,  1011,\n",
      "          6154,  8115,  5162,  2064,  7344,  3686,  2130,  1996,  7842,  2615,\n",
      "         25929,  2102,  9501,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  2009,  1005,  1055,  1999,  7245,  6132,  3512,  1010, 18350,\n",
      "          1010,  2328,  2000, 18708,  1996,  2402,  2111,  1010,  2275,  2000,\n",
      "          2019, 16655, 15683,  6050,  1997,  3509,  2283,  3769,  3616,  1998,\n",
      "          4998,  2013,  2049,  9487,  4950,  6198,  1998, 12476, 17363,  1010,\n",
      "          2009,  1005,  1055,  2055,  2004, 10990,  2004,  1037,  3103,  8022,\n",
      "          1012,   102],\n",
      "        [  101,  2096,  2009,  1005,  1055, 15958,  4658,  2000,  2963,  3494,\n",
      "          2831,  2055,  2220,  9680,  2636,  1006,  5699,  2940,  6080,  1010,\n",
      "          4385,  1012,  1007,  1010,  1996,  5377, 28789,  1997,  5099,  1011,\n",
      "          6154,  8115,  5162,  2064,  7344,  3686,  2130,  1996,  7842,  2615,\n",
      "         25929,  2102,  9501,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2407, 0.7593],\n",
      "        [0.2532, 0.7468]]), 'input_ids': tensor([[  101,  2009,  1005,  1055,  1999,  7245,  6132,  3512,  1010, 18350,\n",
      "          1010,  2328,  2000, 18708,  1996,  2402,  2111,  1010,  2275,  2000,\n",
      "          2019, 16655, 15683,  6050,  1997,  3509,  2283,  3769,  3616,  1998,\n",
      "          4998,  2013,  2049,  9487,  4950,  6198,  1998, 12476, 17363,  1010,\n",
      "          2009,  1005,  1055,  2055,  2004, 10990,  2004,  1037,  3103,  8022,\n",
      "          1012,   102],\n",
      "        [  101,  2096,  2009,  1005,  1055, 15958,  4658,  2000,  2963,  3494,\n",
      "          2831,  2055,  2220,  9680,  2636,  1006,  5699,  2940,  6080,  1010,\n",
      "          4385,  1012,  1007,  1010,  1996,  5377, 28789,  1997,  5099,  1011,\n",
      "          6154,  8115,  5162,  2064,  7344,  3686,  2130,  1996,  7842,  2615,\n",
      "         25929,  2102,  9501,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'ntok': tensor([52, 45]), 'cls_emb': tensor([[ 0.2490,  0.1904,  0.2129,  ..., -0.1440,  0.1905,  0.5000],\n",
      "        [ 0.0691,  0.0771, -0.3303,  ..., -0.0715,  0.5742,  0.6011]])}\n",
      "encoded input is: {'input_ids': tensor([[  101, 10634,  1010, 22185,  1010,  1998,  5515, 19983,  9240,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 23680,  7856,  8953,  3240,  1005,  1055,  4569,  2000,  3422,\n",
      "          1010,  1996,  8626,  2024,  3100,  1010,  2025,  2172,  2543,  1999,\n",
      "          1996,  5896,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101, 10634,  1010, 22185,  1010,  1998,  5515, 19983,  9240,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 23680,  7856,  8953,  3240,  1005,  1055,  4569,  2000,  3422,\n",
      "          1010,  1996,  8626,  2024,  3100,  1010,  2025,  2172,  2543,  1999,\n",
      "          1996,  5896,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2733, 0.7267],\n",
      "        [0.2661, 0.7339]]), 'input_ids': tensor([[  101, 10634,  1010, 22185,  1010,  1998,  5515, 19983,  9240,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 23680,  7856,  8953,  3240,  1005,  1055,  4569,  2000,  3422,\n",
      "          1010,  1996,  8626,  2024,  3100,  1010,  2025,  2172,  2543,  1999,\n",
      "          1996,  5896,  1012,   102]]), 'ntok': tensor([11, 24]), 'cls_emb': tensor([[-0.4395,  0.1255, -0.4187,  ..., -0.3382,  0.3432,  0.1476],\n",
      "        [ 0.0365, -0.0040,  0.0493,  ..., -0.6361,  0.7852,  0.4298]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1996,  2521,  2925,  2089,  2022, 12476,  2000,  5136,  1010,\n",
      "          2021,  2013,  2558,  6987,  2000,  5609,  1997,  1996,  2540,  1010,\n",
      "          2023,  2143,  2003,  2087, 18276,  2043,  2009, 12237,  2404,  1999,\n",
      "          1996,  2627,  1012,   102],\n",
      "        [  101,  2038,  2035,  1996,  5995,  1997,  1037, 28380,  3070,  4770,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1996,  2521,  2925,  2089,  2022, 12476,  2000,  5136,  1010,\n",
      "          2021,  2013,  2558,  6987,  2000,  5609,  1997,  1996,  2540,  1010,\n",
      "          2023,  2143,  2003,  2087, 18276,  2043,  2009, 12237,  2404,  1999,\n",
      "          1996,  2627,  1012,   102],\n",
      "        [  101,  2038,  2035,  1996,  5995,  1997,  1037, 28380,  3070,  4770,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2359, 0.7641],\n",
      "        [0.2579, 0.7421]]), 'input_ids': tensor([[  101,  1996,  2521,  2925,  2089,  2022, 12476,  2000,  5136,  1010,\n",
      "          2021,  2013,  2558,  6987,  2000,  5609,  1997,  1996,  2540,  1010,\n",
      "          2023,  2143,  2003,  2087, 18276,  2043,  2009, 12237,  2404,  1999,\n",
      "          1996,  2627,  1012,   102],\n",
      "        [  101,  2038,  2035,  1996,  5995,  1997,  1037, 28380,  3070,  4770,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'ntok': tensor([34, 12]), 'cls_emb': tensor([[ 0.0030, -0.1654, -0.1700,  ..., -0.3197,  0.4051,  0.3505],\n",
      "        [-0.4592,  0.0188,  0.0238,  ..., -0.0853, -0.0223,  0.3647]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1037,  3185,  2007,  1037,  2613,  9617, 11140,  2594, 22012,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3395,  2066,  2023,  2323, 18708,  4668,  1999,  2049,\n",
      "          4378,  1025,  1996,  9066,  2515,  2025,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1037,  3185,  2007,  1037,  2613,  9617, 11140,  2594, 22012,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3395,  2066,  2023,  2323, 18708,  4668,  1999,  2049,\n",
      "          4378,  1025,  1996,  9066,  2515,  2025,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2769, 0.7231],\n",
      "        [0.2463, 0.7537]]), 'input_ids': tensor([[  101,  1037,  3185,  2007,  1037,  2613,  9617, 11140,  2594, 22012,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  3395,  2066,  2023,  2323, 18708,  4668,  1999,  2049,\n",
      "          4378,  1025,  1996,  9066,  2515,  2025,  1012,   102]]), 'ntok': tensor([12, 18]), 'cls_emb': tensor([[-0.3166, -0.5108, -0.3487,  ..., -0.6682,  0.3807,  0.3973],\n",
      "        [-0.2592,  0.2443, -0.4438,  ..., -0.2444,  0.0748,  0.9241]])}\n",
      "encoded input is: {'input_ids': tensor([[  101,  1012,  1012,  1012,  2003,  2019,  2396, 26378,  4588,  3535,\n",
      "          2012,  9855,  2011, 20072,  1047,  6806,  9496,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2559, 19774,  1010, 25567,  2664,  2729, 12155,  6826,  1999,\n",
      "          4869,  5226,  1005,  1055, 27792, 12703,  1010, 13276,  2989,  3957,\n",
      "          1037,  2836,  2008,  2071,  2025,  2022,  5301,  2588,  1012,  1005,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "encoded input after passing to cuda: {'input_ids': tensor([[  101,  1012,  1012,  1012,  2003,  2019,  2396, 26378,  4588,  3535,\n",
      "          2012,  9855,  2011, 20072,  1047,  6806,  9496,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2559, 19774,  1010, 25567,  2664,  2729, 12155,  6826,  1999,\n",
      "          4869,  5226,  1005,  1055, 27792, 12703,  1010, 13276,  2989,  3957,\n",
      "          1037,  2836,  2008,  2071,  2025,  2022,  5301,  2588,  1012,  1005,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Batched outputs are: {'probas': tensor([[0.2860, 0.7140],\n",
      "        [0.2464, 0.7536]]), 'input_ids': tensor([[  101,  1012,  1012,  1012,  2003,  2019,  2396, 26378,  4588,  3535,\n",
      "          2012,  9855,  2011, 20072,  1047,  6806,  9496,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  2559, 19774,  1010, 25567,  2664,  2729, 12155,  6826,  1999,\n",
      "          4869,  5226,  1005,  1055, 27792, 12703,  1010, 13276,  2989,  3957,\n",
      "          1037,  2836,  2008,  2071,  2025,  2022,  5301,  2588,  1012,  1005,\n",
      "           102]]), 'ntok': tensor([19, 31]), 'cls_emb': tensor([[ 0.1722, -0.0854, -0.4219,  ..., -0.1548,  0.4588,  0.2622],\n",
      "        [-0.0502, -0.0853, -0.2162,  ..., -0.4813,  0.2888,  0.7887]])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets = {'sst_dev': glue.SST2Data('validation')}\n",
    "models = {'sst_tiny': SimpleSentimentModel(\"bert-base-uncased\",cache_dir = \"/mnt/sdg/niallt/hf_models/\")}\n",
    "\n",
    "widget = notebook.LitWidget(models, datasets, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('39nlp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d44b152dbbde612076d8602bde2edf912cdc31b3ee3f21712bf40e7ec5a8c74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
